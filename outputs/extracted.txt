

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank


Published by
World Scientific Publishing Co. Pte. Ltd.
5 Toh Tuck Link, Singapore 596224
USA office:  27 Warren Street, Suite 401-402, Hackensack, NJ 07601
UK office:  57 Shelton Street, Covent Garden, London WC2H 9HE
Library of Congress Cataloging-in-Publication Data
Names: Bóna, Miklós.
Title: A walk through combinatorics : an introduction to enumeration and graph theory / 
	
Miklós Bóna (University of Florida, USA).
Description: 4th edition.  |  New Jersey : World Scientific, 2017.  | 
	
Includes bibliographical references and index.
Identifiers: LCCN 2016030119  |  ISBN 9789813148840 (hardcover : alk. paper)
Subjects: LCSH: Combinatorial analysis--Textbooks.  |  Combinatorial enumeration problems--
	
Textbooks.  |  Graph theory--Textbooks.
Classification: LCC QA164 .B66 2017  |  DDC 511/.6--dc23 
LC record available at https://lccn.loc.gov/2016030119
British Library Cataloguing-in-Publication Data
A catalogue record for this book is available from the British Library.
Copyright © 2017 by World Scientific Publishing Co. Pte. Ltd. 
All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means, 
electronic or mechanical, including photocopying, recording or any information storage and retrieval 
system now known or to be invented, without written permission from the publisher.
For photocopying of material in this volume, please pay a copying fee through the Copyright Clearance 
Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy 
is not required from the publisher.
Printed in Singapore

To Linda
To Mikike, Benny, and Vinnie

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Foreword
The subject of combinatorics is so vast that the author of a textbook faces
a diﬃcult decision as to what topics to include. There is no more-or-less
canonical corpus as in such other subjects as number theory and com-
plex variable theory. Mikl´os B´ona has succeeded admirably in blending
classic results that would be on anyone’s list for inclusion in a textbook,
a sprinkling of more advanced topics that are essential for further study
of combinatorics, and a taste of recent work bringing the reader to the
frontiers of current research. All three items are conveyed in an engag-
ing style, with many interesting examples and exercises.
A worthy fea-
ture of the book is the many exercises that come with complete solutions.
There are also numerous exercises without solutions that can be assigned for
homework.
Some relatively advanced topics covered by B´ona include permutations
with restricted cycle structure, the Matrix-Tree theorem, Ramsey theory
(going well beyond the classical Ramsey’s theorem for graphs), the prob-
abilistic method, and the M¨obius function of a partially ordered set. Any
of these topics could be a springboard for a subsequent course or read-
ing project which will further convince the student of the extraordinary
richness, variety, depth, and applicability of combinatorics. The most un-
usual topic covered by B´ona is pattern avoidance in permutations and
the connection with stack sortable permutations. This is a relatively re-
cent research area in which most of the work has been entirely elemen-
tary. An undergraduate student eager to do some original research has a
good chance of making a worthwhile contribution in the area of pattern
avoidance.
vii

viii
A Walk Through Combinatorics
I only wish that when I was a student beginning to learn combinatorics
there was a textbook available as attractive as B´ona’s. Students today are
fortunate to be able to sample the treasures available herein.
Richard Stanley
Cambridge, Massachusetts
February 6, 2002

Preface
The best way to get to know Yosemite National Park is to walk through it,
on many diﬀerent paths. In the optimal case, the gorgeous sights provide
ample compensation for our sore muscles. In this book, we intend to explain
the basics of Combinatorics while walking through its beautiful results.
Starting from our very ﬁrst chapter, we will show numerous examples of
what may be the most attractive feature of this ﬁeld: that very simple tools
can be very powerful at the same time. We will also show the other side of
the coin, that is, that sometimes totally elementary-looking problems turn
out to be unexpectedly deep, or even unknown.
This book is meant to be a textbook for an introductory combinatorics
course that can take one or two semesters. We included a very extensive list
of exercises, ranging in diﬃculty from “routine” to “worthy of independent
publication”. In each section, we included exercises that contain material
not explicitly discussed in the text before. We chose to do this to provide
instructors with some extra choices if they want to shift the emphasis of
their course.
It goes without saying that we covered the classics, that is, combinato-
rial choice problems, and graph theory. We included some more elaborate
concepts, such as Ramsey theory, the Probabilistic Method, and Pattern
Avoidance (the latter is probably a ﬁrst of its kind). While we realize that
we can only skim the surface of these areas, we believe they are interesting
enough to catch the attention of some students, even at ﬁrst sight. Most
undergraduate students enroll in at most one Combinatorics course during
their studies, therefore it is important that they see as many captivating
examples as possible. It is in this spirit that we included two new chapters
in the second edition, on Algorithms, and on Computational Complexity.
We believe that the best undergraduate students, those who will get to the
ix

x
A Walk Through Combinatorics
end of the book, should be acquainted with the extremely intriguing ques-
tions that abound in these two areas. The third edition has two challenging
new chapters, one on Block Designs and codes obtained from designs, and
the other one on counting unlabeled structures.
We wrote this book as we believe that combinatorics, researching it,
teaching it, learning it, is always fun. We hope that at the end of the walk,
readers will agree.
****
Exercises that are thought to be signiﬁcantly harder than average are
marked by one or more + signs. An exercise with a single + sign is prob-
ably at the level of a harder homework problem. The diﬃculty level of
an exercise with more than one + sign may be comparable to an indepen-
dent publication. An exercise that is thought to be signiﬁcantly easier than
average is marked by a - sign.
We listened to the readers, and added new examples where the readers
suggested. This fourth edition has about 240 new exercises. We placed
three of them at the end of each section, under the header Quick Check.
The majority of exercises are still at the end of the chapters.
We provide Supplementary Exercises without solutions at the end of
each chapter.
These typically include, but are not limited to, the easi-
est exercises in that chapter. A solution manual for the Supplementary
Exercises is available for Instructors.
Gainesville, FL
August 2016

Acknowledgments
This book has been written while I was teaching Combinatorics at the
University of Florida, and during my sabbatical at the University of Penn-
sylvania in the Fall of 2005. I am certainly indebted to the books I used in
my teaching during this time. These were “Introductory Combinatorics” by
Kenneth Bogarth, “Enumerative Combinatorics I.-II” by Richard Stanley,
“Matching Theory” by L´aszl´o Lov´asz and Michael D. Plummer, and “A
Course in Combinatorics” by J. H. van Lint and R. M. Wilson. The two
new chapters of the second edition were certainly inﬂuenced by the books of
which I learned the theory of algorithms and computation, namely “Com-
putational Complexity” by Christos Papadimitriou, “Introduction to the
Theory of Computation” by Michael Sipser, who taught me the subject in
person, “Algorithms and Complexity” by Herbert Wilf, and “Introduction
to Algorithms” by Cormen, Leiserson, Rivest and Stein. Several exercises
in the book come from my long history as a student mathematics competi-
tion participant. This includes various national and international contests,
as well as the long-term contest run by the Hungarian student journal
K ¨OMAL, and the Russian student journal Kvant.
I am grateful to my students who never stopped asking questions and
showed which part of the material needed further explanation.
Some of the presented material was part of my own research, sometimes
in collaboration.
I would like to say thanks to my co-authors, Andrew
MacLennan, Bruce Sagan, Rodica Simion, Daniel Spielman, G´eza T´oth,
and Dennis White.
I am also indebted to my former advisor, Richard
Stanley, who introduced me to the fascinating area of Pattern Avoidance,
discussed in Chapter 14.
I am deeply appreciative for the constructive suggestions of my col-
leagues Vincent Vatter, Andrew Vince, Neil White, and Aleksandr Vayner.
xi

xii
A Walk Through Combinatorics
A signiﬁcant part of the ﬁrst edition was written during the summer
of 2001, when I enjoyed the hospitality of my parents, Mikl´os and Katalin
B´ona, at the Lake Balaton in Hungary.
My gratitude is extended to Joseph Sciacca for the cover page. If you
do not know why a book entitled “A Walk Through Combinatorics” has
such a cover page, you may ﬁgure it out when reading Chapter 10.
After the publication of the ﬁrst edition in 2002, several mathemati-
cians contributed lists of typographical errors to be corrected. Particularly
extensive lists were provided by Margaret Bayer, Richard Ehrenborg, John
Hall, Hyeongkwan Ju, Sergey Kitaev, and Robert Robinson. I am thankful
for their help in making the second edition better by communicating those
lists to me, as well as for similar help from countless other contributors who
will hopefully forgive that I do not list all of them here. The second edition
was improved by a signiﬁcant list of comments by Margaret Bayer, while
the third edition was similarly helped by the remarks of Glenn Tesler. I am
indebted to Thomas Zaslavsky for numerous conversations and suggestions
that made the paperback version of the third edition better. The fourth
edition was improved by suggestions made by Steven Sam.
Most of all, I must thank my wife Linda, my ﬁrst reader, who made it
possible for me to spend long hours writing this book while she also had
her hands full. See Exercise 3 of Chapter 15 for further explanation.

Contents
Foreword
vii
Preface
ix
Acknowledgments
xi
I. Basic Methods
1.
Seven Is More Than Six. The Pigeon-Hole Principle
1
1.1
The Basic Pigeon-Hole Principle
. . . . . . . . . . . . . .
1
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
The Generalized Pigeon-Hole Principle . . . . . . . . . . .
4
Quick Chek . . . . . . . . . . . . . . . . . . . . . . . . . .
10
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
12
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
14
2.
One Step at a Time. The Method of Mathematical Induction
23
2.1
Weak Induction . . . . . . . . . . . . . . . . . . . . . . . .
23
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.2
Strong Induction . . . . . . . . . . . . . . . . . . . . . . .
29
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
30
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
33
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
35
xiii

xiv
A Walk Through Combinatorics
II. Enumerative Combinatorics
3.
There Are A Lot Of Them. Elementary Counting Problems
43
3.1
Permutations . . . . . . . . . . . . . . . . . . . . . . . . .
43
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
46
3.2
Strings over a Finite Alphabet . . . . . . . . . . . . . . . .
46
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
50
3.3
Choice Problems
. . . . . . . . . . . . . . . . . . . . . . .
50
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
53
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
58
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
60
4.
No Matter How You Slice It. The Binomial Theorem and
Related Identities
73
4.1
The Binomial Theorem . . . . . . . . . . . . . . . . . . . .
73
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
78
4.2
The Multinomial Theorem . . . . . . . . . . . . . . . . . .
78
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4.3
When the Exponent Is Not a Positive Integer . . . . . . .
81
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
83
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
87
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
90
5.
Divide and Conquer. Partitions
101
5.1
Compositions . . . . . . . . . . . . . . . . . . . . . . . . .
101
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
103
5.2
Set Partitions . . . . . . . . . . . . . . . . . . . . . . . . .
103
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
106
5.3
Integer Partitions . . . . . . . . . . . . . . . . . . . . . . .
106
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
112
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
115
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
117
6.
Not So Vicious Cycles. Cycles in Permutations
123
6.1
Cycles in Permutations . . . . . . . . . . . . . . . . . . . .
124

Contents
xv
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
130
6.2
Permutations with Restricted Cycle Structure . . . . . . .
130
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
134
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
135
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
137
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
140
7.
You Shall Not Overcount. The Sieve
147
7.1
Enumerating The Elements of Intersecting Sets . . . . . .
147
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
150
7.2
Applications of the Sieve Formula . . . . . . . . . . . . . .
150
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
154
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
155
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
156
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
157
8.
A Function Is Worth Many Numbers. Generating Functions
163
8.1
Ordinary Generating Functions . . . . . . . . . . . . . . .
163
8.1.1
Recurrence Relations and Generating Functions
.
163
8.1.2
Products of Generating Functions . . . . . . . . .
169
8.1.3
Compositions of Generating Functions . . . . . . .
176
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
180
8.2
Exponential Generating Functions
. . . . . . . . . . . . .
180
8.2.1
Recurrence Relations and Exponential Generating
Functions . . . . . . . . . . . . . . . . . . . . . . .
180
8.2.2
Products of Exponential Generating Functions . .
182
8.2.3
Compositions of Exponential Generating Functions 185
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
189
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
189
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
191
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
195
III. Graph Theory
9.
Dots and Lines. The Origins of Graph Theory
205
9.1
The Notion of Graphs. Eulerian Trails . . . . . . . . . . .
205
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
210
9.2
Hamiltonian Cycles . . . . . . . . . . . . . . . . . . . . . .
210

xvi
A Walk Through Combinatorics
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
212
9.3
Directed Graphs
. . . . . . . . . . . . . . . . . . . . . . .
213
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
215
9.4
The Notion of Isomorphisms . . . . . . . . . . . . . . . . .
216
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
218
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
219
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
222
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
225
10. Staying Connected. Trees
233
10.1
Minimally Connected Graphs . . . . . . . . . . . . . . . .
233
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
239
10.2
Minimum-weight Spanning Trees. Kruskal’s Greedy Algo-
rithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
239
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
243
10.3
Graphs and Matrices . . . . . . . . . . . . . . . . . . . . .
244
10.3.1
Adjacency Matrices of Graphs . . . . . . . . . . .
244
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
247
10.4
The Number of Spanning Trees of a Graph
. . . . . . . .
247
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
253
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
253
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
256
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
258
11. Finding A Good Match. Coloring and Matching
269
11.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . .
269
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
271
11.2
Bipartite Graphs . . . . . . . . . . . . . . . . . . . . . . .
271
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
276
11.3
Matchings in Bipartite Graphs
. . . . . . . . . . . . . . .
277
11.3.1
Bipartite Graphs with Perfect Matchings . . . . .
279
11.3.2
Stable Matchings in Bipartite Graphs . . . . . . .
283
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
285
11.4
More Than Two Colors
. . . . . . . . . . . . . . . . . . .
285
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
287
11.5
Matchings in Graphs That Are Not Bipartite . . . . . . .
287
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
291
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
291

Contents
xvii
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
293
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
295
12. Do Not Cross. Planar Graphs
301
12.1
Euler’s Theorem for Planar Graphs . . . . . . . . . . . . .
301
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
304
12.2
Polyhedra . . . . . . . . . . . . . . . . . . . . . . . . . . .
304
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
311
12.3
Coloring Maps
. . . . . . . . . . . . . . . . . . . . . . . .
311
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
313
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
314
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
315
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
317
IV. Horizons
13. Does It Clique? Ramsey Theory
321
13.1
Ramsey Theory for Finite Graphs . . . . . . . . . . . . . .
321
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
327
13.2
Generalizations of the Ramsey Theorem . . . . . . . . . .
327
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
330
13.3
Ramsey Theory in Geometry
. . . . . . . . . . . . . . . .
331
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
333
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
334
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
335
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
337
14. So Hard To Avoid. Subsequence Conditions on Permutations
343
14.1
Pattern Avoidance . . . . . . . . . . . . . . . . . . . . . .
343
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
352
14.2
Stack Sortable Permutations . . . . . . . . . . . . . . . . .
353
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
363
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
364
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
366
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
368
15. Who Knows What It Looks Like, But It Exists.
The
Probabilistic Method
381

xviii
A Walk Through Combinatorics
15.1
The Notion of Probability . . . . . . . . . . . . . . . . . .
381
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
384
15.2
Non-constructive Proofs . . . . . . . . . . . . . . . . . . .
385
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
387
15.3
Independent Events . . . . . . . . . . . . . . . . . . . . . .
387
15.3.1
The Notion of Independence and Bayes’ Theorem
387
15.3.2
More Than Two Events . . . . . . . . . . . . . . .
392
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
394
15.4
Expected Values
. . . . . . . . . . . . . . . . . . . . . . .
395
15.4.1
Linearity of Expectation
. . . . . . . . . . . . . .
396
15.4.2
Existence Proofs Using Expectation . . . . . . . .
399
15.4.3
Conditional Expectation
. . . . . . . . . . . . . .
401
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
403
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
403
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
406
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
410
16. At Least Some Order. Partial Orders and Lattices
417
16.1
The Notion of Partially Ordered Set
. . . . . . . . . . . .
417
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
423
16.2
The M¨obius Function of a Poset . . . . . . . . . . . . . . .
423
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
431
16.3
Lattices
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
431
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
438
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
438
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
440
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
443
17. As Evenly As Possible. Block Designs and Error Cor-
recting Codes
451
17.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . .
451
17.1.1
Moto-cross Races
. . . . . . . . . . . . . . . . . .
451
17.1.2
Incompatible Computer Programs . . . . . . . . .
453
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
455
17.2
Balanced Incomplete Block Designs . . . . . . . . . . . . .
456
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
458
17.3
New Designs From Old . . . . . . . . . . . . . . . . . . . .
458
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
463

Contents
xix
17.4
Existence of Certain BIBDs . . . . . . . . . . . . . . . . .
463
17.4.1
A Residual Design of a Projective Plane . . . . . .
465
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
466
17.5
Codes and Designs . . . . . . . . . . . . . . . . . . . . . .
466
17.5.1
Coding Theory . . . . . . . . . . . . . . . . . . . .
466
17.5.2
Error Correcting Codes . . . . . . . . . . . . . . .
467
17.5.3
Formal Deﬁnitions About Codes . . . . . . . . . .
468
17.5.4
Perfect Codes
. . . . . . . . . . . . . . . . . . . .
472
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
475
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
476
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
478
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
479
18. Are They Really Diﬀerent? Counting Unlabeled Structures
487
18.1
Enumeration Under Group Action
. . . . . . . . . . . . .
487
18.1.1
Introduction . . . . . . . . . . . . . . . . . . . . .
487
18.1.2
Groups . . . . . . . . . . . . . . . . . . . . . . . .
487
18.1.3
Permutation Groups . . . . . . . . . . . . . . . . .
490
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
497
18.2
Counting Unlabeled Trees . . . . . . . . . . . . . . . . . .
498
18.2.1
Counting Rooted Non-plane 1-2 Trees . . . . . . .
498
18.2.2
Counting Rooted Non-plane Trees . . . . . . . . .
501
18.2.3
Counting Unrooted Trees . . . . . . . . . . . . . .
503
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
509
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
510
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
513
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
515
19. The Sooner The Better. Combinatorial Algorithms
523
19.1
In Lieu of Deﬁnitions . . . . . . . . . . . . . . . . . . . . .
523
19.1.1
The Halting Problem . . . . . . . . . . . . . . . .
524
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
525
19.2
Sorting Algorithms . . . . . . . . . . . . . . . . . . . . . .
526
19.2.1
BubbleSort . . . . . . . . . . . . . . . . . . . . . .
526
19.2.2
MergeSort
. . . . . . . . . . . . . . . . . . . . . .
529
19.2.3
Comparing the Growth of Functions . . . . . . . .
532
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
534
19.3
Algorithms on Graphs . . . . . . . . . . . . . . . . . . . .
534

xx
A Walk Through Combinatorics
19.3.1
Minimum-cost Spanning Trees, Revisited . . . . .
534
19.3.2
Finding the Shortest Path
. . . . . . . . . . . . .
537
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
542
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
543
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
546
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
547
20. Does Many Mean More Than One? Computational Complexity
553
20.1
Turing Machines
. . . . . . . . . . . . . . . . . . . . . . .
553
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
556
20.2
Complexity Classes . . . . . . . . . . . . . . . . . . . . . .
556
20.2.1
The Class P . . . . . . . . . . . . . . . . . . . . .
556
20.2.2
The Class NP . . . . . . . . . . . . . . . . . . . .
558
20.2.3
NP-complete Problems . . . . . . . . . . . . . . .
565
20.2.4
Other Complexity Classes . . . . . . . . . . . . . .
571
Quick Check . . . . . . . . . . . . . . . . . . . . . . . . . .
574
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
574
Supplementary Exercises . . . . . . . . . . . . . . . . . . . . . .
576
Solutions to Exercises . . . . . . . . . . . . . . . . . . . . . . . .
577
Bibliography
583
Index
587

Chapter 1
Seven Is More Than Six. The
Pigeon-Hole Principle
1.1
The Basic Pigeon-Hole Principle
Seven is more than six. Four is more than three. Two is more than one.
These statements do not seem to be too interesting, exciting, or deep. We
will see, however, that the famous Pigeon-hole Principle makes excellent use
of them. We choose to start our walk through combinatorics by discussing
the Pigeon-hole Principle because it epitomizes one of the most attractive
treats of this ﬁeld: the possibility of obtaining very strong results by very
simple means.
Theorem 1.1 (Pigeon-hole Principle). Let n and k be positive inte-
gers, and let n > k.
Suppose we have to place n identical balls into k
identical boxes. Then there will be at least one box in which we place at
least two balls.
Proof. While the statement seems intuitively obvious, we are going to give
a formal proof because proofs of this nature will be used throughout this
book.
We prove our statement in an indirect way, that is, we assume its con-
trary is true, and deduce a contradiction from that assumption. This is a
very common strategy in mathematics; in fact, if we have no idea how to
prove something, we can always try an indirect proof.
Let us assume there is no box with at least two balls. Then each of
the k boxes has either 0 or 1 ball in it. Denote by m the number of boxes
that have zero balls in them; then certainly m ≥0. Then, of course, there
are k −m boxes that have one. However, that would mean that the total
number of balls placed into the k boxes is k −m which is a contradiction
1

2
A Walk Through Combinatorics
because we had to place n balls into the boxes, and k −m ≤k < n.
Therefore, our assumption that there is no box with at least two balls must
have been false.
In what follows, we will present several applications that show that this
innocuous statement is in fact a very powerful tool.
Example 1.2. There is an element in the sequence 7, 77, 777, 7777, · · · ,
that is divisible by 2003.
Solution. We prove that an even stronger statement is true, in fact, one of
the ﬁrst 2003 elements of the sequence is divisible by 2003. Let us assume
that the contrary is true. Then take the ﬁrst 2003 elements of the sequence
and divide each of them by 2003. As none of them is divisible by 2003,
they will all have a remainder that is at least 1 and at most 2002. As
there are 2003 remainders (one for each of the ﬁrst 2003 elements of the
sequence), and only 2002 possible values for these remainders, it follows by
the Pigeon-hole Principle that there are two elements out of the ﬁrst 2003
that have the same remainder. Let us say that the ith and the jth elements
of the sequence, ai and aj, have this property, and let i < j.
7777777777777777777777777
777777777777777777
7777777000000000000000000
j digits
i digits
i digits equal to 0
j-i digits equal to 7,
_
Fig. 1.1
The diﬀerence of aj and ai.
As ai and aj have the same remainder when divided by 2003, there exist
non-negative integers ki, kj, and r so that r ≤2002, and ai = 2003ki + r,
and aj = 2003kj + r.
This shows that aj −ai = 2003(kj −ki), so in
particular, aj −ai is divisible by 2003.
This is nice, but we need to show that there is an element in our sequence
that is divisible by 2003, and aj −ai is not an element in our sequence.
Figure 1.1 helps understand why the information that aj −ai is divisible
by 2003 is nevertheless very useful.
Indeed, aj −ai consists of j −i digits equal to 7, then i digits equal to

Seven Is More Than Six. The Pigeon-Hole Principle
3
0. In other words,
aj −ai = aj−i · 10i,
and the proof follows as 10i is relatively prime to 2003, so aj−i must be
divisible by 2003.
In this example, the possible values of the remainders were the boxes,
all 2002 of them, while the ﬁrst 2003 elements of the sequence played the
role of the balls. There were more balls than boxes, so the Pigeon-hole
Principle applied.
Example 1.3. A chess tournament has n participants, and any two players
play one game against each other. Then it is true that in any given point of
time, there are two players who have ﬁnished the same number of games.
Solution. First we could think that the Pigeon-hole Principle will not be
applicable here as the number of players (“balls”) is n, and the number of
possibilities for the number of games ﬁnished by any one of them (“boxes”)
is also n. Indeed, a player could ﬁnish either no games, or one game, or
two games, and so on, up to and including n −1 games.
The fact, however, that two players play their games against each other,
provides the missing piece of our proof. If there is a player A who has com-
pleted all his n −1 games, then there cannot be any player who completed
zero games because at the very least, everyone has played with A. There-
fore, the values 0 and n−1 cannot both occur among the numbers of games
ﬁnished by the players at any one time. So the number of possibilities for
these numbers (“boxes”) is at most n −1 at any given point of time, and
the proof follows.
Quick Check
(1) Prove that among eight integers, there are always two whose diﬀerence
is divisible by seven.
(2) A student wrote six distinct positive integers on the board, and pointed
out that none of them had a prime factor larger than 10. Prove that
there are two integers on the board that have a common prime divisor.
Could we make the same conclusion if in the ﬁrst sentence we replaced
”six” by ”ﬁve”?
(3) A bicycle path is 30 miles long, with four rest areas. Prove that either
there are two rest areas that are at most six miles from each other,

4
A Walk Through Combinatorics
or there is a rest area that is at most six miles away from one of the
endpoints of the path.
1.2
The Generalized Pigeon-Hole Principle
It is easy to generalize the Pigeon-hole Principle in the following way.
Theorem 1.4 (Pigeon-hole Principle, general version). Let n,
m,
and r be positive integers so that n > rm, and let us distribute n iden-
tical balls into m identical boxes. Then there will be at least one box into
which we place at least r + 1 balls.
Proof. Just as in the proof of Theorem 1.1, we assume the contrary state-
ment. Then each of the m boxes can hold at most r balls, so all the boxes
can hold at most rm < n balls, which contradicts the requirement that we
distribute n balls.
It is certainly not only in number theory that the Pigeon-hole Princi-
ple proves to be very useful. The following example provides a geometric
application.
Example 1.5. Ten points are given within a square of unit size. Then
there are two of them that are closer to each other than 0.48, and there are
three of them that can be covered by a disk of radius 0.5.
Solution. Let us split our unit square into nine equal squares by straight
lines as shown in Figure 1.2. As there are ten points given inside the nine
small squares, Theorem 1.1 implies that there will be at least one small
square containing two of our ten points.
The longest distance within a
square of side length 1/3 is that of two opposite endpoints of a diagonal.
By the Pythagorean theorem, that distance is
√
2
3 < 0.48, so the ﬁrst part
of the statement follows.
To prove the second statement, divide our square into four equal parts
by its two diagonals as shown in Figure 1.3. Theorem 1.4 then implies that
at least one of these triangles will contain three of our points. The proof
again follows as the radius of the circumcircle of these triangles is shorter
than 0.5.

Seven Is More Than Six. The Pigeon-Hole Principle
5
Fig. 1.2
Nine small squares for ten points.
Fig. 1.3
Four triangles for ten points.
We ﬁnish our discussion of the Pigeon-hole Principle by two highly sur-
prising applications. What is striking in our ﬁrst example is that it is valid
for everybody, not just say, the majority of people. So we might as well
discuss our example choosing the reader herself for its subject.

6
A Walk Through Combinatorics
Example 1.6. During the last 1000 years, the reader had an ancestor A
such that there was a person P who was an ancestor of both the father and
the mother of A.
Solution. Again, we prove our statement in an indirect way: we assume
its contrary, and deduce a contradiction. We will use some rough estimates
for the sake of shortness, but they will not make our argument any less
valid.
Take the family tree of the reader. This tree is shown in Figure 1.4.
Parents
The reader
Grandparents
Fig. 1.4
The ﬁrst few levels of the family tree of the reader.
The root of this tree is the reader herself. On the ﬁrst level of the tree,
we see the two parents of the reader, on the second level we ﬁnd her four
grandparents, and so on. Assume (for shortness) that one generation takes
25 years to produce oﬀspring. That means that 1000 years was suﬃcient
time for 40 generations to grow up, yielding 1 + 2 + 22 + · · · + 240 = 241 −1
nodes in the family tree. If any two nodes of this tree are associated to the
same person B, then we are done as B can play the role of P.
Now assume that no two nodes of the ﬁrst 40 levels of the family tree
coincide. Then all the 241 −1 nodes of the family tree must be distinct.
That would mean 241 −1 distinct people, and that is a lot more than the
number of all people who have lived in our planet during the last 1000 years.
Indeed, the current population of our planet is less than 1010, and was much
less at any earlier point of time. Therefore, the cumulative population of
the last 1000 years, or 40 generations, was less than 40 ·1010 < 241 −1, and
the proof follows by contradiction.

Seven Is More Than Six. The Pigeon-Hole Principle
7
Our assumption that every generation takes 25 years to produce oﬀ-
spring was a realistic one. Given that by all available data, the average
life expectancy of humans is longer today than ever before, 25 seems to
be a high-end estimate. The reader should spend a little time thinking
about how (and if) the argument would have to be modiﬁed if 25 were to
be replaced by a smaller or larger number.
Our last example comes from the theory of graphs, an extensive and
important area of combinatorics to which we will devote several chapters
later.
Example 1.7. Mr. and Mrs. Smith invited four couples to their home.
Some guests were friends of Mr. Smith, and some others were friends of Mrs.
Smith. When the guests arrived, people who knew each other beforehand
shook hands, those who did not know each other just greeted each other.
After all this took place, the observant Mr. Smith said “How interesting.
If you disregard me, there are no two people present who shook hands the
same number of times”.
How many times did Mrs. Smith shake hands?
Solution. The reader may well think that this question cannot be an-
swered from the given information any better than say, a question about
the age of the second cousin of Mr. Smith. However, using the Pigeon-
hole Principle and a very handy model called a graph, this question can be
answered.
To start, let us represent each person by a node, and let us write the
number of handshakes carried out by each person except Mr. Smith next to
the corresponding vertex. This way we must write down nine diﬀerent non-
negative integers. All these integers must be smaller than nine as nobody
shook hands with himself/herself or his/her spouse. So the numbers we
wrote down are between 0 and 8, and since there are nine of them, we must
have written down each of the numbers 0, 1, 2, 3, 4, 5, 6, 7, 8 exactly once.
The diagram we have constructed so far can be seen in Figure 1.5.
Now let us join two nodes by a line if the corresponding two people
shook each other’s hands. Such a diagram is called a graph, the nodes are
called the vertices of the graph, and the lines are called the edges of the
graph. So our diagram will be a graph with ten vertices.
Let us denote the person with i handshakes by Yi. (Mr. Smith is not
assigned any additional notation.) Who can be the spouse of the person
Y8? We know that Y8 did not shake the hand of only one other person,

8
A Walk Through Combinatorics
8
7
6
5
4
3
2
1
0
Mr. Smith
Fig. 1.5
The participants of the party.
so that person must have been his or her spouse. On the other hand, Y8
certainly did not shake the hand Y0 as nobody did that. Therefore, Y8 and
Y0 are married, and Y8 shook everyone’s hand except for Y0. We represent
this by joining his vertex to all vertices other than Y0. We also encircle Y8
and Y0 together, to express that they are married.
Mr. Smith
8
7
6
5
4
3
2
1
0
Fig. 1.6
Y8 and Y0 are married.
Now try to ﬁnd the spouse of Y7, the person with seven handshakes. This
person did not shake the hands of two people, one of whom was his/her

Seven Is More Than Six. The Pigeon-Hole Principle
9
spouse. Looking at Figure 1.6, we can tell who these two people are. One
of them is Y0 as he or she did not shake anyone’s hand, and the other one is
Y1 as he or she had only one handshake, and that was with Y8. As spouses
do not shake hands, this implies that the spouse of Y7 is either Y0 or Y1.
However, Y0 is married to Y8, so Y1 must be married to Y7.
8
7
6
5
4
3
2
1
0
Mr. Smith
Fig. 1.7
Y1 and Y7 are married.
By a similar argument that the reader should be able to complete, Y6
and Y2 must be married, and also, Y5 and Y3 must be married. That implies
that by exclusion, Y4 is Mrs. Smith, therefore Mrs. Smith shook hands four
times.
How did we obtain such a strong result from “almost no data”? The
truth is that the data we had, that is, that all people except Mr. Smith
shook hands a diﬀerent number of times, is quite restrictive. Indeed, con-
sider Example 1.3 again. An obvious reformulation of that Example shows
that it is simply impossible to have a party at which no two people shake
hands the same number of times (as long as no two people shake hands
more than once). Example 1.7 relaxes the “all-diﬀerent-numbers” require-
ment a little bit, by waiving it for Mr. Smith. Our argument then shows
that with that extra level of freedom, we can indeed have a party satisfying
the new, weaker conditions, but only in one way. That way is described by
the graph shown in Figure 1.8.

10
A Walk Through Combinatorics
Mr.Smith
8
7
6
5
4
3
2
1
0
Fig. 1.8
Mrs. Smith shook hands four times.
Quick Check
(1) The product of ﬁve given polynomials is a polynomial of degree 21.
Prove that we can choose two of those polynomials so that the degree
of their product is at least nine.
(2) A college has 39 departments, and a total of 261 faculty members in
those departments.
Prove that there are three departments in this
college that have a total of at least 21 faculty members.
(3) Let n be a positive integer that has exactly three prime divisors, and
at least seven divisors of the form pk, where p is a prime, and k is
a positive integer. Prove that n must be divisible by the cube of an
integer that is larger than 1.
Exercises
(1) A busy airport sees 1500 takeoﬀs per day. Prove that there are two
planes that must take oﬀwithin a minute of each other.
(2) Find all triples of positive integers a < b < c for which
1
a + 1
b + 1
c = 1
holds.

Seven Is More Than Six. The Pigeon-Hole Principle
11
(3) We have selected 169 points inside a regular triangle of side length 100
at random. Prove that there will be three among the selected points
that span a triangle of area at most 68.
(4) (+) We have distributed two hundred balls into one hundred boxes with
the restrictions that no box got more than one hundred balls, and each
box got at least one. Prove that it is possible to ﬁnd some boxes that
together contain exactly one hundred balls.
(5) (+) Last year, the Division One basketball teams played against an
average of eighteen diﬀerent opponents. Is it possible to ﬁnd a group
of teams so that each of them played against at least ten other teams
of the group?
(6)(a) The set M consists of nine positive integers, none of which has a
prime divisor larger than six. Prove that M has two elements whose
product is the square of an integer.
(b) (+) (Some knowledge of linear algebra and abstract algebra re-
quired.) The set A consists of n + 1 positive integers, none of which
has a prime divisor that is larger than the nth smallest prime num-
ber. Prove that there exists a non-empty subset B ⊆A so that the
product of the elements of B is a perfect square.
(7) (++) The set L consists of 2003 integers, none of which has a prime
divisor larger than 24. Prove that L has four elements, the product of
which is equal to the fourth power of an integer.
(8) (+) The sum of one hundred given real numbers is zero. Prove that
at least 99 of the pairwise sums of these hundred numbers are non-
negative. Is this result the best possible one?
(9) (+) We colored all points of R2 with integer coordinates by one of six
colors. Prove that there is a rectangle whose vertices are monochro-
matic. Can we make the statement stronger by limiting the size of the
purported monochromatic rectangle?
(10) Prove that among 502 positive integers, there are always two integers
so that either their sum or their diﬀerence is divisible by 1000.
(11) (+) We chose n+2 numbers from the set 1, 2, · · · , 3n. Prove that there
are always two among the chosen numbers whose diﬀerence is more
than n but less than 2n.
(12) There are four heaps of stones in our backyard. We rearrange them
into ﬁve heaps. Prove that at least two stones are placed into a smaller
heap.
(13) There are inﬁnitely many pieces of paper in a basket, and there is a
positive integer written on each of them. We know that no matter how

12
A Walk Through Combinatorics
we choose inﬁnitely many pieces, there will always be two of them so
that the diﬀerence of the numbers written on them is at most ten mil-
lion. Prove that there is an integer that has been written on inﬁnitely
many pieces of paper.
(14) (+)
(a) A soccer team played 30 games this year, and scored a total of 53
goals, scoring at least one goal in each game. Prove that there was
a sequence of consecutive games in which the team scored exactly
six goals.
(b) Prove that the claim of part (a) does not hold for a team that scored
60 goals, with the other parameters unchanged.
(c) Prove that the claim of part (a) does hold for a team that scored 59
goals, with the other parameters unchanged.
(15) (+) The set of all positive integers is partitioned into several arithmetic
progressions. Show that there is at least one among these arithmetic
progressions whose initial term is divisible by its diﬀerence.
(16) Sixty-ﬁve points are given inside a square of side length 1. Prove that
there are three of them that span a triangle of area at most 1/32.
(17) Let A be an n × n matrix with 0 and 1 entries only. Let us assume
that n ≥2, and that at least 2n entries are equal to 1. Prove that A
contains two entries equal to 1 so that one of them is strictly above and
strictly on the right of the other.
(18) A state has seven counties.
In one year, three candidates run in a
statewide election. Is it possible that in each county the same number
of people vote, and the candidate who gets the highest number of votes
statewide does not get the highest number of votes in any county?
Supplementary Exercises
(19) (-) Prove that every year contains at least four and at most ﬁve months
that contain ﬁve Sundays.
(20) (-) A soccer league features 17 games for today. Let us assume that no
team will score more than three goals. Prove that there will be a result
that will occur more than once. (A result consists of the number of
goals scored by the home team, followed by the number of goals scored
by the visiting team. So 3-2 and 2-3 are considered diﬀerent scores.)
(21) (-) A group of seven co-workers are trying to predict the total number
of points scored in a given basketball game. The ﬁrst six people al-

Seven Is More Than Six. The Pigeon-Hole Principle
13
ready took their guesses, and, curiously, they all picked distinct even
numbers. Mr. Slow is the last person to guess, and he knows all pre-
vious guesses. Is there a strategy for him that assures that his guess
will be better than the guesses of half of his colleagues?
(22) (-) A soccer team scored a total of 40 goals this season. Nine players
scored at least one of those goals. Prove that there are two players
among those nine who scored the same number of goals.
(23)(a) In the month of April, Ms. Consistent went to the swimming pool
26 times, though she never went more than once on the same day.
Is it true that there were six consecutive days when she went to the
swimming pool?
(b) Same as (a), but for the month of May instead of April.
(24)(a) We select 11 positive integers that are less than 29 at random.
Prove that there will always be two integers selected that have a
common divisor larger than 1.
(b) Is the statement of part (a) true if we only select ten integers that
are less than 29?
(25) Prove that there exists a positive integer n so that 44n −1 is divisible
by 7.
(26) The sum of ﬁve positive real numbers is 100. Prove that there are two
numbers among them whose diﬀerence is at most 10.
(27) Find all 4-tuples (a, b, c, d) of distinct positive integers so that a < b <
c < d and
1
a + 1
b + 1
c + 1
d = 1.
(28) Complete the following sentence, that is a generalization of the Pigeon-
hole Principle to real numbers. “If the sum of k real numbers is n,
then there must be one of them which is...”. Prove your claim.
(29) We are given 17 points inside a regular triangle of side length one.
Prove that there are two points among them whose distance is not
more than 1/4.
(30) Prove that the sequence 1967, 19671967, 196719671967, · · · , contains
an element that is divisible by 1969.
(31) A teacher receives a paycheck every two weeks, always the same day
of the week. Is it true that in any six consecutive calendar months she
receives exactly 13 paychecks?
(32) (+) Let T be a triangle with angles of 30, 60 and 90 degrees whose
hypotenuse is of length 1. We choose ten points inside T at random.
Prove that there will be four points among them that can be covered

14
A Walk Through Combinatorics
by a half-circle of radius 0.42.
(33) We select n + 1 diﬀerent integers from the set {1, 2, · · · , 2n}. Prove
that there will always be two among the selected integers whose largest
common divisor is 1.
(34)(a) Let n ≥2.
We select n + 1 diﬀerent integers from the set
{1, 2, · · · , 2n}. Is it true that there will always be two among the
selected integers so that one of them is equal to twice the other?
(b) Is it true that there will always be two among the selected integers
so that one is a multiple of the other?
(35) One afternoon, a mathematics library had several visitors. A librarian
noticed that it was impossible to ﬁnd three visitors so that no two of
them met in the library that afternoon. Prove that then it was possible
to ﬁnd two moments of time that afternoon so that each visitor was
in the library at one of those two moments.
(36) (+) Let r be any irrational real number. Prove that there exists a
positive integer n so that the distance of nr from the closest integer
is less than 10−10.
(37) Let p and q be two positive integers so that the largest common divisor
of p and q is 1. Prove that for any non-negative integers s ≤p −1
and t ≤q −1, there exists a non-negative integer m ≤pq so that if
we divide m by p, the remainder is s, and if we divide m by q, the
remainder is t.
(38) Does the statement of Exercise 17 remains true if we only assume that
A has at least 2n −1 entries equal to 1?
(39) (++) Let K denote the 1000 points in the three-dimensional space
whose coordinates are all integers in the interval [1, 10]. Let S be a
subset of K that has at least 272 points. Prove that S contains two
points u and v so that each coordinate of v is strictly larger than the
corresponding coordinate of u.
(40) Six points are given on the perimeter of a circle of radius 1. Prove
that there are two among the given points whose distance from each
other is at most 1.
Solutions to Exercises
(1) There are 1440 minutes per day. If our 1440 minutes are the boxes,
and our 1500 planes are the balls, the Pigeon-hole Principle says that
there are two balls in the same box, that is, there are two planes that

Seven Is More Than Six. The Pigeon-Hole Principle
15
take oﬀwithin a minute of each other.
(2) It is clear that a = 2. Indeed, a = 1 is impossible because then the
left-hand side would be larger than 1, and a ≥3 is impossible as
a < b < c implies 1
a > 1
b > 1
c, so a = 3 would imply that the left-hand
side is smaller than 1. Thus we only have to solve
1
b + 1
c = 1
2,
with 3 ≤b < c. We claim that b must take its smallest possible value,
3. Indeed, if b ≥4, then c ≥5, and so 1
b + 1
c ≤1
4 + 1
5 < 1
2. Thus b = 3,
and therefore, c = 6.
(3) Split the original regular triangle into 64 congruent triangles, by re-
peatedly using the method of midlines. Each of these small triangles
will have area 67.658. On the other hand, by the Pigeon-hole Princi-
ple, at least one of these triangles must contain at least three of the
selected points.
(4) Arrange our boxes in a line so that the ﬁrst two boxes do not have
the same number of balls in them. We can always do this unless all
boxes have two balls, in which case the statement is certainly true.
Let ai denote the number of balls in box i, for all positive integers
1 ≤i ≤100. Now look at the following sums: a1, a1 +a2, a1 +a2 +a3,
· · · , a1 +a2+· · ·+a100. If two of them yield the same remainder when
divided by 100, then take the diﬀerence of those two sums. That will
yield a sum of type ai+ai+1+· · ·+aj that is divisible by 100, is smaller
than 200, and is positive. In other words, ai + ai+1 + · · · + aj = 100,
so the total content of boxes i, i + 1, · · · , j is exactly 100 balls.
Now assume this does not happen, that is, all sums a1 + a2 + · · · +
ak yield diﬀerent remainders when divided by 100. Attach the one-
element sum a2 to our list of sums. Now we have 101 sums, so by
Theorem 1.1, two of them must have the same remainder when divided
by 100. Since we assumed this did not happen before a2 joined the list,
we know that there is a sum S on our list that has the same remainder
as a2. As we know that a1 ̸= a2, we also know that S ̸= a1, and we are
done as in the previous paragraph, since S −a2 = a1 + a3 + · · · + at =
100.
We note that this argument works in general with 2n boxes and 4n
balls. We also note that we in fact proved a stronger statement as our
chosen boxes are almost consecutive.
(5) Yes. Take a team T that played against at most nine opponents. If
there is no such team, then the group of all Division One teams has the

16
A Walk Through Combinatorics
required property, and we are done. Omit T ; we claim that this will
not decrease the average number of opponents. Indeed, as we are only
interested in the number of opponents played (and not games), we
can assume that any two teams played each other at most once. The
18-game-average means that all the m Division One teams together
played 9m games as a game involves two teams. Omitting T , we are
left with m −1 teams, who played a grand total of at least 9m −9
games. This means that the remaining teams still played at least 18
games on average against other remaining teams.
Now iterate this procedure- look for a team from the remaining group
that has only played nine games and omit it. As the number of teams
is ﬁnite, this elimination procedure has to come to an end. The only
way that can happen is that there will be a group of which we cannot
eliminate any team, that is, in which every team has played at least
ten games against the other teams of the group.
(6)(a) Each element of M can be written as 2i3j5k for some non-negative
integers i, j, k. Therefore, we can divide the elements of M into
eight classes according to the parity of their exponents i, j, k. By
the Pigeon-hole Principle, there will be two elements of M, say x
and y, that are in the same class. As the sum of two integers of
the same parity is even, this implies that x · y = 22a32b52c for some
non-negative integers a, b, c, therefore, xy = (2a3b5c)2.
(b) The n + 1 elements of A can be considered as elements of an n-
dimensional vector space over the binary ﬁeld. Let B be a linearly
dependent subset of A, then the product of all elements of B is a
perfect square since all prime factors must occur in that product
an even number of times in that product.
(7) If we try to copy the exact method of the previous problem, we may
run into diﬃculties. Indeed, the elements of L can have nine diﬀerent
prime divisors, 2, 3, 5, 7, 11, 13, 17, 19, 23. If we classify them according
to the remainder of the exponents of these prime divisors modulo four,
we get a classiﬁcation into 49 > 2003 classes. So it seems that it is
not even sure that there will be a class containing two elements of L,
let alone four.
The reason this attempt did not work is that it tried to prove too
much. For the product of four integers to be a fourth power, it is
not necessary that the exponents of each prime divisor have the same
remainder modulo four in each of the four integers.
For example,
1,1,2,8 do not have that property, but their product is 16 = 24.

Seven Is More Than Six. The Pigeon-Hole Principle
17
A more gradual approach is more successful. Let us classify the ele-
ments of L again just by the parity of the exponents of the nine pos-
sible prime divisors in them. This classiﬁcation creates just 29 = 512
classes. Now pick two elements of L that are in the same class, and
remove them from L. Put their product into a new set L′. This pro-
cedure clearly decreased the size of L by 2. Then repeat this same
procedure, that is, pick two elements of L that are in the same class,
remove them, and put their product into L′. Note that all elements
of L′ will be squares as they will contain all their prime divisors with
even exponents. Do this until you can, that is, until there are no two
elements of L in the same class. Stop when that happens. Then L
has at most 511 elements left, so we have removed at least 1492 ele-
ments from L. Therefore L′ has at least 746 elements, all of which are
squares of integers.
Now classify the elements of L′ according to the remainders of the
exponents of their prime divisors modulo four. As the elements of
L′ are all squares, all these exponents are even numbers, so their
remainders modulo four are either 0 or 2. So again, this classiﬁcation
creates only 512 classes, and therefore, there will be two elements of
L′ in the same class, say u and v. Then uv is the fourth power of an
integer, and since both u and v are products of two integers in L, our
claim is proved.
(8) First Solution: Let a1 ≤a2 ≤· · · ≤a100 denote our one hundred
numbers. We will show 99 non-negative sums. We have to distinguish
two cases, according to the sign of a50 + a99. Assume ﬁrst that a50 +
a99 ≥0. Then we have
0 ≤a50 + a99 ≤a51 + a99 ≤a52 + a99 ≤· · · ≤a100 + a99,
providing 51 non-negative sums. On the other hand, for any i so that
50 ≤i ≤100, we now have
0 ≤ai + a99 ≤ai + a100,
providing the new non-negative sums a50 + a100, a51 + a100, · · · , a98 +
a100, which is 49 new sums, so we have found 100 non-negative sums.
Now assume that a50 + a99 < 0. Then necessarily
a1 + a2 + · · · + a49 + a51 + · · · + a98 + a100 > 0.
(1.1)
In this case we claim that all sums ai + a100 are non-negative. To
see this, it suﬃces to show that the smallest of them, a1 + a100 is
non-negative. And that is true as
0 > a50 + a99 ≥a49 + a98 ≥a48 + a97 ≥· · · ≥a2 + a51,

18
A Walk Through Combinatorics
and therefore the left-hand side of (1.1) can be decomposed as the
sum of a1 + a100, and 48 negative numbers. So a1 + a100 is positive,
and the proof follows.
Second Solution: It is well known from everyday life that one can
organize a round robin tournament for 2n teams in 2n −1 rounds,
so that each round consists of n games, and that each team plays a
diﬀerent team each round. A rigorous proof of this fact can be found
in Chapter 2, Exercise 4. Now take such a round robin tournament,
and replace the teams with the numbers a1, a2, · · · , a100. So the ﬁfty
games of each round are replaced by ﬁfty pairs of type ai+aj. As each
team plays in each round, the sum of the 100 numbers, or 50 pairs,
in any given round is zero. Therefore, at least one pair must have a
non-negative sum in any given row, otherwise that row would have a
negative sum.
This result is the best possible one: if a100 = 99, and ai = −1 if
1 ≤i ≤99, then there will be exactly 99 non-negative two-element
sums.
(9) There is only a ﬁnite number of choices for the color of each point, so
there is only a ﬁnite number F of choices to color the integer points
of a 7 × 7 square. Now take a column built up from F + 1 squares of
size 7 × 7 that have the same x coordinates. (They are “above one
another”.) By the Pigeon-hole Principle, two of them must have the
very same coloring. This means that if the ﬁrst one has two points of
the same color in the ith and jth positions, then so does the second,
and a monochromatic rectangle is formed. The Pigeon-hole Principle
ensures that such i and j always exist, and the proof follows. In fact,
we also proved that there will always be a monochromatic rectangle
whose shorter side contains at most 7 points with integer coordinates.
(10) Consider the remainders of each of the given integers modulo 1000,
and the opposites of these remainders modulo 1000. Note that if an
integer is not congruent to 0 or 500 modulo 1000, then its remainder
and opposite remainder modulo 1000 are two diﬀerent integers.
We distinguish two cases. First, if at least two of our integers are
divisible by 1000, or if at least two of our integers have remainder 500
modulo 1000, then the diﬀerence and sum of these two integers are
both divisible by 1000, and we are done.
If there is at most one among our integers that is divisible by 1000,
and there is at most one among our integers that has remainder 500
modulo 1000, then we have at least 500 integers that do not fall into

Seven Is More Than Six. The Pigeon-Hole Principle
19
either category. Consider their remainders and opposite remainders
modulo 1000, altogether 1000 numbers. They cannot be equal to 0
or 500, so there are only 998 possibilities for them. Therefore, the
Pigeon-hole Principle implies that there must be two equal among
them, and the proof follows.
(11) Denote 3n −a the largest chosen number (it could be that a = 0).
Let us add a to all our chosen numbers; this clearly does not change
their pairwise diﬀerences. So now 3n is the largest chosen number.
Therefore, if any number from the interval [n + 1, 2n −1] is chosen,
we are done. Otherwise, we had to choose a total of n + 1 numbers
from the intervals [1, n] and [2n, 3n −1]. Consider the n pairs
(1, 2n); (2, 2n + 1); · · · ; (i, i + 2n −1), · · · ; (n, 3n −1).
As there are n such pairs, and we chose n + 1 integers, there is one
pair with two chosen elements. The diﬀerence of those two chosen
elements is 2n −1, and our claim is proved.
(12) Let the numbers of stones in the original four heaps be a1 ≥a2 ≥
a3 ≥a4, and let the numbers of stones in the ﬁve new heaps be
b1 ≥b2 ≥b3 ≥b4 ≥b5. Then a1 + a2 + a3 + a4 > b1 + b2 + b3 + b4.
Let k be the smallest index so that a1 + · · · + ak > b1 + · · · + bk. (It
follows from the previous sentence that there is such an index.) This
implies that ak > bk. Then the stones from the k largest old heaps
could not all go to the k largest new heaps. (Indeed, there are too
many of them.) In fact, note that a1 + · · · + ak > b1 + · · · + bk−1 + 1.
So at least two of these stones had to go to a heap with bk stones or
less, and we are done as a1 ≥· · · ≥ak > bk ≥bk+1 ≥· · · ≥b5.
(13) Assume the contrary, that is, that each positive integer appears on a
ﬁnite number of pieces only. As we have an inﬁnite number of pieces,
this means that there is an inﬁnite sequence of diﬀerent positive inte-
gers a1 < a2 < a3 < · · · so that each ai appears on at least one piece
of paper. Then the subsequence a1, a107+1, a2·107+1, a3·107+1, · · · , is
an inﬁnite set in which any two elements diﬀer by at least ten million.
As all elements of this subsequence appear on some pieces of paper,
we have reached a contradiction.
(14)(a) Let ai denote the number of goals the team scored in the ith game.
Consider the 30 numbers bi = a1 + a2 + · · · + ai for all i satisfying
1 ≤i ≤30, and the 30 numbers bi + 6 for 1 ≤i ≤30. This is a
collection of 60 numbers, each of which is a positive integer, and
none of which is larger than 53 + 6 = 59. So by the Pigeon-hole

20
A Walk Through Combinatorics
Principle, two of these numbers are equal. One of them must be
bi and the other must be bj + 6 for some j < i, since all the bi are
diﬀerent. Then the team scored exactly six goals total in games
j + 1, j + 2, · · · , i.
(b) A counterexample is given by the sequence 2, 1, 2, 2, 3, 2, repeated
four more times, for the numbers a1, a2, · · · as deﬁned in the solu-
tion of part (a). Another counterexample is given by the sequence
1, 1, 1, 1, 1, 7 repeated four more times.
(c) Let the numbers ai and bi be deﬁned as in the solution of part
(a). Let us assume that our claim does not hold. Consider the
sequence of the ten integers F = {1, 7, 13, · · · , 55}. Let B denote
the sequence b1, b2, · · · , b30.
At most ﬁve elements of F can be elements of B since no two consec-
utive elements of F can be part B. Similarly, at most ﬁve elements
of the sequence 2, 8, · · · , 56 can be part of B. The same goes for the
sequence 3, 9, · · · , 57, the seqeunce 4, 10, · · · , 58, and the sequence
5, 11, · · · , 59. Therefore, since B consists of 30 positive integers,
the largest of which is 59, the sequence of the remaining positive
integers not larger than 60, that is, the sequence 6, 12, · · · , 54 must
contain at least ﬁve elements of B. If our claim does not hold, then
6 /∈B, so the eight-element sequence S = {12, 18, · · · , 54} contains
at least ﬁve numbers bi. That means that the there are two con-
secutive elements of S that are part of B, which is a contradiction.
(15) Let a1, a2, · · · , ak be the initial terms of our k progressions, and let
d1, d2, · · · , dk be their diﬀerences. The number d1d2 · · · dk is an ele-
ment of one of these progressions, say, the ith one. Therefore, there
is a positive integer m so that
d1d2 · · · dk = ai + mdi,
d1d2 · · · dk −mdi = ai.
So ai is divisible by di. This problem had nothing to do with the
Pigeon-hole Principle. We included it to warn the reader that not all
that glitters is gold. Just because we have to prove that one of many
objects has a given property, we cannot necessarily use the Pigeon-hole
Principle.
(16) Let us cut the square into two congruent triangles using one of its
diagonals; then cut each of these triangles into 16 congruent triangles
using the method of midlines. This yields 32 congruent triangles of

Seven Is More Than Six. The Pigeon-Hole Principle
21
area 1/32 each. As we have 65 > 2 · 32 points, by the generalized
version of the Pigeon-hole principle, at least one of these 32 triangles
must contain at least three of our points.
(17) Let us call a set of entries of A a diagonal if they form the intersection
of A with a line of slope 1. There are 2n −1 such diagonals in A,
and each entry belongs to exactly one of them. (Indeed, the diagonals
are obtained as intersections of the lines y = x + a with A, where
a ∈[−(n −1), n −1] is an integer.) As there are 2n −1 diagonals and
at least 2n entries equal to 1, at least one diagonal contains at least
two entries 1, and the statement is proved.
(18) Yes. Here is an example. Let us assume that in each county, 100 people
vote. Candidate A gets 40 votes in each county. Candidate B gets 50
votes in three counties, and 10 votes in the remaining four counties,
while candidate C gets 10 votes in the ﬁrst three counties, and 50 votes
in the remaining four counties. This means that statewide, candidate
A gets 280 votes, candidate B gets 190 votes, and candidate C gets
230 votes.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 2
One Step at a Time. The Method of
Mathematical Induction
2.1
Weak Induction
Let us assume it is almost midnight, and it has not rained all day today. If,
from the fact that it does not rain on a given day, it followed that it will not
rain the following day, it would then also follow that it would never rain
again. Indeed, from the fact that it does not rain today, it would follow
that it will not rain tomorrow, from which it would follow that it will not
rain the day after tomorrow, and so on.
This simple logic leads to another very powerful tool in mathematics:
the method of mathematical induction. We can try to apply this method
any time we need to prove a statement for all natural numbers m. Our
method then has two steps.
(1) The Initial Step. Prove that the statement is true for the smallest
value of m for which it is deﬁned, usually 0 or 1.
(2) The Induction Step. Prove that from the fact that the statement is
true for n (“the induction hypothesis”), it follows that the statement
is also true for n + 1.
If we can complete both of these steps, then we will have proved our
statement for all natural values of m. Indeed, suppose not, that is, that
we have completed the two steps described above, but still there are some
positive integers for which our statement is not true. Let m + 1 be the
smallest such integer. Then m + 1 is not the smallest integer for which our
statement is deﬁned, for that would contradict the fact that we completed
the Initial Step. So our statement is deﬁned, and therefore, true, for m as
m + 1 was the smallest integer for which it was false. So our statement is
true for m, but false for m+1, which contradicts the fact that we completed
23

24
A Walk Through Combinatorics
the Induction Step. Indeed, choosing m = n in the Induction Step yields
this contradiction.
Having seen that the method of mathematical induction is a valid one,
let us survey some of its applications.
Example 2.1. For all positive integers n,
12 + 22 + · · · + m2 = m(m + 1)(2m + 1)
6
.
(2.1)
Without the method of mathematical induction, we could be in trouble
here.
The left-hand side is a sum that is not an arithmetic series or a
geometric series, so we could not use the known formulae for those series.
Moreover, the right-hand side looks slightly counter-intuitive; for example,
it is not clear how the number 6 will show up in the denominator. The
method of mathematical induction, however, solves this problem eﬀortlessly
as we will see below.
Solution. (1) The Initial Step. If m = 1, then the left-hand side is 1, and
so is the right-hand side, so the statement is true.
(2) The Induction Step. Now assume equation (2.1) is true for n, and prove
it for n + 1. The statement for n + 1 can be obtained from (2.1) by
replacing n by n + 1 and is as follows.
12 + 22 + · · · + n2 + (n + 1)2 = (n + 1)(n + 2)(2n + 3)
6
.
(2.2)
To prove (2.2) from (2.1), note that these two equations look pretty
much alike; in fact, their diﬀerence is a rather simple equation. We
are going to prove that this diﬀerence is an equation that is in fact
an identity. This is true as the diﬀerence of the two left-hand sides is
clearly (n + 1)2, while that of the two right-hand sides is
(n + 1)[(n + 2)(2n + 3) −n(2n + 1)]
6
= (n + 1)2.
Therefore, adding the true statements
12 + 22 + · · · + n2 = n(n + 1)(2n + 1)
6
and
(n + 1)2 = (n + 1)[(n + 2)(2n + 3) −n(2n + 1)]
6
we get that
12 + 22 + · · · + n2 + (n + 1)2 = (n + 1)(n + 2)(2n + 3)
6
.
Therefore, the statement holds for all positive integers m.

One Step at a Time. The Method of Mathematical Induction
25
The previous example shows the one serious advantage and one serious
disadvantage of the method of mathematical induction.
The advantage
is that instead of having to prove a general statement, we only have to
prove two speciﬁc statements. That is, ﬁrst, we have to complete the initial
step, which is usually easy as the substitution m = 0 or m = 1 usually
simpliﬁes the expressions at hand signiﬁcantly. Then we have to complete
the induction step which only involves proving the statement for n + 1
assuming that it is true for n, which is again usually easier than proving
the statement for n + 1 without the induction hypothesis.
The drawback will become more apparent after the next example.
Example 2.2. Let f(m) be the maximum number of domains into which
m straight lines can divide the plane. Then for all positive integers m, the
equality f(m) = m(m+1)
2
+ 1 holds.
It is clear that one straight line always divides the plane into two do-
mains, so f(1) = 2, and the initial step is complete. The reader can easily
verify that the constructions below are optimal for m = 2 and m = 3, and
therefore f(2) = 4, and f(3) = 7. This step is not a necessary part of our
induction proof, but it helps the reader visualize the problem.
Fig. 2.1
Optimal constructions for m = 2 and m = 3.
Now let us assume the statement is true for an integer n, and let us
prove that it is true for n + 1. Let s be one of our n + 1 straight lines; we
may think of s as the straight line we added to our picture last. Then s
intersects at most n other straight lines, since there are only n other lines
in the picture. Denote by t1, t2, · · · , tk the straight lines that s crosses, in
the order it crosses them, in some order. As we said, k ≤n since there are
n + 1 lines altogether. This means that s passes through k + 1 diﬀerent
domains formed by the other n lines, and cuts each of them into two new

26
A Walk Through Combinatorics
domains.
Indeed, s cuts through a domain before crossing each ti, and
after crossing tk. In other words, s increases the number of domains by
k + 1 ≤n+ 1. Therefore, we have just proved that f(n+ 1) ≤f(n)+ n+ 1,
and equality occurs if and only if s does intersect all the other n lines. Thus
f(n + 1) = f(n) + n + 1. However, the induction hypothesis claims that
f(n) = n(n+1)
2
+ 1. Therefore,
f(n + 1) = f(n) + n + 1 = n(n + 1)
2
+ 1 + n + 1 = (n + 1)(n + 2)
2
+ 1,
completing the proof.
This proof was possible because we were given a formula for f(m) to
prove, just as we were given a formula to prove for the sum of squares in
the previous example. Had we been not given these formulae beforehand,
ﬁrst we would have had to guess them, then we could have proved them
by the method of mathematical induction. This is the disadvantage of the
inductive method we were referring to. However, this guessing is not always
hard to do, as the following example shows.
Example 2.3. Let a0 = 1, and let an+1 = 3an + 1, for all positive integers
n ≥1. Find an explicit formula for am.
We will learn techniques that enable us to solve problems like this with-
out any guessing. For now, however, let us compute the ﬁrst few values of
the sequence. We get that they are 1, 4, 13, 40, 121. It is easy to conjec-
ture that am = (3m −1)/2. Now we are going to prove our statement by
induction. For m = 1, the statement is trivially true. Now assume that the
statement holds for n. Then
an+1 = 3an + 1 = 3 · (3n −1)
2
+ 1 = 3n+1 −1
2
,
so the statement also holds for n + 1, and the proof follows.
We point out that the formula an+1 = 3an + 1 in Example 2.3 is called
a recurrence relation, since it provides a way to compute the value of an
element of a sequence from another element of that sequence. The formula
an+1 =
3n+1−1
2
is called an explicit formula since it provides a way to
compute an+1 directly, without computing other elements of the sequence
{ai} ﬁrst. It is also called a closed formula because it does not contain a 
or  sign. Even more precisely, a closed formula can contain the sum or
product of a ﬁxed number of parts, but not the sum or product of a changing
number of parts.
The formulas f(n) = n
i=1 i and f(n) = (n + 1)n/2
are both explicit, but the former is not closed, while the latter is closed.

One Step at a Time. The Method of Mathematical Induction
27
Induction is often a good way to turn a recurrence relation into an explicit
formula, or to turn an explicit, but not closed formula into a closed formula.
Remark. Readers should have a basic understanding of the method of
mathematical induction by now, and probably noticed that at the end of
the induction proofs, we always choose m = n. Therefore, we will no longer
use diﬀerent variables for m and n.
For our purposes, a ﬁnite set is a ﬁnite unordered collection of diﬀerent
objects. That is, {1, 3, 2} and {2, 1, 3} are the same as sets, because they
only diﬀer in the order of their elements, and as we said, sets are unordered
structures. If an element is allowed to appear more than one time in a
collection, such as the element 1 in the collection (1, 1, 2, 3), then that
collection is called a multiset. We say that the set B is a subset of the set
A, denoted B ⊆A, if each element of B is also an element of A. In this
case it is clear that B has at most as many elements as A.
In combinatorial enumeration, the most important property of a set is
the number of its elements. Usually, if a statement of enumerative combi-
natorial nature is true for one set of size n, then it is true for all sets of
size n. Therefore, it is permissible, and certainly convenient, to use one
example of n-element sets for most of our discussion: that of the ﬁrst n
positive integers, that is, the set {1, 2, 3, · · · , n}. As this set will be our
canonical example, we introduce the notation [n] = {1, 2, 3, · · · , n} for this
set.
Theorem 2.4. For all positive integers n, the number of all subsets of [n]
is 2n.
Proof. For n = 1, the statement is true as [1] has two subsets, the empty
set, and {1}.
Now assume we know the statement for n, and prove it for n + 1. We
divide the subsets of [n + 1] into two classes: there will be those subsets
that do not contain the element n + 1, and there will be those that do.
Those that do not contain n + 1 are also subsets of [n], so by the induction
hypothesis, their number is 2n. Those that contain n+1 consist of n+1 and
a subset of [n], however, that subset of [n] can be any of the 2n subsets of
[n], so the number of these subsets of [n+1] is once more 2n. So altogether,
[n + 1] has 2n + 2n = 2n+1 subsets, and the theorem is proved.
With all its strength, the method of induction can also be dangerous
if not applied carefully. One common pitfall is to omit a careful proof of

28
A Walk Through Combinatorics
the Initial Step, then “prove” a faulty statement by a correct Induction
Step. For example, we could “prove” the faulty statement that all positive
integers of the form 2n+1 are divisible by 2, if we could start the induction
somewhere, that is, if we could ﬁnd just one positive integer n for which
this property holds.
The Induction Step would be easy to complete as
2(n + 1) + 1 −(2n + 1) = (2n + 1) + 2 −(2n + 1) = 2 is certainly divisible
by 2, the Initial Step, however, cannot be completed.
The following provides an example of a much more subtle fallacy.
We claim that all horses have the same color. As the number of all
horses in the world is certainly ﬁnite, we can restate our claim as follows.
For any positive integer n, any n horses always have the same color. And
here is our “proof” by induction. For n = 1, the statement is obviously
true: any one horse has the same color as itself. Now suppose that the
statement is true for n, and prove it for n + 1. Take n + 1 horses, and line
them up. Then the ﬁrst n horses must have the same color, say black, by
the induction hypothesis, but the last n horses also must have the same
color, by the same induction hypothesis, so they too must be black as we
already have seen that all the ﬁrst n horses were black, and that included
the second, third, fourth,· · · , nth horses, which are also included among
the last n horses. Therefore, all n + 1 horses are black.
It is not so easy to catch the faulty step in this argument because this
argument would indeed work for all values of n, except for n = 1. When,
however, we want to apply this argument to prove that the statement holds
for two horses using the fact that it holds for one horse, we encounter
insurmountable diﬃculties. The reason for this is simple: in this case the
“ﬁrst n horses” simply means the ﬁrst horse, while the “last n horses”
means the last horse. These two sets have no intersection, so nothing forces
the color of the horse in the ﬁrst set to be the same as that of the horse in
the second one!
This shows that we must be careful that our Induction Step is correct
for all values of n at least as large as the value used in the Initial Step.
Our argument proves that if any two horses did have the same color,
then all horses would have the same color, but that result would be a horse
of a diﬀerent color.
Quick Check
(1) Use induction to prove that if an = 1+2+· · ·+n, then an = n(n+1)/2,
for all positive integers n.

One Step at a Time. The Method of Mathematical Induction
29
(2) Let a0 = 1, and let an+1 = 4an+1 for all nonnegative integers n. Prove
that for all nonnegative integers n, the equality
an = 4n+1 −1
3
holds.
(3) Prove that for all positive integers n, the equality
1 + 2q + 3q2 + · · · + nqn−1 = 1 −qn+1
(1 −q)2 −(n + 1) qn
1 −q
holds for all complex numbers q ̸= 1.
2.2
Strong Induction
Example 2.5. Let the sequence {an} be deﬁned by the relations a0 = 0,
and an+1 = a0 + a1 + a2 + · · · + an + n + 1 if n ≥0. Prove that for all
positive integers n, the equality an = 2n −1 holds.
Here we certainly could not hope to prove our statement by our usual
way of induction.
Indeed, an+1 depends not only on an, but also on
an−1, an−2, · · · , a1, so simply using the fact that an−1 = 2n−1 −1 cannot
be suﬃcient.
Solution. (of Example 2.5) As a0 = 0, the initial case is true. Now let us
assume that we know that the statement is true for all positive integers less
than or equal to n. Then, by our recurrence relation,
an+1 = a0 + · · · + an + n + 1 = (20 −1) + · · · + (2n −1) + n + 1
1 + 2 + 4 + · · · + 2n = 2n+1 −1.
This shows that our explicit formula is correct for n + 1, and the proof is
complete.
Note that if we remove a0 from our sequence {an}, we get a geometric
series.
Let us review the steps of this strong induction algorithm.
(1) The Initial Step. Prove that the statement is true for the smallest value
of n for which it is deﬁned, usually 0 or 1.
(2) The Induction Step. Prove that from the fact that the statement is true
for all integers less than n + 1 (“the induction hypothesis”), it follows
that the statement is also true for n + 1.

30
A Walk Through Combinatorics
Just as in the case of weak induction, if we can complete both of these
steps, then we will have proved our statement for all natural numbers n.
Indeed, suppose not, that is, that we have completed the two steps described
above, but still there are some positive integers for which our statement
is not true. Let n + 1 be the smallest such integer. Then n + 1 is not
the smallest integer for which our statement is deﬁned, for that would
contradict the fact that we completed the Initial Step. So our statement is
deﬁned, and therefore, true, for all integers less than or equal to n, because
n + 1 was the smallest integer for which it was false. So our statement
is true for all integers less than or equal to n, but false for n + 1, which
contradicts the fact that we completed the Induction Step.
Let us see one more application of the strong induction algorithm. For
the rest of this book, denote N the set of natural numbers, that is, the set
of non-negative integers.
Example 2.6. Let f(0) = 1, let f(1) = 2, and let f(n + 1) = f(n −1) +
2f(n) if n ≥1. Prove that then f(n) ≤3n for all n ∈N.
Solution. It follows from the conditions that the statement is true for
n = 0 and n = 1. Now let us assume that the statement is true for all non-
negative integers that are less than or equal to n, and prove it for n + 1.
For n ≥1, we have
f(n + 1) = f(n −1) + 2f(n)
≤3n−1 + 2 · 3n
= 7 · 3n−1
< 3n+1,
and our induction proof is complete. Note that we have used the induction
hypothesis when passing from the ﬁrst line to the second. Also note that
we did need the strong induction hypothesis in that we needed the both
inequalities f(n −1) ≤3n−1 and f(n) ≤3n in order to complete that step.
Quick Check
(1) Let a0 = 1, and let a1 = 2, and let an = 2an−2 + an−1 for n ≥2. Find
and prove an explicit formula for an.
(2) A child walks up a staircase, moving up one, two, or three stairs with
each step. Let a0 be the number of ways in which the child can get to

One Step at a Time. The Method of Mathematical Induction
31
the nth stair. So a0 = a1 = 1, a2 = 2, and a3 = 4. Prove that for all
positive integers n, the inequality an ≤2n−1 holds.
(3) Let a0 = 1, and let
an = 3 (a0 + a1 + · · · + an−1) + 1
for n > 0. Compute the ﬁrst few values of an, then conjecture an ex-
plicit formula for an, and then prove that formula by strong induction.
Notes
It is sometimes convenient to shift the parameters in an induction proof.
This means that the Induction Step involves assuming the statement for
n −1, and proving it for n (in the weak case), or assuming the statement
for all integers less than n, and proving it for n. It can also happen that
we want to prove some property of even integers, or odd integers, in which
case we would have to adjust our Induction Step accordingly. We will see
some of these variations of the method of mathematical induction in the
upcoming chapters of this book.
Exercises
(1) (+) Let p(k) be a polynomial of degree d. Prove that q(n) = n
k=1 p(k)
is a polynomial of degree d + 1. Prove that this polynomial q satisﬁes
q(0) = 0.
(2) At a tennis tournament, every two players played against each other ex-
actly one time. After all games were over, each player listed the names
of those he defeated, and the names of those defeated by someone he
defeated. Prove that at least one player listed the names of everybody
else.
(3) At a tennis tournament, there were 2n participants, and any two of
them played against each other exactly one time. Prove that we can
ﬁnd n+ 1 players that can form a line in which everybody has defeated
all the players who are behind him in the line.
(4) Prove that for all positive integers n, it is possible to organize a round
robin tournament of n football teams in
(a) n −1 rounds if n is even,
(b) n rounds if n is odd.
A round is a set of games in which each team plays one opponent if
n is even, and there is only one idle team if n is odd. A round-robin

32
A Walk Through Combinatorics
tournament is a tournament in which any pair of teams meet exactly
once.
(5) Let a0 = 1, and let an+1 = 3an + 2, for all non-negative integers n.
Prove that an = 2 · 3n −1.
(6) Let a0 = 1, and let an+1 = 4an −1, for all non-negative integers n.
Prove that an = 2·4n+1
3
.
(7) Let a0 = 1, and let an+1 = 2 n
i=0 ai for all non-negative integers n.
Find an explicit formula for an.
(8) There are n patients waiting in a doctor’s oﬃce. Each of them took a
number, from 1 to n. The patients are told that they will not necessarily
be called in the order their numbers would indicate, but nobody will
be preceded by more patients than he would be if the order of their
numbers were strictly respected. That is, the patient holding number
i will be preceded by at most i −1 patients.
When Mr. Jones heard this, he said, “This is just the same as respecting
the order of the numbers.” Was he right?
(9) Prove that for all natural numbers n, the number a(n) = n3 + 11n is
divisible by 6.
(10) Prove that 3n > n4 if n ≥8.
(11) Prove that if n is a positive integer, then 8n −14n + 27 is divisible by
7.
(12) We cut a square into four smaller squares, then we cut some of the
obtained small squares into four smaller squares, and so on. Prove that
at any given point of time during this operation, the number of all
squares we have is of the form 3m + 1.
(13) (Some calculus required.) Recall that n! = 1 · 2 · · · · · n. Prove that for
all positive integers n, the inequality n! > nn
3n holds.
(14) Prove that there exists a positive integer N so that if n > N, then the
inequality
n! <
nn
(2.5)n
holds.
(15) (+) Give an induction proof for the inequality between the geometric
and the arithmetic mean, that is, prove that if a1, a2, · · · , an are non-
negative numbers, then
n√a1a2 · · · an ≤a1 + a2 + · · · + an
n
.
(2.3)
(16) (+) Give an induction proof for the inequality between the harmonic
mean and the geometric mean, that is, prove that if a1, a2, · · · , an are

One Step at a Time. The Method of Mathematical Induction
33
positive real numbers, then
n
1
a1 +
1
a2 + · · · +
1
an
≤
n√a1a2 · · · an.
(17)(a) Let m ≥2, let n ≥2, and let A be an m × n matrix whose entries
are all 0 or 1.
Let us assume that at least m + n −1 of these
entries is a 1. Prove that there are three entries 1 in A that form a
(possibly reﬂected or rotated) copy of the letter L. In other words, it
is possible to choose an index i and an index j so that the intersection
of the ith row and jth column of A is a 1, and both the ith row and
the jth column of A contain at least one more 1.
(b) Does the statement of part (a) remain true if we only assume that
A contains at least m + n −2 entries 1?
Supplementary Exercises
(18) (-) Prove that for all positive integers n, we have
1 + 3 + · · · + (2n −1) = n2.
(19) (-) Let n be a positive integer. Prove that it is possible to cut up a
cube into 7n + 1 smaller cubes.
(20) (-) Let a1 = 3, and let an = a1 · a2 · · · · · an−1 + 2 for n ≥2. Prove
that an = 2n + 1.
(21) (-) Prove that
1 · 2 + 2 · 3 + · · · + (n −1)n = (n −1)n(n + 1)
3
.
(22) (-) Prove by induction that the sum of the angles of a convex n-gon
is (n −2)180 degrees.
(23) Prove that for all positive integers n,
13 + 23 + · · · + n3 = (1 + 2 + · · · + n)2.
(2.4)
(24) Prove that for all positive integers n,
2(1 + 2 + · · · + n)4 = (15 + 25 + · · · + n5) + (17 + 27 + · · · + n7).
(25) Find a closed formula (no summation signs) for the expression
n
i=0 qi.
(26) (+) Find a closed formula (no summation signs) for the expression
n
i=1 iqi−1.

34
A Walk Through Combinatorics
(27) Let a0 = 1, and let an+1 = 10an −1. Prove that for all n ≥1, the
equality an = (8 · 10n + 1)/9 holds.
(28) Let a0 = 1, and let an+1 = 10an −3. Find an explicit formula for an.
(29) Let a0 = 3, and let an+1 = √an + 7 if n > 0. Prove that 3 < an < 4
for all n > 0.
(30) Let a0 = 0, a1 = 1, and let an+2 = 6an+1 −9an for n ≥0. Prove that
an = n · 3n−1 for all n ≥0.
(31) Let a1 = 1, and let an+1 = 3an + 4 for n ≥1. Prove that for all
positive integers n, the inequality an ≤3n holds.
(32) Let a0 = a1 = 1, and let an+2 = an+1 + 5an for n ≥0. Prove that
an ≤3n for all n ≥0.
(33) Let H be a ten-element set of two-digit positive integers. Prove that
H has two disjoint subsets A and B so that the sum of the elements
of A is equal to the sum of the elements of B.
(34) Prove that a positive integer is divisible by 3 if and only if the sum of
its digits is divisible by 3.
(35) Let a1, a2, · · · , an be the digits of a positive integer m, from left to
right. Prove that m is divisible by 11 if and only if a1 −a2 +a3 −· · ·+
(−1)n−1an is divisible by 11.
(36) Let a1 = 5, and let an+1 = a2
n. Prove that the last n digits of an are
the same as the last n digits of an+1.
(37) Prove that for any positive integer n, it is possible to partition any
triangle T into 3n + 1 similar triangles.
(38)(a) Let n > 14 be an integer. Prove that a square can be partitioned
into n smaller squares.
(b) Let n > 5 be an integer. Prove that a square can be partitioned
into n smaller squares.
(39) Prove that if n ≥2 is an integer, then n can be written as a product
of primes.
(40) Deﬁne a function μ on the set of non-negative integers as follows. Let
μ(1) = 1, and let μ(n) = 0 if n > 1 and n is divisible by the square
of an integer a > 1. Otherwise, if n = p1p2 · · · pk, where the pi are all
distinct primes, then let μ(n) = (−1)k. Use induction to prove that
for all positive integers m > 1,
Zn =

d|n
μ(d) = 0.
The summation is taken over all positive divisors d of n. (This is what
d|n denotes.)

One Step at a Time. The Method of Mathematical Induction
35
Solutions to Exercises
(1) We prove the statement by strong induction on d. If d = 0, then p
is a constant polynomial, say p = c. Then n
i=1 p(i) = nc, and the
statement is true.
Now let us assume that we know the statement for all polynomials of
degree less than d, and let p be a polynomial of degree d. First we claim
that it suﬃces to prove our statement for the polynomial p(d) = nd.
Let a0, a1, · · · , ad be real numbers, with ad ̸= 0. Then the statement
is true for the polynomial nd if and only if it is true for the polynomial
adnd. Moreover, the statement is true for the polynomial adnd if and
only if it is true for the polynomial h(n) = adnd + ad−1nd−1 + · · · +
a1d + a0. Indeed, r(n) = ad−1nd−1 + · · · + a1d + a0 is a polynomial of
degree d −1, so the induction hypothesis implies that n
i=1 r(i) is a
polynomial of n of degree at most d. Therefore,
n

i=1
h(i) −
n

i=1
adid =
n

i=1
r(i)
is a polynomial of degree at most d.
To prove that the statement is true for nd, it suﬃces to show that there
exists a polynomial z(n) of degree d + 1 so that z(n + 1) −z(n) = nd
for all positive integers n, and z(0) = 0. That will imply that
1d + 2d + · · · + nd = (z(1) −z(0)) + · · · + (z(n + 1) −z(n))
= z(n + 1) −z(0)
= z(n + 1).
Finally, in order to prove that such a polynomial z(n) exists, let us
recall that (n + 1)d+1 −nd+1 is a polynomial of degree d. This is not
exactly what we want, that is, the polynomial nd. However, using the
induction hypothesis just as we did in the previous paragraph, it is
easy to show that this implies the existence of z(n).
(2) First solution. We claim that the winner of the tournament (or any
winner, if there is a tie at the top) always lists the names of everyone
else. Indeed, suppose W is a winner of the tournament, that is, he
won k games, and nobody won more than k games. Now assume there
is a player P whose name W did not list. That means that P defeated
W, and P also defeated all the k players W defeated. So P won at
least k + 1 games, which is a contradiction.
Second solution.
Induction on n, the number of players at the
tournament.
If n = 2, the statement is true, for the player who

36
A Walk Through Combinatorics
won the sole game lists the name of his opponent. Now assume the
statement is true for n, and take a tournament with n + 1 players.
Call the player with the smallest number of victories A. (If there is a
tie at the bottom, any player from that tie will do.) If we temporarily
disregard A, we have n players left, so by the induction hypothesis
there will be one of them, say B, who will list the names of the other
n−1 players. Now if B defeated A, or if anyone defeated by B defeated
A, then B lists the name of A, too, and we are done. If not, then A
has defeated B, and all the players defeated by B, so A won more
games than B, a contradiction.
(3) Induction on n. For n = 1, the statement is trivially true. Now assume
the statement is true for n and prove it for n + 1. The winner X of a
tournament with 2n+1 games must have won at least 2n games (why?).
Take X, and 2n people he defeated. By the induction hypothesis, we
can ﬁnd n + 1 people among the 2n people defeated by X who can
form a line with the required property. Then we put X to the front
of this line and we have obtained a line of length n + 2 that has the
required property.
(4) We are going to prove the statement by strong induction on n. For
n = 1, 2, the statement is trivially true. Now assume that we know
the statement for all positive integers less than n + 1, and prove it for
n + 1.
First, we claim that we can assume that n + 1 is even. Indeed, if
n + 1 is odd, then we can add one more player to the tournament,
and have an even number of players. Once we have our round robin
tournament, we can simply take away the extra player, and say that
his opponent has a bye in each round.
Thus n + 1 is even. We distinguish two cases.
• First assume that n+1 = 4k. Let us split our group of players into
two groups of size 2k each. Have both groups play a round-robin
tournament. By the induction hypothesis, that is possible in 2k−1
rounds. Then denote the players in the two groups a1, a2, · · · , a2k
and b1, b2, · · · , b2k. Have them play 2k rounds as follows. In the
ﬁrst round, ai plays bi. In the second round ai plays bi+1, modulo
2k, that is, a2k plays b1. Continue this way, in round j, ai will
play bi+j. This completes a round robin tournament in 4k −1 = n
rounds, as claimed.
• If n + 1 = 4k + 2, then again split the group of players into two

One Step at a Time. The Method of Mathematical Induction
37
groups of size 2k +1 each. Proceed as before, except that when the
groups play their tournaments, there will be an idle player in each
of them, in each round. Have those two play each other.
(5) The statement is true for n = 0. Now assume it is true for n, and
prove it for n + 1. We know that an+1 = 3an + 2. By our induction
hypothesis, we have an = 2 · 3n −1. Substituting this for an, we get
an+1 = 3 · (2 · 3n −1) + 2 = 2 · 3n+1 −3 + 2 = 2 · 3n+1 −1, and the
statement is proved.
(6) The statement is true for n = 0. Now assume it is true for n, and
prove it for n + 1. We know that an+1 = 4an −1. By our induction
hypothesis, an = 2·4n+1
3
. Substituting this for an, we get
an+1 = 4 · 2 · 4n + 1
3
−1 = 2 · 4n+1 + 4
3
−1 = 2 · 4n+1 + 1
3
,
which was to be proved.
(7) Computing the ﬁrst few elements, we ﬁnd that a0 = 1, a1 = 2, a2 = 6,
a3 = 18, a4 = 54, and so on. This seems to suggest that an = 2 · 3n−1
if n ≥1. We prove this by strong induction on n. The initial case is
true. Now assume we know the statement for all positive integers less
than or equal to n. Then, by our recurrence relation,
an+1 = 2a0 + 2a1 + · · · + 2an
= 2 + 2(2 + 6 + · · · + 2 · 3n−1)
= 2 + 4 · 3n −1
2
= 2 · 3n.
This proves that our explicit formula is correct for n+1, and the proof
is complete.
(8) Yes, he was. Let us identify the patients by their numbers, and let
f(i) be the function that tells when patient i is called.
Then we
have to prove that the only one-to-one function f : {1, 2, · · · , n} →
{1, 2, · · · , n} that satisﬁes f(i) ≤i for all i is the identity function.
(That is, the function deﬁned by f(i) = i for all i.) Note that a one-
to-one function between two sets of the same size is necessarily onto.
A function that is both one-to-one and onto is called a bijection. We
will use bijections often in later chapters. We will then explain these
words, though we suspect you heard them before.
We prove our statement by induction on n. The statement is obviously
true for n = 1. Now assume we know that the statement is true for

38
A Walk Through Combinatorics
n, and prove it for n + 1. Let f : {1, 2, · · · , n + 1} →{1, 2, · · · , n + 1}
be a bijection that satisﬁes f(i) ≤i for all i. Then we must have
f(n + 1) = n + 1. Indeed, there has to be an i so that f(i) = n + 1,
and if this i is not n + 1, then the condition f(i) ≤i is violated. So
f(n + 1) = n + 1. This means that f maps the set {1, 2, · · · , n} onto
the set {1, 2, · · · , n}, and of course, satisﬁes f(i) ≤i. However, the
induction hypothesis then says that f(i) = i for all i ≤n, and the
statement follows.
(9) As a(0) = 0, the initial step is complete. Now assume we know that
the statement is true for n, and prove it for n + 1. As a(n) is divisible
by six, it suﬃces to show that a(n + 1) −a(n) is divisible by six, and
that will prove that so is a(n + 1). Indeed,
a(n + 1) −a(n) = (n + 1)3 + 11(n + 1) −n3 −11n
= 3n2 + 3n + 1 + 11
= 3(n2 + n + 4),
and the statement follows as n2 + n is always an even number.
(10) The statement is true for n = 8. Indeed, 38 = 94 > 84. This will be
our initial step. Now assume that we know that the statement is true
for n (where n ≥8). We then have to prove that bn+1 =
3n+1
(n+1)4 > 1.
We know that bn > 1, and that
bn+1 = bn · 3 ·

n
n + 1
4
.
Therefore, to show that bn+1 > 1, it suﬃces to show that (
n
n+1)4 > 1
3
when n ≥8. As (
n
n+1)4 = (1−
1
n+1)4 obviously grows when n grows, it
suﬃces to show that this holds when n = 8. Indeed,
 8
9
4 = 0.624 > 1
3.
(11) Let an = 8n −14n + 27. Then a1 = 21 is divisible by seven. Now
assume the statement is true for n, and prove it for n+1. To do that, it
suﬃces to show that an+1−an is divisible by seven. One veriﬁes easily
that an+1 −an = 8n+1 −14(n+1)−8n −14n = 7·8n −14 = 7(8n −2),
which is always divisible by seven.
(12) We prove the statement by induction on the number n of squares that
have been cut up. When n = 0, then we have one square, and the
statement is true. Now assume the statement is true for n, and prove
it for n + 1. At step n + 1, we cut up one additional square. This
increases the number of all squares by three, so if that number was
of the form 3m + 1, now it is of the form 3m + 4 = 3(m + 1) + 1.
This proves our claim. A little additional thought shows that in fact,
n = m, that is, after we cut up n squares, we have 3n + 1 squares.

One Step at a Time. The Method of Mathematical Induction
39
(13) Let an =
n!
(n/3)n . We have to prove that an > 1. If n = 1, then we
have a1 = 3, and the statement is true. Assume the statement is true
for n. To prove it for n + 1, we show that an+1/an > 1. Indeed,
an+1
an
= 3n+1 · (n + 1)!
(n + 1)n+1
·
nn
3n · n! = 3 ·

n
n + 1
n
.
It is a well-known fact in Calculus that the sequence
	
n
n+1

n
is de-
creasing and converges to 1/e. In particular, it is always larger than
1/e, let alone 1/3, and our statement is proved.
(14) Let bn =
n!
(n/2.5)n . Then we compute
bn+1
bn
= 2.5n+1 · (n + 1)!
(n + 1)n+1
·
nn
2.5n · n! = 2.5 ·

n
n + 1
n
.
As the sequence cn = (
n
n+1)n is decreasing, the ratio bn+1
bn
= 2.5cn
is decreasing with n. Moreover, cn →1/e, so there exists an integer
m such that if n > m, then bn+1
bn
< 2.5
2.6. As ( 2.5
2.6)n converges to 0, it
follows that eventually, we will have an N so that bN < 1, and the
proof follows by induction.
(15) We prove the statement by induction on n. For n = 1, the statement
is trivially true. Now assume we know that the statement is true for
all integers less than n, and prove it for n.
Assume ﬁrst that n is even, say n = 2k. Then apply this same in-
equality for the numbers a1, · · · , ak and ak+1, · · · , a2k. As k < n, we
know by the induction hypothesis that for both sets of numbers, the
geometric mean is at most as large as the arithmetic mean. Replace
each of the numbers a1, · · · , ak by their arithmetic mean A, and re-
place each of the numbers ak+1, · · · , a2k by their arithmetic mean B.
Then the left-hand side of (2.3) increases, while the right-hand side
does not change. For our new sets of numbers, the inequality between
the geometric and arithmetic means is the following.
2k√
AkBk ≤k(A + B)
2k
.
(2.5)
Note if we can prove (2.5), we will also get a proof of our original in-
equality (2.3). Indeed, (2.5) was obtained from (2.3) by increasing the
left-hand side and leaving the right-hand side unchanged. Therefore
(2.5) implies (2.3).
To see that (2.5) holds, note that (2.5) simpliﬁes to
√
AB ≤A + B
2
,

40
A Walk Through Combinatorics
0 ≤(A −B)2.
If n is odd, then assume without loss of generality that an is maxi-
mal among the ai. Replace the numbers a1, a2, · · · , an−1 with their
arithmetic mean C. By the induction hypothesis, this is larger than
their geometric mean.
Therefore, this operation increases the left-
hand side of (2.3) or leaves it the same, and leaves the right-hand
side unchanged. Just as in the case of even n, we have turned our
inequality into a sharper one, namely
n
Cn−1an ≤(n −1)C + an
n
.
Again, it suﬃces to prove this inequality as it implies (2.3). Let us
prove this inequality. As an ≥C, the arithmetic mean (n−1)C+an
n
is
at distance d from C, and distance (n −1)d from an. We will modify
our numbers so that the left-hand side increases and the right-hand
side does not change. We will do this in n −1 steps, and in each
step, we will change two numbers, one of which will always be the
maximal number. First we take one of our n −1 copies of C, add d to
it, and subtract this d from an. Clearly, the sum, and therefore, the
arithmetic mean of our numbers did not change. On the other hand,
their geometric mean grew as Can ≤(C + d)(an −d). Then add d
to another copy of C, and subtract d from an −d, and so on. After
n−1 steps, all our entries are equal to C +d. So raising the geometric
mean and keeping the arithmetic mean unchanged, we reach a point
where these two are equal. This shows that the geometric mean could
not be larger than the arithmetic mean.
Remark. In the second case, we have not used the fact that n was
odd, so we could have done the whole proof with just that method.
It would have been faster, but we wanted to show the nice trick of
splitting the set of our numbers into two subsets. If n is not even, but
not prime, the same method would have worked. We just would have
had to split the set of our numbers into k equal parts, where k is a
prime divisor of n.
(16) This is similar to the solution of the previous exercise.
The only
diﬀerence is that we substitute the relevant sets of numbers by their
geometric means, not their arithmetic means.
(17)(a) We use strong induction on m + n, the initial case of m + n = 4
being obvious. The statement is obviously true when m = 2, so we
will assume that m > 2. Find a row of A that contains at least two

One Step at a Time. The Method of Mathematical Induction
41
copies of 1. Let k be the number of 1s in that row. It is clear that if
k = n or k = n −1, we are done, so we will assume that k ≤n −2.
If any of the columns of these k copies of 1 contains another 1, we
are done. Otherwise, remove all these k columns from A, together
with the selected row. This results in the (m −1) × (n −k) matrix
A′ that contains at least m + n −1 −k copies of 1. So, by the
induction hypothesis, A′ contains a copy of L, and therefore, so
does A.
(b) No, that is not true. A counterexample is a matrix whose ﬁrst row
and ﬁrst column consist of 1s only, except for the top left corner,
which is a 0, and all other entries of the matrix are 0.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 3
There Are A Lot Of Them.
Elementary Counting Problems
In the ﬁrst two chapters, we have explained how to use the Pigeon-hole
Principle and the method of mathematical induction to draw conclusions
from certain numbers. However, to ﬁnd those numbers is not always easy.
It is high time that we learned some fundamental counting techniques.
3.1
Permutations
Let us assume that n people arrived at a dentist’s oﬃce at the same time.
The dentist will treat them one by one, so they must ﬁrst decide the order
in which they will be served. How many diﬀerent orders are possible?
This problem, that is, arranging diﬀerent objects linearly, is so om-
nipresent in combinatorics that we will have a name for both the arrange-
ments and the number of arrangements. However, we are going to answer
the question ﬁrst.
Certainly, there are n choices for the person who will indulge in dental
pleasures ﬁrst. How many choices are there for the person who goes second?
There are only n−1 choices as the person who went ﬁrst will not go second,
but everybody else can.
The crucial observation now is that for each of the n choices for the
patient to be seen ﬁrst, we have n −1 choices for the patient who will be
seen second. Therefore, we have n(n −1) ways to select these two patients.
If you do not believe this, try it out with four patients, called A, B, C,
and D, and you will see that there are indeed 12 ways the ﬁrst two lucky
patients can be chosen.
We can then proceed in a similar manner: we have n −2 choices for
the patient to be seen third as the ﬁrst two patients no longer need to be
seen. Then we have n −3 choices for the patient to be seen fourth, and
43

44
A Walk Through Combinatorics
so on, two choices for the patient to be seen next-to-last, and only one
choice, the remaining, frightened patient, to be seen last. Therefore, the
number of orders in which the patients can sit down in the dentist’s chair
is n · (n −1) · (n −2) · · · 2 · 1.
Deﬁnition 3.1. The arrangement of diﬀerent objects into a linear order
using each object exactly once is called a permutation of these objects. The
number n · (n −1) · (n −2) · · · 2 · 1 of all permutations of n objects is called
n factorial, and is denoted by n!.
So we have just proved the following basic theorem.
Theorem 3.2. The number of all permutations of an n-element set is n!.
We note that by convention, 0! = 1. If you really want to know why we
choose 0! to be 1, and not, say, 0, here is an answer. Let us assume that
there are n people in a room and m people in another room. How many
ways are there for people in the ﬁrst room to form a line and people in the
second room to form a line? The answer is, of course, n! · m! as any line in
the ﬁrst room is possible with any line in the second room. Now consider
the special case of n = 0. Then people in the second room can still form
m! diﬀerent lines. Therefore, if we want our answer, n!m! to be correct in
this singular case too, we must choose 0! = 1. You will soon see that there
are plenty of other situations that show that 0! = 1 is the good deﬁnition.
The number n! is extremely important in combinatorial enumeration,
as you will see throughout this book.
You may wonder how large this
number is, in terms of n. This question can be answered at various levels of
precision. All answers that are at least somewhat precise require advanced
calculus. Here we will just mention, without proof that
n! ∼
√
2πn
	n
e

n
.
(3.1)
The symbol n! ∼z(n) sign means that limn→∞
n!
z(n) = 1. Relation (3.1) is
called Stirling’s formula, and we will use it in several later chapters.
Example 3.3. How many diﬀerent ﬂags can we construct using colors
red, white, and green if all ﬂags must consist of three horizontal stripes
of diﬀerent colors?
Solution. By Theorem 3.2, the answer is 3! = 3 · 2 · 1 = 6. It is easy to
convince ourselves that this is indeed correct by listing all six ﬂags: RWG,
RGW, WRG, WGR and GWR, and GRW.

There Are A Lot Of Them. Elementary Counting Problems
45
The simplicity of the answer to the previous question was due to several
factors: we used each of our objects exactly once, the order of the objects
mattered, and the objects were all diﬀerent. In the rest of this section we
will study problems without one or more of these simplifying factors.
Example 3.4. A gardener has ﬁve red ﬂowers, three yellow ﬂowers and
two white ﬂowers to plant in a row. In how many diﬀerent ways can she
do that?
This problem diﬀers from the previous one in only one aspect: the
objects are not all diﬀerent. The collection of the ﬁve red, three yellow,
and two white ﬂowers is often called a multiset. A linear order that contains
all the elements of a multiset exactly once is called a multiset permutation.
How many permutations does our multiset have? We are going to an-
swer this question by reducing it to the previous one, in which all objects
were diﬀerent. Assume our gardener plants her ﬂowers in a row, in any of
A diﬀerent ways, then sticks labels (say numbers 1 through 5 for the red
ﬂowers, 1 through 3 for the yellow ones, and 1 through 2 for the white ones)
to her ﬂowers so that she can distinguish them. Now she has ten diﬀerent
ﬂowers, and therefore the row of ﬂowers she has just ﬁnished working on can
look in 10! diﬀerent ways. We have to tell how many of these arrangements
diﬀer only because of these labels.
The ﬁve red ﬂowers could be given ﬁve diﬀerent labels in 5! diﬀerent
ways. The three yellow ﬂowers could be given three diﬀerent labels in 3!
diﬀerent ways. The two white ﬂowers could be given two diﬀerent labels in
2! diﬀerent ways. Moreover, the labeling of ﬂowers of diﬀerent colors can be
done independently of each other. Therefore, the labeling of all ten ﬂowers
can be done in 5! · 3! · 2! diﬀerent ways once the ﬂowers are planted in any
of A diﬀerent ways. Therefore, A · 5! · 3! · 2! = 10!, or, in other words,
A =
10!
5! · 3! · 2! = 2520.
This argument can easily be generalized to a general theorem. However,
we will need a greater level of abstraction in our notations to achieve that.
This is because we will take general variables for the number of objects, but
also for the number of diﬀerent kinds of objects. In other words, instead
of saying that we have ﬁve red ﬂowers, three yellow ﬂowers, and two white
ﬂowers, we will allow ﬂowers of k diﬀerent colors, and we will say that there
are a1 ﬂowers of the ﬁrst color, a2 ﬂowers of the second color, a3 ﬂowers

46
A Walk Through Combinatorics
of the third color, and so on. We complete the set of these conditions by
saying that we have ak ﬂowers of color k (or ak ﬂowers of the kth color).
This is a long set of conditions, so some shorter way of expressing it
would certainly make it less cumbersome. We will achieve this by saying
that we have ai ﬂowers of color i, for all i ∈[k]. Instead of saying that
we plant our ﬂowers in a line, we will often say that we linearly order our
objects.
Now we are in a position to state our general theorem.
Theorem 3.5. Let n, k, a1, a2, · · · , ak be nonnegative integers satisfying
a1 + a2 + · · · + ak = n.
Consider a multiset of n objects, in which ai
objects are of type i, for all i ∈[k]. Then the number of ways to linearly
order these objects is
n!
a1! · a2! · · · · · ak!.
Proof. This is a generalization of Example 3.4, and the same idea of proof
works here. The reader should work out the details.
Quick Check
(1) How many ways are there to permute the elements of the set [7] so
that an even number is in the ﬁrst position?
(2) How many ways are there to permute elements of the multiset
{1, 1, 2, 2, 3, 4, 5, 6} so that the ﬁrst and last elements are diﬀerent?
(3) A garden has two rectangular ﬂower beds. In the ﬁrst bed, we will
plant ﬁve diﬀerent ﬂowers in a row. In the second bed, we will plant six
ﬂowers in a row, so that there will be two ﬂowers of each of three kinds.
For which ﬂower bed do we have more possibilities of proceeding?
3.2
Strings over a Finite Alphabet
Now we are going to study problems in which we are not simply arranging
certain objects, knowing how many times we can use each object, but rather
construct strings, or words, from a ﬁnite set of symbols, which we call a
ﬁnite alphabet. We will not require that each symbol occur a speciﬁc number
of times; though we may require that each symbol occur at most once.
Theorem 3.6. The number of k-digit strings over an n-element alphabet
is nk.

There Are A Lot Of Them. Elementary Counting Problems
47
Proof. We can choose the ﬁrst digit in n diﬀerent ways. Then, we can
choose the second digit in n diﬀerent ways as well since we are allowed to
use the same digit again (unlike in case of permutations). Similarly, we
can choose the third, fourth, etc., kth element in n diﬀerent ways. We can
make all these choices independently from each other, so the total number
of choices is nk.
Example 3.7. The number of k-digit positive integers is 9 · 10k−1.
Solution. There are two ways one can see this. From Theorem 3.6, we
know that the number of k-digit strings that can be made up from the
alphabet {0, 1, · · · , 9} is 10k. However, not all these yield a k-digit positive
integer. Indeed, those with ﬁrst digit 0 do not. What is the number of
these bad strings? Disregarding their ﬁrst digit, these strings are (k −1)-
digit strings over {0, 1, · · · , 9} with no restriction, so Theorem 3.6 shows
that there are 10k−1 of them. Therefore, the number of k-digit strings that
do not start with 0, in other words, the number of k-digit positive integers
is 10k −10k−1 = 9 · 10k−1 as claimed.
Alternatively, we could argue as follows. We have 9 choices for the ﬁrst
digit (everything but 0), and ten choices for each of the remaining k −1
digits. Therefore, the number of total choices is 9·10·10·· · ··10 = 9·10k−1,
just as in the previous argument.
Before we discuss our next example, we mention a general technique in
enumeration, the method of bijections. Let us assume that there are many
men and many women in a huge ballroom. We do not know the number of
men, but we know that the number of women is exactly 253. We think that
the number of men is also 253, but we are not sure. What is a fast way to
test this conjecture? We can ask the men and women to form man-woman
pairs. If they succeed in doing this, that is, nobody is left without a match,
and everyone has a match of the opposite gender, then we know that the
number of men is 253 as well. If not, then there are two possibilities: if
some man did not ﬁnd a woman for himself, then the number of men is
more than 253. If some woman did not ﬁnd a man, then the number of
men is less than 253.
This technique of matching two sets element-wise and then conclude
(in case of success) that the sets are equinumerous is very often used in
combinatorial enumeration. Let us put it in a more formal context.

48
A Walk Through Combinatorics
Deﬁnition 3.8. Let X and Y be two ﬁnite sets, and let f : X →Y be a
function so that
(1) if f(a) = f(b), then a = b, and
(2) for all y ∈Y there is an x ∈X so that f(x) = y,
then we say that f is a bijection from X onto Y .
Equivalently, f is a
bijection if for all y ∈Y , there exists a unique x ∈X so that f(x) = y.
In other words, a bijection matches the elements of X with the elements
of Y , so that each element will have exactly one match.
The functions that have only one of the two deﬁning properties of bi-
jections also have their own names.
Deﬁnition 3.9. Let f : X →Y be a function. If f satisﬁes criterion (1)
of Deﬁnition 3.8, then we say that f is one-to-one or injective, or is an
injection. If f satisﬁes criterion (2) of Deﬁnition 3.8, then we say that f is
onto or surjective, or is a surjection.
Proposition 3.10. Let X and Y be two ﬁnite sets. If there exists a bijec-
tion f from X onto Y , then X and Y have the same number of elements.
Proof. The bijection f matches elements of X to elements of Y , in other
words it creates pairs with one element from X and one from Y in each
pair. If f created m pairs, then both X and Y have m elements.
The advantages of the bijective method are signiﬁcant. Instead of enu-
merating the elements of X, we can enumerate the elements of Y if that
is easier. Then, we can ﬁnd a bijection from X onto Y . Let us illustrate
this by computing the number of all subsets of [n] without resorting to
induction.
Example 3.11. The number of all subsets of an n-element set is 2n.
Solution. We construct a bijection from the set of all subsets of an n-
element set into that of all n-digit strings over the binary alphabet {0, 1}.
As this latter set has 2n elements by Theorem 3.6, it will follow that so
does the former.
To construct the bijection, let B be any subset of [n]. Now let f(B) be
the string whose ith digit is 1 if and only if i ∈B and 0 otherwise. This way
f(B) will indeed be an n-digit word over the binary alphabet. Moreover, it
is clear that given any string s of length n containing digits equal to 0 and

There Are A Lot Of Them. Elementary Counting Problems
49
1 only, we can ﬁnd the unique subset B ⊆[n] for which f(B) = s. Indeed,
B will precisely consist of the elements i ∈[n] so that the ith element of s
is 1.
Example 3.12. A city has recently built ten intersections. Some of these
will get traﬃc lights, and some of those that get traﬃc lights will also get
a gas station. In how many diﬀerent ways can this happen?
Solution. It is easy to construct a bijection from the set of all distributions
of lights and gas stations onto that of ten-digit words over the alphabet
A, B, C. Indeed, for each distribution of these objects, we deﬁne a word
over {A, B, C} as follows: if the ith intersection gets both a gas station and
a traﬃc light, then let the ith digit of the word that we are constructing
be A, if only a traﬃc light, then let the ith digit be B, and if neither, then
let the ith digit be C.
Clearly, this is a bijection, for any ten-digit word can be obtained from
exactly one distribution of gas stations and traﬃc lights this way. So the
number we are looking for is, by Proposition 3.10, the number of all ten-
digit words over a three-digit alphabet, that is, 310.
Theorem 3.13. Let n and k be positive integers satisfying n ≥k. Then
the number of k-digit strings over an n-element alphabet in which no letter
is used more than once is
n(n −1) · · · (n −k + 1) =
n!
(n −k)!.
Proof. Indeed, we have n choices for the ﬁrst digit, n −1 choices for the
second digit, and so on, just as we did in the case of factorials. The only
diﬀerence is that here we do not necessarily use all our n objects, we stop
after choosing k of them.
The number n(n −1) · · · (n −k + 1) is sometimes denoted (n)k.
Example 3.14. A president must choose ﬁve politicians from a pool of
20 candidates to ﬁll ﬁve diﬀerent cabinet positions. In how many diﬀerent
ways can she do that?
Solution. We can directly apply Theorem 3.13. We have a 20-element
alphabet (the politicians) and we need to count the number of 5-letter words
with no repeated letters. Therefore, the answer is (20)5 = 20·19·18·17·16.
If the candidates are all equally qualiﬁed, it may take a while...

50
A Walk Through Combinatorics
Quick Check
(1) How many six-digit positive integers are there in which the ﬁrst and
last digits are the same?
(2) How many six-digit positive integers are there in which the ﬁrst and
last digits are of the same parity?
(3) How many functions f : [n] →[n] are there for which there exists
exactly one i ∈[n] satisfying f(i) = i?
3.3
Choice Problems
At the national lottery drawings in Hungary, ﬁve numbers are selected at
random from the set [90]. To win the main prize, one must guess all ﬁve
numbers correctly. How many lottery tickets does one need in order to
secure the main prize?
This problem is an example of the last and most interesting kind of ele-
mentary enumeration problems, called choice problems. In these problems,
we have to choose certain subsets of a given set. We will often require that
the subsets have a speciﬁc size. The important diﬀerence from the previous
two sections is that the order of the elements of the subset will not matter;
for example, {1, 43, 52, 8, 3} and {52, 1, 8, 43, 3} are identical as subsets of
[90].
The number of k-element subsets of [n] is of pivotal importance in enu-
merative combinatorics. Therefore, we have a symbol and name for this
number.
Deﬁnition 3.15. The number of k-element subsets of [n] is denoted
n
k

and is read “n choose k”.
The numbers
n
k

are often called binomial coeﬃcients, for reasons that
will become clear in Chapter 4.
Theorem 3.16. For all nonnegative integers k ≤n, the equality
n
k

=
n!
k!(n −k)! = (n)k
k!
holds.
Proof. To select a k-element subset of [n], we ﬁrst select a k-element string
in which the digits are elements of [n]. By Theorem 3.6, we can do that
in n!/(n −k)! diﬀerent ways. However, in these strings the order of the
elements does matter. In fact, each k-element subset occurs k! times among

There Are A Lot Of Them. Elementary Counting Problems
51
these strings as its elements can be permuted in k! diﬀerent ways. Therefore,
the number of k-element subsets is 1/k! times the number of k-element
strings, and the proof follows.
Therefore, if we want to be absolutely sure to win at the Hungarian
lottery, we have to buy
90
5

= 90·89·88·87·86
1·2·3·4·5
= 43949268 tickets. If you do
that, make sure you ﬁll them out right...
Deﬁnition 3.17. Let S ⊆[n]. Then the complement of S, denoted Sc is
the subset of [n] that consists precisely of the elements that are not in S.
In other words, Sc is the unique subset of [n] that for all i ∈[n] satisﬁes
the following statement: i ∈Sc if and only if i /∈S.
The following proposition summarizes some straightforward properties
of the numbers
n
k

. We choose to announce these easy statements as a
proposition since they will be used incessantly in the coming sections.
Proposition 3.18. For all nonnegative integers k ≤n, the following hold.
(1)
n
k

=

n
n −k

.
(2)
n
0

=
n
n

= 1.
Proof. (1) We set up a bijection f from the set of all k-element subsets
of [n] onto that of all n −k-element subsets of n.
This f will be
simplicity itself: it will map any given k-element subset S ⊆[n] into
its complement Sc. Then for any n −k-element subset T ⊆[n], there
is exactly one S so that f(S) = T , namely S = T c. So f is indeed
a bijection, proving that the number of k-element subsets of [n] is the
same as that of n−k-element subsets of [n], which, by deﬁnition, means
that
n
k

=
 n
n−k

.
(2) The ﬁrst equality is a special case of the claim of part 1, with k = 0.
To see that
n
0

= 1, note that the only 0-element subset of [n] is the
empty set.
We note in particular that
0
0

= 1, and that sometimes it is convenient
to deﬁne
n
k

even in the case when n < k. It goes without saying that in

52
A Walk Through Combinatorics
that case, we deﬁne
n
k

= 0 as no set has a subset that is larger than the
set itself.
Example 3.19. A medical student has to work in a hospital for ﬁve days
in January. However, he is not allowed to work two consecutive days in the
hospital. In how many diﬀerent ways can he choose the ﬁve days he will
work in the hospital?
Solution. The diﬃculty here is to make sure that we do not choose
two consecutive days.
This can be assured by the following trick.
Let
a1, a2, a3, a4, a5 be the dates of the ﬁve days of January that the student
will spend in the hospital, in increasing order. Note that the requirement
that there are no two consecutive numbers among the ai, and 1 ≤ai ≤31
for all i is equivalent to the requirement that 1 ≤a1 < a2 −1 < a3 −2 <
a4 −3 < a5 −4 ≤27. In other words, there is an obvious bijection between
the set of 5-element subsets of [31] containing no two consecutive elements
and the set of 5-element subsets of [27].
Instead of choosing the numbers ai, we can choose the numbers 1 ≤
a1 < a2 −1 < a3 −2 < a4 −3 < a5 −4 ≤27, that is, we can simply choose
a ﬁve-element subset of [27], and we know that there are
27
5

ways to do
that.
The trick we used here is also useful when instead of requiring that the
chosen elements are far apart, we even allow them to be identical.
Example 3.20. Now let us assume that we play a lottery game where ﬁve
numbers are drawn out of [90], but the numbers drawn are put back into
the basket right after being selected. To win the jackpot, one must have
played the same multiset of numbers as the one drawn (regardless of the
order in which the numbers were drawn). How many lottery tickets do we
have to buy to make sure that we win the jackpot?
Solution. We are going to apply the same trick as in the previous example,
just backwards. We claim there is a bijection from the set of 5-element
multisets
1 ≤b1 ≤b2 ≤b3 ≤b4 ≤b5 ≤90
(3.2)
onto the set of 5-elements subsets of [94]. Indeed, such a bijection f is
given by f(b1, b2, b3, b4, b5) = (b1, b2 + 1, b3 + 2, b4 + 3, b5 + 4). It is obvious
that the numbers bi satisfy the requirements given by (3.2) if and only if

There Are A Lot Of Them. Elementary Counting Problems
53
f(b1, b2, b3, b4, b5) = (b1, b2 + 1, b3 + 2, b4 + 3, b5 + 4) is a subset of [94].
Therefore, we need to buy
94
5

lottery tickets to secure a jackpot.
There is nothing magic about the numbers 90 and 5 here. In fact, the
same argument can be repeated in a general setup, to yield the following
Theorem.
Theorem 3.21. The number of k-element multisets whose elements all
belong to [n] is
n + k −1
k

.
The following table summarizes our enumeration theorems proved in this
chapter.
parameters
formula
Permutations
n distinct objects
n!
ai objects of type i,
n!
a1!a2! · · · ak!

ai = n
Lists
n distinct objects
(n)k =
n!
(n −k)!
list of length k
n distinct letters
nk
words of length k
Subsets
k-element subsets of [n]
n
k

k-element multisets
n + k −1
k

with elements from [n]
Quick Check
(1) A company has 20 male and 15 female employees. How many ways
are there to form a committee consisting of four male and three female
employees of the company?

54
A Walk Through Combinatorics
(2) A professor wants to schedule a total of three hours of oﬃce hours for
the next ﬁve days. In how many ways is that possible if the length of
each oﬃce hour must be an integer (in hours)?
(3) In one lottery, we have to correctly pick ﬁve numbers out of ten in
order to win, repetitions are not possible, and the order of the chosen
numbers does not matter. In another lottery, we have to correctly pick
four numbers out of ten, repetitions are possible, and the order of the
chosen numbers does not matter. In which lottery do we have a higher
chance to win?
Notes
One of the most diﬃcult exercises of this chapter is Exercise 24.
The
ﬁrst mathematician to prove the formula given in that exercise was prob-
ably P. A. MacMahon [35], in 1916. The proof presented here is due to
the present author [17]. A high-level survey (using commutative algebra)
of results concerning magic squares can be found in “Combinatorics and
Commutative Algebra” [48] by Richard Stanley, while a survey intended
for undergraduate and starting graduate students is presented in Chapter 9
of “Introduction to Enumerative and Analytic Combinatorics” [11] by the
present author.
Exercises
(1) How many functions are there from [n] to [n] that are not one-to-one?
(2) Prove that the number of subsets of [n] that have an odd number of
elements is 2n−1.
(3) A company has 20 employees, 12 males and eight females. How many
ways are there to form a committee of 5 employees that contains at
least one male and at least one female?
(4) A track and ﬁeld championship has participants from 49 countries. The
ﬂag of each participating country consists of three horizontal stripes of
diﬀerent colors. However, no ﬂag contains colors other than red, white,
blue, and green. Is it true that there are three participating countries
with identical ﬂags?
(5) In countries that currently belong to a certain alliance, 17 languages are
spoken by at least ten million people. For any two of these languages,
the alliance employs an interpreter who can translate documents from
one language to the other, and vice versa. One journalist has recently

There Are A Lot Of Them. Elementary Counting Problems
55
noted that when the soon-to-be admitted countries bring the number
of languages spoken by at least ten million people in the alliance to 22,
more than a hundred new interpreters will be needed. Was she right?
(No interpreter works two jobs.)
(6) How many ﬁve-digit positive integers are there with middle digit 6 that
are divisible by three?
(7) How many ﬁve-digit positive integers are there that contain the digit 9
and are divisible by three?
(8) How many ways are there to list the digits {1, 2, 2, 3, 4, 5, 6} so that
identical digits are not in consecutive positions?
(9) How many ways are there to list the digits {1, 1, 2, 2, 3, 4, 5} so that the
two 1s are in consecutive positions?
(10) A cashier wants to work ﬁve days a week, but he wants to have at least
one of Saturday and Sunday oﬀ. In how many ways can he choose the
days he will work?
(11) A car dealership employs ﬁve salespeople.
A salesperson receives a
100-dollar bonus for each car he or she sells.
Yesterday the dealer-
ship sold seven cars. In how many diﬀerent ways could this happen?
(Let us consider two scenarios diﬀerent if they result in diﬀerent bonus
payments.)
(12) A traveling agent has to visit four cities, each of them ﬁve times. In
how many diﬀerent ways can he do this if he is not allowed to start and
ﬁnish in the same city?
(13) A college professor has been working for the same department for 30
years. He taught two courses in each semester. The department oﬀers
15 diﬀerent courses. Is it sure that there were at least two semesters
when this professor had identical teaching programs? (A year has two
semesters.)
(14) A restaurant oﬀers ﬁve diﬀerent soups, ten main courses, and six
desserts. Joe decided to order at most one soup, at most one main
course, and at most one dessert. In how many ways can he do this?
(15) A student in physics needs to spend ﬁve days in a laboratory during her
last semester of studies. After each day in the lab, she needs to spend
at least six days in her oﬃce to analyze the data before she can return
to the lab. After the last day in the lab, she needs ten days to complete
her report that is due at the end of the last day of the semester. In how
many ways can she choose her lab days if we assume that the semester
is 105 days long?
(16)(a) Three friends, having the nice names A, B, and C played a ping-

56
A Walk Through Combinatorics
pong tournament each day of a given week. There were no ties at
the end of the tournament. Prove that there were two days when
the ﬁnal ranking of the three people was the same.
(b) A fourth person, called D, joined the company of the mentioned
three. These four friends played a tennis competition each day for
ﬁve weeks. When the ﬁve weeks were over, one of them noticed that
none of their one-day tournaments resulted in a tie at the ﬁrst place,
or in a tie at the last place. Is it true that there were two contests
with the same ﬁnal ranking of players?
(c) Now A, B and, C are playing a round-robin chess tournament each
day starting January 1. Each player plays against each other player
once playing the white pieces, and once playing the black pieces.
The three friends agreed that they will stop when there will be two
days with completely identical results. (That is, if on the earlier
day, A beat B when playing the whites, but played a draw with him
when playing the blacks, then, on the last day the friends play, A
has to beat B when playing the whites, and has to play a draw with
him when playing the blacks, and the same coinciding results must
occur for the pair (B, C), and for the pair (A, C).)
When their left-out friend, D, heard about their plan, she said “are
you sure you want to do this? You might be playing chess for two
years!” Was she exaggerating?
(17) Let k ≥1, and let b1, b2, · · · , bk be positive integers with sum less than
n, where n is a positive integer. Prove that then
b1!b2! · · · bk! < n!
holds. Can you make that statement stronger?
(18) How many 6-digit positive integers are there in which the sum of the
digits is at most 51?
(19) How many ways are there to select an 11-member soccer team and a
5-member basketball team from a class of 30 students if
(a) nobody can be on two teams
(b) any number of students can be on both teams
(c) at most one student can be on both teams?
(20) On the island of Combinatoria, all cars have license plates consisting
of six numerical digits only.
A witness to a crime could only give
a partial description of the getaway car.
In particular, she noticed
that the license plate was from Combinatoria, there was only one digit
that occurred more than once, and that digit occurred three times. A

There Are A Lot Of Them. Elementary Counting Problems
57
police oﬃcer estimated that this information will exclude more than 90
percent of all cars as suspects. Was his estimate correct?
(21) (+) A round robin chess tournament had 2n participants from two
countries, n from each country. There were no two players with the
same number of points at the end. Prove that there was at least one
player who scored at least as many points against his compatriots as
against the players of the other country. (In chess, a player gets one
point for a win and one half of a point for a draw.)
(22) (+)
(a) At a round robin chess tournament, at least 3/4 of the games ended
by a draw. Prove that there were two players who had the same
ﬁnal score.
(b) Now assume the tournament has been interrupted after t rounds,
that is, after each player has ﬁnished t games.
(We assume, for
simplicity, that the number of players is even.) Is it still true that if
at least 3/4 of the games played ended by a draw, then there were
two players with the same total score?
(c) Prove that if the games of the tournament are played in a random
order (there are no rounds; one player can ﬁnish many games before
another player starts), and the tournament is interrupted at some
point. Could it happen that three 3/4 of the ﬁnished games ended
by a draw, but there were no two players with the same total score?
(d) Is there a constant K < 1 such that if we organize the tournament
as in the preceding case, and we interrupt the tournament at a point
when at least K of the ﬁnished games ended by a draw, then there
will always be two players with the same total score?
(23) In how many diﬀerent ways can we place eight identical rooks on a
chess board so that no two of them attack each other?
(24) (++) A magic square is a square matrix with nonnegative integer en-
tries in which all row sums and column sums are equal. Let H3(r) be
the number of magic squares of size 3×3 in which each row and column
have sum r. Prove that
H3(r) =
r + 4
4

+
r + 3
4

+
r + 2
4

,
(3.3)
where H3(r) is the number of 3 × 3 magic squares of line sum r. We
will return to formula (3.3) in Chapter 11. The material covered in
that chapter will allow us to give a simpler proof to this result.

58
A Walk Through Combinatorics
(25) How many ways are there to select a subset S ⊆[15] so that S does
not have two distinct elements a and b for which a + b is divisible by
three?
(26) How many permutations of the set [n] are there in which no entry is
larger than both of its neighbors? (We can assume that the condition
is automatically satisﬁed for the leftmost and the rightmost entry.)
Supplementary Exercises
(27) (-) How many three-digit positive integers contain two (but not three)
diﬀerent digits?
(28) (-) How many ways are there to list the letters of the word AL-
ABAMA?
(29) (-) How many subsets does [n] have that contain exactly one of the
elements 1 and 2?
(30) (-) How many subsets does [n] have that contain at least one of the
elements 1 and 2?
(31) (-) How many three-digit positive integers start and end with an even
digit?
(32) How many four-digit positive integers are there in which all digits are
diﬀerent?
(33) How many four-digit positive integers are there that contain the digit
1?
(34) How many n-element subsets S ⊆[2n] are there so that there are no
two elements x and y in S satisfying x + y = 2n + 1?
(35) How many subsets S ⊆[2n] are there (of any size) so that there are
no two elements x and y in S satisfying x + y = 2n + 1?
(36) How many three-digit numbers are there in which the sum of the digits
is even? (We do not allow the ﬁrst digit to be zero.)
(37) In this exercise, the words precede does not mean immediately precede.
(a) In how many ways can the elements of [n] be permuted if 1 is to
precede 2 and 3 is to precede 4?
(b) In how many ways can the elements of [n] be permuted if 1 is to
precede both 2 and 3?
(38) In how many ways can the elements of [n] be permuted so that the
sum of every two consecutive elements in the permutation is odd?
(39) Let n = pa1
1 pa2
2 · · · pak
k , where the pi are distinct primes, and the ai are
positive integers. How many positive divisors does n have?

There Are A Lot Of Them. Elementary Counting Problems
59
(40)(a) Let d(n) be the number of positive divisors of n. For what numbers
n will d(n) be a power of 2?
(b) Is it true that for all positive integers n, the inequality d(n) ≤
1 + log2 n holds?
(41) A student needs to work ﬁve days in January. He does not want to
work on more than one Sunday. In how many ways can he select his
ﬁve working days? (Assume that in the year in question, January has
ﬁve Sundays.)
(42) (+) A host invites n couples to a party. She wants to ask a subset
of the 2n guests to give a speech, but she does not want to ask both
members of any couple to give speeches. In how many ways can she
proceed?
(43) We want to select as many subsets of [n] as possible so that any two
selected subsets have at least one element in common. What is the
largest number of subsets we can select?
(44) We want to select an ordered pair (A, B) of subsets of [n] so that
A ∩B ̸= ∅. In how many diﬀerent ways can we do this?
(45) We want to select three subsets A, B, and C of [n] so that A ⊆C,
B ⊆C, and A ∩B ̸= ∅. In how many diﬀerent ways can we do this?
(46) A two-day mathematics conference has n participants. Some of the
participants give a talk on Saturday, some others give a talk on Sunday.
Nobody gives more than one talk, and there may be some people who
do not give a talk at all. At the end of the conference, a few talks
are selected to be included in a book. In how many diﬀerent ways is
this all possible if we assume that there is at least one talk selected
for inclusion in the book?
(47) A group organizing a faculty-student tennis match must match four
faculty volunteers to four of the 13 students who volunteered to be in
the match. In how many ways can they do this?
(48) Let P be a convex n-gon in which no three diagonals intersect in one
point. How many intersection points do the diagonals of P have?
(49) A student will study 26 hours in preparation for an exam. She will
due this in the course of six consecutive days. On each of these days,
she will study either four hours, or ﬁve hours, or six hours. In how
many diﬀerent ways is this possible?
(50) (+) Andy and Brenda play with dice. They throw four dice at the
same time. If at least one of the four dice shows a six, then Andy
wins, if not, then Brenda. Who has a greater chance of winning?
(51) (+) A store has n diﬀerent products for sale. Each of them has a

60
A Walk Through Combinatorics
diﬀerent price that is at least one dollar, at most n dollars, and is
a whole dollar. A customer only has the time to inspect k diﬀerent
products. After doing so, she buys the product that has the lowest
price among the k products she inspected. Prove that on average, she
will pay n+1
k+1 dollars.
(52) In how many ways can we place n non-attacking rooks on an n × n
chess board?
(53) A class is attended by n sophomores, n juniors, and n seniors. In how
many ways can these students form n groups of three people each if
each group is to contain a sophomore, a junior, and a senior?
(54) The National Football League consists of 32 teams. These teams are
ﬁrst divided into two conferences, the American Conference and the
National Conference, each of which consists of sixteen teams. Then
each conference is divided into four divisions of four teams each. Each
division has a distinct name. In how many ways can this be done?
(55) Answer the question of the previous exercise if there are two teams
from New York City in the National Football League, and they cannot
be assigned to the same conference.
(56) Let P3(r) be the number of 3 × 3 magic squares that are symmetric
to their main diagonal. Prove that P3(r) ≤(r + 1)3. (Magic squares
are deﬁned in Exercise 24.)
(57) How many n × n square matrices are there whose entries are 0 or 1
and in which each row and column has an even sum?
(58) How many ways are there for n people to sit around a circular table if
two seating arrangements are considered identical if each person has
the same left neighbor in them?
Solutions to Exercises
(1) The number of all functions from [n] to [n] is nn by Theo-
rem 3.6.
Indeed,
such a function f
is deﬁned by the array
(f(1), f(2), f(3), · · · , f(n)), and any entry in this array can be any
element of [n].
If f is a one-to-one function, then the array
(f(1), f(2), f(3), · · · , f(n)) is a permutation of the elements 1, 2, · · · , n
as it contains each of them exactly once. So the number of one-to-one
functions from [n] to [n] is n!, by Theorem 3.2. Therefore, the number
of functions from [n] to [n] that are not one-to-one is nn −n!.

There Are A Lot Of Them. Elementary Counting Problems
61
Remark: Note that we were asked to compute the number of func-
tions that were not one-to-one, and we obtained that number in an
indirect way. We ﬁrst computed the number of all functions from [n]
to [n], then we computed the number of all functions from [n] to [n]
that were one-to-one, and then we subtracted the second number from
the ﬁrst.
This technique of “number of good objects is equal to that of all
objects minus that of bad objects” is very often used in combinatorial
enumeration. Several exercises in this chapter can be solved this way.
(2) As in the proof of Example 3.11, we can bijectively encode all subsets
of [n] by 0-1 sequences consisting of n digits. If we want this sequence
to contain an odd number of ones, then we can choose the ﬁrst n −1
digits any way we want. The last digit can be used to make sure that
the number of all ones is odd. That is, if there were an odd number
of ones among the ﬁrst n −1 digits, then the last digit has to be a
zero, otherwise it has to be a one. Therefore, we make a choice n −1
times, and each time we have two possibilities. So the total number
of possibilities is 2n−1.
(3) There are
20
5

ways to choose ﬁve people out of our twenty employees.
However,
12
5

of these choices will result in male-only committees, and
8
5

will result in female-only committees. Therefore, the number of
good choices is
20
5

−
12
5

−
8
5

.
(4) There are 4 · 3 · 2 = 24 diﬀerent 3-color ﬂags that can be made from
our four colors. As 2·24 = 48 < 49, it follows from the general version
of the Pigeon-hole Principle that there are three identical ﬂags among
any 49 such ﬂags.
(5) There are
17
2

= 17·16
2
= 136 pairs that can be formed of the 17 lan-
guages currently spoken by at least ten million people in the alliance.
When the number of these languages grows to 22, the number of pairs
of languages will be
22
2

= 22·21
2
= 231, so 95 new interpreters will be
needed. Therefore, the journalist was wrong.
(6) It is well-known (see Exercise 34 of Chapter 2) that a positive integer
is divisible by three if and only if the sum of its digits is divisible
by three.
Therefore, a ﬁve-digit a integer with middle digit six is
divisible by three if and only if the four-digit integer obtained by
deleting the middle digit of a is divisible by three. There are 9000 four-
digit positive integers, and the third, sixth, ninth,....,9000th of them
are divisible by 3 (these are the integers 1002, 1005, 1008,...,9999).
In other words, there are 3000 four-digit positive integers divisible by

62
A Walk Through Combinatorics
three, so there are 3000 ﬁve-digit positive integers divisible by three
and having middle digit 6.
(7) The number of all ﬁve-digit positive integers is 90000, and one third of
them, 30000, are divisible by three. Let us count how many of these
30000 numbers do not contain the digit nine. Such a number can start
with one of eight digits (1, 2, · · · , 8), then can have any of nine digits
(0, 1, 2, · · · , 8) in the second, third, and fourth positions. For the ﬁfth
digit, we have more limited choice. We have to pick the ﬁfth digit so
that the sum of all ﬁve digits is divisible by three. Depending on the
ﬁrst four digits, we can either choose one of 0,3,6, or one of 1,4,7, or
one of 2,5,8. Either way, this means three choices. The total number
of choices we have is 8 · 93 · 3 = 17496, so this is the number of 5-digit
positive integers that are divisible by three, but do not contain the
digit 9. Therefore, there are 30000 −17496 = 12504 5-digit positive
integers that are divisible by three and do contain the digit 9.
(8) The number of all permutations of this multiset is given by Theorem
3.5, and is equal to
7!
2! = 2520. However, we have to subtract the
number of those permutations in which the two identical digits are
in consecutive positions. To count these, let us glue the two identical
digits together. Then we have six digits, which are all diﬀerent, and
therefore Theorem 3.2 shows that they have 6! = 720 permutations.
Therefore, the number of all permutations of our multiset in which the
two identical digits are not in consecutive positions is 2520 −720 =
1800.
(9) Just as in Exercise 8, let us glue the two 1s together. Then we simply
have to count permutations of the multiset {1, 2, 2, 3, 4, 5}. Theorem
3.5 shows that there are 6!
2! = 360 such permutations.
(10) There are
7
5

=
7
2

= 21 ways to choose ﬁve days of the week. Let us
now count the bad choices, that is, those that contain both Saturday
and Sunday. Clearly, there are
5
3

= 10 of these. Indeed, they contain
Saturday, Sunday, and three of the remaining ﬁve days. Therefore, the
number of good choices is 21 −10 = 11.
(11) As we only consider two scenarios diﬀerent if they result in diﬀerent
bonus payments, we are not interested in the order in which the dif-
ferent salespeople sold the seven cars. What matters is how many
cars each of them sold. Therefore, we are interested in the number of
7-element multisets whose elements are from the set [5]. By Theorem
3.21, this number is
5+7−1
7

=
11
7

=
11
4

= 330.
(12) There are
20!
5!·5!·5!·5! ways to visit four cities, each of them ﬁve times.

There Are A Lot Of Them. Elementary Counting Problems
63
Let us determine the number of ways to do this so that we start in
city A, and end in city A. In that case, we are free to choose the order
in which we make the remaining 18 visits. As three of those visits will
be to city A, and ﬁve will be to each of the remaining three cities, this
can be done in
18!
5!·5!·5!·3! ways. Obviously, the same argument applies
for the number of visiting arrangements that start and end in B, that
start and end in C, and that start and end in D. So the ﬁnal answer
is
20!
5! · 5! · 5! · 5! −4 ·
18!
5! · 5! · 5! · 3!.
(13) No, that is not sure. There are
15
2

= 15·14
2
= 105 ways to pick two
courses out of 15 courses, and 30 years consist of 60 semesters only.
(14) Joe can make one of six choices on soup as he may decide not to order
soup at all. Similarly, he can make one of 11 choices on the main
course, and one of seven choices on dessert. So the total number of
possibilities is 6 · 11 · 7 = 462.
(15) Let us number the days of the semester from 1 to 105, and let us
denote the days when the student is in the lab by a1, a2, . . . , a5. Then
the conditions imply that a5 ≤95, and
1 ≤a1 < a2 −6 < a3 −12 < a4 −18 < a5 −24 ≤95 −24 = 71.
Denote b1 = a1, b2 = a2−6, b3 = a3−12, b4 = a4−18, and b5 = a5−24.
Clearly, knowing the numbers bi is equivalent to knowing the numbers
ai.
Note that b5 ≤95 −24 = 71. There is no additional requirement for
the numbers bi besides 1 ≤b1 < b2 < b3 < b4 < b5, so there are
71
5

possible choices for the set of these numbers. Therefore, our student
can make this many choices.
(16)(a) There are 3! = 6 ways the contest could end, and there are seven
days in a week. We know, if from nowhere else, then from the title
of Chapter 1, that Seven Is More Than Six. Therefore, the pigeon-
hole principle implies that there were two contests with identical
results.
(b) If there were no ties at all, the contest could end in 4! = 24 diﬀerent
ways. If there is a tie, it could only be at the second-third place.
The two people who tie can be chosen in
4
2

= 6 ways, then the
winner can be either of the remaining two people. So there are
6·2 = 12 diﬀerent outcomes with a tie. Therefore the total number
of possible endings for the competition is 24 + 12 = 36. There are

64
A Walk Through Combinatorics
only 35 days in ﬁve weeks, so it is possible that there are no two
days when the contest ends the same way.
(c) Each tournament consists of six games as we have three choices
for the person leading the white pieces, and two choices leading
the black pieces. Each of these six games can have three diﬀerent
results: either white wins, or black wins, or it is a draw. So there
are 36 = 729 ways the games of a tournament can end. Therefore,
the three friends will play for at most 730 days, which is exactly
two years as neither 2013, nor 2014 is a leap-year. So D was in fact
right, she was not exaggerating.
(17) Let bk+1 be a positive integer so that n = k+1
i=1 bi. Theorem 3.5 then
tells us that
T =
n!
b1!b2! · · · bk+1!
is the number of linear orderings of n objects of k + 1 various kinds,
so that bi objects are of kind i. In particular, T =
n!
b1!b2!···bk+1! is a
positive integer, (as it is the number of elements in a nonempty set),
so
n!
b1!b2! · · · bk! = bk+1!T.
The right-hand side (and therefore, the left-hand side) is larger than
1 as long as one of T and bk+1 is larger than 1. The only way in which
T = 1 could hold would be if there were no two distinct objects at all,
but that is not possible since there is at least one object of type k + 1,
and one other object. So we proved that not only b1!b2! · · · bk! < n!,
but also, b1b2 · · · bk is a proper divisor of n!.
(18) The number of all 6-digit integers is 900000 by Example 3.7. Again, we
are going to count those which do not satisfy the criteria, that is, those
with digit sum of at least 52. There are only four 6-element multisets of
digits that sum to at least 52, namely {9, 9, 9, 9, 9, 9}, {9, 9, 9, 9, 9, 8},
{9, 9, 9, 9, 9, 7}, and {9, 9, 9, 9, 8, 8}. Theorem 3.5 implies that they
have 1,6,6, and 15 multiset permutations (respectively), so altogether
there are 28 numbers out of 900000 that violate the criteria. So the
number of 6-digit positive integers that satisfy the criteria is 899972.
(19)(a) We have
30
11

choices for the soccer team. Then we have to choose
from the remaining 19 people in
19
5

ways for the basketball team.
Consequently, the ﬁnal answer is
30
11

·
19
5

.
(b) If there is no restriction at all, then after choosing the soccer team,
we can choose the basketball team in
30
5

ways, from the set of all
students. So the total number of choices is
30
11

·
30
5

.

There Are A Lot Of Them. Elementary Counting Problems
65
(c) All
30
11

·
19
5

team compositions (computed in the ﬁrst part in this
exercise) in which no student is on two teams are certainly good.
Apart from these, there are those in which there is exactly one
student on both teams. We have 30 choices for this person, then
there are
29
10

·
19
4

ways to choose the remaining players from the
rest of the class. Thus the total number of possibilities is
30
11

·
19
5

+ 30 ·
29
10

·
19
4

.
(20) The digit that occurred three times could be any of ten digits. The
positions of its three occurrences could be any of the
6
3

= 20 three-
element subsets of [6].
The other three digits form a 3-digit word
over the remaining 9-letter alphabet without repetition, so we have
9 · 8 · 7 = 504 choices for them. As all these choices can be made
independently from each other, the total number of our choices is
10 · 20 · 504 = 100800. This is slightly more than ten percent of all
license plates, which would be 100000, so the police oﬃcer was a little
bit too optimistic.
(21) Let A be the country whose players scored, in totality, at most as many
points in the international games as players from the other country.
Take the n players from A, and let a1, a2, · · · , an denote the number of
points they accumulated against their countrymen. Let b1, b2, · · · , bn
be the number of points they accumulated against players from coun-
try B. Now assume that our claim is false, that is, ai < bi for all i. In
other words, ai ≤bi −0.5 for all i. Summing these inequalities over
all i ∈[n], we get that
n

i=1
ai ≤
 n

i=1
bi

−n/2.
(3.4)
On the other hand, note that n
i=1 ai = n(n−1)/2 as any two players
from A played each other once, and in each of those games, one point
was up for grabs. Comparing this with (3.4), we get
n(n −1)
2
+ n
2 = n2
2 ≤
 n

i=1
bi

.
(3.5)
Similarly,
n

i=1
bi ≤n2/2
(3.6)

66
A Walk Through Combinatorics
as players from A got at most half of all points that were available at
the international games.
Comparing (3.5) and (3.6) we see that n
i=1 bi = n2/2 must hold.
That is, n
i=1 bi is exactly n/2 larger than n
i=1 ai. Therefore, equal-
ity holds in (3.4), and so equality must hold in all equations of the
type ai ≤bi −0.5.
(Recall that (3.4) was obtained by taking the
sum of these equations for all i.) Therefore, for all i, we must have
ai = bi −0.5, meaning that the total score of the ith player from coun-
try A was ai + bi = 2a + 0.5, which is never an integer. Therefore,
no player from country A has a ﬁnal score that is an integer. By the
very same argument, no player from country B has a ﬁnal score that
is an integer. Indeed, in totality, players from B scored n2/2 points
against players from A, so the same argument works.
This is a contradiction as we know there are no two players with the
same ﬁnal score. The number of possible non-integer ﬁnal scores is
less than 2n: indeed, they are 0.5, 1.5, 2.5, · · ·(2n −1) −0.5, which
is only 2n −1 diﬀerent scores for the 2n players. So there must be
a player who did better against his compatriots than against players
from the other country.
(22)(a) Let us change the scoring system of chess as follows: a player gets
one point for a win, zero points for a draw, and −1 points for a loss.
Clearly, this does not change the facts in our problem: people who
had diﬀerent scores in the original scoring system have diﬀerent
scores now, and people who had identical scores in the original
scoring system have identical scores now. Indeed, if player x won
ax games, got a draw bx times, and lost cx times, then his total
score in the old system is ax + (bx/2), and his total score in the
new system is ax −cx. Assume player y got the same total score
in the old system. That means
ax + bx
2 = ay + bx
2 .
Multiply this equation by 2, and subtract the equation ax+bx+cx =
ay + by + cy from it. (The latter simply shows that both players
played the same number of games.) We get
ax −cx = ay −cy,
which shows that the two players had the same score in the new
system, too.
Let us assume that all n players had diﬀerent ﬁnal scores.
Let
k = n/2 if n is even, and let k = (n −1)/2 if n is odd. Then we

There Are A Lot Of Them. Elementary Counting Problems
67
can assume without loss of generality that there are k players with
positive ﬁnal scores. As these scores are all diﬀerent, their sum is
at least 1 + 2 +· · ·+ k = k(k + 1)/2. As only wins result in positive
scores, there had to be at least k(k + 1)/2 wins at the tournament.
The number of all games is, on the other hand,
n
2

. Therefore, the
ratio of wins (games not ended in a draw) and all games is
k(k + 1)
(n −1)n > 1
4.
(3.7)
(b) Yes, the same argument will work, except that the total number of
games played will be less than
n
2

, therefore the denominator in
formula (3.7) will decrease, therefore the ratio of wins will be even
larger.
(c) The problem with the previous argument here is that if not all
players complete the same number of games, then the new scoring
system is not the same as the classical one. Indeed, the argument
of part (a) would not work here as ax +bx+cx = ay +by +cy would
not hold. The statement is no longer true. A counterexample can
then be found for n = 4 as follows. Let games A−B, A−C end by
draws, and let game B −D be won by B. Then B has 1.5 points,
A has 1, C has 0.5, and D has 0. (Note that in the 1 −0 −(−1)
scoring system, A and C would both have 0 points.)
(d) No. Our counterexample will be a generalization of the preceding
example, and also, of Example 1.7 of Chapter 1. Say we have n
players, (n is even) A1, A2, · · · , An−1 and B. Let An−1 play with
everyone, except for A1, let An−2 play with everyone except for A1
and A2, in general, let Ai play with Aj if i+ j > n, and let Ai play
with B if i > n/2. Let all these games end by a draw. Then Ai has
i/2 points for all i, and B has n
4 −1
2 points. The only problem now
is that B has the same number of points as one of the players Ai.
To correct that, let B play with all the Ai he did not (there are n
2
of those), and defeat them all. Then B becomes a clear winner of
the tournament, and the points of the Ai do not change, so they
stay all diﬀerent. Also note that the number of games played is
quadratic in n, whereas that of wins is linear in n, proving that the
ratio of draws can be arbitrarily close to 1 if n is large enough.
(23) First Solution. We can place the ﬁrst rook anywhere on the board,
that is, we have 82 = 64 choices for its position. The second rook
cannot be in the row or column of the ﬁrst one, leaving 72 = 49
choices for its position. Similarly, we will have 62 = 36 choices for

68
A Walk Through Combinatorics
the position of the third rook, and so on. Therefore, if our rooks were
distinguishable, we would have 82 · 72 · · · 12 = 8!2 ways to place them.
However, they are indistinguishable, so it does not matter which rook
is in which position as long as the set of all rooks covers the same eight
positions. Consequently, we have counted every placement n! times,
and the number of all placements is 8!2/8! = 8! = 40320.
Second solution. Each f : [8] →[8] can be bijectively associated
to a non-attacking rook placement as follows. For all i ∈[8], put a
rook into the square (i, f(i)). This ensures that there will be exactly
one rook in each row and column. It is also easy to see that this is a
bijection, that is, all rook placements deﬁne one one-to-one function
from [8] onto itself. So the number of rook placements is n! by Exercise
1.
(24) Take any magic square of line sum r and side length 3. It is clear
that the four elements shown in the ﬁgure determine all the rest of
the square.
a
b
c
d
Indeed, the next table shows our only possible choice for each remain-
ing entry. Thus all we need to do is to compute the number of ways
we can choose a, b, c and d so that we indeed have that one choice, i.e.,

There Are A Lot Of Them. Elementary Counting Problems
69
the obtained entries of the magic square are all nonnegative.
a
b
c
d
r −a −d
a + d −c
r −b −d
b + d −c
r + c−
(a + d + b)
The previous table shows that the entries of our matrix will be non-
negative if and only if the following inequalities hold:
a + d ≤r
(3.8)
b + d ≤r
(3.9)
c ≤a + d
(3.10)
c ≤b + d
(3.11)
a + d + b −c ≤r.
(3.12)
We will consider three diﬀerent cases, according to the position of the
smallest element on the main diagonal. In each of them, at least three
of the ﬁve conditions above will become redundant, and we will only
need to deal with the remaining one or two.
(a) Suppose 0 ≤a ≤b and 0 ≤a ≤c. In this case conditions (3.8),
(3.11), and (3.12) are clearly redundant, because they are implied
by (3.9) and (3.10).
The crucial observation is that in all the three cases we can collect
all our conditions into one single chain of inequalities. In this case
we do it as follows:
a ≤2a + d −c ≤a + b + d −c ≤b + d ≤r.
(3.13)

70
A Walk Through Combinatorics
Indeed, the ﬁrst inequality is equivalent to (3.10), the second one
is equivalent to our assumption a ≤b, the third one is equivalent
to our assumption a ≤c, and the last one is equivalent to (3.9).
Moreover, note that once we know the terms of this chain, that is,
a, 2a+d−c, a+b+d−c and b+d, then we know a, b, c and d, too,
thus we have determined the magic square. Thus all we need to
do is simply count how many ways there are to choose these four
terms. Inequality (3.13) shows that these terms are nondecreasing,
therefore the number of ways to choose them is simply the number
of 4-combinations of r + 1 elements with repetitions allowed, which
is
r+4
4

. (Recall that 0 is allowed to be an entry.)
(b) Now suppose a > b and c ≥b. Then (3.9), (3.11) and (3.12) are
redundant. Consider the chain of inequalities
b ≤2b + d −c ≤a + b + d −c −1 ≤a + d −1 ≤r −1.
(3.14)
We can use the argument of the previous case to prove that (3.14)
equivalent to (3.8), (3.12) and our assumptions, as the roles of a
and b are completely symmetric. The only change is that here we
do not count those magic squares in which a = b, and this explains
the (−1) in the last three terms. Thus here we have to choose four
elements in non-decreasing order out of the set {0, 1, · · · , r −1},
which can be done in
r+3
4

ways.
(c) Finally, suppose that a > c and b > c. Then (3.8), (3.9), (3.10)
and (3.11) are redundant. Condition (3.12) and our assumptions
can be collected into the following chain:
c ≤b −1 ≤b + d −1 ≤a + b + d −c −2 ≤r −2.
(3.15)
Here the ﬁrst inequality is equivalent to our assumption c < b, the
second one says that d is nonnegative, the third one is equivalent
to our assumption c < a, and the last one is equivalent to (3.12).
The four terms of (3.15) determine a, b, c and d, and they can be
chosen in
r+2
4

ways, which completes the proof.
Thus the number of 3 × 3 magic squares of line sum r is indeed
r+4
4

+
r+3
4

+
r+2
4

. Furthermore, the three terms in this sum count
the magic squares in which the (ﬁrst) minimal element of the main
diagonal is the ﬁrst, second, or third element.
(25) The set [15] has ﬁve elements divisible by three, ﬁve elements of the
form 3k + 1, and ﬁve elements of the form 3k + 2. Let S0, S1, and
S2 denote the sets of these elements. Then we can select one element

There Are A Lot Of Them. Elementary Counting Problems
71
or no element of S0, which gives us six possibilities. After this, we
can either not select any more elements, or we can select a non-empty
subset of S1 in 25 −1 = 31 ways, or we can select a non-empty subset
of S2 in 31 ways. So the total number of choices we have for selecting
elements from S1 and S2 is 1+31+31 = 63, leading to the ﬁnal count
of 6 · 63 = 378.
(26) In such permutations, if an increasing subsequence starts, it must last
till the end. So, a permutation satisﬁes this requirement if and only if
it decreases all the way to its entry 1, then it increases all the way to
the end, like 421356. This means that the set S of entries on the left of
1 completely determines the permutation. As S can be any subset of
{2, 3, · · · , n}, there are 2n−1 possibilities for S, so that is the number
of permutations with the desired property.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 4
No Matter How You Slice It. The
Binomial Theorem and Related
Identities
In the last chapter, we started developing enumeration techniques by ﬁnd-
ing formulae that covered six basic situations. We will continue in that
direction in Chapter 5. However, in the current chapter, we take a break
and discuss the binomial and the multinomial theorems, as well as several
important identities on binomial coeﬃcients. The proofs of these identities
are probably even more signiﬁcant than the identities themselves. They
will consist of showing that both sides of a given equation count the same
kind of objects; they just do it in two diﬀerent ways. Therefore, the two ex-
pressions must be equal to each other. This type of argument is the dream
of most combinatorialists when they prove identities.
4.1
The Binomial Theorem
Theorem 4.1 (Binomial Theorem). For all nonnegative integers n,
(x + y)n =
n

k=0
n
k

xkyn−k.
(4.1)
Proof. Consider the product of n sums, (x + y)(x + y) · · · (x + y). When
computing this product, we take one summand from each parentheses, mul-
tiply them together, then repeat this in all of 2n possible ways and add the
results. We get a product equal to xkyn−k each time we take k summands
equal to x. There are
n
k

k-element subsets of the set of all n parentheses,
so we will get such a term
n
k

times, and the proof is complete.
The binomial theorem has a vast array of applications, starting as early
as elementary calculus. In this section we will see some of its immediate
applications to prove identities on binomial coeﬃcients.
73

74
A Walk Through Combinatorics
Theorem 4.2. For all positive integers n, the alternating sum of binomial
coeﬃcients
n
k

is zero. In other words,
n

k=0
(−1)k ·
n
k

= 0.
Proof. Applying the binomial theorem with x = −1 and y = 1 we imme-
diately get our claim.
Theorem 4.3. For all nonnegative integers n and k, the identity
n
k

+

n
k + 1

=
n + 1
k + 1

(4.2)
holds.
Proof. The right-hand side is, by deﬁnition, the number of k + 1-element
subsets of [n + 1]. Such a subset S either contains the element n + 1, or
it does not. If it does, then the rest of S is a k-element subset of [n], and
these are enumerated by the ﬁrst member of the left-hand side. If it does
not, then S is a k + 1-element subset of [n], and these are enumerated by
the second member of the left-hand side.
Theorem 4.4. For all nonnegative integers n,
2n =
n

k=0
n
k

.
Proof. Both sides count the number of all subsets of an n-element set. The
left-hand side counts directly, while the right-hand side counts the number
of k-element subsets, then sums over k.
We can get an even shorter proof applying our fresh knowledge.
Proof. (of Theorem 4.4) Apply the binomial theorem with x = y = 1.
The ﬁrst proof is an example of a classic way of proving combinatorial
identities: by proving that both sides of the identity to be proved count the
same objects. If we count the same objects in two diﬀerent ways, we should
get the same result, so this is a valid reasoning. Such proofs are ubiquitous
and well-liked in enumerative combinatorics. This section will contain a
handful of them, and many additional examples are listed as exercises.
Now let us write down all binomial coeﬃcients in a triangle as shown in
Figure 4.1. That is, the ith element of row n is
n
i

, and the diagram starts
with row 0.

No Matter How You Slice It. The Binomial Theorem and Related Identities
75
6
15
20
15
6
5
10
10
5
4
6
4
1
1
1
1
1
1
1
3
3
1
1
2
1
1
1
1
Fig. 4.1
The ﬁrst few rows of the Pascal triangle.
This diagram is called a Pascal triangle and has many beautiful prop-
erties. For example, Theorem 4.4 shows that the sum of the nth row is
2n, when we call the one-element row at the top the zeroth row. Theorem
4.3 shows that each entry of the triangle is the sum of the entries above it.
And Theorem 4.2 shows that the alternating sum of the rows is always 0.
Let us prove one more interesting property of the Pascal triangle.
Theorem 4.5. For all nonnegative integers k and n,
k
k

+
k + 1
k

+
k + 2
k

+ · · · +
n
k

=
n + 1
k + 1

.
(4.3)
Proof. The right-hand side clearly counts all k+1-element subsets of [n+1].
The left-hand side counts the same, separated into cases according to the
largest element. That is, there are
k
k

subsets of [n + 1] that have k + 1
elements whose largest element is k + 1; there are
k+1
k

subsets of [n + 1]
that have k + 1 elements whose largest element is k + 2, and so on. In
general, there are
k+i
k

subsets of [n + 1] that have k + 1 elements whose
largest element is k + i + 1, for all i ≤n −k. Indeed, if the largest element
of such a subset is k + i + 1, then its remaining k elements must form a
subset of [k + i].
This means that if we start with the rightmost element of the kth row
of the Pascal triangle, and descend diagonally to the southwest for a while,
then the sum of all numbers we touch in this procedure is also an entry of
the Pascal triangle. The reader should ﬁnd out where that entry is located.

76
A Walk Through Combinatorics
Finally, let us prove some identities about binomial coeﬃcients that do
not directly follow from the binomial theorem, but nevertheless are a lot of
fun.
Theorem 4.6. For all nonnegative integers n, the identity
n

k=1
k
n
k

= n2n−1
(4.4)
holds.
Before proving the theorem, note that it is not even obvious why
n
k=1 k
n
k

2n−1
should be an integer. Our proof will show that it is not only an integer, it
is equal to n. This hopefully convinces the reader that binomial coeﬃcient
identities are beautiful.
Proof. (of Theorem 4.6) Both sides count the number of ways to choose a
committee among n people, then to choose a president from the committee.
On the left-hand side, we ﬁrst choose a k-member committee in
n
k

ways,
then we choose its president in k ways. On the right-hand side, we ﬁrst
choose the president in n ways, then we choose a subset of the remain-
ing (n −1)-member set of people for the role of non-president committee
members in 2n−1 ways.
We provide another proof that uses the binomial theorem. It also gives
us an early hint that sometimes very ﬁnite-looking problems, such as choice
problems, can be solved by using methods from inﬁnite calculus, such as
functions and their derivatives.
Proof. (of Theorem 4.6) Apply the binomial theorem with y = 1 to get
the identity
(x + 1)n =
n

k=0
n
k

xk.
(4.5)
Both sides are diﬀerentiable functions of the variable x. So we can take
their derivatives with respect to x, and they must be equal. This yields
n(x + 1)n−1 =
n

k=1
k ·
n
k

xk−1.
Now substitute x = 1 to get (4.4).

No Matter How You Slice It. The Binomial Theorem and Related Identities
77
These direct combinatorial arguments are so enjoyable that we cannot
refrain from discussing one more of them.
Theorem 4.7 (Vandermonde’s identity). For all positive integers n,
m, and k,
n + m
k

=
k

i=0
n
i
 m
k −i

.
Proof. The left-hand side counts all k-element subsets of [n + m]. The
right-hand side counts the same, according to the number of elements cho-
sen from [n]. Indeed, we can ﬁrst choose i elements from [n] in
n
i

ways,
then choose the remaining k−i elements from the set {n+1, n+2, · · · , n+m}
in
 m
k−i

ways.
Considering any one row of the Pascal triangle, we note that the bi-
nomial coeﬃcients
n
0

,
n
1

, · · · seem to increase as k increases, up to the
middle of the row, after which they seem to decrease. As the following
theorem shows, this is indeed true for all n.
Theorem 4.8. For all nonnegative integers k and n, such that k ≤n−1
2 ,
the inequality
n
k

≤

n
k + 1

(4.6)
holds. Furthermore, equality holds if and only if n = 2k + 1.
Proof. We provide a computational proof here. We need to show that if
the conditions hold, then
n!
k! · (n −k)! ≤
n!
(k + 1)! · (n −k −1)!.
Let us divide both sides by n!, then multiply both sides by k! · (n −k −1)!
to get
1
n −k ≤
1
k + 1.
Taking reciprocals and rearranging, we get 2k + 1 ≤n, which is equivalent
to the condition k ≤n−1
2 , so the theorem is proved.

78
A Walk Through Combinatorics
Corollary 4.9. For all positive integers k and n, such that k ≥n−1
2 , the
inequality
n
k

≥

n
k + 1

(4.7)
holds. Furthermore, equality holds if and only if n = 2k + 1.
Proof. This is immediate from Theorem 4.8, and the fact that
n
k

=
 n
n−k

.
A sequence of numbers with this property, that is, that it ﬁrst increases
steadily, then it decreases steadily, is called unimodal. The formal deﬁnition
is that the sequence a0, a1, · · · , an of real numbers is called unimodal if there
exists an index m so that a0 ≤. . . ≤am and am ≥. . . ≥an. It can often be
quite diﬃcult to prove that a given sequence is unimodal. A more elegant,
but less straightforward, non-computational proof of Theorem 4.8 is given
in Exercise 20. A stronger statement is proved in Exercise 21.
Quick Check
(1) Prove that for any positive integers n,
n

k=0
2k
n
k

(−1)n−k = 1.
(2) Prove that for any positive integers n,
n

k≥0
n−k even
3k2n−k
n
k

= 1 +
n

k≥0
n−k odd
3k2n−k
n
k

.
(3) Find a combinatorial proof for the identity
n

k=1
k2
n
k

= n(n + 1)2n−2.
4.2
The Multinomial Theorem
What if we want to compute the powers of (x + y + z), or (u + x + y + z)
instead of just (x + y)? The same line of thinking will help, only the result
will be a little more complicated to describe.
Example 4.10. We have
(x+y+z)3 = x3 +y3+z3+3x2y+3x2z+3y2x+3y2z+3z2x+3z2y+6xyz.
(4.8)

No Matter How You Slice It. The Binomial Theorem and Related Identities
79
Solution. We want to compute the product (x+y+z)·(x+y+z)·(x+y+z).
To do this, we have to pick one member of each of the three sums, take
their product, do this in all 33 = 27 possible ways, then add the obtained
27 products.
All the 27 products we obtain will be terms of degree three. The only
question is what the coeﬃcients of these terms will be.
Why is it, for
example, that the right-hand side of (4.8) contains 3x2y and 6xyz?
Let us ﬁrst examine how can one of our products be equal to x2y. This
happens when two of our three picks is an x, and the third one is a y. There
are three ways this can happen as we can pick the single y from any of our
three parentheses, then we must pick the two x terms from the remaining
three variables. Therefore, the coeﬃcient of 3x2y in (x + y + z)3 is indeed
three. Clearly, identical argument applies for all terms of degree three that
contain one variable on the second power.
There is only one way for one of our 27 products to be equal to x3.
Indeed, that happens if and only if we choose an x from each of our three
parentheses. Therefore, the coeﬃcient of x3 in (x + y + z)3 is one, and the
same is true for y3 and z3.
Finally, what about the term xyz?
To get such a term, we have to
choose an x from one of our three parentheses, which can be done in three
ways. Then, we have to choose a y from the remaining two parentheses,
which can be done in two ways.
At the end, we must pick z from the
last parentheses. Therefore, there are six ways we can obtain an xyz-term,
completing the proof.
Just as in Theorem 3.21, we need a higher level of abstraction before
we can state a general theorem along the lines of Example 4.10. First of
all, we want a theorem that works for any number of variables, not just
three. Therefore, instead of calling our variables x, y, z, we will call them
x1, x2, · · · , xk. The following deﬁnition generalizes the notion of binomial
coeﬃcients.
Deﬁnition 4.11. Let n = k
i=1 ai, where n and a1, a2, · · · , ak are nonneg-
ative integers. We deﬁne

n
a1, a2, · · · , ak

=
n!
a1! · a2! · · · ak!.
(4.9)
The numbers

n
a1,a2,··· ,ak

are called multinomial coeﬃcients.
The reader should verify that if k = 2, then this deﬁnition reduces to
that of binomial coeﬃcients.

80
A Walk Through Combinatorics
Now we are in a position to state and prove the general theorem we
have been looking for.
Theorem 4.12 (Multinomial theorem). For all nonnegative integers n
and k, the equality
(x1 + x2 + · · · + xk)n =

a1,a2,··· ,ak

n
a1, a2, · · · , ak

xa1
1 xa2
2 · · · xak
k
(4.10)
holds.
Here the sum is taken over all k-tuples of nonnegative integers
a1, a2, · · · , ak such that n = k
i=1 ai.
Proof. We have to show that the term xa1
1 xa2
2 · · · xak
k
can be obtained in
exactly

n
a1,a2,··· ,ak

ways as a product of k variables, one from each paren-
theses of (x1 + x2 + · · ·+ xk) · · · (x1 + x2 + · · ·+ xk). To obtain such a term,
we have to choose xi from exactly i parentheses, for all i ∈[k].
Now let us take ai copies of xi, for all i ∈[k], and order these n letters
linearly. Theorem 3.5 shows that this can be done in exactly

n
a1,a2,··· ,ak

ways. On the other hand, each linear ordering p deﬁnes a natural way of
choosing variables from the parentheses. Indeed, if the jth letter of p is
xi, then from the jth parentheses, we choose xi. This way our

n
a1,a2,··· ,ak

linear orderings will produce exactly

n
a1,a2,··· ,ak

terms that are equal to
xa1
1 xa2
2 · · · xak
k .
It is clear that this procedure establishes a bijection from the set of linear
orderings of n letters, ai of which is equal to xi for all i ∈[k] onto that of
terms of (x1+x2+· · ·+xk)n that are equal to xa1
1 xa2
2 · · · xak
k . Therefore, the
coeﬃcient of xa1
1 xa2
2 · · · xak
k
in (x1 + x2 + · · · + xk)n is precisely

n
a1,a2,··· ,ak

,
and the proof follows.
There is a close connection between multinomial and binomial coeﬃ-
cients as explained by the following theorem.
Theorem 4.13. For all nonnegative integers n and a1, a2, · · · , ak such that
n = k
i=1 ai, the equality

n
a1, a2, · · · , ak

=
 n
a1

· · ·
n −a1 −· · · −ai
ai+1

· · ·
n −a1 −· · · −ak−1
ak

(4.11)
holds.
Note that n −a1 −a2 −· · · −ak−1 = ak, so the last binomial coeﬃcient
on the right-hand side of (4.11) is equal to
ak
ak

= 1.

No Matter How You Slice It. The Binomial Theorem and Related Identities
81
Proof. The left-hand side counts all linear orderings of a multiset that
consists of ai copies of the symbol xi, for all i ∈[k]. We show that the
right-hand side counts the same objects. Indeed, let us ﬁrst choose the a1
positions we place all our symbols x1. This can be done in
 n
a1

ways. Let us
now choose the a2 positions where we place our symbols x2. As a1 positions
are already taken, this can be done in
n−a1
a2

ways. Then we can choose the
a3 positions where we place our symbols x3. As a1+a2 positions are already
taken, this can be done in
n−a1−a2
a3

ways. Iterating this procedure, we will
choose the positions of all symbols, and we see that the total number of
possible outcomes is indeed the right-hand side of (4.11).
Quick Check
(1) What is the coeﬃcient of x1x2x3 in (x1 + 2x2 + 3x3)3?
(2) Prove the identity

a+b+c=n
a

n
a, b, c

= n3n−1,
where the sum is taken over all triples (a, b, c) of nonnegative integers
satisfying a + b + c = n.
(3) Prove the identity

a+b+c=n
ab

n
a, b, c

= n(n −1)3n−2,
where the sum is taken over all triples (a, b, c) of nonnegative integers
satisfying a + b + c = n.
4.3
When the Exponent Is Not a Positive Integer
This subject belongs to this chapter in that it discusses a case of the bi-
nomial theorem. However, that case of the binomial theorem, namely the
case when the exponent is not a positive integer, will not show up in appli-
cations until Chapter 8. So readers can choose whether to learn about this
case now, or right before Chapter 8.
What can we say about (1 + x)m when m is not a positive integer?
That is, how can we expand an expression like (1 + x)−2/3? In order to
ﬁnd a nice, compact answer to this question, ﬁrst we deﬁne the binomial
coeﬃcient
m
k

for all real numbers m.

82
A Walk Through Combinatorics
Deﬁnition 4.14. Let m be any real number, and let k be a nonnegative
integer. Then
m
0

= 1, and
m
k

= m(m −1) · · · (m −k + 1)
k!
,
if k > 0.
This deﬁnition expands the deﬁnition of binomial coeﬃcients for positive
integers. Let us consider the Taylor series of (1 + x)m around x = 0. Note
that the nth derivative of (1 + x)m is (m)n(1 + x)m−n, and this expression
takes the value (m)n =
m!
(m−n)! when x = 0.
Therefore, using Taylor’s
theorem, we get the following identity.
Theorem 4.15 (Binomial Theorem, General Version). Let
m
be
any real number. Then
(1 + x)m =

n≥0
m
n

xn,
where the sum is taken over all nonnegative integers n.
Thus (1 + x)m is an inﬁnite power series if m is not a positive integer.
Note that if m is a positive integer, then
m
n

= 0 if n > m, and therefore
we only get a sum of m + 1 elements for (1 + x)m.
Example 4.16. Find the power series expansion of √1 −4x.
Solution. By Theorem 4.15,
√
1 −4x = (1 −4x)1/2 =

n≥0
1/2
n

(−4x)n.
(4.12)
To simplify this expression, we have to ﬁnd a simpler form for
1/2
n

. Note
that
1/2
0

= 1, while
1/2
1

= 1/2, and if n ≥2, then
1/2
n

=
1
2 · −1
2 · −3
2 · · · −2n+3
2
n!
= (−1)n−1 (2n −3)!!
2n · n!
,
where (2n −3)!! stands for the product of all odd integers from 1 to 2n −3,
and is called 2n −3 semifactorial.
Substituting this into formula (4.12), we get
√
1 −4x = 1 −2x −

n≥2
2n · (2n −3)!!
n!
xn.

No Matter How You Slice It. The Binomial Theorem and Related Identities
83
For n ≥2, let us multiply both the numerator and the denominator of
2n·(2n−3)!!
n!
by (n−1)!, and note that in the numerator, 2n−1(n−1)! is equal
to the product of all even integers from 2 to 2n −2. Therefore, if n ≥2,
then
2n · (2n −3)!!
n!
= 2 (2n −2)!
n!(n −1)!,
and so
√
1 −4x = 1 −2x −2
n

n≥2
2n −2
n −1

xn.
Another useful practice problem is to compute (1 −x)r, for a negative
integer r.
Quick Check
(1) Compute the power series form of (1 −x)−3.
(2) Compute the power series form of (1 −x)−m, for a general positive
integer m.
(3) Compute the power series form of √1 + x.
Notes
Exercises 20 and 21 concern two interesting areas of Combinatorics. One of
them is unimodality and log-concavity, and the other is the combinatorics
of lattice paths. Interested readers can consult Chapter 8 of [11] for an
introductory text on the topic. Another good starting point is [45], where
lattice paths are used to prove unimodality results in a very accessible way.
For high-level surveys, we recommend Chapter 7 of [12], written by Petter
Br¨and´en, on unimodality and log-concavity, and Chapter 10 of the same
book, written by Christian Krattenthaler, on lattice path enumeration.
A high-powered method to prove some identities involving binomial co-
eﬃcients is the WZ-method, developed by Herbert Wilf and Doron Zeil-
berger. The interested reader should consult the book A=B, by Wilf, Zeil-
berger, and Marko Petkovˇsek, [40].
Exercises
(1)(a) Is it possible to write a real number into each square of a 5 × 5 grid
so that the sum of the numbers in the entire grid is negative, but the

84
A Walk Through Combinatorics
sum of the numbers in any 2 × 2 square (formed by 4 neighboring
boxes) is positive?
(b) What about a 6 × 6 grid?
(2) (+)
(a) We plant 13 trees at various points in the interior of a garden whose
shape is a convex octagon. Then we create some non-intersecting
paths joining some of these trees and the eight corners of the garden
so that these paths partition the garden into triangles. How many
triangles will be created?
(b) What if we also add ﬁve trees to the boundary of the garden?
(These ﬁve trees are not in corners.)
(3) Prove that for all integers n ≥2,
2n−2 · n · (n −1) =
n

k=2
k(k −1)
n
k

.
How can we generalize this identity?
(4) Let k, m, n be nonnegative integers such that k + m ≤n. Prove that
n
m

·
n −m
k

=
n
k
n −k
m

.
(5) Prove that for integers 0 ≤k ≤n −1,
k

j=0
n
j

=
k

j=0
n −1 −j
k −j

2j.
(6) Prove that for all positive integers k < n, the equality
n

i=k
n
i
i
k

= 2n−k
n
k

holds.
(7) A heap consists of n stones. We split the heap into two smaller heaps,
neither of which are empty. Denote by p1 the product of the number
of stones in each of these two heaps. Now take any of the two small
heaps, and do likewise. Let p2 be the product of the number of stones
in each of the two smaller heaps just obtained. Continue this procedure
until each heap consists of one stone only. This will clearly take n −1
steps, where a step is the splitting of one heap. For what sequence of
splits will the sum p1 + p2 + · · · + pn−1 be maximal? When is that sum
minimal?

No Matter How You Slice It. The Binomial Theorem and Related Identities
85
(8) Prove that any positive integer n has at least as many divisors of the
form 4k + 1 as divisors of the form 4k −1.
(9) Prove that for all positive integers n, the inequality
2n
n

< 4n holds.
(10) How many subsets of [n] are larger than their complements?
(11) Which term of (x1 + x2 + · · · + xk)k has the largest coeﬃcient? What
is that coeﬃcient?
(12) Let n < k. What is the largest coeﬃcient in (x1 + x2 + · · · + xk)n?
(13) Let n = rk, where r > 1 is an integer. What is the largest coeﬃcient
in (x1 + x2 + · · · + xk)n?
(14) Let k be a nonnegative integer, let m be a positive integer so that
k < 2m, and let n = 2m −1. Prove that
n
k

is odd.
(15) Let k and m be positive integers so that k < 2m, and let n = 2m. Prove
that
n
k

is even.
(16) Let p ≥3 be a prime number, and let m and k < pm be positive
integers. Show that
pm
k

is divisible by p.
(17) Let p be a prime number, and let x > 1 be any positive integer. Con-
sider a wheel with p spokes shown in Figure 4.2.
Fig. 4.2
A wheel with ﬁve spokes.
(a) We have paints of x diﬀerent colors. How many ways are there to
color the spokes if we want to use at least two colors?
(b) How many ways are there to do the same if we do not consider

86
A Walk Through Combinatorics
two paint jobs diﬀerent if one can be obtained from the other by
rotation?
(c) What theorem of number theory does this prove?
(18) Prove that

a1+a2+a3=n

n
a1, a2, a3

= 3n.
(19) Prove that

a1+a2+a3=n

n
a1, a2, a3

(−1)a2 = 1.
(20) (+) A walk on the grid of points with integer coordinates that uses the
steps (0, 1) and (1, 0) only is called a northeastern lattice path.
Let k and n be positive integers so that k < n/2. Deﬁne an injection
from the set of northeastern lattice paths from (0, 0) to (k, n −k) into
the set of northeastern lattice paths from (0, 0) to (k + 1, n −k −1).
(Recall that the function f is called an injection if f(x) = f(y) implies
x = y; in other words, diﬀerent elements have diﬀerent images.) Why
does this prove that the sequence
n
0

,
n
1

, · · · ,
n
n

is unimodal?
(21) Prove that if k and n are positive integers, and k ≤n−1, then we have

n
k −1

n
k + 1

≤
n
k
n
k

.
(4.13)
We note that the sequence a0, a1, a2, · · · , an of positive real numbers is
called logarithmically concave or log-concave if for 1 ≤i ≤n −1, the
inequality ai−1ai+1 ≤a2
i holds. So the exercise asks us to prove that
the sequence
n
0

,
n
1

, · · · ,
n
n

is log-concave.
(22) (+) Give a non-computational proof of the previous exercise, using
northeastern lattice paths.
(23) Prove that if the sequence a0, a1, a2, · · · , an of positive real numbers is
log-concave, then it is unimodal.
(24) (+) Let Cn be the number of northeastern lattice paths from (0, 0)
to (n, n) that never go above the diagonal x = y. Prove that Cn =
2n
n

−
 2n
n−1

=
2n
n

/(n + 1).
(25) (+) Let a ≥b be two positive integers.
Prove that the number of
northeastern lattice paths from (0, 0) to (a, b) that never go above the
main diagonal is
a+b
b

−
a+b
b−1

.
(26) Find a closed form for ∞
n=1 nxn−1.
(27) Prove that
1
√1−4x = 
n≥0
2n
n

xn.
(28) Find the power series form of f(x) =

1+x
1−x.

No Matter How You Slice It. The Binomial Theorem and Related Identities
87
Supplementary Exercises
(29) (-) Prove that for all positive integers n > 1, the inequality 2n <
2n
n

holds.
(30) (-) Prove that for all positive integers n, the number
2n
n

is even.
(31) (-) Prove that for all positive integers n > k ≥2, the inequality
kn <
kn
n

holds.
(32) (-) The sum of each row of a 10 × 6 matrix (that means ten rows, six
columns) is 36. If each column of the matrix has the same sum r,
what is that sum?
(33) (-) How many northeastern lattice paths are there from (0, 0) to (n, k)?
(34) Prove, by a combinatorial argument, that for all positive integers n,
the number
 3n
n,n,n

is divisible by six.
(35) A computer programmer claims that he generated six real numbers
a1, a2, · · · , a6 so that the sum of any four consecutive ai is positive,
but the sum of any three consecutive ai is negative. Prove that his
claim is false.
(36) A school has 105 students, and seven classes. If each student takes
three classes, and each class is taken by the same number of students,
how many students are taking each class?
(37) How many northeastern lattice paths are there from (0, 0) to (10, 10)
that do not touch the point (5, 5), but do touch the point (3, 3)?
(38) (+) What is the number of northeastern lattice paths from (0, 0) to
(n, n) that never touch the main diagonal other than in the starting
and ending point?
(39) Prove that for all positive integers n,
2n
n

=
n

k=0
n
k
2
.
(40) Prove that for all positive integers n,
n
2n −1
n −1

=
n

k=1
k
n
k
2
.
(41) Prove that for all positive integers n,
3n =
n

k=0
2k
n
k

.
(42) Prove that for all positive integers k ≤n, the equality
k

i=0
n
i

(−1)i =
n −1
k

(−1)k
holds.

88
A Walk Through Combinatorics
(43) Take the integral of both sides of the equation
(1 + x)n =
n

k=0
n
k

xk.
Explain what constant C you will need to take on the right-hand side
to keep the equation valid.
(44) Prove that for all positive integers n > 1,
n

k=0
1
k + 1
n
k

(−1)k+1 =
−1
n + 1.
(45) Find a closed formula for the expression
n

k=0
1
k + 1
n
k

tk+1,
where t is any ﬁxed real number.
(46) Prove that for all positive integers n, the equality
n

k=0
k even
n
k

2k = 3n + (−1)n
2
holds.
(47) Prove that for all positive integers n, the equality
n

k=1
k odd
n
k

5k = 6n −(−4)n
2
holds.
(48) (+) Let n = 4k, with k being a nonnegative integer. Prove that
2k

i=0
n
2i

(−1)i =
n
0

−
n
2

+
n
4

−· · · = 22k(−1)k.
(49) (++)
(a) Let n = 3k. Prove that
lim
n→∞
k
i=0
n
3i

2n
= 1
3.
In other words, the sum of every third element of the nth row of
the Pascal triangle is roughly one third of the sum of all elements
of that row.
(b) Generalize the result of part (a).

No Matter How You Slice It. The Binomial Theorem and Related Identities
89
(50) What is the coeﬃcient of xn in the power series form of
3√1 −2x?
(51) If we expand the expression
(x1 + x2 + x3 + x4)6,
what will be the largest coeﬃcient that occurs?
(52) Consider the expression
(x1 + x2 + · · · + xk)n.
(a) Let us assume that when we expand this power, there will be an
integer that occurs as a coeﬃcient only once. What relation does
that imply between k and n?
(b) Can it happen that there will be more than one coeﬃcient that
occurs only once in the expansion?
(53) (+) What digit is immediately on the right of the decimal point in
(
√
3 +
√
2)2002?
(54) (+) What digits are immediately on the left and right of the decimal
point in (
√
11 +
√
10)2002?
(55) Let n ≥2.
We want to select as many subsets of [n] as possible,
without selecting two subsets so that one of them contains the other.
(a) Prove that we can always select at least 2n/n subsets.
(b) Can we improve the result of part (a)?
(56) Is it possible to choose 70 subsets of [7] so that there will not be three
distinct subsets A, B, and C among the selected ones that satisfy
A ⊂B ⊂C?
(57) (+) A company specializing in international trade has 70 employees.
For any two employees A and B, there is a language that A speaks
but B does not, and also a language that B speaks but A does not.
At least how many diﬀerent languages are spoken by the employees of
this company?
(58) Find the number of pairs of non-intersecting northeastern lattice paths
(p, q) so that p goes from (0, 0) to (k, n −k) and q goes from (−1, 1)
to (k −1, n −k + 1).
(59) We have written 2n + 1 numbers around a circle. Among these num-
bers, n are equal to 1, and n + 1 are equal to −1. Prove that there
is exactly one among these 2n + 1 numbers with the following prop-
erty. If we call this number a1, and we call the numbers following it
in clockwise order a2, a3, · · · , a2n+1, then for all k ∈[2n], the sums
k
i=1 ai are nonnegative.

90
A Walk Through Combinatorics
(60) Explain the connection between the previous exercise and Exercise 24.
(61) Let p > 2 be a prime number. For what values of n will each binomial
coeﬃcient
n
k

, with 0 < k < n, be divisible by p?
(62) Exercise 21 showed that for any ﬁxed n, the sequence
n
0

,
n
1

, · · · ,
n
k

was log-concave. Now let us prove that for any ﬁxed k, the inﬁnite
sequence
k
k

,
k+1
k

,
k+2
k

, · · · is log-concave. That is, show that for
any positive integers n ≥k, the inequality
n
k
n + 2
k

≤
n + 1
k
2
holds. Try to give a combinatorial proof, similar to the proof of Ex-
ercise 21.
(63) In the proof of Theorem 4.6, we showed that both sides counted the
ways to choose a committee out of a set of n people, and then to choose
a president who is a member of that committee. What combinatorial
identity can we prove along the same lines if we assume that the
president cannot be the youngest member of the committee?
Solutions to Exercises
(1)(a) Yes, one example is shown in Figure 4.3.
−1
−1
−1
−1
−1
4                  4
−1
−1     −1      −1      −1     −1
−1     −1      −1      −1     −1
−1     −1      −1      −1     −1
4                  4
Fig. 4.3
All 2 × 2 squares have a negative sum.

No Matter How You Slice It. The Binomial Theorem and Related Identities
91
(b) For 6 × 6 grids, however, the answer is no. Indeed, if B is a 6 × 6
grid, then B can be partitioned into nine squares of size 2×2 each,
in an obvious way. Then the sum of the elements of B must equal
that of the sum of elements of these 2 × 2 squares.
(2)(a) Let us determine the angles of all the k triangles to be created.
These angles will be either at one of the vertices of the octogon, and
then their sum is equal to the sum of the vertices of the octogon,
which is 6 · 180 = 1080 degrees, or they are around one of the
thirteen trees, and then they clearly sum to 13·360 = 4680 degrees.
Thus the total sum of the angles of the k triangles is 1080+4680 =
5760 degrees.
On the other hand, the sum of the degrees of k triangles is 180 · k
degrees, so we have 5760 = 180k, and therefore, k = 32.
(b) The ﬁve trees on the boundary simply add 5 · 180 degrees to the
sum of all angles, so the number of triangles also increases by ﬁve,
to 37.
(3) Same as the proof of Theorem 4.6, except that now we are choosing
a president and vice-president (if we follow the ﬁrst proof), or we
diﬀerentiate (4.5) twice (if we follow the second).
To generalize, for any positive integer m ≤n, we can diﬀerentiate
(4.5) m times, or we can choose m committee members for m diﬀerent
oﬃces, to get
2n−m(n)m =
n

k=m
(k)m
n
k

.
(4) Both sides count the ways to choose an m-member soccer team and a
k-member basketball team from a group of n people, so that nobody
is on two teams. The left-hand side is the result of computing this
number by choosing the soccer team ﬁrst, while the right-hand side is
the result of computing this number by choosing the basketball team
ﬁrst.
(5) The left-hand side is the number of 0-1 sequences of length n with at
most k ones. The right-hand side is more complicated. Note that if
we want to check if a 0-1 sequence S of length n has at most k ones,
and to that end, we test the ﬁrst, second, third, etc. digits of S in this
order, then as soon as we ﬁnd n −k zeros in S, we can be sure that S
has at most k ones. If, on the other hand we do not ﬁnd n −k zeros
in S, then S has more than k ones.
Knowing this, let us count 0-1 sequences with at most k ones according

92
A Walk Through Combinatorics
to the position of their (n −k)th zeros. The above paragraph shows
that such a zero always exists. Let us say that this zero occurs in the
(n −j)th position. Then 0 ≤j ≤k for trivial reasons. There have
to be n −k −1 zeros on the left of this position- that can happen in
n−j−1
n−k−1

=
n−1−j
k−j

ways, and there can be any number of zeros on
the right of this position, which can be done in 2j ways. Summing for
j we obtain our claim.
(6) Both sides count the ways to choose a committee from a set of n peo-
ple, and then to choose a k-element subcommittee from the committee,
where k is ﬁxed. On the left-hand side, we choose the committee ﬁrst,
while on the right-hand side, we choose the subcommittee ﬁrst.
(7) This sum is always the same, namely, it is
n
2

if n > 1. We prove
this by strong induction on n. The initial case is trivial. Assume we
know the statement for all positive integers less than n, and prove it
for n. Let us split our heap of n stones into two small heaps, one of
size k, and one of size n −k. Then p1 = k(n −k). Then, by our
induction hypothesis, the contribution of the ﬁrst heap to the sum
p1 + p2 + · · · + pn−1 is
k
2

, and that of the second heap is
n−k
2

. As
k(n −k) +
k
2

+
n −k
2

=
n
2

,
our claim is proved.
(8) Consider all odd prime divisors of a positive integer n.
They are
either of the form 4k + 1, or of the form 4k −1. Denote them by
a1, a2, · · · , am, and b1, b2, · · · bp, respectively. Let
n = 2t · ax1
1 · · · axm
m · by1
1 · · · byp
p .
An odd divisor of n will be of the form 4k −1 if and only if it contains
an odd number of prime factors of the form 4k −1, multiplicities
counted.
Now we construct an injection from the set of divisors of n of the form
4k −1 into the set of divisors of n of the form 4k + 1. Our injection
will be very simple as it will only change the exponent of one of the
bi. However, the construction of the injection will depend on n.
Let q be a divisor of n of the form 4k −1. Then
q = ac1
1 · · · acm
m · bd1
1 · · · bdp
p ,
with ci ≤xi, di ≤yi, for all i, and the sum of the di is odd.
Assume ﬁrst that n is such that one of the yi is odd; say y1. We then
deﬁne
f(q) = ac1
1 · · · acm
m · by1−d1
1
· · · bdp
p .

No Matter How You Slice It. The Binomial Theorem and Related Identities
93
Then the parity of the exponent of b1 changed, all other parities are the
same, so the sum of the exponents of the bi is now even. Therefore,
f(q) is of the form 4k + 1.
This is clearly an injection (in fact, a
bijection), as f(f(q)) = q.
If n is such that all the yi are even, then we deﬁne a diﬀerent injection
g. Let i be minimal so that di < yi. (There has to be such an i,
otherwise all di are even, and q is of the form 4k + 1.) Then we deﬁne
ac1
1 · · · acm
m · by1
1 · · · byi−1−di
i
· · · bdp
p .
This will again change the parity of the exponent of bi, therefore g(q)
will be of the form 4k + 1. Also note that i can be read oﬀthe image
g(i) as it is still the smallest index for which di < yi. This function g
is an injection. Indeed, to have g(q) = g(q′), the integer g′ must have
the exact same prime decomposition as q, so it must be equal to q′.
It is not a bijection though, for by1
1 · · · byp
p is not in its image.
So for all positive integers, we showed that there is an injection from
the set of divisors of the form 4k −1 into that of divisors of the form
4k + 1, and therefore we proved the statement.
(9) The left-hand side is the number of n-element subsets of [2n], while
the right-hand side is the number of all subsets of [2n].
(10) Arrange all subsets of [n] into pairs, by matching each subset to its
complement. If n is odd, then two subsets of the same pair can never
be the same size, so exactly one of them has the required property
(the larger one). Therefore, half of all subsets, that is, 2n−1 subsets
are larger than their complements.
If n is even, then there will be
2n
n

/2 pairs, namely those pairs consist-
ing of n/2-element subsets and their complements, in which no subset
has the required property. So in this case, the answer is 2n−1 −1
2
2n
n

.
(11) We must ﬁnd the k-tuple of nonnegative integers a1, a2, · · · , ak for
which k
i=1 ai = k, and
k!
a1!·a2!···ak! is maximal. The numerator of
this fraction is constant, while its denominator is at least 1 as it is
a product of positive integers. (Recall that 0! = 1.) Therefore, the
fraction is largest when its denominator is equal to 1. That happens
when a1 = a2 = · · · = ak = 1. In that case, the obtained coeﬃcient is
k!, and it belongs to x1x2 · · · xk.
(12) The largest coeﬃcient is n!, by the same argument as in the previous
exercise.
(13) It is straightforward to verify that if a + b is constant, then a!b! is
minimal when a = b (if a + b is even), or when |a −b| = 1 (when a + b

94
A Walk Through Combinatorics
is odd). Now consider
n!
a1!·a2!···ak!. Again, the numerator is constant, so
we need to minimize the denominator. Using the fact we mentioned
at the beginning of this solution, one sees that the denominator is
minimal when ai = r for all r. Therefore, the largest coeﬃcient is

rk
r, r, · · · , r

= (rk)!
r!k .
(14) Let i ≤2m −1 be a positive integer. There is a unique way to write
i = 2j · p, where p is an odd integer. Then 2m −i = 2m −2j · p =
2j(2m−j −p). This shows that the number of times 2 occurs in the
prime factorization of i is equal to the number of times 2 occurs in
the prime factorization of 2m −i. Now note that
n
k

=
k

i=1
2m −i
i
.
Our argument shows that no factor
2m−i
i
of the right-hand side is
divisible by 2.
Therefore, the prime factorization of
n
k

does not
contain 2, and so
n
k

is odd.
(15) We know from Theorem 4.2 that
n
k

=
n−1
k−1

+
n−1
k

. The previous
exercise shows that both members of the right-hand side are odd, so
the left-hand side is even.
(16) Let j be an integer so that 1 ≤i ≤k, and let j be the unique integer
such that i = pjt, where t is not divisible by j. Then pm −i = pm −
pjt = pj(pm−j −t). So if p occurs j times in the prime factorization
of i, then p occurs j times in the prime factorization of pm −i. Now
pm
k

= pm
k ·
k−1

i=1
pm −i
i
.
Note that the ﬁrst term of the right-hand side is divisible by p, while
in the other terms of the right-hand side, the p-factors cancel out, and
the proof is complete.
(17)(a) There are xp paint jobs, but x of them use only one color, thus the
number of good paint jobs is xp −x.
(b) As p is prime, each paint job can be rotated to p −1 other paint
jobs. Thus the number of diﬀerent paint jobs is (xp −x)/p.
(c) As the number of diﬀerent paint jobs must be an integer, this proves
that xp −x is divisible by p. This is called Euler’s theorem (or,
sometimes, Fermat’s theorem).
(18) This follows directly from the multinomial theorem by substituting
x1 = x2 = x3 = 1.

No Matter How You Slice It. The Binomial Theorem and Related Identities
95
(19) This follows directly from the multinomial theorem by substituting
x1 = x3 = 1, and x2 = −1.
(20) Let p be a northeastern lattice path from (0, 0) to (k, n −k).
Let
t be the bisector of the segment joining A = (k, n −k) and B′ =
(k + 1, n −k −1). As k < n/2, the path p must intersect t at least
once. Let L be the intersection point of p and t that is closest to A.
Now reﬂect the part of p between L and A through t, to get a path
from L to B. Prepending this with the unchanged part of p from (0, 0)
to L, we get a path p′ from (0, 0) to B. It is clear that the function
f deﬁned this way by f(p) = p′ is an injection. Indeed, given a path
q from (0, 0) to B, either q and t do not intersect, and then q does
not have a preimage, or they do intersect, and then L can be found
as above, and the preimage of q is obtained by reﬂecting the part of q
between L and B through t.
B
p
p’
t
A
L
(0,0)
Fig. 4.4
Constructing the injection f.
As we know from Exercise 33, the number of northeastern lattice
paths from (0, 0) to (k, n −k) is
n
k

. This proves that
n
k

≤
 n
k+1

if k < n/2.
On the other hand, we also know that
n
k

=
 n
n−k

,
proving that
n
k

>
 n
k+1

if k > n/2. So the numbers
n
k

ﬁrst increase
steadily, then decrease steadily, in other words, they form a unimodal

96
A Walk Through Combinatorics
sequence.
The technique used in this solution is called the reﬂection principle.
See the Notes for references on this subject.
(21) By the deﬁnition of the binomial coeﬃcients, (4.13) is equivalent to
n!
(k −1)!(n −k + 1)! ·
n!
(k + 1)!(n −k −1)! ≤
n!
k!(n −k)! ·
n!
k!(n −k)!.
Dividing both sides by n!2 and then multiplying both sides by the
product (k + 1)!(k −1)!(n −k + 1)!(n −k −1)!, we get that (4.13) is
equivalent to
1 ≤k + 1
k
· n −k + 1
n −k
,
which is obviously true as both terms on the right-hand side are larger
than one.
(22) Clearly, the binomial coeﬃcient
 n
k−1

enumerates northeastern lattice
paths from A = (1, 0) to B = (k, n −k + 1), whereas the binomial
coeﬃcient
 n
k+1

enumerates northeastern lattice paths from C = (0, 1)
to D = (k+1, n−k). On the other hand,
n
k

enumerates northeastern
lattice paths from A to D and also from C to B.
We are going to deﬁne a function g that takes a pair of paths, one
from A to B, and one from C to D, and maps them into a pair of
paths, one from A to D, and one from B to C. We will then show that
g is an injection. That will prove our claim by the easy enumerative
considerations of the previous paragraph.
Our map g is simplicity itself. Take a northeastern path p from A to B,
and a northeastern path q from C to D. Then p and q must intersect;
let X be their ﬁrst intersection point. Flip the parts of paths XB and
XD, to get two new paths, one from A to X to D, and one from C to
X to B. Call these two paths p′ and q′, and deﬁne g(p, q) = (p′, q′).
To see that the map g is an injection, note that given two paths s and
u from A to D, and from B to C, either s and u do not intersect, or
they do, but then they have a ﬁrst intersection point X. In this latter
case, their preimage can be obtained by ﬂipping the part XB of s and
the part XB of u back.
(23) If the mentioned sequence is log-concave, then
a1
a0
≥a2
a1
≥a3
a2
≥· · · ≥an−1
an
.
This means that the ratio
ai
ai−1 is steadily decreasing, so in particular
once it dips below one, it will stay below one. Therefore, once the

No Matter How You Slice It. The Binomial Theorem and Related Identities
97
B
D
C
X
q’
q
A
C
B
D
A
p
p’
X
Fig. 4.5
Constructing the injection g.
sequence of the ai starts decreasing, it will keep decreasing, showing
that this is indeed a unimodal sequence.
(24) We know from Exercise 33 that the number of all northeastern lattice
paths from (0, 0) to (n, n) is
2n
n

. Let us enumerate the bad ones,
that is, those that go above the diagonal. In other words, these are
the northeastern paths that touch the line y = x + 1.
We prove that these paths are in bijection with northeastern paths
from (−1, 1) to (n, n). Let p be such a path, and let P be the ﬁrst
intersection point of p and the line y = x+1. Let us reﬂect the part ps
of p that is between the origin and P through the line y = x+ 1. This
reﬂection takes (0, 0) into (−1, 1), and so it take ps into a northeastern
lattice path p′
s from (−1, 1) to P. If we append the rest of p to the
end of p′
s, we get a path h(p) from (−1, 1) to (n, n). To see that h is
a bijection, note that every path from (−1, 1) to (n, n) must intersect
the line y = x + 1, so P can be recovered, and therefore, by reﬂection,
the preimage of any path can be uniquely recovered.
Thus the number of “bad” paths is
 2n
n−1

, therefore the number of
good paths is
2n
n

−
 2n
n−1

=
2n
n

/(n + 1).
(25) Note that the previous problem was a special case of this, i.e., when
a = b, but we have not used the equality of these two parameters in
the proof. Therefore, the same proof will work.
(26) First solution. Recall that 1/(1−x) = 
n≥0 xn. Taking derivatives,
we get
1
(1 −x)2 =

n≥1
nxn−1 =

n≥0
(n + 1)xn.
Second solution. Apply Theorem 4.15 with m = −2, and replace x
by −x. Note that
−2
n

= (−2)(−3) · · · (−n −1)
n!
= (n + 1)(−1)n.

98
A Walk Through Combinatorics
(-1,1)
(0,0)
(n,n)
P
sp
sp’
Fig. 4.6
Constructing the bijection h.
Therefore, Theorem 4.15 implies
1
(1 −x)2 =

n≥0
(n + 1)(−1)n(−x)n =

n≥0
(n + 1)xn.
(27) We know that
1
√1−4x = (1 −4x)−1/2, therefore, the binomial theorem
implies
1
√1 −4x =

n≥0
 −1
2
n

(−4x)n
=

n≥0
−1
2 · −3
2 · · · −2n+1
2
n!
(−1)n22nxn
=

n≥0
2n 1 · 3 · · · (2n −1)
n!
xn.
So all we have to show is that
2n
n

= 2n 1 · 3 · · · (2n −1)
n!
,
(2n)!
n!
= 2n1 · 3 · · · (2n −1),
and this is true as on the left-hand side we can simplify all fractions
of the form 2i
i . Then we will be left with 2n from the n fractions of
this form, and all the odd terms (2i + 1).

No Matter How You Slice It. The Binomial Theorem and Related Identities
99
(28) First of all, f(x) = (1 + x)(1 −x2)1/2. If we replace x by x2/4 in the
result of the previous exercise, this implies that
f(x) = (1 + x)

n≥0
2n
n

4n x2n
= (1 + x)

n≥0
2n (2n −1)!!
4nn!
x2n
= (1 + x)

n≥0
(2n −1)!!
(2n)!
x2n
=

n≥0
(2n −1)!!
(2n)!
x2n +

n≥0
(2n −1)!!
(2n)!
x2n+1.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 5
Divide and Conquer. Partitions
After the break taken in the last chapter, it is time we returned to our basic
enumeration problems. In Chapter 3 we were mainly concerned about lists
of objects, distinct or not, with repetitions allowed or not, and with the
order of the elements on the list being relevant or not.
In this chapter
we will go one step further by considering distribution problems. We will
distribute n objects (balls) into k boxes, and ask in how many ways this
can be done.
5.1
Compositions
Let us assume we want to give away twenty identical balls to four children,
Alice, Bob, Charlie and Denise. As the balls are identical, what matters is
how many balls each child will get. So if we want to know the number of
ways we can give away these balls, we simply have to know the number of
ways to write 20 as a sum of four non-negative integers. Clearly, the order
of the integers will matter, that is, 1 + 6 + 8 + 5 does not correspond to the
same way of distributing the balls as 6 + 1 + 5 + 8. Indeed, in the ﬁrst case,
Alice gets only one ball, in the second, she gets six.
Deﬁnition 5.1. A sequence (a1, a2, · · · , ak) of integers fulﬁlling ai ≥0 for
all i, and (a1 + a2 + · · · + ak) = n is called a weak composition of n. If, in
addition, the ai are positive for all i ∈[k], then the sequence (a1, a2, · · · , ak)
is called a composition of n.
Theorem 5.2. For all positive integers n and k, the number of weak com-
positions of n into k parts is
n + k −1
k −1

=
n + k −1
n

.
101

102
A Walk Through Combinatorics
Proof. The problem is certainly equivalent to counting the number of ways
of putting n identical balls into k diﬀerent boxes. Place the k boxes in a
line, then place the balls in them in some way and align them in the middle
of the boxes. This creates a long line consisting of n balls and k −1 walls
separating the k boxes from each other. Note that simply knowing in which
order the n identical balls and k−1 separating walls follow each other is the
same as knowing the number of balls in each box. So our task is reduced
to ﬁnding the number of ways to permute the multiset consisting of n balls
and k −1 walls. Theorem 3.5 tells us that this number is
(n + k −1)!
n! · (k −1)! .
What if a grandparent insists on giving at least one ball to each child?
The problem is not any harder. First we can give one ball to each child, then
give away the remaining 16 balls to the four children in any of
16+4−1
4−1

=
19
3

ways. The generalization of this argument to n balls and k children is
the following statement.
Corollary 5.3. For all positive integers n and k, the number of composi-
tions of n into k parts is
n−1
k−1

.
How about the number of all compositions, that is, the number of com-
positions of n into any number of parts? Clearly, this question only makes
real sense for compositions, not for weak compositions. Indeed, if 0 is al-
lowed to be a part, then any number of zeros can be appended to the end of
any composition, therefore any positive integer n has inﬁnitely many weak
compositions. For compositions, however, the question has a remarkably
compact answer.
Corollary 5.4. For all positive integers n, the number of all compositions
of n is 2n−1.
Proof. A composition of n will have at least one and at most n parts. So
the total number of compositions of n is
n

k=1
n −1
k −1

= 2n−1.
Indeed, the left-hand side is the number of all subsets of [n −1], ﬁrst
enumerated by their size k, and then summed over k ∈[n].

Divide and Conquer. Partitions
103
The reader is hopefully thinking right now that such a nice closed result,
2n−1, must have an alternative explanation, one that really explains why
the result is a power of two. Such a proof indeed exists and we provide it
below.
Proof. (of Corollary 5.4) We prove the statement by induction on n. For
n = 1, the statement is true as the integer 1 has one composition. Now
assume that the statement is true for n, and take all 2n−1 compositions of
n. For each such composition C, we will deﬁne two diﬀerent compositions
of n + 1.
First, add one to the ﬁrst element of C.
This way we get a
composition of n + 1 with the ﬁrst element at least 2. Second, take C,
and write an additional 1 to its front. This way we get a composition of
n + 1 with ﬁrst element 1. It is clear that diﬀerent compositions of n lead
to diﬀerent compositions of n + 1 this way. Each decomposition of n + 1
can be obtained in exactly one of these two ways. Therefore, it follows that
n + 1 has twice as many compositions as n, which was to be proved.
Quick Check
(1) What is the number of all compositions of n in which the ﬁrst part is
not 2?
(2) What is the number of all compositions of n into four parts, each of
which is at least 2?
(3) What is the number of all weak compositions of 10 into ﬁve parts so
that exactly two parts are 0?
5.2
Set Partitions
Now let us assume that the balls are diﬀerent, but the boxes are not. Then
we might as well label the balls by numbers 1 through n. In other words,
we may simply say that we want to partition the set [n] into k nonempty
subsets.
Deﬁnition 5.5. A partition of the set [n] is a collection of non-empty blocks
so that each element of [n] belongs to exactly one of these blocks.
The number of partitions of [n] into k nonempty blocks is denoted by
S(n, k). The numbers S(n, k) are called the Stirling numbers of the second
kind.

104
A Walk Through Combinatorics
It follows from Deﬁnition 5.5 that S(n, k) = 0 if n < k. We set S(0, 0) =
1 by convention. In the next chapter, you will see an advantage of this
convention. Until then, be comforted in knowing that there is one way to
distribute zero objects into zero boxes, namely by not doing anything.
Example 5.6. For all n ≥1, we have S(n, 1) = S(n, n) = 1. For all n ≥2,
the equality S(n, n −1) =
n
2

holds as a partition of [n] into n −1 blocks
must consist of one doubleton and n −2 singletons.
Example 5.7. The set [4] has seven partitions into two nonempty
blocks, namely {1, 2, 3}{4}; {1, 2, 4}{3}; {1, 3, 4}{2}; {2, 3, 4}{1}, and also
{1, 2}{3, 4}; {1, 3}{2, 4}; and {1, 4}{2, 3}. Therefore, S(4, 2) = 7.
Several questions are in order. The reader may wonder what happened
to the Stirling numbers of the ﬁrst kind. These will be discussed in Chapter
6. The reader may also think that the ﬁrst thing we will do is to provide a
formula for S(n, k), and may in fact wonder why we have not done it yet.
However, there exists no closed formula for S(n, k). There is a formula for
S(n, k) that contains one summation sign, and we will prove it in Chapter
7 as we need the sieve formula to obtain it.
Nevertheless, we can prove some nice identities about set partitions right
now. They will be of recursive nature.
Theorem 5.8. For all positive integers k ≤n,
S(n, k) = S(n −1, k −1) + k · S(n −1, k).
(5.1)
Proof. As before, we can obtain a combinatorial proof by taking a close
look at one particular element, say the maximum element n. If this el-
ement forms a singleton block, then the remaining n −1 elements have
exactly S(n −1, k −1) ways to complete the partition. These partitions
are enumerated by the ﬁrst member of the right-hand side. If, on the other
hand, the element n does not form a block by itself, then the remaining
n −1 elements must form a partition with k blocks in one of S(n −1, k)
ways. Then we can add n into any of the k blocks formed by this partition,
multiplying the number of all our possibilities by k. These partitions are
enumerated by the second member of the right-hand side. As the left-hand
side enumerates all partitions of [n] into k blocks, the claim is proved.
If we have to put n diﬀerent balls into k diﬀerent boxes then the number
of ways to do this is k! · S(n, k). Indeed, ﬁrst we can partition [n] into k

Divide and Conquer. Partitions
105
non-distinguishable blocks in S(n, k) ways, then we can label the k blocks
with labels 1, 2, · · · , k in k! diﬀerent ways.
Corollary 5.9. The number of all surjective functions f : [n] →[k] is
k! · S(n, k).
Proof. Such a function deﬁnes a partition of [n]. The blocks are the subsets
of elements that are mapped into the same element i ∈[k]. Therefore, the
blocks are labeled, and there are exactly k of them, so the proof follows
from the previous paragraph.
An interesting consequence of this is the following unexpected corollary.
It is surprising as it shows that xn, this very compact expression, is in fact
a sum of n + 1 terms involving Stirling numbers.
Corollary 5.10. For all real numbers x, and all non-negative integers n,
xn =
n

k=0
S(n, k)(x)k.
(5.2)
Proof. Both sides are polynomials of x of degree n. So if we can show that
they agree for more than n values of x, we will be done. We will prove an
even stronger statement, namely that the two sides agree for all positive
integers x.
So let x be a positive integer. Then the left-hand side is the number
of all functions from [n] to [x]. We claim that the right-hand side is the
same, enumerated according to the size of the image. Indeed, if the image
of such a function is of size k, then there are
x
k

choices for the image I,
then, by Corollary 5.9, there are k! · S(n, k) choices for the function itself.
As (x)k = k! ·
x
k

, the claim is proved.
Another way of extending our enumeration of partitions is by enumer-
ating all partitions, without restricting the number of parts.
Deﬁnition 5.11. The number of all set partitions of [n] into nonempty
parts is denoted by B(n), and is called the nth Bell number. We also set
B(0) = 1.
So B(n) = n
i=0 S(n, i). The Bell numbers also satisfy a nice recurrence
relation.
Theorem 5.12. For all non-negative integers n,
B(n + 1) =
n

i=0
n
i

B(i).
(5.3)

106
A Walk Through Combinatorics
Proof. We must prove that the right-hand side enumerates all partitions
of [n+1]. Let us assume the element n+1 is in a block of size n−i+1. Then
there are i elements that are not in the same block as n + 1. Therefore,
there are
n
i

ways to choose these elements, and then there are B(i) ways to
partition them. Summing over all possible values of i, we get the statement
of the theorem.
Quick Check
(1) Compute S(6, 3).
(2) Let f(n) be the number of partitions of [n] into k blocks in which the
elements 1 and 2 are in separate blocks. Find a formula for f(n) using
Stirling numbers of the second kind.
(3) Find a simple proof for the identity
6S(n, 3) + 6S(n, 2) + 3S(n, 1) = 3n.
5.3
Integer Partitions
Now let us assume that both the balls and the boxes are indistinguishable,
so when we distribute the balls into the boxes, the only thing that matters is
their numbers. In other words, we are interested in ﬁnding out the number
of ways of writing the positive integer n as a sum of positive integers, where
the order of the summands does not matter. That is, 4 = 3 + 1 or 4 = 1 + 3
will count as only one way of writing four as a sum of positive integers.
As the order of the summands does not matter, we do not lose generality
if we assume that they are in weakly decreasing order.
Deﬁnition 5.13. Let a1 ≥a2 ≥· · · ≥ak ≥1 be integers so that a1 +
a2 + · · · + ak = n. Then the sequence (a1, a2, · · · , ak) is called a partition
of the integer n. The number of all partitions of n is denoted by p(n). The
number of partitions of n into exactly k parts is denoted by pk(n).
We note that the word “partition” is used in a new meaning here. We
have used it before, in Deﬁnition 5.5, to mean “a way to split the set
[n]”.
The new meaning, given in Deﬁnition 5.13 is independent of the
old one. This double meaning of the same word usually does not result in
confusion as the context usually clearly indicates which meaning is relevant.
In writing, so too does the notation, that is, we either speak of partitions
of [n], or of partitions of n. If there is a danger of confusion after all, it

Divide and Conquer. Partitions
107
is customary to refer to partitions of [n] as “set-partitions”. We also note
that some languages, like French, do have two diﬀerent words for these two
notions (“partition” for set-partitions, and “partage” for partitions of the
integer n).
Example 5.14. The positive integer 5 has 7 partitions.
Indeed, they
are (5); (4, 1); (3, 2); (3, 1, 1); (2, 2, 1); (2, 1, 1, 1); (1, 1, 1, 1, 1). Therefore,
p(5) = 7.
The problem of ﬁnding an exact formula for p(n) is even harder than
that of ﬁnding an exact formula for S(n, k). If we know p(n −1), or, for
that matter, p(i) for all i < n, we still cannot directly compute p(n) from
these data (though some sophisticated recurrence relations do exist, and
we will mention them in the Notes section). The approximate size of the
number p(n) is provided by the following asymptotic formula.
p(n) ∼
1
4
√
3
exp

π

2n
3

.
(5.4)
In other words, p(n) grows faster than any polynomial, but slower than
any exponential function g(n) = cn, with c > 1.
We will nevertheless ﬁnd some surprising and useful results concerning
p(n) once we will have learned about generating functions in Chapter 8.
Until then, we will discuss some highly interesting and enjoyable identities.
Our main tool in proving them will be the following graphical representation
of partitions.
A Ferrers shape of a partition p = (x1, x2, · · · , xk) is a set of n square
boxes with horizontal and vertical sides so that in the ith row we have xi
boxes and all rows start at the same vertical line. It is named after the
British mathematician Norman Macleod Ferrers. The Ferrers shape of the
partition p = (4, 2, 1) is shown in Figure 5.1. Clearly, there is an obvious
bijection between partitions of n and Ferrers shapes of size n.
If we reﬂect a Ferrers shape of a partition p with respect to its main
diagonal, we get another shape, representing the conjugate partition of p.
Thus, in our example, the conjugate of (4, 2, 1) is (3, 2, 1, 1). In particular,
the ith row of the Ferrers shape of the conjugate partition of p is as long
as the ith column of the Ferrers shape of p.
Deﬁnition 5.15. A partition of n is called self-conjugate if it is equal to
its conjugate.

108
A Walk Through Combinatorics
Fig. 5.1
The Ferrers shape of the partition p = (4, 2, 1).
Example 5.16. Partitions (4, 3, 2, 1), (5, 1, 1, 1, 1), and (4, 2, 1, 1) are all
self-conjugate.
Fig. 5.2
Self-conjugate partitions.
Now we are in a position to use Ferrers shapes to prove various partition
identities.
Example 5.14 shows that the positive integer 5 has three partitions into
at most two parts, 5, (4, 1) and (3, 2), and it also has three partitions into
parts that are at most two, namely (2, 2, 1), (2, 1, 1, 1), and (1, 1, 1, 1, 1).
This is not by accident.
Theorem 5.17. The number of partitions of n into at most k parts is equal
to that of partitions of n into parts not larger than k.
Proof. The ﬁrst number is equal to that of Ferrers shapes of size n with at
most k rows. The second number is equal to that of Ferrers shapes with at
most k columns. Finally, these two sets of Ferrers shapes are equinumerous
as one can see by taking conjugates.
Theorem 5.18. The number of partitions of n into distinct odd parts is
equal to that of all self-conjugate partitions of n.

Divide and Conquer. Partitions
109
Proof. We deﬁne a bijection f from the set of self-conjugate partitions of
n onto that of partitions of n into distinct odd parts as follows. Take any
self-conjugate partition π = (π1, π2, · · · , πt) of n. Take its Ferrers shape,
and remove all the boxes from its ﬁrst row and ﬁrst column. As π is self-
conjugate, this means removing 2π1 −1 boxes. Set f(π)1 = 2π1 −1, that is,
make the ﬁrst part of the image of π of size 2π1−1. Then continue this way.
That is, remove the ﬁrst row and column of the remaining Ferrers shape.
This means removing 2π2 −3 boxes. So set f(π)2 = 2π2 −3. Continue this
way until the entire Ferrers shape is removed. The resulting partition will
be of the form f(π) = (2π1 −1, 2π2 −3, · · · , 2πi −(2i −1), · · · ). So it will
indeed be a partition of n into odd parts, and the parts will all be distinct,
as we had π1 ≥π2 ≥· · · ≥πt. We note that the set of all boxes consisting
of one ﬁxed box b, all boxes below b, and all boxes on the right of b, is often
called a hook. Using this terminology, we can say that in each step of our
algorithm, we remove the hook of the box that is currently in the top left
corner of our Ferrers shape.
To see that f is a bijection, it suﬃces to prove that for any partition α of
n into distinct odd parts, there exists exactly one self-conjugate partition π
of n so that f(π) = α. Indeed, let α = (2a1 −1, 2a2 −3, · · · , 2au −(2u−1)).
Then it follows from the deﬁnition of f that if f(π) = α, then the ﬁrst row
and column of π must each contain a1 boxes, the second row and second
column of π must each contain a2 additional boxes, and so on. So we can
build up the unique Ferrers shape whose partition has image α, proving our
claim.
Example 5.19. If π = (6, 6, 4, 3, 2, 2), then f(π) = (11, 9, 3). Figure 5.3
shows how f(π) is constructed. In step i, the hook consisting of all boxes
labeled i in the Ferrers shape of π is removed, and its boxes form row i of
the Ferrers shape of f(π).
1
2
2
2
1
1
2
1
1
1
1
1
1
1
2
1
1
1
1
1
1
1
1
1
1
1
1
2
2
2
2
3
2
2
2
2
2
2
2
2
3
3
3
3
3
2
Fig. 5.3
A self-conjugate partition and its image.
Theorem 5.20. Let q(n) be the number of partitions of n in which each

110
A Walk Through Combinatorics
part is at least two. Then q(n) = p(n) −p(n −1), for all positive integers
n ≥2.
Proof. We construct a bijection from the set of all partitions of n −1
onto the set of all partitions of n that have at least one part equal to one.
The bijection is very simple: just add a part equal to 1 to the end of each
partition of n −1. The only partitions of p(n) that cannot be obtained this
way are those enumerated by q(n), so the claim is proved.
We will not provide a formula for pk(n) here (any such formula would
be cumbersome anyway). However, we will see in Chapter 8 how to get a
good description of these numbers.
Let us try to ﬁnd some connection between the number of partitions of
the integer n, and that of partitions of the set [n]. It is clear that the set
partitions {1, 2, 3}, {4} and {1, 2, 4}, {3} do have something in common. In-
deed, they both consist of a block of size three and another block of size one.
We are going to generalize this notion as follows. Let π = {π1, π2, · · · , πk}
be a partition of [n], where the πi denote the blocks of π. Rearrange the
sequence of block sizes |π1|,|π2|,· · · , |πk| in non-increasing order to get the
sequence a1 ≥a2 ≥· · · ≥ak. Then a = (a1, a2, · · · , ak) is a partition of
the integer n. We say that a is the type of the set partition π.
Example 5.21. The set partition {1, 5, 6}, {2, 7}, {3, 9}, {4, 8}, {10} is of
type (3, 2, 2, 2, 1).
We can now state and prove a theorem on the number of set partitions
of a given type.
Theorem 5.22. Let a = (a1, a2, · · · , ak) be a partition of the integer n,
and let mi be the multiplicity of i as a part of a. Then the number of set
partitions of [n] that are of type a is equal to
Pa =

n
a1,a2,··· ,ak


i≥1 mi! .
Proof. Take ai balls of color i, for all i ∈[k].
Order them linearly in

n
a1,a2,··· ,ak

ways. Then partition [n] so that i and j are in the same block
if and only if the linear order we just created has monochromatic balls in
positions i and j. This procedure clearly creates a set partition of type a.
However, the number of diﬀerent set partitions constructed this way is
not necessarily

n
a1,a2,··· ,ak

. For example, if a1 = a2, then having the a1
balls of color 1 in a subset A of positions, and having the a1 balls of color

Divide and Conquer. Partitions
111
2 in a subset B of positions will result in the same partition as having the
balls of color 1 in B, and having the balls of color 2 in A. In general, if mi
is the multiplicity of i as a part of a, then there are mi! ways the mi color
classes having i balls each can be permuted among each other. Therefore,
every set partition of type a will be obtained from exactly 
i≥1 mi! linear
orders, and the proof follows.
The following table summarizes our results from this chapter when no
empty boxes are allowed.
Table 5.1.
parameters
formula
Surjections
n distinct objects,
S(n, k)k!
k distinct boxes
n distinct objects,
n
i=1 S(n, i)i!
any number of distinct boxes
Compositions
n identical objects,
n
k

k distinct boxes
n identical objects,
2n−1
any number of distinct boxes
Set Partitions
n distinct objects,
S(n, k)
k identical boxes
n distinct objects,
B(n)
any number of identical boxes
Integer Partitions
n identical objects,
pk(n)
k identical boxes
n distinct objects,
p(n)
any number of identical boxes
If empty boxes are allowed, then we have to ﬁx the number of boxes.
Indeed, if we do not, then we can add as many empty boxes as we want,

112
A Walk Through Combinatorics
yielding inﬁnitely many solutions to all these problems. Therefore, instead
of eight diﬀerent enumeration problems, we only have to treat four. Their
results have either been proved in this chapter, or are trivial. Table 5.2
summarizes them.
Table 5.2.
parameters
formula
Functions
n distinctl objects,
kn
k distinct boxes
Weak Compositions
n identical objects,
n + k −1
k −1

k distinct boxes
Set Partitions
n distinct objects,
k

i=1
S(n, i)
k identical boxes
Integer Partitions
n identical objects,
k

i=1
pi(n)
k identical boxes
Quick Check
(1) Compute p(6).
(2) Let us assume that for a given integer n, the number of self-conjugate
partitions of n is even. What can we say about the parity of p(n)?
(3) Let n ≥7. Prove that the number of partitions of n into four distinct
parts is at least as large as the number of partitions of n −6 into four
parts.
Notes
Of the various enumeration problems discussed in this chapter, it is the
enumeration of the partitions of the integer n that has been the subject
of the most vigorous research. This problem proved to be interesting not
only for combinatorialists, but also for number theorists. The interested
reader should see [4] for further information on integer partitions. A par-
ticularly nice classic result is the following recurrence relation, due to Percy
MacMahon. Let us say that a pentagonal number is an integer of the form

Divide and Conquer. Partitions
113
k(3k−1)/2, where k is any integer, positive or not. So pentagonal numbers
are never negative, and the ﬁrst few are 0, 1, 2, 5, 7, 12. Then for any
positive integer n,
p(n) = p(n −1) + p(n −2) −p(n −5) −p(n −7) + · · ·
(5.5)
where the ith term of the right-hand side has sign (−1)⌊i/2⌋and absolute
value p(n −ki), with ki being the ith largest pentagonal number.
So for instance, for n = 8, the above formula shows that
p(8) = p(7) + p(6) −p(3) −p(1) = 15 + 11 −3 −1 = 22.
Pentagonal numbers have other applications besides formula (5.5).
The
interested reader can consult [13] for an application to permutation enu-
meration. Euler’s famous pentagonal number theorem states that the num-
ber of partitions of n into an odd number of distinct parts is equal to the
number of partitions of n into an even number of distinct parts, as long
as n is not pentagonal, and that these two numbers only diﬀer by one if n
is pentagonal. For instance, the number 6 is not pentagonal, and indeed,
it can be partitioned into an odd number of distinct parts as 6, and as
3 + 2 + 1, and into an even number of distinct parts as 5 + 1 and as 4 + 2.
A precise statement of this theorem and its detailed proof can be found in
the textbook [11].
Exercises
(1) Find a formula for S(n, 3).
(2) Prove that if n ≥3, then B(n) < n!.
(3) Prove that if n ≥2, then n! < S(2n, n) < (2n)!.
(4) (+)
(a) Let h(n) be the number of ways to place any number (including
zero) of non-attacking rooks on the Ferrers shape of the “staircase”
partition (n −1, n −2, · · · , 1). Prove that h(n) = B(n).
(b) In how many ways can we place k non-attacking rooks on this Ferrers
shape?
(5) Let m and n be positive integers so that m ≥n. Prove that the Stirling
numbers of the second kind satisfy the recurrence relation
S(m, n) =
m

i=1
S(m −i, n −1)ni−1.

114
A Walk Through Combinatorics
(6) Prove that the number of partitions of n into exactly k parts is equal
to the number of partitions of n in which the largest part is exactly k.
(7) Prove that the number of partitions of n into at most k parts is equal
to that of partitions of n + k into exactly k parts.
(8) The Durfee square of a partition p is the largest square that ﬁts in
the top left corner of the Ferrers shape of p.
The Durfee square of
p = (5, 3, 2, 2) has side length 2 as shown in the Figure 5.4.
                                    





Fig. 5.4
The Durfee square of the partition (5, 3, 2, 2).
If we know the parts of a partition p, how can we ﬁgure out the side
length of its Durfee square without drawing the Ferrers shape of p?
(9) Let k be a positive integer, and let q be a non-negative integer such that
q < k. Deﬁne pk,q(r) = pk(rk + q). Prove that pk,q(r) is a polynomial
function of r.
(10) Let m be a ﬁxed positive integer. Prove that S(n, n−m) is a polynomial
function of n. What is the degree of this polynomial?
(11) Prove that for all integers n ≥2, the number p(n)−p(n−1) is equal to
the number of partitions of n in which the two largest parts are equal.
(12) Let n ≥4. Find the number of partitions of n in which the diﬀerence
of the ﬁrst two parts is
(a) at least three,
(b) exactly three.
(13) Find a formula involving p(n) for the number of partitions of n in which
the three largest parts are equal. (You can assume that n ≥4.)

Divide and Conquer. Partitions
115
(14) Prove that for all positive integers n,
p(1) + p(2) + · · · + p(n) < p(2n).
(15) Our four friends from Exercise 16 of Chapter 3, A, B, C, and D organize
a long jump competition every day until the ﬁnal ranking of the four
of them will be the same on two diﬀerent days.
At most how long
will they have to wait for that to happen? (Each jump is measured
in centimeters, so all kinds of ties, twofold, threefold, fourfold, are
possible.)
(16) Prove that for all positive integers n,
n

k=1
(−1)kk!S(n, k) = (−1)n.
Explain what this identity means without resorting to mathematical
formulas.
(17) Find the number of compositions n in which the ith part is equal to k.
Supplementary Exercises
(18) (-) How many compositions does the integer 15 have whose ﬁrst part
is not 1?
(19) (-) How many partitions does the set [10] have in which the element
1 does not form a block by itself?
(20) (-) What is the number of partitions of [8] into two blocks in which
the two blocks do not have the same size?
(21) (-) What is the number of compositions of 5 with a unique largest
part?
(22) (-) Prove that p(n) is equal to the number of partitions of the integer
2n with no odd parts.
(23) A student has to take twelve hours of classes a week.
Due to her
extracurricular activities, she must take at least three hours of classes
on Monday, at least two on Thursday, and at least one on Friday.
(a) In how many ways can she do this?
(b) In how many ways can she do this if there is only one class on
Tuesday that she may take?
(24) Find the number of compositions of n into an even number of parts.
(25) Find the number of weak compositions of 25 into ﬁve odd parts.

116
A Walk Through Combinatorics
(26) A student has to take eight hours of classes a week. He wants to have
fewer hours on Friday than on Thursday. In how many ways can he
do this?
(27) Find a closed formula for S(n, 2) if n ≥2.
(28) Find a closed formula for S(n, n −2), for all n ≥2.
(29) Find a closed formula for S(n, n −3), for all n ≥3.
(30) Recall that pk(n) is the number of partitions of the integer n into
exactly k parts.
(a) Prove that for all positive integers k ≤n, the inequality pk(n) ≤
(n −k + 1)k−1 holds.
(b) Is it true that pk(n) is a polynomial function of n?
(31) Prove that p(n) grows faster than any polynomial function of n. That
is, prove that if f is any polynomial function in n, then there exists
an integer N so that f(n) < p(n) for all n > N. Do not use formula
(5.4).
(32) Prove that for all positive integers n, the inequality p(n)2 < p(n2+2n)
holds.
(33) Let F(n) be the number of all partitions of [n] with no singleton blocks.
Prove that B(n) = F(n) + F(n + 1). A bijective proof is preferred.
(34) Find a recurrence relation for the numbers F(n) in terms of the num-
bers F(i), with i ≤n −1.
(35) Let Bk(n) be the number of partitions of [n] so that if i and j are in
the same block, then |i −j| > k. Prove that Bk(n) = B(n −k), for all
n ≥k.
(36) Let an be the number of compositions of n into parts that are larger
than 1. Express an by an−1 and an−2.
(37) Let bn be the number of compositions of n into parts that are larger
than 2. Find a recurrence relation satisﬁed by bn, similar to the one
you found for an in the previous exercise.
(38) Let Bn be the number of compositions of n in which the ﬁrst part is
odd. Prove that if n ≥1, then Bn + Bn+1 = 2n.
(39) Let An be the total number parts that are equal to 1 in all composi-
tions of n. So A1 = 1, A2 = 2, A3 = 5, and A4 = 12. Prove that for
all n ≥2, the recurrence relation An+1 = 2An + 2n−2 holds.
(40) Let sn be the sum of the ﬁrst part of all compositions of n. So s1 = 1,
s2 = 3, and s3 = 7. Find an explicit formula for sn.

Divide and Conquer. Partitions
117
Solutions to Exercises
(1) We can assume that n ≥3. First we determine the number of sur-
jections f : [n] →[3]. The number of all functions f : [n] →[3] is
3n. Three of these functions have an image of size one. Moreover, by
Exercise 27 and Corollary 5.9, 3 · 2 · (2n−1 −1) such functions have an
image of size two. Therefore, the number of all surjections f : [n] →[3]
is 3n −3 · 2 · (2n−1 −1) −3. So Corollary 5.9 shows that
S(n, 3) = 3n −3 · (2n −2) −3
6
= 3n−1 −(2n −2) −1
2
= 3n−1 + 1
2
−2n−1.
(2) We prove the statement by induction on n. For n = 3, the statement
is true as 3! = 6 > B(3) = 5. Now assume the statement is true for
n and let us prove that it is true for n + 1. Equation (5.3) and the
induction hypothesis together yield the following upper bound on the
left-hand side.
B(n + 1) =
n

i=0
n
i

B(i) <
n

i=0
n
i

i!
=
n

i=0
(n)i < (n + 1)n! = (n + 1)!,
and the proof follows.
(3) The upper bound follows from the previous exercise. For the lower
bound, write the numbers 1, 2, · · · , n in one line in this order, then
write the numbers n + 1, n + 2, · · · 2n below them in any order. This
can be done in n! ways, and each such arrangement deﬁnes a partition
of [2n] into n blocks of size two each. Strict inequality follows as n ≥2,
so partitions with other block sizes are possible.
(4)(a) Number the rows and columns of the staircase Ferrers shape as
shown in Figure 5.6. Then each set of non-attacking rooks deﬁnes
a partition of the set [n] as follows. Let i and j be in the same
block if there is a rook in the intersection of row i and column j.
In order to see that this is a bijection, let π be a partition of [n],
and let B be a block of π. Let b1 < b2 < · · · < bm be elements of
B. Then it follows from the previous paragraph that B had to be
deﬁned by a rook on the box (b1, b2), a rook on the box (b2, b3), and
so on, ending with a rook on the box (bk−1, bk). Indeed, a block of
size k takes k −1 rooks to deﬁne. No row or column can contain

118
A Walk Through Combinatorics
more than one rook. The fact that b1 and b2 are in the same block
means that there has to be a rook on the box (b1, b2), then the fact
that b2 and b3 are in the same block implies that there has to be a
rook on the box (b2, b3), and so on.
1
2
3
4
5
6
5
4
3
2
Fig. 5.5
Numbering the rows and columns of the staircase shape.
(b) Continuing the argument from part (a), the placement of no rooks
corresponds to the all singleton partition, which has n blocks. The
placement of each rook decreases the number of blocks by one (by
uniting two blocks), hence the placement of k rooks creates a par-
tition with n −k blocks.
So the number of ways of placing k
non-attacking rooks on this Ferrers shape is S(n, n −k).
(5) Let π be a partition of [m] into n parts. The left-hand side is the
number of such partitions. To see that the right-hand side is the same,
let m −i be the largest integer so that the restriction πi of π into [i]
has only n−1 blocks. Then we have S(m−i, n−1) possibilities for πi.
It follows from the deﬁnition of m−i that m−i+1 must be in a new,
last block B of π. Then, the numbers m−i+2, m−i+3, · · · , m can be
in any blocks, yielding ni−1 choices for the blocks of these elements.
Therefore, the total number of possibilities for π is S(m−i, n−1)ni−1.
Summing over all i, the statement follows.
(6) These are partitions whose Ferrers shape has exactly k rows (resp.
columns), so the statement follows by taking conjugates.

Divide and Conquer. Partitions
119
(7) Take the Ferrers shape of a partition of n into at most k parts, and
add an extra box to the end of each row. If there were less than k
rows, then add additional rows of length one so that the shape has k
rows. This way, you get the Ferrers shape of a partition of n + k with
exactly k rows.
To see that this is a bijection, it suﬃces to show that for all Ferrers
shapes F with k rows and n + k boxes, one can ﬁnd a unique Fer-
rers shape whose image is F. That shape can be obtained by simply
deleting the last box of each of the k rows of F.
(8) Let p = (p1, p2, · · · , pi). Then the side length of the Durfee square is
the largest i so that pi ≥i.
(9) We will prove a stronger statement by induction on k, namely that
pk,q(r) is a polynomial of degree k −1. If k = 1, then pk,q(r) = 1, and
the statement is true.
It is a well-known fact of calculus (see Exercise 1 of Chapter 2) that
a function f(n) is a polynomial of degree d if and only if the function
g(n) = f(n) −f(n −1) is a polynomial of degree d −1. It is therefore
suﬃcient to prove that pk,q(r) −pk,q(r −1) is a polynomial of degree
n −2.
Take a partition of rk + q into k parts. Subtract one from each of its
parts. We get a partition of (r −1)k + q into at most k parts. Indeed,
some parts could be equal to 1 in the original partition and now they
would disappear.
Therefore,
pk,q(r) = pk,q(r −1) + pk−1,q(r −1) + · · · + p0,q(r −1),
where p0,q(r−1) = 1 if q = 0 and r = 1, and p0,q(r−1) = 0 otherwise.
After rearrangement, we get
pk,q(r) −pk,q(r −1) =
k−1

i=0
pi,q(r −1).
By the induction hypothesis, all terms on the right-hand side are poly-
nomials. The last one of them has degree k −2, and the rest have
smaller degrees. Therefore, the right-hand side is a polynomial of de-
gree k −2, and thus so is the left-hand side. Consequently, pk,q(r) is
a polynomial of degree k −1, by the fact we mentioned in the second
paragraph of this solution.
(10) We prove the statement by induction on m, the initial case of m = 0
being obvious. We will use the same fact of calculus that we used to

120
A Walk Through Combinatorics
solve the previous exercise. Applying formula (5.1) with k = n −m,
we get, after rearrangement
S(n, n −m) −S(n −1, n −1 −m) = (n −m)S(n −1, n −1 −(m −1)).
Here, the right-hand side is a polynomial by the induction hypothesis,
so the left-hand side must be a polynomial. However, the left-hand
side is just the diﬀerence of two consecutive values of S(n, n −m), so
S(n, n −m) is a polynomial.
The degree of S(n, n −m) as a polynomial is 2m. This can be proved
as a similar statement was proved in the previous exercise.
(11) We know from Theorem 5.20 that p(n) −p(n −1) is equal to the
number of partitions of n in which each part is at least two. Taking
conjugates, this latter is equal to the number of partitions of n in
which the two largest parts are equal.
(12)(a) Take any partition of n −3, and add three to its ﬁrst part. This
way we get each partition of the desired property exactly once.
Therefore, the answer is p(n −3).
(b) Decreasing the ﬁrst part of such a partition by three, we get a
partition of n −3 with the ﬁrst two parts equal. Exercise 11 shows
that the number of these is p(n −3) −p(n −4).
(13) The conjugate of such a partition consists of parts of size at least
three. Therefore the number q(n) of such partitions is equal to p(n)−
r(n) −s(n), where r(n) is the number of partitions of n with smallest
part one, and s(n) is the number of partitions of n with smallest part
two.
We know from Theorem 5.20 that r(n) = p(n −1). Let us determine
s(n). If π is a partition of n with smallest part two, and we remove
the smallest part of π, then we get a partition π′ of n−2 with smallest
part at least two. In other words, π′ does not contain one as a part,
therefore, by Theorem 5.20, we have p(n −2) −p(n −3) = s(n). This
shows that
q(n) = p(n) −r(n) −s(n) = p(n) −p(n −1) −p(n −2) + p(n −3).
(14) If π is a partition of i for i ≤n, then its largest part is at most n, so
it can be prepended by a new ﬁrst part 2n−i > n. The new partition
we obtain is a partition of 2n. This sets up an injection from the set
of partitions of all positive integers at most n into the set of partitions
of 2n, and the proof follows.

Divide and Conquer. Partitions
121
(15) Each ﬁnal result of the competition deﬁnes an ordered partition of
{A, B, C, D} into k blocks, where k is the number of jumps of diﬀer-
ent length. In other words, people who tied form the blocks of this
partition, and the blocks are ordered according to the sizes of the
jumps belonging to people in each block. For example, if B won, A
and D tied for the second place, and C got last, then the ordered
partition deﬁned by this result is {B}, {A, D}, {C}.
The number of ordered partitions of [n] into k blocks is obviously
S(n, k) · k!.
Therefore, the number of all ordered partitions of
{A, B, C, D} into at most four blocks is
4

k=1
S(n, k) · k! = 1 · 1 + 7 · 2 + 6 · 6 + 1 · 24 = 75.
So the four friends will have their competitions for at most 76 days.
(16) Simply set x = −1 in formula (5.2). The meaning of the result is that
the number of surjections from a given set with an even-sized image
and the number of surjections from that same set with an odd-sized
image diﬀer by ±1.
(17) Let us say that the composition c in question has m parts, where
m ≥i. If we remove the ith part of c, we get a composition of n −k
into m −1 parts. Given the imposed limits on m, we get that the
number of such compositions is
Cn,k,i =
n

m=i
n −k −1
m −2

.
(5.6)

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 6
Not So Vicious Cycles. Cycles in
Permutations
We have considered several enumeration problems in the previous three
chapters. One of them, that of permutations, stands out by its omnipres-
ence in mathematics.
The reason for that is that permutations can be
viewed not only as linear orders of diﬀerent objects, most often elements
of [n], but also as functions from [n] to [n]. In particular, a permutation
p = p1p2 · · · pn can be conceived as the unique function p : [n] →[n] for
which p(i) = pi.
Example 6.1. The permutation 312 can be viewed as the (bijective) func-
tion f : [3] →[3] deﬁned by f(1) = 3, f(2) = 1, and f(3) = 2.
The advantage of this approach is that now one can deﬁne the prod-
uct of two permutations on [n] by simply taking their composition as a
composition of functions.
Example 6.2. Let f = 312 and let g = 213. Then (f · g)(1) = g(f(1)) =
g(3) = 3, (f · g)(2) = g(f(2)) = g(1) = 2, and (f · g)(3) = g(f(3)) = g(2) =
1. Therefore, fg = 321.
Example 6.3. Let f and g be deﬁned as in the preceding example. Then
(g · f)(1) = f(g(1)) = f(2) = 1, (g · f)(2) = f(g(2)) = f(1) = 3, and
(g · f)(3) = f(g(3)) = f(3) = 2. Therefore, gf = 132.
As these two examples show, multiplication of permutations is not a
commutative operation, that is, it is not true in general that fg = gf. The
reader may have seen examples of such operations before, such as matrix
multiplication. Exercise 12 explains why multiplication of permutations is
a special case of that.
Note that many authors use a slightly diﬀerent notation for the product
of two permutations, in that when they write gf, they mean that we ﬁrst
123

124
A Walk Through Combinatorics
apply f, then g. In this book, multiplication of permutations will not be as
important as enumeration of permutations, so even if the reader used that
notation before, there will be no danger of confusion.
Operations involving multiplications of permutations are the subject of
the theory of permutation groups. Our book walks through Combinatorics,
and will not contain a digression to that very interesting ﬁeld, except for
an interesting application in Chapter 18. However, some of the exercises at
the end of this chapter do relate to the multiplication of permutations.
6.1
Cycles in Permutations
Take the permutation 321564. Again, this permutation can be viewed as
a function g : [6] →[6]. Let us take a closer look at g. First, g(2) = 2,
in other words, 2 is a ﬁxed point of the permutation g. Second, g(1) = 3,
and g(3) = 1. This implies in particular that g2(1) = 1, and g2(3) = 3,
moreover, g3(1) = 3, and g3(3) = 1, and so on.
In other words, if we
repeatedly apply g, the elements 1 and 3 will only be permuted among
each other, without any interference from the other entries. Furthermore,
g2 has the eﬀect of the identity permutation 12 · · ·n on the entries 1 and 3,
but g does not. To describe this phenomenon, we will say that 1 and 3 form
a 2-cycle in g. Similarly, g(4) = 5, g(5) = 6, and g(6) = 4. Iterating g, we
see that g2(4) = 6, g2(5) = 4, and g2(6) = 5. Finally, g3(4) = 4, g3(5) = 5,
and g3(6) = 6. Again, we notice that g permutes elements 4, 5, and 6
among each other so that g3 has the eﬀect of the identity permutation on
the entries 4, 5, and 6, but g and g2 do not. To describe this phenomenon,
we will say that 4, 5 and 6 form a 3-cycle in g.
Before we can formally deﬁne cycles, we need the following lemma.
Lemma 6.4. Let p : [n] →[n] be a permutation, and let x ∈[n]. Then
there exists a positive integer 1 ≤i ≤n so that pi(x) = x.
Proof. Consider the entries p(x), p2(x), · · · , pn(x). If none of them is equal
to x, then the Pigeon-hole Principle implies that there are two of them
that are equal, say pj(x) = pk(x), with j < k. Then, applying p−1 to both
sides of this equation, we get pj−1(x) = pk−1(x). Repeating this step, we
get pj−2(x) = pk−2(x), and repeating this step j −3 more times, we get
p(x) = pk−j+1(x).
Time has come for us to make a formal deﬁnition of the notion of cycles
in permutations.

Not So Vicious Cycles. Cycles in Permutations
125
Deﬁnition 6.5. Let p : [n] →[n] be a permutation. Let x ∈[n], and let
i be the smallest positive integer so that pi(x) = x. Then we say that the
entries x, p(x), p2(x), · · · , pi−1(x) form an i-cycle in p.
Corollary 6.6. All permutations can be decomposed into the disjoint
unions of their cycles.
Proof. Lemma 6.4 shows that each entry is a member of a cycle. By the
deﬁnition of cycles, distinct cycles are disjoint.
Example 6.7. The cycles of 321564 are (31), (2), and (564).
Given the cycle decomposition (31)(2)(564) of g, it is easy to reconstruct
g as follows: the image g(i) of i is the entry immediately following i in its
cycle, or, if i is the last entry in its cycle, then g(i) is the ﬁrst entry of that
same cycle.
While the cycle decomposition of a permutation f is unique, the same
cycle decomposition can be written in many diﬀerent ways. The convention
is to write entries that belong to the same cycle in parentheses. The order
of the entries in the parentheses is such that j immediately follows i if
f(i) = j. Furthermore, f(b) = a, where b is the last entry and a is the
ﬁrst entry in the parentheses. However, these principles do not preclude
multiple notations for the same permutation. For instance, (241)(35) and
(53)(412) denote the same permutation. In that permutation, f(2) = 4,
f(4) = 1, f(1) = 2, f(3) = 5, and f(5) = 3.
We would like to avoid the danger of confusion caused by the phe-
nomenon we have just described. Therefore, we will write our permutations
in canonical cycle form. That is, each cycle will be written with its largest
element ﬁrst, and the cycles will be written in increasing order of their ﬁrst
elements. Thus the permutation f of our previous example has canonical
cycle form (412)(53).
Recall that besides using the canonical cycle form, we can also write
a permutation f : [n] →[n] as a list, or linear order, by simply writing
f(1)f(2) · · · f(n). This is sometimes called the one-line notation of permu-
tations.
Example 6.8. Our running example, (412)(53) would be written as 24513
in the one-line notation.
The next section will show the extreme usefulness of our ability to write
permutations using two diﬀerent notations. Figure 6.1 illustrates the two

126
A Walk Through Combinatorics
diﬀerent ways one can think about the same permutation.
1
2
3
4
5
5
5
4
4
1
1
2
2
3
3
Fig. 6.1
Two ways to look at 24513 = (412)(53).
The cycle decomposition of a permutation contains a lot of information
about the permutation. It is therefore important to enumerate permuta-
tions according to their cycle decompositions.
In the rest of this section, all permutations will be taken on the set
[n], and for shortness we will call them n-permutations. The set of all n-
permutations is denoted by Sn. This is because in group theory, this set is
called the symmetric group.
Theorem 6.9. Let a1, a2, · · · , an be nonnegative integers so that the equal-
ity n
i=1 i·ai = n holds. Then the number of n-permutations with ai cycles
of length i where i ∈[n], is
n!
a1!a2! · · · an! · 1a12a2 · · · nan .
(6.1)
Proof. Write down all elements of [n] in a row in some order, then insert
parentheses going left to right, according to the required cycle lengths: ﬁrst
a1 pairs of parentheses creating a1 1-cycles, then a2 pairs of parentheses
creating a2 2-cycles, and so on. This way we obtain a permutation in which
the cycle lengths are nondecreasing left to right.
There are n! ways to do this- that is the number of ways to write down
the elements of [n], and there is only one way to insert the parentheses in
the described manner. However, there are several ways of writing down the
n integers that will lead to the same permutation once the parentheses are
inserted. We must ﬁgure out how many.
The elements within any cycle of length i can be in i diﬀerent orders and
still yield the same cyclic permutation. Therefore, every permutation can
be obtained at least n
i=1 iai times as there are ai cycles of size i. Moreover,
if two ways of writing down the elements of [n] result in permutations which

Not So Vicious Cycles. Cycles in Permutations
127
have the exact same cycles of length i for all i, just in diﬀerent order, then
again they lead to the same permutation. As ai cycles can be permuted
in ai! diﬀerent ways, and permuting the cycles can be done independently
from the order of the elements within the cycles, we have shown that each
permutation can be obtained n
i=1 iaiai! ways, and the proof follows.
If an n-permutation p has ai cycles of length i, for i = 1, 2, · · · , n, then
we say that (a1, a2, · · · , an) is the type or cycle type of p. Thus (6.1) provides
a formula for the number of permutations with a given type.
Example 6.10. The number of n-permutations having only one cycle, in
other words, the number of n-permutations of type (0, 0, · · · , 0, 1) is equal
to (n −1)!.
One combinatorial meaning of Example 6.10 is this. The number of
ways n people can sit around a table is (n −1)!. (We consider two seating
assignments identical if everyone has the same left neighbor in the ﬁrst
seating as in the second.)
Now we are in a position to fulﬁll an old promise, namely we can deﬁne
the Stirling numbers of the ﬁrst kind.
Deﬁnition 6.11. The number of n-permutations with k cycles is called a
signless Stirling number of the ﬁrst kind, and is denoted by c(n, k). The
number s(n, k) = (−1)n−kc(n, k) is called a Stirling number of the ﬁrst
kind.
We will explain the reason for including (−1)n−k in the deﬁnition of
s(n, k) shortly. It will not surprise anyone that c(n, 0) = 0 if n > 0 as
nonempty permutations all have cycles. Moreover, we set c(0, 0) = 1, and
c(n, k) = 0 if n < k, just as was the case with the Stirling numbers of the
second kind.
Like the numbers S(n, k), the numbers c(n, k) also satisfy a simple re-
currence relation.
Theorem 6.12. Let n and k be positive integers satisfying n ≥k. Then
c(n, k) = c(n −1, k −1) + (n −1)c(n −1, k).
(6.2)
Proof. We show that the right-hand side counts all n-permutations with
k cycles, just as the left-hand side. In such a permutation, there are two
possibilities for the position of the entry n.

128
A Walk Through Combinatorics
(1) The entry n can form a cycle by itself, and then the remaining n −1
entries have to form k −1 cycles. This can happen in c(n −1, k −1)
ways, so the ﬁrst member of the right-hand side of (6.2) enumerates
these permutations.
(2) If the entry n does not form a cycle by itself, then the remaining n−1
entries must form k cycles, and then the entry n has to be inserted
somehow into one of these cycles.
The k cycles can be formed in
c(n −1, k) ways, then the entry n can be inserted in any of these
cycles, after each element. This multiplies the number of possibilities
by n −1, and explains the second term of the right-hand side of (6.2).
Readers should test their understanding by trying to explain why we did
not miss any permutations by inserting n after each entry in each cycle,
and not into the front of each cycle.
The reader is probably wondering whether there is some strong connec-
tion between the Stirling numbers of the ﬁrst kind and the Stirling numbers
of the second kind that justiﬁes the similar names. The following Lemma
is our main tool in establishing that connection.
Lemma 6.13. Let n be a ﬁxed positive integer. Then
n

k=0
c(n, k)xk = x(x + 1) · · · (x + n −1).
(6.3)
Proof. We prove that the coeﬃcients of xk on the right-hand side also
satisfy the recurrence relation (6.2) that is satisﬁed by the signless Stirling
numbers of the ﬁrst kind.
Let Gn(x) = x(x + 1) · · · (x + n −1) = n
k=0 an,kxk. Then
Gn(x) = (x + n −1)Gn−1(x) = (x + n −1)
n−1

k=0
an−1,kxk
=
n

k=1
an−1,k−1xk + (n −1)
n−1

k=0
an−1,kxk.
Now we are using a technique that will return in countless applications
in Chapter 8. We have just proved that
n

k=0
an,kxk =
n

k=1
an−1,k−1xk + (n −1)
n−1

k=0
an−1,kxk.

Not So Vicious Cycles. Cycles in Permutations
129
In other words, we proved that two polynomials were identical. The only
way that can happen is when the coeﬃcients of the corresponding terms
agree in the two polynomials. That is, the equality
an,k = an−1,k−1 + (n −1)an−1,k
must hold for all positive integers n and k such that n ≥k. Therefore, the
numbers an,k and c(n, k) do satisfy the same recurrence relation. As their
initial terms trivially agree, that is, c(0, 0) = a0,0 = 1, c(n, 0) = an,0 = 0 if
n > 0, this implies that c(n, k) = an,k.
Let us replace x by −x in (6.3), and multiply both sides by (−1)n. We
get
n

k=0
s(n, k)xk = (x)n.
(6.4)
Now the reader can see why we included the term (−1)n−k in the deﬁ-
nition of s(n, k). Comparing this equation to (5.2), that stated
xn =
n

k=0
S(n, k)(x)k,
we see that the Stirling numbers of the ﬁrst kind have the “inverse eﬀect”
of the Stirling numbers of the second kind. To formulate this observation
in a more precise way, we need some notions from linear algebra, and we
will assume that the reader has taken a basic course in that ﬁeld.
It is well-known that the set of all polynomials with real coeﬃcients is a
vector space V over the ﬁeld of real numbers. The most obvious basis of V
is B = {1, x, x2, x3, · · · }, but it is not the only interesting basis. It is easy
to show that B′ = {1, (x)1, (x)2, (x)3, · · · } is also a basis of V .
Now let S (resp. s) be the inﬁnite matrix whose entry in position (n, k)
is S(n, k) (resp. s(n, k)). Then (6.4) shows that s is the transition matrix
from B to B′, while (5.2) shows that S is the transition matrix from B′ to
B. This proves the promised connection between the two diﬀerent kinds of
Stirling numbers.
Theorem 6.14. The matrices S and s are inverses of each other, that is,
Ss = sS = I.

130
A Walk Through Combinatorics
Quick Check
(1) Write the permutation p = 2453716 in canonical cycle notation.
(2) Write the permutation p = (412)(753)(86) in one-line notation.
(3) Prove that for any n and k, the inequality S(n, k) ≤c(n, k) holds.
(4) How many permutations of length six are there in which every cycle
length is the same?
6.2
Permutations with Restricted Cycle Structure
The following lemma turns the canonical cycle form into a very powerful
tool.
Lemma 6.15 (Transition Lemma). Let p : [n] →[n] be a permutation
written in canonical cycle notation. Let g(p) be the permutation obtained
from p by removing the parentheses and reading the entries as a permuta-
tion in the one-line notation. Then g is a bijection from the set Sn of all
permutations on [n] onto Sn.
Example 6.16. Let p be our running example, that is, p = (412)(53).
Then g(p) = g((412)(53)) = 41253.
Proof. It suﬃces to show that for each permutation q = q1q2 · · · qn written
in the one-line notation, there exists exactly one permutation p ∈Sn so
that q = g(p). In other words, we have to show that there is exactly one
way to insert parentheses into the string q = q1q2 · · · qn so that we get a
permutation in canonical cycle form.
To see this, note that q1 certainly starts a new cycle, so the ﬁrst left
parenthesis has to be inserted to the front of the string. Where will this ﬁrst
cycle end? As we are looking for a permutation in canonical cycle form, q1
has to be the largest of its cycle. Therefore, if i is the smallest index so
that q1 < qi, then the ﬁrst cycle has to end before qi. On the other hand, if
j < i, then the second cycle cannot start with qj as we know that qj < q1,
and the cycles have to be in increasing order of their ﬁrst elements. This
implies that the second cycle has to start with qi, and so we have to insert
the ﬁrst right parenthesis and the second left parenthesis between qi−1 and
qi.
Then we can continue this deterministic procedure to ﬁnd all our cycles.
By an analogous argument, we have to start a new cycle at qk if and only if
qk is larger than the leading entries of all previous cycles, which means in

Not So Vicious Cycles. Cycles in Permutations
131
particular that qk is larger than all entries on its left. As these entries are
uniquely determined by q, the preimage g−1(q) of q exists and is unique.
Example 6.17. The preimage of 4356172 under g is (43)(5)(61)(72).
The entries of q that are larger than all entries on their left are called left-
to-right maxima. Note that if q has t left-to-right maxima, then g−1(q) = p
has t cycles.
Also note that the leftmost left-to-right maximum of q is
always q1, and the rightmost left-to-right maximum of q is always the entry
n. A surprising application of Lemma 6.15 is the following.
Proposition 6.18. Let i and j be two elements of [n]. Then i and j are
in the same cycle in exactly half of all n-permutations.
Proof. As we can relabel our entries by switching n and i, and switching
n −1 and j, it is suﬃcient to prove that the entries n and n −1 are in the
same cycle in exactly half of all n-permutations. Let q = q1q2 · · · qn be an
n-permutation, and let g(p) = q, where g is the bijection of Lemma 6.15.
As we said, the entry n of q is always a left-to-right maximum, namely the
rightmost left-to-right maximum of q. Therefore, the last cycle of p starts
with n, and the entries in that cycle of p are precisely the entries on the
right of n in q.
Therefore, p contains n and n −1 in the same cycle if and only if n −1
is on the right of n in q. As that happens in half of all n-permutations, the
proof follows.
The following surprising result shows that the likelihood that a given
entry i is part of a k-cycle is independent of k. In fact, it is 1/n.
Lemma 6.19. Let i ∈[n]. Then for all k ∈[n], there are exactly (n −1)!
permutations of length n in which the cycle containing i is of length k.
Proof. Again, it is suﬃcient to prove the statement for i = n, then the
general statement follows by relabeling.
Let q = q1q2 · · · qn be an n-
permutation, let g(p) = q, where g is the bijection of Lemma 6.15, and
let qj = n. Then the cycle C containing n in p is of length n −j + 1 as n
itself starts the last cycle. So if we want C to have length k, we must have
j = n + 1 −k. However, there are clearly (n −1)! permutations of length
n that contain n in a given position, and the proof follows.
Theorem 6.9 tells us how to compute the number of permutations of a
given type. Sometimes we do not exactly know the type of our permuta-

132
A Walk Through Combinatorics
tions, but we at least know something about it. As it turns out, we can
still enumerate the relevant permutations in many cases. In what follows,
we will show a nice example for that. Other examples can be found in the
Exercises.
Let ODD(m), resp. EVEN(m) be the set of m-permutations with all
cycle lengths odd, resp. even.
Lemma 6.20. For all positive integers m, the equality | ODD(2m)| =
| EVEN(2m)| holds.
Proof. We construct a bijection Φ from ODD(2m) onto EVEN(2m).
Let π ∈ODD(2m).
Then π consists of an even number 2k of odd
cycles. Denote by C1, C2, · · · , C2k the cycles in canonical order. For all i,
1 ≤i ≤k, take the last element of C2i−1, and put it to the end of C2i to
get Φ(π), the image of π.
Example 6.21. If p = (4)(513)(726)(8), then Φ(p) = (5134)(72)(86).
Note that if C2i−1 is a singleton, it disappears.
Also note that the
canonical form is maintained.
We claim that Φ is a bijection from ODD(2m) onto EVEN(2m). Let
σ ∈EVEN(2m), with cycles c1, c2, · · · , ch. To prove that Φ is a bijection,
it suﬃces to show that we can recover the only permutation π ∈ODD(2m)
for which Φ(π) = σ.
While recovering π, we must keep in mind that it might have more than
h cycles, because some of its singletons might have been absorbed by the
cycles immediately after them. If the last entry in ch is larger than the
ﬁrst entry in ch−1, then create a singleton cycle with the last entry in ch,
placing it in front of ch, and repeat the whole procedure using ch−2 and
ch−1. Otherwise, move the last entry in ch from ch to the end of ch−1, and
repeat the whole procedure using ch−3 and ch−2. If at any point only one
cycle remains, create a singleton cycle with the last entry in that cycle. It
is then straightforward to check that the permutation π obtained this way
fulﬁlls Φ(π) = σ. It also follows from the simple structure of Φ that at no
point of the recovering procedure could we have done anything else.
Example
6.22. The
preimage
of
(41)(62)(75)(83)
under
Φ
is
(412)(6)(753)(8).
Example
6.23. The
preimage
of
(21)(53)(64)(87)
under
Φ
is
(1)(2)(534)(6)(7)(8).

Not So Vicious Cycles. Cycles in Permutations
133
Now that we so nicely proved that | ODD(2m)| = | EVEN(2m)|, we may
well ask if there is a formula describing these numbers. The following The-
orem answers that question in the aﬃrmative, and has a touch of surprise
in it. Would you have thought that the number of these permutations is
always a perfect square?
Theorem 6.24. For all positive integers m,
| ODD(2m)| = | EVEN(2m)| = 12 · 32 · 52 · · · (2m −1)2.
(6.5)
Solution. Because of Lemma 6.20, it suﬃces to prove the second equality.
Let p be an n-permutation with even cycles only. Clearly, we cannot have
p(1) = 1, as that would mean that the entry 1 forms a 1-cycle in p. So there
are 2m−1 choices for p(1). Then there are 2m−1 choices for p2(1) = p(p(1))
as we can choose everything but p(1) itself.
So far we have chosen p(1) and p(p(1)). These two elements will either
form a 2-cycle (when p(p(1)) = 1), or they will not. In either case, we will
have 2m −3 choices for the image of the next entry. That is, if 1 and p(1)
form a 2-cycle, and i is an element outside that cycle, then we have 2m −3
choices for p(i). Indeed, we can choose anything except 1, p(1), these have
already been chosen, and p(i), as that would mean that i is a 1-cycle. If,
on the other hand 1 and p(1) do not form a 2-cycle, then we choose the
next element of their cycle, p3(1) next. The entry p3(1) cannot be p(1) and
p2(1) as those elements are already chosen, and cannot be 1 either as that
would create the 3-cycle (1, p(1), p2(1)). So there are 2m−3 choices for the
next element in this case too.
Continuing this line of argument, we see that selecting our (2i −1)st
entry we always have 2m −2i + 1 choices, and selecting our 2ith entry we
always have 2m −2i + 1 choices, (as we can close cycles of even length),
and the proof follows.
Thus we have a formula for | ODD(n)| if n is even. If n is odd, then
clearly, | EVEN(n)| = 0, but we can still look for a formula for | ODD(n)|.
Theorem 6.25. For all positive integers m,
| ODD(2m+ 1)| = (2m+ 1)·| ODD(2m)| = 12 ·32 ·52 · · · (2m−1)2(2m+ 1).
(6.6)
Proof. We construct a bijection Ψ from ODD(2m) × [2m + 1] onto
ODD(2m + 1). In this bijection, we will need the notion of a gap posi-
tion. This notion will be useful to solve some of the exercises, too. An

134
A Walk Through Combinatorics
m-permutation has m + 1 gap positions, one after each element in each
cycle, and one at the very beginning of the permutation, before all entries
and cycles.
Example 6.26. The permutation (42)(513) has six gap positions, indicated
by bars in the following array: |(4|2|)(5|1|3|).
Let π ∈ODD(2m), and let k ≤2m + 1 be a positive integer. We deﬁne
Ψ(π, k) as follows. First, take Φ(π), where Φ is the bijection of Lemma 6.20.
Let us now add 1 to each entry of Φ(π), so it becomes a permutation of the
set {2, 3, · · · , 2m + 1}. Insert the new entry 1 to the kth gap position of
Φ(π). That will change one cycle to an odd cycle. Note that the canonical
cycle form is preserved. Apply the bijection Φ−1 to the permutation given
by the remaining cycles to get a permutation that has odd cycles only. This
way we obtain a (2m + 1)-permutation consisting of odd cycles only, and
that permutation is our Ψ(π).
Lemma 6.27. The map Ψ deﬁned above is a bijection from the set
ODD(2m) × [2m + 1] onto the set ODD(2m + 1).
Proof. To ﬁnd the reverse of Ψ, take π′ ∈ODD(2m + 1), put the cycle in
π′ which contains the entry 1 aside, and run the remaining cycles through
Φ to get even cycles. Read oﬀk as the gap position in which the entry 1 is.
Remove the entry 1 from its odd cycle, and run the obtained permutation,
which has all even cycles, through Φ−1, to get Ψ−1(π′). Note that at every
step, we have reversed the corresponding step of Ψ.
This completes the proof of the theorem.
Quick Check
(1) Let n ≥4 be an even number. How many permutations of length n are
there in which 1 and 2 are in the same cycle, and that cycle is longer
than n/2?
(2) Find all permutations p of length ﬁve so that g(p) = p holds, where g
is the map deﬁned in the Transition lemma.
(3) Find a formula for the number of permutations of length n that contain
exactly one cycle of even length.

Not So Vicious Cycles. Cycles in Permutations
135
Notes
A fair part of the results in Section 6.2 were obtained after Herb Wilf asked
some intriguing questions in [59]. Most of the results presented here have
been generalized in [16]. For example, it has been proved that if p is prime,
then the ratio of n-permutations that have a pth root to all n-permutations
is steadily decreasing, and converges to zero. See Exercises 21 and 22 for
the relevant deﬁnitions.
For more details on the combinatorics of permutations, the reader is
encouraged to consult the book [13].
Exercises
(1) Is it true that c(n, n −1) = S(n, n −1)?
(2) Find a formula for c(n, n −2).
(3) Compute the values of c(5, k), for k = 1, 2, 3, 4, 5.
(4) Prove that for any ﬁxed k, the function c(n, n −k) is a polynomial
function of n. What is the degree of that polynomial?
(5) Let r(n) be the number of n-permutations whose square is the identity
permutation. Prove that if n ≥1, then r(n + 1) = r(n) + nr(n −1),
where r(0) = 1.
(6) Find a recursive formula for the number t(n) of n-permutations whose
cube is the identity permutation.
(7) Prove that on average, permutations of length n have Hn cycles, where
Hn =
n

i=1
1
i .
(8) How many n-permutations contain entries 1, 2 and 3 in the same cycle?
(9) An alpine ski team has n members. They descend a particular slope
one by one every day, and no two of them ever record identical times.
On an average day, how many times will the best record of that day be
broken?
(10) An airplane has n seats, and all of them have been sold for a particular
ﬂight, with no overbooking. When the last passenger arrives, he ﬁnds
that his seat is taken. When he shows his reservation to the passenger
at his seat, that passenger stands up, and goes to her own assigned
seat. If that seat is empty, she seats down, and the seating procedure
is over. If not, she shows her reservation to the person seating at that

136
A Walk Through Combinatorics
seat. That person stands up, and goes to his assigned seat, and so on.
This procedure continues until someone ﬁnds his or her assigned seat
empty.
Tom was not the last passenger to board the plane. What is the prob-
ability that he has to move during this procedure?
(11) Let p be an n-permutation. We associate a permutation matrix Ap to
p as follows. Let Ap(i, j) = 1 if p(i) = j, and let Ap(i, j) = 0 otherwise.
Here Ap(i, j) denotes the entry of Ap that is in the intersection of the
ith row and the jth column. Prove that | det A| = 1.
(12) Prove that if p and q are two n-permutations, then ApAq = Apq.
(13) The inverse of an n-permutation is the permutation q for which pq =
qp = 123 · · ·n. We then write q = p−1. Prove that each permutation
has a unique inverse.
(14) Prove that permutations f and f −1 are of the same type.
(15) What is the combinatorial meaning of AT
p ?
(16) In permutations, 1-cycles are often called ﬁxed points. Prove, using
permutation matrices, that permutations pq and qp always have the
same number of ﬁxed points.
(17) Let us assume that we know the type (a1, a2, · · · , an) of an n-
permutation.
Determine the smallest positive integer d such that
pd = 123 · · ·n.
(18) A permutation p is called a nontrivial involution if p2 = 12 · · · n, but p ̸=
12 · · ·n. Prove that if n > 1, then the number of nontrivial involutions
in Sn is odd.
(19) Generalize the previous exercise for all prime numbers t.
(20) Let n ≥2.
Prove that det Ap = 1 for exactly one half of all n-
permutations p.
(21) We say that a permutation p ∈Sn has a square root if there is a
permutation q ∈Sn so that q2 = p. Find a suﬃcient and necessary
condition for p to have a square root, in terms of its cycle lengths.
(22) We say that a permutation p ∈Sn has a kth root if there is a permu-
tation q ∈Sn so that qk = p. Is the following statement true?
“A permutation has a kth root if and only if it is of type (a1, a2, · · · , an),
where whenever i is divisible by k, ai is divisible by k.”
(23) (+) Construct a bijection
τ : ODD(2m + 1) × [2m + 1] →ODD(2m + 2).
(24) (++) Let SQ(n) be the set of n-permutations having at least one square
root. Prove that for all positive integers n, we have |SQ(2n)|·(2n+1) =

Not So Vicious Cycles. Cycles in Permutations
137
|SQ(2n+1)|. Note that this means that p(2n) = p(2n+1), where p(m)
denotes the probability that a randomly chosen m-permutation has a
square root.
(25) Let k, m, and r be positive integers, and let kr = m. Prove that the
number of m-permutations all of whose cycle lengths are divisible by k
is
1 · 2 · · · (k −1)(k + 1)2(k + 2) · · · (2k −1)(2k + 1)2(2k + 2) · · · (m −1)
= m!
krr! · (k + 1)(2k + 1) · ((r −1)k + 1).
Supplementary Exercises
(26) (-) What is the number of n-permutations in which entries 1 and 2
are part of the same 3-cycle?
(27) (-) Find the number of permutations of length six whose square is the
identity permutation.
(28) (-) What is the number of permutations of length 20 whose longest
cycle is of length 11?
(29) (-) What is the number of n-permutations that have n−1 left-to-right
maxima?
(30) (-) A group of ten children want to play cards. They split into three
groups, one of these groups has four children in it, the other two have
three each. Then each group sits around a table. Two seatings are
considered the same if everyone’s left neighbor is the same.
(a) In how many ways can this be done if the three tables are identical?
(b) In how many ways can this be done if the three tables are distinct?
(31) What is the number of (2n)-permutations whose longest cycle is of
length n?
(32) Let p = p1p2 · · · pn be a permutation. An inversion of p is a pair of
entries (pi, pj) so that i < j but pi > pj.
Let us call a permutation even (resp. odd) if it has an even (resp. odd)
number of inversions.
Prove that the permutation consisting of the one cycle (a1a2 · · · ak) is
even if k is odd, and is odd if k is even.
(33) Find a combinatorial proof for the fact that there are n!/2 even n-
permutations.
(34) What is the relation between the parity of a permutation p and det Ap?

138
A Walk Through Combinatorics
(35) Let us assume that we only know the type of the n-permutation p.
How can we decide whether p is odd or even?
(36) Let us assume that we know the length n of a permutation p, and the
number k of its cycles. Can we ﬁgure out from these data whether p
is an odd or an even permutation?
(37) Prove the result of Supplementary Exercise 33 by an appropriate sub-
stitution into formula (6.3).
(38) How many permutations p ∈S6 satisfy p3 = id, where id = 123456
(the identity permutation)?
(39) How many even permutations p ∈S6 satisfy p2 = id?
(40) Let n be divisible by 3. Prove that c(n, n/3) ≥
n!
3n/3(n/3)!.
(41) Prove that for all positive integers n, r and k such that n = rk, the
inequality
(r −1)!k ≤c(n, k)
S(n, k) ≤(n −k)!
holds.
(42)(a) Prove that in the polynomial
(1 + x)(1 + 2x) · · · (1 + (n −1)x)
the coeﬃcient of xn−k is c(n, k), for all k ∈n.
(b) State and prove the corresponding fact for the numbers s(n, k).
(43) Let a(n, k) be the number of permutations of length n with k cycles in
which the entries 1 and 2 are in the same cycle. Prove that for n ≥2,
n

k=1
a(n, k)xk = x(x + 2)(x + 3) · · · (x + n −1).
(44) (+) Let br(n, k) be the number of permutations of length n with k
cycles in which all entries of [r] are in the same cycle. Prove that for
n ≥r,
n

k=1
br(n, k)xk = (r −1)!
x(x + 1) · · · (x + n −1)
(x + 1)(x + 2) · · · (x + r −1).
(45) Let a(n, k) be deﬁned as in Supplementary Exercise 43. Let t(n, k) =
c(n, k) −a(n, k) be the number of permutations of length n with k
cycles in which the entries 1 and 2 are not in the same cycle. Prove
that a(n, k) = t(n, k + 1), for all k ≤n −1.
(46) A group of n tourists arrive at a restaurant. They sit down around an
unspeciﬁed number of circular tables, leaving no table empty. Then

Not So Vicious Cycles. Cycles in Permutations
139
each table orders one of r possible drinks. Prove that the number of
ways this can happen is
r(r + 1) · · · (n + r −1).
Two seating arrangements are considered the same if each person has
the same left neighbor in both of them.
(47) We write each element of [n −1] on a separate card, then randomly
select any number of cards, and take the product of the numbers of
written on them. Then we do this for all 2n−1 possible subsets of the
set of n −1 cards. (The empty product is taken to be 1.) Finally, we
take the sum of the 2n−1 products we obtained. What is this sum?
(48) Modify the previous exercise so that instead of considering all 2n−1
subsets, we only consider all k-element subsets of the n −1 cards.
What is the sum of all
n−1
k

products we obtain in that scenario?
(49) Find a recurrence relation satisﬁed by the numbers u(n) of n-
permutations whose fourth power is the identity permutation.
(50) A library has n books. Readers of this library are “almost” careful.
That is, after reading a book, they put it back to its shelf, missing its
proper place by only one notch. Prove that after a suﬃcient amount
of time, any permutation of the books on the shelves can occur.
(51) Prove that two n-permutations p and q have the same type if and only
if there exists an n-permutation g so that q = gpg−1 holds.
(52) Inversions of a permutation were deﬁned in Supplementary Exercise
32. Let I(n, k) be the number of n-permutations that have k inver-
sions. Prove that I(n, k) = I(n,
n
2

−k).
(53) Let I(n, k) be deﬁned as in the previous exercise. Prove that
(n
2)

k=0
I(n, k)xk = (1 + x)(1 + x + x2) · · · (1 + x + · · · + xn−1).
(54) Deduce from the result of the previous exercise that the number of even
n-permutations is the same as the number of odd n-permutations.
(See Supplementary Exercise 32 for the deﬁnition of even and odd
permutations.)
(55) Find an explicit formula for I(n, 3).
(56) Is it true that p and p−1 always have the same number of inversions?
(57) The notion of a square root of a permutation was deﬁned in Exercise
21. Find a suﬃcient and necessary condition, in terms of cycle lengths,
for a permutation p to have a square root that is an even permutation.

140
A Walk Through Combinatorics
Solutions to Exercises
(1) Yes, that is true. S(n, n−1) is the number of ways to partition [n] into
one doubleton and n−2 singletons. To get c(n, n−1), we have to take
a permutation consisting of one cycle on each of these n −1 subsets.
There is only one way to do this, thus c(n, n −1) = S(n, n −1) =
n
2

.
(2) An n-permutation that has n −2 cycles can have either two 2-cycles,
or one 3-cycle, and the rest must be all 1-cycles. In the ﬁrst case, we
can choose the elements of the ﬁrst 2-cycle in
n
2

ways, the elements
of the second 2-cycle in
n−2
2

ways, then take a 2-cycle on each of
them in one way. This yields
n
2

·
n−2
2

/2 permutations as the order
of the cycles is irrelevant. In the second case, we have to choose the
elements of the 3-cycle in
n
3

ways, then take a 3-cycle on them in 2
ways. This yields 2
n
3

permutations, and proves that
c(n, n −2) = n(n −1)(n −2)(n −3)
8
+ n(n −1)(n −2)
3
.
(3) It follows from (6.10) that c(5, 1) = 4! = 24. Exercise 1 shows that
c(5, 4) =
5
2

= 10, and Exercise 2 shows that c(5, 3) = 15 + 20 = 35.
It is obvious that c(5, 5) = 1. As 5
k=1 c(5, k) = 5! = 120, the equality
c(5, 2) = 50 follows.
(4) We prove the statement by induction on k. If k = 1, then the state-
ment is true by Exercise 1. Now assume we know the statement for
k −1. This implies
c(n, n −k) = c(n −1, n −k −1) + (n −1)c(n −1, n −k),
c(n, n −k) −c(n −1, n −k −1) = (n −1)c(n −1, n −k).
Here the right-hand side is a polynomial by the induction hypothesis,
and therefore so is the left-hand side. However, the left-hand side is the
diﬀerence of two consecutive values of c(n, n−k), therefore c(n, n−k)
must be a polynomial by Exercise 1 of Chapter 2. Similarly, the degree
of c(n, n −k) is 2n, by this same inductive setup, and Exercise 1 of
Chapter 2.
(5) In such permutations, all cycles must be 1-cycles or 2-cycles. If the
entry n + 1 forms a 1-cycle, then the remaining n entries can form
a good permutation in r(n) ways. If the entry n + 1 is part of a 2-
cycle, then there are n choices for the other entry of that 2-cycle, then
there are r(n −1) ways for the remaining n −1 entries to form a good
permutation.

Not So Vicious Cycles. Cycles in Permutations
141
(6) This is similar to the previous exercise. All cycles of such permutations
have length one or three. If n + 1 is in a 3-cycle, then there are
n
2

choices for the other two elements of the cycle, and there are 2 choices
for the cycle itself, once its elements are known. Then the remaining
entries can form a good permutation in t(n −2) ways. If the entry
n + 1 forms a 1-cycle, then the remaining n entries can form a good
permutation in t(n) ways. Therefore, t(n+1) = n(n−1)t(n−2)+t(n)
if n ≥3.
(7) We prove the statement by induction on n. For n = 1, the statement is
true. Assume it is true for n−1. There is 1/n chance that entry 1 forms
a 1-cycle, and then the remaining n−1 elements form Hn−1 cycles on
average. If entry 1 does not form a 1-cycle, then, take any permutation
of the elements {2, 3, 4, · · · , n} in the canonical distribution. Insert
entry 1 after any of these elements. This will not change the number
of cycles as entry 1 will not start a new cycle. Therefore, the number
of permutations with k cycles stays the same for all k, so their average
stays the same, too, i.e. H(n −1). Therefore, we get
H(n) = 1
n · (H(n −1) + 1) + n −1
n
· H(n −1) = H(n −1) + 1
n,
and the statement follows.
(8) Entries 1, 2, and 3 are together in one cycle exactly as often as elements
n −2, n −1, n are. This latter happens exactly when, after omitting
all parentheses from the cycle notation, n precedes both n −2 and
n −1. And that clearly happens in 1/3 of all permutations. So there
are n!/3 such permutations, for n ≥3.
(9) This is the same as asking that on average, how many left-to-right
minima does a random n-permutation have. In accordance with the
paragraph following Example 6.17, a left-to-right minimum is an entry
of a permutation p = p1 · · · pn that is smaller than all entries on its left.
This is the same as the average number of cycles in an n-permutation,
and we have computed that in Exercise 7.
(10) If 1, 2, · · · , n denote the passengers, and f(1), f(2), · · · , f(n) denote
their assigned seats, then it is clear that f(1)f(2) · · · f(n) is a permu-
tation. Tom will have to move if and only if in this permutation, his
seat is part of the same cycle as the seat f(n) of passenger n, who
arrived last. We know from Proposition 6.18 that the chance of that
is one half.
Exercise 7, and the paragraph following Example 6.17 tell us that for
left-to-right maxima, the answer is H(n) = n
i=1
1
n. To see that this

142
A Walk Through Combinatorics
is also the answer for left-to-right minima, note that p1p2 · · · pn has
t left-to-right minima if and only if the permutation q = q1q2 · · · qn,
where qi = n + 1 −pi, has t left-to-right maxima. By the way, q is
called the complement of p.
(11) That is true as each row and column will have exactly one nonzero
member. Therefore, when expanding the determinant by any row or
column, we will only obtain one nonzero product. That product will
be the product of many ones, so the only open question is whether
that product will occur in the determinant with a positive sign or with
a negative sign. That depends on p.
(12) Consider (ApAq)(i, j). By the deﬁnition of matrix multiplication, this
is the inner product of the ith row of Ap and the jth column of Aq. As
both of these vectors have exactly one nonzero element in them, their
inner product will be 1 if and only if those nonzero elements occur
in the (same) kth position in both vectors. That, however, happens
if and only if p(i) = k, and q(k) = j, which is also equivalent to
pq(i) = j. Therefore, (ApAq)(i, j) = Apq(i, j).
(13) The n-permutation q is the inverse of the n-permutation p if and only
if p(i) = j implies q(j) = i. This relation uniquely deﬁnes q.
(14) Reversing each cycle of p results in p−1.
(15) If p(i) = j, then Ap(i, j) = 1, so AT
p (j, i) = 1. Therefore, AT
p deﬁnes
a permutation q in which q(j) = i if and only if p(i) = j. This means
pq = qp = 12 · · ·n, so q is the inverse of p. Thus the transpose of a
permutation matrix is the permutation matrix of the inverse of the
original permutation. This also implies ApAT
p = I.
(16) The number of ﬁxed points of a permutation can be read oﬀits per-
mutation matrix as the number of ones in the main diagonal. As the
remaining entries of the main diagonal are zeros, the number of ones in
the main diagonal also equals the sum of diagonal elements, which is
called the trace of the matrix. It is well known in Linear Algebra that
trace(AB) = trace(BA) for all n × n matrices A and B. Therefore,
trace(ApAq) = trace(AqAp),
and the claim is proved.
(17) The smallest positive integer d with that property is the least common
multiple of the cycle lengths of the permutation, that is, the indices
i so that ai > 0. Indeed, the kth, 2kth, etc. powers of a k-cycle are
equal to the identity permutation.
(18) If n > 1, then n! is even. Let us arrange all n-permutations into pairs,
by placing p and p−1 in the same pair. That will create a t pairs,

Not So Vicious Cycles. Cycles in Permutations
143
containing altogether 2t permutations, but will not match involutions
and 12 · · ·n to anything. Thus the number of these latter is n! −2t,
therefore the number of involutions is n! −2t −1, and that is an odd
number.
(19) If t is prime, and n ≥t, then the number of n-permutations p so that
pt = 12 · · · n, but p ̸= 12 · · ·n is congruent to −1 modulo t. The proof
is analogous to that of the previous exercise.
(20) Consider (21) = (21)(3)(4) · · · (p), the permutation that simply swaps
the ﬁrst two entries. For any p ∈Sn, we deﬁne h(p) = (12)p. As
det A(12) = −1, the matrices Ap and Ah(p) have determinants of op-
posite signs. On the other hand, h(h(p)) = p, therefore h creates pairs
of permutations (p, h(p)). Each pair will contain exactly one permu-
tation whose matrix has determinant 1, and the claim is proved.
(21) Let r ∈Sn, and consider r2. It is straightforward to verify that if k
is odd, then the k-cycles of r will stay k-cycles in r2, and if k is even,
the k-cycles of r will split into two k
2-cycles in r2. So the only way
r2 can have even cycles is by obtaining them from an even cycle of
r, that has split into two cycles of the same size, each of them even.
Therefore, r2 will have an even number of cycles of each even length.
On the other hand, we claim that this is suﬃcient. That is, if p has an
even number of cycles of each even length, then p has a square root.
Indeed, if p has even cycles (a1 · · · at) and (b1 · · · bt), then they can be
obtained by taking the square of the (2t)-cycle (a1b1a2b2a3 · · · atbt).
Odd cycles of p, such as (d1d3d5 · · · dkd2d4 · · · dk−1) can be obtained
as the square of (d1d2 · · · dk). After ﬁnding square roots for all cycles
of p, a good choice for the square root of p is the product of those
cycles.
We have proved that p has a square root if and only if p has an even
number of cycles of each even length.
(22) No, that is not true in this generality. The claim is true if k is prime,
and in that case, it can be proved the same way the previous exercise
was proved.
If k is not prime, however, then the statement is not true. For instance,
if k = 4, then the requirements do not say anything about the number
of 2-cycles of p. Thus p = (21)(3)(4)(5) · · · (n) would have to have a
fourth root. That is clearly impossible, however, as this p does not
even have a square root. (If there were a q so that q4 = p, then q2
would be a square root of p.) The reader is invited to construct a
similar counterexample for a generic composite number k.

144
A Walk Through Combinatorics
(23) Take a pair (π, k) ∈ODD(2m + 1) × [2m + 1], and insert the entry 1
to the (k + 1)st gap position. Note that this implies that the entry 1
cannot create a singleton cycle as it cannot go to the ﬁrst gap position.
Take away the cycle C containing 1, and run Φ (of Lemma 6.20)
through the remaining cycles.
Then, together with C, we have a
permutation in EVEN(2m + 2). Run it through Φ−1 to get τ(π, k) ∈
ODD(2m + 2).
(24) We are going to construct a bijection κ from SQ(2n) × [2n + 1] onto
SQ(2n + 1). As the growth of |SQ(n)| is equal to that of | ODD(n)|
when passing from an even n to an odd n + 1, we try to integrate
Ψ of Lemma 6.27 into κ, by “stretching” the odd cycles part of our
permutations. We proceed as follows.
Let (π, k) ∈SQ(2n) × [2n + 1]. Take π, and break it into even cycles
part and odd cycles part, or, for short, odd part and even part. Again,
let k mark a gap position in π. If this gap position is in the odd cycles,
or at the end of π, then interpret the gap position as a gap position for
the odd part only, and simply run the odd part and this gap position
through Ψ to get κ(π), together with the unchanged even parts. Note
that 2n + 1 will appear in an odd cycle when we are done.
If the gap position marked by k is in one of the even cycles, say c, we
can think of it as marking the member of c immediately following it,
say x. Replace x by 2n + 1 in c. To keep the information encoded by
x, we interpret x as a gap position in the odd part of π. Indeed, if x is
larger than exactly i −1 entries in the odd part, then let us mark the
ith gap position in the odd cycles part. So now we are in a situation
like in the previous case, that is, the gap position is in the odd part.
Run the odd part and this gap position through Ψ. Instead of inserting
2n + 1 to the marked position, however, insert temporarily a symbol
B, to denote a number larger than all entries in the odd part. Then
decrement all entries in the odd part that are larger than x (including
B) by one notch. The obtained odd cycles and the unchanged even
cycles (except for the mentioned change in c) give us κ(π). Note that
2n + 1 will be in an even cycle when we’re done.
We claim that the map κ deﬁned above is a bijection from the set
SQ(2n) × [2n + 1] onto the set SQ(2n + 1). First, let us verify that κ
maps into SQ(2n + 1). Indeed, (π) and κ(π) have the same number
of cycles of each even length, so by Exercise 21, π ∈SQ(2n) implies
κ(π) ∈SQ(2n + 1).
To get the reverse of κ, take a permutation π′ ∈SQ(2n+1), and locate

Not So Vicious Cycles. Cycles in Permutations
145
2n + 1. If it is in an odd cycle, then run the odd cycles through Ψ−1.
This will yield an odd part one shorter, and an element of [2n + 1].
Putting this together with the unchanged even part, we get κ−1(π′).
If 2n+1 is in an even cycle, then run the odd cycles part through Ψ−1.
This will specify a gap position in the odd part, and so we recover the
entry x. Increment entries larger than x by one notch in the odd part.
To get the even part, put x back to the place of 2n + 1. The gap
position immediately preceding 2n + 1 is our k in κ−1(π′).
(25) Note that when we proved Theorem 6.24, we proved a special case of
this problem, that is, the one when k = 2. The very same method will
prove this general statement.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 7
You Shall Not Overcount. The Sieve
7.1
Enumerating The Elements of Intersecting Sets
In a high school class there are 14 students who play soccer and there are
17 students who play basketball. How many students play at least one of
these two sports?
The above question may sound extremely simple. However, we cannot
answer it from the given information. Simply adding the two given numbers
could yield an incorrect answer. Indeed, there may be students who play
both sports. If we simply added the number of basketball players and the
number of soccer players, we would count these students twice. To correct
that, we would have to subtract their number once (so that they are counted
only once), but we can only do that if we know their number.
Example 7.1. There are 14 students in a high school class who play soccer,
and there are 17 students who play basketball. Four students play both
games. How many students play at least one of the two games?
Solution. By the above argument, the number of students playing at least
one of these two games is 14 + 17 −4 = 27.
Figure 7.1 illustrates the above situation.
The situation becomes more complicated, but still controllable, if the
students are playing up to three diﬀerent games. This is the content of our
next example.
Example 7.2. In a high school class, there are 14 students who play soccer,
17 students who play basketball, and 18 students who play hockey. Four
students play both soccer and basketball, three play both soccer and hockey,
147

148
A Walk Through Combinatorics
Soccer
Basketball
4
10
13
Fig. 7.1
Two intersecting sets.
and ﬁve play both basketball and hockey. There is one student who plays
all three games. How many students play at least one of these games?
Solution. We can start our answer as before: adding the numbers of stu-
dents playing soccer, basketball and hockey 14 + 17 + 18 results in an
overcount because we count students who play two of these games twice,
therefore we have to correct this mistake and subtract the number of these
students so that they are only counted once.
This yields the number
14 + 17 + 18 −4 −3 −5. This is not a complete answer, however. The
only student who plays all three games was counted three times (once for
each game), but then she was subtracted three times (once for each pair of
games), so right now she is not counted at all. Therefore, we have to correct
this mistake by counting her, that is, by adding 1 to our ﬁnal answer. Thus
there are 14 + 17 + 18 −4 −3 −5 + 1 = 38 students in the class that play
at least one of these three games.
We can again represent this situation by a diagram. This diagram is
shown in Figure 7.2.
The reader can probably see that as the number of games increases,
the same question requires a more and more tedious answer. Therefore, a
general theorem is certainly useful to handle situations of this kind. Such a
theorem does exist, and we will cover it now. There are at least two names
for this theorem, namely the Principle of Inclusion-Exclusion, or the Sieve
Formula.
It is important to note that while the formula given in the following
theorem may look complicated, it describes a relatively simple phenomenon,

You Shall Not Overcount. The Sieve
149
1
Soccer
Basketball
Hockey
3
9
2
11
4
8
Fig. 7.2
Three intersecting sets.
and the computation it involves is often simpler than it looks, since many
summands are often identical.
Theorem 7.3 (Sieve Formula, or Principle of Inclusion-Exclusion).
Let A1, A2, · · · , An be ﬁnite sets. Then
|A1 ∪A2 ∪· · · ∪An| =
n

j=1
(−1)j−1

i1,i2,··· ,ij
|Ai1 ∩Ai2 ∩· · · ∩Aij|,
(7.1)
where {i1, i2, · · · , ij} ranges over all j-element subsets of [n].
Note that Theorem 7.3 is called the Sieve Formula since it counts “good”
elements by sifting out the “bad” ones. A more formal name for the princple
behind that counting idea is the Inclusion-Exclusion Principle.
Before proving this quintessential theorem, we would like to stress that
the seemingly complicated expression on the right-hand side refers in fact
to a conceptually simple sum: the alternating sum of the sizes of all j-fold
intersections. The alternating sign is explained by the fact that we have
to correct the overcounts. The two examples discussed before the theorem
were the special cases when n = 2 and n = 3. In the ﬁrst example, the sum
on the right-hand side was |A1| + |A2| −|A1 ∩A2|, in the second example,
the sum on the right-hand side was
|A1| + |A2| + |A3| −|A1 ∩A2| −|A1 ∩A3| −|A2 ∩A3| + |A1 ∩A2 ∩A3|.

150
A Walk Through Combinatorics
Proof of Theorem 7.3. Notice that an element not in A1 ∪A2 ∪· · · ∪An
is not counted in any term on the right-hand side of (7.1). Thus we only
have to show that each element of A1 ∪A2 ∪· · ·∪An is counted exactly once
on the right-hand side. To do that, pick any element x ∈A1 ∪A2 ∪· · ·∪An.
Let S ⊆[n] be the set of indices so that x ∈Ai if and only if i ∈S,
and let s = |S|.
Note that s ≥1.
As x ∈Ai only if i ∈S, a t-fold
intersection Ai1 ∩Ai2 ∩· · ·∩Ait cannot contain x unless (i1, i2, · · · , it) ⊆S.
So when determining the number of times x is counted by the right-hand
side, we only have to consider the intersections involving the Ai which are
indexed by S. On the other hand, each of these intersections does contain x.
Therefore, the right-hand side counts x once for each of these subsets, with
alternating signs. So altogether, the right-hand side counts the element x
s −
s
2

+
s
3

−· · · + (−1)s−1
s
s

= 1
(7.2)
times. To see that the left-hand side of (7.2) is indeed 1, subtract 1 from
both sides, then multiply both sides by −1, to get
1 −s +
s
2

−
s
3

−· · · + (−1)s
s
s

= 0 = (1 −1)s,
which is true by the Binomial theorem (and is further explained in Theorem
16.21).
Quick Check
(1) How many partitions does [n] have in which 1 shares a block with at
least one of 2 and 3?
(2) How many positive integers are there that are divisible by at least one
of 5, 6, and 7, and are at most 1000?
(3) How many compositions does the integer 12 have into three parts none
of which is equal to 2?
7.2
Applications of the Sieve Formula
Let us discuss some classic applications of the sieve formula. The ﬁrst is
the problem of derangements.
Example 7.4. A party was attended by n guests. When the guests arrived,
they left their hats in the same coatroom. After the party ended, there was
an electrical power failure, so each guest took a hat from the coatroom at

You Shall Not Overcount. The Sieve
151
random. When the guests were back on the street, they were amused to
ﬁnd out that none of them got his hat back. In how many diﬀerent ways
could that happen?
In a more mathematical formulation: how many permutations of the
set [n] have no ﬁxed points, that is, have the element i in the ith position
for no i? Such permutations are called derangements. Indeed, if the hat of
the ﬁrst person is denoted by 1, that of the second person is denoted by 2,
and so on, then every way of the n people taking the n hats corresponds to
a permutation of the set [n]. If the ﬁrst person takes hat 7, then the ﬁrst
element of this permutation will be 7, if the second person takes hat 3, then
the second element of this permutation will be 3, and so on.
Now that we
showed that the two formulations are in fact equivalent, we will give our
answer in the language of permutations.
Solution. (of Example 7.4) It is easy to count permutations in which entry
1 or entry 2 or entry i is not a ﬁxed point, but we want permutations
with no ﬁxed points. Their number is clearly equal to the number of all
permutations minus the number of permutations with at least one ﬁxed
point. This sounds similar to the two examples we have discussed at the
beginning of this section.
Let Ai be the set of all permutations of [n] in which the element i is
in the ith position, in other words, in which the element i is ﬁxed. Then
Theorem 7.3 will give us the answer to our question if we can compute the
sizes of the intersections on the right-hand side of (7.1).
What is the size of A1? The set A1 consists of permutations in which
the ﬁrst element is 1. This means that elements 2, 3, · · · , n, can be freely
permuted among each other, and this can be done in (n−1)! diﬀerent ways.
So |A1| = (n −1)!. Similarly, |A2| = (n −1)! as in this case element 2 has
to be ﬁxed, and all the remaining elements can be freely permuted. An
analogous argument shows that |Ai| = (n −1)! for all n values i ∈[n].
Therefore, the total contribution of the ﬁrst term of the right-hand side to
the total value of the right-hand side is (n −1)! · n = n!.
Now we move up to the next member of the right-hand side of (7.1),
that is, to intersections of the type |Ai ∩Aj|. The set Ai ∩Aj consists of
permutations in which elements i and j are ﬁxed, and the remaining n −2
entries can be permuted freely, in (n −2)! ways. As there are
n
2

choices
for i and j, the total contribution of the second term is
−
n
2

(n −2)! = −
n!
2! · (n −2)! · (n −2)! = −n!
2! .

152
A Walk Through Combinatorics
In general, a similar argument shows that the contribution of the ith
term is
(−1)i−1
n
i

· (n −i)! = (−1)i−1
n!
i! · (n −i)! · (n −i)! = (−1)i−1 n!
i! .
Indeed, if i given elements are ﬁxed, the remaining n −i elements can be
permuted in (n −i)! ways. On the other hand, there are
n
i

possibilities
for the set of i given elements.
Therefore, Theorem 7.3 yields
|A1 ∪A2 · · · ∪An| =
n

j=1
(−1)j−1

i1,i2,··· ,ij
|Ai1 ∩Ai2 ∩· · · ∩Aij|
= n! −n!
2! + n!
3! −· · · + (−1)n−1 n!
n! =
n

i=1
(−1)i−1 n!
i! .
So we have computed the number of permutations of [n] with at least
one ﬁxed point. Consequently, the number D(n) of permutations of [n] with
no ﬁxed points, or the number of derangements, is n! minus this number,
that is,
D(n) =
n

i=0
(−1)i n!
i! .
(7.3)
This completes the proof.
The right-hand side of formula (7.3) strongly depends on n. Still, the
reader may want to get a feeling about roughly how likely it is that a
random permutation has no ﬁxed point. One can get such an intuition by
dividing the number of favorable outcomes by that of all outcomes, that is,
dividing the number of all derangements of [n] by that of all permutations
of [n]. This yields
D(n)
n!
=
n

i=0
(−1)i 1
i!
=
n

i=0
(−1)i
i!
.
This shows that if n diverges to inﬁnity, then D(n)/n! converges to e−1, so
for large values of n, roughly 1/e (so more than one third) of all permuta-
tions are derangements. So there is a fairly high chance all people will be
looking for their hats.

You Shall Not Overcount. The Sieve
153
The reader is invited to prove that for all positive integers n, the number
D(n) is the closest integer to n!/e.
We have promised in Section 5.2 that we will obtain a formula for the
Stirling numbers of the second kind. Time has come to fulﬁll that promise.
Theorem 7.5. For all positive integers n and k, the equality
S(n, k) = 1
k!
k

i=0
(−1)i
k
i

(k −i)n =
k

i=0
(−1)i
1
i!(k −i)!(k −i)n
holds.
Proof. Instead of ﬁnding a formula for S(n, k), we will ﬁnd a formula for
k! · S(n, k). We know from Corollary 5.9 that the latter is the number of
all surjections from [n] to [k].
It is clear that the number of all functions from [n] to [k] is kn as any
element of the domain can be mapped into one of k elements. However,
not all these functions will be surjections; many will miss one, two, or more
elements of [k] in their image. We have to enumerate those that do not
miss any element of k.
This sounds a little bit similar to the previous
problem (there we were also interested in the number of certain objects no
part of which had a certain property). It is therefore hopeful that the same
approach will work here.
Let i ∈[k] and let Ai denote the set of all functions from [n] to [k]
whose image does not contain i. It is then clear that |Ai| = (k −1)n as
such functions can map any element of [n] into any one of k −1 elements.
Similarly,
|Ai1 ∩Ai2 ∩· · · ∩Aij| = (k −j)n,
for all j ≤k. Therefore, the sieve formula yields:
|A1 ∪A2 · · · ∪An| =
n

j=1
(−1)j−1

i1,i2,··· ,ij
|Ai1 ∩Ai2 ∩· · · ∩Aij|
=
k

i=1
(−1)i−1
k
i

(k −i)n.
This is the number of functions from [n] to [k] whose range is not the
entire set [k]. So the number of those with range [k], in other words, the
number of surjections, can be obtained by subtracting this number from
that of all functions from [n] to [k], and our claim follows.

154
A Walk Through Combinatorics
The following theorem is just a version of the sieve formula. We state it
separately as its formulation goes in a direction we will continue in Chapter
16.
Theorem 7.6. Let f and g be functions that are deﬁned on the subsets of
[n], and whose range is the set of real numbers. Let us assume that f and
g are connected by
g(S) =

T ⊆S
f(T ).
Then
f(S) =

T ⊆S
g(T )(−1)|S−T |.
(7.4)
Proof. If we express g(T ) by values of f on the right-hand side of (7.4),
we see that for all U ⊆S, the value f(U) will appear once for each set
T satisfying U ⊆T ⊆S. Each such appearance of f(U) will be counted
with a sign given by (−1)|S−T |. The number of such subsets T for which
|S −T | = i is equal to
|S−U|
i

, since T is determined by the elements of S
that are not in T , and T contains U.
Therefore, f(U) will appear on the right-hand side of (7.4) exactly
|S−U|
i=0
(−1)i|S−U|
i

= (1 −1)|S−U| times. This number is always zero,
except when |S −U| = 0, that is, when S = U.
So the only term on
the right-hand side that does not cancel out will be f(S), and the claim is
proved.
Quick Check
(1) Let n = 2m. Find a formula for the number of permutations of length
n in which no even entry is a ﬁxed point.
(2) Let n = 2m. Find a formula for the number of partitions of [n] in which
no odd element forms a singleton block.
(3) We would like to visit each of n people twice. In how many diﬀerent
orders can we do this if we cannot schedule two visits to the same
person in consecutive slots?
Notes
Chapter 2 of “Enumerative Combinatorics”, (Volume 1) by Richard Stanley
[51] provides a higher-level review of the applications of the Sieve Formula.

You Shall Not Overcount. The Sieve
155
Exercises
(1) A grade school class has two sports teams. For any two students in the
class, there is at least one team so that the two students are members
of that team. Prove that there is a team that contains all students of
that class.
(2) A grade school class has three sports teams. For any two students in the
class, there is at least one team so that the two students are members
of that team. Prove that there is a team that contains at least 2/3 of
the students of the class.
(3) How many positive integers k ≤210 are relatively prime to 210?
(4) Let m be a positive integer. Denote by φ(m) the number of integers in
[m] that are relatively prime to m. Let p, q, and r be distinct prime
numbers. Compute φ(pqr).
(5) Let p1, · · · , pk be distinct prime numbers.
Find a formula for
φ(p1 · · · pk).
(6) Is it true that φ(mn) = φ(n)φ(m), for all positive integers m and n?
(7) Find a formula for φ(pk), where p is a prime number.
(8) Find a formula for φ(n) if the prime factorization of n is known.
(9) Let p = p1p2 · · · pn be an n-permutation. We say that i is a descent of
p if pi > pi+1. The descent set of p is the set of all of its descents. How
many 8-permutations have descent set T that is a subset of {1, 4, 6}?
(10) How many 8-permutations have descent set {1, 4, 6}?
(11) How many 8-permutations have descent set {1, 2, 4, 5, 7}?
(12) (This is a dual version of Theorem 7.6.) Let h and r be functions that
are deﬁned on the subsets of [n], and whose range is the set of real
numbers. Assume that h and r are connected by
r(S) =

S⊆T
h(T ).
Prove that then
h(S) =

S⊆T
r(T )(−1)|T −S|.
(13) Let p = p1p2 · · · pn be an n-permutation, and assume n ≥3.
We
say that i is an excedance of p if pi > i. Compute the number of n-
permutations whose excedance set contains at least one of n −2 and
n −1.
(14) (+) Let f(n, k) be the number of ways to select a subset of [n], and
then to select an involution on that subset that has k ﬁxed points. (The

156
A Walk Through Combinatorics
empty set has one involution, and that involution has no ﬁxed points.)
Let g(n) = n
k=0 f(n, k)(−1)k. Prove that g(n) is equal to the number
of ﬁxed point-free involutions on [n].
(15) (+) Let an be the number of permutations of length n in which the
entry i is never immediately followed by the entry i + 1. Prove that for
all n ≥3, the recurrence relation an = (n−1)an−1 +(n−2)an−2 holds.
(16) Let an be deﬁned as in the previous exercise. Prove that an is equal to
the number of derangements p of length n + 1 in which p(1) = 2.
Supplementary Exercises
(17) (-) How many partitions of [n] contain at least one of the singleton
blocks {1} and {n}?
(18) (-) How many n-permutations contain at least one of the 1-cycles (1),
(2), and (3)?
(19) (-) How many compositions does the integer n have in which neither
the ﬁrst nor the last entry is 1?
(20) (-) How many permutations of length n contain at least one of the
2-cycles (12) and (34)?
(21) (-) How many n-permutations p = p1p2 · · · pn are there in which at
least one of p1 and pn is even?
(22) Give a combinatorial proof of the identity
D(n + 1) = n(D(n) + D(n −1))
for n ≥1. Do not use the formula for the numbers D(n) that we
proved in the text. Set D(0) = 1 and D(1) = 0.
(23) How many n-permutations are there that contain exactly one cycle of
length one?
(24) Let f(n) be the number of permutations discussed in the previous
exercise. Which number is larger, f(n) or D(n), and by how much?
(25) What is the number of permutations p = p1p2 · · · pn so that the equal-
ity pi = i + 1 does not hold for any i ∈[n −1]?
(26) Let d(n, k) be the number of derangements of length n that consist
of k cycles. Find a formula for d(n, k) in terms of signless Stirling
numbers of the ﬁrst kind.
(27) Let Fk(n) be the number of partitions of [n] into k blocks, each block
consisting of more than one element. Express the numbers Fk(n) in
terms of Stirling numbers of the second kind.

You Shall Not Overcount. The Sieve
157
(28) How many three-digit positive integers are divisible by at least one of
six and seven?
(29) How many two-digit positive integers are relatively prime to both two
and three?
(30) In how many ways can we list the digits {1, 1, 2, 2, 3, 4, 5} so that two
identical digits are not in consecutive positions?
(31) How many positive integers are there that are not larger than 1000
and are neither perfect squares nor perfect cubes?
(32) Show an example of four inﬁnite subsets of the set of all positive
integers so that the intersection of any three of them is an inﬁnite set,
but the intersection of all four of them is empty.
(33) How many n-permutations are there with exactly one descent?
(34) (+) How many n-permutations are there with exactly two descents?
(35) How many 2 × 2 matrices are there with entries from the set
{0, 1, · · · , k} in which there are no zero rows and no zero columns?
(36) Let F(n) denote the number of partitions of [n] which contain no
singleton blocks. Find a formula for the numbers F(n) in terms of the
Bell numbers B(n).
(37) (+) Prove that limn→∞
F (n)
B(n) = 0.
(38) Solve Exercise 35 with an argument that does not involve ﬁrst counting
a larger set of matrices and then subtracting the number of matrices
violating some of the conditions.
(39) (+) Find a combinatorial proof for the result of Exercise 16 of Chapter
5. Do not use equation (5.2).
(40) Find a closed formula (no summation signs) for n
i=0
n
i

D(i).
Solutions to Exercises
(1) Consider the diagram of this situation. It will look similar to Figure
7.1. We note, however, that in this case, it cannot happen that the
leftmost and the rightmost domains of that diagram both contain a
nonzero number. Indeed, that would mean that there is one student
who is only a member of team A, and there is another one who is
only a member of team B, so they are not on any common teams.
Therefore, all positive integers of the diagram are contained in one of
the two circles. Thus one team must contain all students.
(2) Again, consider the diagram of this situation. It will be similar to
Figure 7.2. However, there cannot be any positive numbers in the

158
A Walk Through Combinatorics
domains that belong to one circle only. (Unless, that is, all students
are on that team.) Denote A, B, C, D the numbers in the remaining
domains as shown in Figure 7.3. Assume without loss of generality
that C ≤A, and C ≤B. Then
A + B + D
A + B + C + D ≥
A + B
A + B + C ≥
A + B
A + B + (A + B)/2 = 2
3.
We used the fact that a fraction that is less than one increases if we
increase its numerator and denominator by the same positive number.
D
A
C
B
Fig. 7.3
The situation of Exercise (2).
(3) Let Ai be the set of those positive integers from [210] that are divisible
by pi, where p1 = 2, p2 = 3, p3 = 5, and p5 = 7. Then |Ai| = 210
pi ,
|Ai ∩Aj| =
210
pipj , and |Ai ∩Aj ∩Ak| =
210
pipjpk . Therefore, we have all
the ingredients for the application of the sieve formula. We get, after
routine computation,
210 −|
4
i=1
Ai| = 48.
This method takes a long time, even for small numbers like 210. The
following exercises will show a much faster method.
(4) We count those positive integers that are not relatively prime to pqr
instead. Clearly, there are pq integers in [pqr] that are divisible by r,
there are pr that are divisible by q, and there are qr that are divisible
by p. On the other hand, there are p integers in [pqr] that are divisible

You Shall Not Overcount. The Sieve
159
by qr, there are q that are divisible by pr, and there are pq that are
divisible by r. Finally, pqr is the only integer in this interval that is
divisible by pqr. Therefore, the sieve implies
φ(pqr) = pqr −pq −pr −qr + p + q + r −1 = (p −1)(q −1)(r −1).
Note that the function φ is called Euler’s totient function.
(5) Let m = p1 · · · pk, and let m′ = p1 · · · pk−1. We claim that φ(m) =
Πk
i=1(pi −1). We are going to prove this claim by induction on k. The
initial case of k = 1 is obviously true. Assume the statement is true
for k −1, and prove it for k.
By the induction hypothesis, there are φ(m′) = Πk−1
i=1 (pi −1) integers
in [m′] that are relatively prime to [m′]. Moreover, if q ≤pk −1, then
n = m′q + r is relatively prime to m′ if and only if r is relatively
prime to m′. Therefore, there are pk · φ(m′) integers in [m] that are
relatively prime to [m′].
As divisibility by pi for i < k does not
inﬂuence divisibility by pk, exactly
1
pk of these numbers is divisible by
pk, and exactly pk−1
pk
of them is relatively prime to pk. Therefore, we
get
φ(m) = pk −1
pk
· pk · φ(m′) = Πk
i=1(pi −1).
(6) No, that is not true.
For instance, φ(2) = 1, φ(4) = 2, however
φ(8) = 4.
(7) In this case, m is relatively prime to pk if and only if m is not divisible
by p. As exactly one integer in [p] is divisible by p, we have φ(pk) =
p−1
p
· pk = pk−1(p −1).
(8) Let n = pa1
1 · · · pak
k , where the pi are the prime divisors of n. We claim
that φ(n) = Πk
i=1pai−1
i
(pi −1). We prove this claim by induction on
k. The initial case of k = 1 is true as it was proved in the previous
exercise. The induction step is analogue to that of Exercise 5.
(9) In 8-permutations with a descent set contained in {1, 4, 6}, we know
that p2 < p3 < p4, moreover p5 < p6, and p7 < p8.
There is no
requirement on the relations not listed here. Therefore, we can get
such a permutation if we split the set [8] into four subsets, of sizes
1, 3, 2, and 2, arrange each of these subsets in increasing order, then
concatenate the four increasing strings in this order. The number of
ways to do this is
8
1
7
3
4
2
2
2

= 8 · 35 · 6 · 1 = 1680,
so this is the number of permutations with the required property.

160
A Walk Through Combinatorics
(10) We are going to use Theorem 7.6. Denote by g(S) the number of
permutations with descent set contained in S, and denote by f(S) the
number of permutations with descent set equal to S. In order to be
able to use Theorem 7.6, we have to compute the values of g(T ), for
all T ⊆{1, 4, 6}. This has been done for T = {1, 4, 6} in the previous
exercise. It is also obvious that g(∅) = 1. For the other subsets, we
proceed as in the previous exercise, and get
• g({1}) =
8
1

= 8,
• g({4}) =
8
4

= 70,
• g({6}) =
8
6

= 28,
• g({1, 4}) =
8
1
7
3

= 280,
• g({1, 6}) =
8
1
7
5

= 168,
• g({4, 6}) =
8
4
4
2

= 420.
Therefore, Theorem 7.6 shows
f({1, 4, 6}) = 1680 −280 −168 −420 + 8 + 70 + 28 −1 = 917.
(11) It would take a long time to proceed as in the previous exercise, so
we apply the following trick. Instead of counting these permutations
p = p1p2 · · · p8, count their reverses p′ = p8p7 · · · p1. As p had descent
set {1, 2, 4, 5, 7}, its reverse will have descent set {2, 5}. Indeed, if i
was not a descent in p, then pi < pi+1. So in the reverse permutation
p′, the entry pi+1, that is in position 8 −i, will be larger than the
entry immediately following it. Therefore, 8 −i is a descent of p′.
Consequently, we only have to compute f({2, 5}), and that is relatively
simple. We have
• g(∅) = 1,
• g({2}) =
8
2

= 28,
• g({5}) =
8
5

= 56,
• g({2, 5}) =
8
2
6
3

= 560.
Therefore, Theorem 7.3 implies
f({2, 5}) = 560 −28 −56 + 1 = 477 = f({1, 2, 4, 5, 7}).
(12) Deﬁne new functions f and g by f(A) = h(Ac), and g(A) = r(Ac),
where Ac denotes the complement of A in [n]. Then the condition
of this exercise translates into the condition of Theorem 7.6, and the
result of Theorem 7.3 translates back to the result of this exercise.
(13) Let f(S) be the number of n-permutations whose excedance set con-
tains S. Then f(n −1) = (n −1)! as in such permutations, the entry

You Shall Not Overcount. The Sieve
161
n must be in position n −1. Similarly, f(n −2) = 2(n −1)! as in
permutations enumerated by f(n −2), either the entry n −1 or the
entry n has to be in position n −2. Finally, f(n −2, n −1) = (n −2)!
as in such permutations, the entry n must be in position n −1, and
the entry n −1 must be in position n −2. Therefore, by the sieve
formula, there are
f(n −1) + f(n −2) −f(n −2, n −1) = 3(n −1)! −(n −2)!
permutations with the required property.
(14) The statement to prove is equivalent to

k even
f(n, k) −

k odd
f(n, k) = g(n).
Let S ⊆[n], and let p be an involution on S.
Now consider the
following map. Find the largest element M of [n] that is either a ﬁxed
point of p or is not in S. If M ∈S, remove M from S, and remove
M from p. This results in a new, shorter involution F(p) that has one
less ﬁxed points than p. If M /∈S, then add M to S, and add M to
p as a ﬁxed point. This results in a new, longer involution F(p) that
has one more ﬁxed points than p.
So the parity of the number of ﬁxed points of p and F(p) is always
diﬀerent. In other words, the involution F matches involutions with
an even number of ﬁxed points with involutions with an odd number
of ﬁxed points.
The only time F is not deﬁned is when M is not
deﬁned, that is, when the set whose maximum was deﬁned to be M is
empty. That happens exactly when S = [n] and p has no ﬁxed points.
(15) If p = p1p2 · · · pn satisﬁes the requirements, then there are two pos-
sibilities, based on what happens if we remove p1 and decrease all
entries larger than p1 by 1.
First, it can happen that the obtained permutation p′ still satisﬁes
the requirements. Then there are an−1 possibilities for an−1, while
the removed entry p1 could be anything except p2 −1. So there are
(n −1)an−1 original permutations p for which this happens.
Second, it can also happen that the obtained permutation p′ no longer
satisﬁes the requirements. That means that in p, the entries p1 −1
and p1 + 1 were in consecutive positions in increasing order. Those
positions could have been anywhere, starting from the second and
third positions, all the way to the (n −1)st and nth positions. On
the other hand, keeping p1 in the permutation, but removing these
two entries, we get a permutation of length n −2 that satisﬁes the

162
A Walk Through Combinatorics
requirements. So a total of (n −2)an−2 permutations belong to this
case.
(16) Strong induction on n. In the case of n = 1, the statement holds true,
since p = 21 is the only derangement of length two, and it satisﬁes the
requirement. Similarly, in the case of n = 2, the statement holds true,
since p = 231 is the only derangement of length three starting with
2. Let us assume that the statement is true for all positive integers
less than n. If p is a derangment of length n + 1, then there are two
possibilities for the entry n + 1.
First, the entry n + 1 may be part of a 2-cycle, which can happen in
n −2 ways, since the other entry of that 2-cycle may not be 1, 2, or
n + 1 itself. As the rest of the permutation may be any derangement
of length n −1 starting with 2, the induction hypothesis implies that
there are an−2 ways to choose the rest of the permutation. So this
case contains (n −2)an−2 derangements.
Second, the entry n + 1 may be part of a cycle that is longer than
2. We get all such derangements by simply taking a derangement p
in which p(1) = 2, and insert p anywhere, into any existing cycle,
except that we cannot insert it to the position immediately preceding
the entry 2. By the induction hypothesis, we can start from an−1
derangments, then we can insert n+ 1 in n−1 diﬀerent ways, and the
proof is complete.

Chapter 8
A Function Is Worth Many Numbers.
Generating Functions
As Herb Wilf said, a generating function of a sequence is a clothesline on
which you hang all elements of the sequence. That single clothesline con-
tains all elements of the sequence, and all information about them. This
great idea, that is, to comprise data given by inﬁnitely many numbers into
a single function, leads to what is arguably the most powerful tool in Enu-
merative Combinatorics, namely to the technique of generating functions.
8.1
Ordinary Generating Functions
8.1.1
Recurrence Relations and Generating Functions
The frog population of an inﬁnitely large lake grows fourfold each year. On
the ﬁrst day of each year, 100 frogs are taken out of the lake and shipped
into another lake. Assuming that there were 50 frogs in the lake originally,
how many frogs will be in the lake in 20 years? In 30 years? In 100 years?
In n years?
The diﬃculty here does not lie in ﬁnding some kind of an answer. It is
very easy to ﬁnd a recursive answer. Indeed, if ai denotes the number of
frogs at the end of the ith year, so that a0 = 50, a1 = 4 · 50 −100 = 100,
a2 = 4 · 100 −100 = 300, and so on, then it is not diﬃcult to prove that
an+1 = 4an −100 if n ≥0. In the age of computers, such an answer is very
useful, as we can go ahead and compute the values of an for all n as long as
the memory of our computer lasts. There is, however, a tremendous waste
in this method. Let us assume that we are only interested in the number of
frogs after 87 years. Then, using the formula an+1 = 4an −100, we would
have to compute the values of a1, a2, · · · , a86 in order to be able to compute
a87 at the end. So we would have to compute 86 values in which we were
163

164
A Walk Through Combinatorics
not interested.
To avoid such a waste of time and energy, it is best to ﬁnd an explicit
formula for an. That is, we would like to deduce a formula for an that does
not contain an−1, or any other elements of the sequence; a formula that
depends only on n, and is therefore directly computable.
All we have to work with is the equation
an+1 = 4an −100,
(8.1)
for all integers n ≥0, and the initial condition a0 = 50. This seems to
be precious little at ﬁrst sight. However, (8.1) holds for all non-negative
integer values of n. So we in fact have inﬁnitely many equations, in inﬁnitely
many variables. To collect all the information scattered in these inﬁnitely
many equations into just one equation, we will introduce the technique of
generating functions.
Deﬁnition 8.1. Let {fn}n≥0 be a sequence of real numbers. Then the
formal power series F(x) = 
n≥0 fnxn is called the ordinary generating
function of the sequence {fn}n≥0.
As this section discusses ordinary generating functions only, we will some-
times omit the word “ordinary” for shortness.
In what follows, we will
manipulate (8.1) so that the ordinary generating function of the sequence
{an} appears. To that end, let us multiply both sides of (8.1) by xn+1,
then sum over all n ≥0. This may well be a new operation for the reader,
and it is crucial for the rest of this chapter, so we repeat it one more time.
Take a copy of (8.1) for each non-negative integer n, multiply both sides by
xn+1, and then take the sum of the inﬁnitely many equations obtained. We
get

n≥0
an+1xn+1 =

n≥0
4anxn+1 −

n≥0
100xn+1.
(8.2)
The left-hand side is almost the generating function G(x) of the sequence
{an}n≥0. Indeed, after replacing n + 1 by n, the only missing term is a0.
So the left-hand side of (8.2) is G(x) −a0. The ﬁrst term of the right-hand
side is 4xG(x), while the second term of the right-hand side is 100x
1−x , since

n≥0 xn = 1/(1−x), as the reader learned in elementary calculus. So (8.2)
is equivalent to
G(x) −a0 = 4xG(x) −100x
1 −x.
(8.3)

A Function Is Worth Many Numbers. Generating Functions
165
We have completed our ﬁrst task: we compressed the information given
by the inﬁnitely many equations of the type an+1 = 4an −100 into just one
equation.
The reader may think something along these lines “Big deal. True, the
number of equations is only one, but that one equation contains the function
G(x), which has inﬁnitely many terms, and is a weird thing anyway. So
where is the great progress?” We cannot blame the reader for such thoughts
at this point; they are quite natural. However, equation (8.3) is very useful,
mainly because G(x) is not just any function, it is a (formal) power series.
Though the reader has probably met power series while studying calculus,
the word formal is important there. By deﬁnition, a formal power series is
an expression of the form 
n≥0 bnxn, where the bi are real numbers. Thus
formal power series are deﬁned by their coeﬃcients, and are not necessarily
equal to the Taylor series of some function. For example, the formal power
series 
n≥0 n!xn is not equal to the Taylor series of any function as it is
not convergent for any x ̸= 0.
Rearranging (8.3) we get
G(x) =
a0
1 −4x −
100x
(1 −x)(1 −4x).
(8.4)
Remember that a0 = 50, so the right-hand side does not contain any
unknowns, in other words, it is a formal power series in x. Therefore, we
have obtained an explicit formula for G(x), the generating function of the
sequence {an}.
Finally, we want to obtain an explicit formula for the numbers an them-
selves. Note that (8.4) is an equation on formal power series, and two formal
power series are equal if and only if for all n, the coeﬃcient of xn is the
same in both of them. The coeﬃcient of xn in G(x) (so on the left-hand
side of (8.4)) is an by deﬁnition. Therefore, in the formal power series on
the right-hand side of (8.4), the coeﬃcient of xn is also an. On the other
hand, we can also compute this coeﬃcient as the sum of the coeﬃcients
of xn in the two members of the right-hand side. The ﬁrst term is easier.
Indeed,
a0
1 −4x = 50

n≥0
(4x)n = 50

n≥0
4nxn,
so in the ﬁrst term of the right-hand side, the coeﬃcient of xn is 50 · 4n.
The second term is a little bit more complicated. That term is
100x
(1 −x)(1 −4x) = 100x ·
⎛
⎝
n≥0
xn
⎞
⎠·
⎛
⎝
n≥0
4nxn
⎞
⎠.

166
A Walk Through Combinatorics
So the constant (the coeﬃcient of x0) is 0 in this term, and if n ≥1,
then we have to ﬁnd the coeﬃcient of xn−1 in the product
	
n≥0 xn
·
	
n≥0 4nxn
. This, that is, ﬁnding the coeﬃcient of an in a product, is
something we will have to do very often while using generating functions.
The method we show now is that of partial fractions, which the reader
has probably seen before in a Calculus or Diﬀerential Equations class.
Let us try to ﬁnd constants A and B so that
A
1 −x +
B
1 −4x =
100x
(1 −x)(1 −4x).
Multiplying both sides by (1 −x)(1 −4x) yields
A(1 −4x) + B(1 −x) = 100x,
(−B −4A)x + A + B = 100x.
The polynomial on the left-hand side will be equal to the polynomial on the
right-hand side if the coeﬃcients of the two linear terms are the same and
the two constants are the same. That is, −B −4A = 100, and A + B = 0.
Solving this system, we get that A = −100/3 and B = 100/3. Therefore,
100x
(1 −x)(1 −4x) = 100
3
·
1
1 −4x −100
3
·
1
1 −x
= 100
3
⎛
⎝
n≥0
4nxn −

n≥0
xn
⎞
⎠
=

n≥0
(4n −1)xn 100
3 .
Now that we have computed both terms on the right-hand side of (8.3),
we can conclude that the coeﬃcient of xn there (and thus, the left-hand
side of (8.3)) is
an = 50 · 4n −100 · 4n −1
3
.
(8.5)
We have completed our task, that is, we have found an explicit for-
mula for an. It is easy to check that (8.5) is indeed the correct formula.
Substituting n = 0 we indeed get a0 = 50. Moreover,
4an −100 = 4(50·4n −100· 4n −1
3
)−100 = 50·4n+1 −100· 4n+1 −4
3
−100

A Function Is Worth Many Numbers. Generating Functions
167
= 50 · 4n+1 −100 · 4n+1 −1
3
,
so the sequence of numbers given by our explicit formula (8.5) satisﬁes the
recurrence relation (8.1).
Let us summarize the technique we have just learned to turn recursive
formulae into explicit ones.
(1) Deﬁne the ordinary generating function G(x) of the sequence {an}n≥0.
(2) Transform the recursive formula into an equation in G(x). This can
usually be done by multiplying both sides of the recursion by xn, or
xn+1, sometimes xn+k, and summing for all non-negative n.
(3) Solve for G(x).
(4) Find the coeﬃcient of xn in G(x). As this coeﬃcient is an, this will
provide an explicit formula for an.
Remark: There are several software packages that can compute the
partial fraction decomposition of
100x
(1−x)(1−4x). For instance, in Maple, we
can simply type
convert(100*x/((1-x)*(1-4*x),parfrac,x));
to obtain the desired decomposition.
Let us practice the technique of generating functions with another ex-
ample.
Example 8.2. We have invested 1000 dollars into a savings account that
pays ﬁve percent interest at the end of each year. At the beginning of each
year, we deposit another 500 dollars into this account. How much money
will be in this account after n years?
Solution. It is again very easy to ﬁnd a recurrence relation. Let an be the
account balance after n years. Then a0 = 1000, and an+1 = 1.05 · an + 500.
Let us go through the steps of our strategy one by one.
(1) Let G(x) = 
n≥0 anxn be the generating function of the sequence
{an}n≥0.
(2) Multiplying both sides of the recurrence relation by xn+1 and summing
over all non-negative integers n, we get

n≥0
an+1xn+1 =

n≥0
1.05anxn+1 +

n≥0
500xn+1.
(8.6)

168
A Walk Through Combinatorics
Here the left-hand side is clearly G(x) −a0, while the ﬁrst term of the
right-hand side is 1.05xG(x), and the second term of the right-hand
side is simply 500x
1−x . So (8.6) is equivalent to
G(x) −a0 = 1.05xG(x) + 500x
1 −x.
(3) Therefore,
G(x) =
1000
1 −1.05x +
500x
(1 −x)(1 −1.05x).
(8.7)
(4) To ﬁnd an, it suﬃces to ﬁnd the coeﬃcient of xn on the right-hand
side, which is the sum of the coeﬃcient of xn in the ﬁrst term, and the
coeﬃcient of xn in the second term. Note that
1000
1 −1.05x = 1000 ·

n≥0
1.05nxn,
so the coeﬃcient of xn in the ﬁrst term is 1000 · 1.05n. For the second
term, note that
500x
(1 −x)(1 −1.05x) =
10000
1 −1.05x −10000
1 −x
(8.8)
=
10000

n≥0
1.05nxn −10000

n≥0
xn
=
10000

n≥0
(1.05n −1)xn.
Therefore, the coeﬃcient of xn on the right-hand side, and therefore,
the left-hand side of (8.7) is
an = 1000 · 1.05n + 10000 · (1.05n −1) = 1.05n · 11000 −10000.
The following example shows how we could use the technique of gener-
ating functions to turn a recurrence relation to an explicit formula if the
recurrence relation has more terms.
Example 8.3. Let an+2 = 3an+1 −2an if n ≥0, and let a0 = 0, and let
a1 = 1. Find an explicit formula for an.
Solution. Let G(x) = 
n≥0 anxn. Multiply both sides of the recurrence
relation by xn+2, and sum over all natural numbers n, to get

n≥0
an+2xn+2 = 3

n≥0
an+1xn+2 −2

n≥0
anxn+2,

A Function Is Worth Many Numbers. Generating Functions
169
which is equivalent to
G(x) −x = 3xG(x) −2x2G(x).
Expressing G(x), we get
G(x) =
x
1 −3x + 2x2 .
The denominator of the right-hand side is again a quadratic polynomial.
Note that 1 −3x + 2x2 = (x −1)(2x −1). Therefore, we are going to ﬁnd
real numbers A and B so that
G(x) =
x
1 −3x + 2x2 =
A
x −1 +
B
2x −1.
(8.9)
After rearranging (8.9), we get
x = (2A + B)x −(A + B).
Two polynomials are the same if and only if their corresponding coeﬃcients
are the same. Therefore, it follows that 2A + B = 1, and A + B = 0. So
A = 1, and B = −1. Consequently, (8.9) yields
G(x) =
x
1 −3x + 2x2 =
−1
1 −x +
1
1 −2x.
(8.10)
Both terms on the right-hand side are very easy to expand now. So
G(x) = −

n≥0
xn +

n≥0
2nxn =

n≥0
(2n −1)xn
and therefore, an = 2n −1.
8.1.2
Products of Generating Functions
Our examples in the previous subsection showed how to use generating
functions to turn a recurrence relation into an explicit formula. However,
they only contained one generating function. Time has come for us to learn
about the combinatorial use of the product of several generating functions.
Lemma 8.4. Let {an}n≥0 and {bn}n≥0 be two sequences, and let A(x) =

n≥0 anxn, and B(x) = 
n≥0 bnxn be their respective generating func-
tions. Deﬁne cn = n
i=0 aibn−i, and let C(x) = 
n≥0 cnxn. Then
A(x)B(x) = C(x).
In other words, the coeﬃcient of xn in A(x)B(x) is cn = n
i=0 aibn−i.

170
A Walk Through Combinatorics
Proof. When we multiply the inﬁnite sum A(x) = a0 + a1x + a2x2 + · · ·
and the sum B(x) = b0 + b1x + b2x2 + · · · , we multiply each term of the
ﬁrst sum by each term of the second sum, then add all these products. So a
typical product is of the form aixi ·bjxj. The exponent of x in this product
will be n if and only if j = n −i, and the claim follows.
The combinatorial consequence of Lemma 8.4 is the following theorem.
Theorem 8.5 (The Product formula). Let an be the number of ways to
build a certain structure on an n-element set, and let bn be the number of
way to build another structure on an n-element set. Let cn be the number
of ways to separate the set [n] into the intervals S = {1, 2, · · · , i} and
T = {i + 1, i + 2, · · · , n}, (the intervals S and T are allowed to be empty),
and then to build a structure of the ﬁrst kind on S, and a structure of the
second kind on T . Let A(x), B(x), and C(x) be the respective generating
functions of the sequences {an}, {bn}, and {cn}. Then
A(x)B(x) = C(x).
Proof. There are ai ways to build a structure of the ﬁrst kind on S, and
bn−i ways to build a structure of the second kind on T . This is true for all
i, as long as 0 ≤i ≤n. Therefore, cn = n
i=0 aibn−i, and our claim follows
from Lemma 8.4.
Example 8.6. A semester at a Technical University consists of n days. At
the beginning of each semester, the Dean of Engineering designs the term
in the following way. She splits the term into two parts. The ﬁrst k days
of the term will form the theoretical part of the semester, and the second
n −k days will form the laboratory part (here 1 ≤k ≤n −2). Then she
chooses one holiday in the ﬁrst part, and two holidays in the second part.
In how many diﬀerent ways can she design the term with these constraints?
Solution. Let fn be the number of ways the Dean can plan the semester.
It is straightforward to see that fn = n−2
k=1 k
n−k
2

. Looking at this ex-
pression, however, it is not so easy to see if it has a closed form (that is, a
form without a summation sign), and if it does, what it is.
Let us separate problems of ﬁnding holidays in the two parts of the
semester. There are k ways to do it in the ﬁrst part, and
m
2

ways to do it
in the second part, where m = n −k.

A Function Is Worth Many Numbers. Generating Functions
171
The generating functions of these two sequences are A(x) = 
k≥1 kxk,
and B(x) = 
m≥2
m
2

xm.
Recall from Calculus that 
i≥0 xi =
1
1−x.
Taking derivatives, (see Exercise 26 of Chapter 4 for another argument)
this implies
A(x) =
x
(1 −x)2 ,
B(x) =
x2
(1 −x)3 .
Now let F(x) be the generating function of the sequence {fn}. Then
A(x)B(x) = F(x). Therefore,
F(x) = A(x)B(x) =
x3
(1 −x)5 = x3 
n≥0
n + 4
4

xn =

n≥3
n + 1
4

xn.
This shows that fn =
n+1
4

.
Note that the solution of the previous example used the fact that (1−x)−5 =

n≥0
n+4
4

xn. The reader is encouraged to ﬁnd two proofs of this fact.
Example 8.7. Now let us assume that instead of holidays, the Dean
chooses some days for independent study in both parts of the semester. In
how many diﬀerent ways can she plan the semester with these constraints?
Solution. Let gn be the number of ways the dean can complete this task.
Again, let us split the problem into two parts. Let C(x) be the generating
function for the number of ways to pick a set of days for independent study
in the ﬁrst part.
As a k-element set has 2k subsets, we have C(x) =

k≥0 2kxk =
1
1−2x. Note that the summation starts at k = 0 here, since
it is possible that the dean will not choose any days for independent study
in one or both parts. This was diﬀerent in the preceding example. Clearly,
the second part has the same generating function, as the task at hand is
the same. Therefore, we get
F(x) = C(x)C(x) =
1
(1 −2x)2 .
This shows that F(x) = 1
2C′(x). Therefore,
F(x) = 1
2 ·

n≥1
n · 2nxn−1 =

n≥0
(n + 1)2nxn,
showing that gn = (n + 1) · 2n.

172
A Walk Through Combinatorics
A little thought shows that Theorem 8.5 can easily be generalized from
two generating functions into any ﬁxed number of generating functions. The
following example is an application of this generalized Product formula.
Example 8.8. Find the number of ways to split an n-day semester into
three parts, choose any number of holidays in the ﬁrst part, an odd number
of holidays in the second part, and an even number of holidays in the third
part.
Solution. Let gn be the number of ways the one can plan such a semester.
Let A(x), B(x), and C(x) be the generating functions for the sequences for
the three individual tasks. That is A(x) = 
n≥0 2nxn =
1
1−2x since there
are 2n ways to choose an unspeciﬁed number of holidays from a set of n
days. As we have seen in Exercise 2 of Chapter 3, the number of subsets
of [n] that are of odd size is 2n−1 if n ≥1, and 0 if n = 0. Therefore,
B(x) = 
n≥1 2n−1xn =
x
1−2x. Finally, the reader is asked to prove that
the number of subsets of [n] that are of even size is 2n−1 if n ≥1, and 1 if
n = 0. Therefore, C(x) = 1 +
x
1−2x =
1−x
1−2x.
Now let G(x) be the generating function of the sequence {gn}. Then
G(x) = A(x)B(x)C(x).
Therefore,
G(x) = A(x)B(x)C(x) =
1
1 −2x ·
x
1 −2x · 1 −x
1 −2x
= x(1 −x)
(1 −2x)3 .
The partial fraction decomposition leads to the equation
G(x) = −1
4 ·
1
1 −2x + 1
4 ·
1
(1 −2x)3 .
Finally, using the binomial theorem, we get that
(1 −2x)−3 =

n≥0
−3
n

(−2x)n =

n≥0
n + 2
2

2nxn.
Therefore,
G(x) = −1
4
⎛
⎝
n≥0
2nxn
⎞
⎠+ 1
4
⎛
⎝
n≥0
n + 2
2

2nxn
⎞
⎠.
So gn = (
n+2
2

2n −2n)/4 = 2n−3n(n + 3), for n ≥0.

A Function Is Worth Many Numbers. Generating Functions
173
Example 8.9. If p≤k(n) denotes the number of partitions of the integer n
into parts of size at most k, then
∞

n≥0
p≤k(n)xn =
k

i=1
1
1 −xi
(8.11)
= (1+x+x2 +x3 +· · · )(1+x2 +x4 +x6 +· · · ) · · · (1+xk +x2k +x3k +· · · ).
Solution. Let us determine the coeﬃcient of xn on the right-hand side.
The right-hand side is a sum of k-term products, such that each member
comes from a diﬀerent parentheses. The member from the ith parentheses
is of the form xiji, and the sum of the exponents of the k terms is n. In
other words, 1j1 + 2j2 + · · · kjk = n. If we write 1 + 1 + · · · + 1 (j1 copies
of 1) instead of 1j1, and in general, i + i + · · · + i (ji copies of i) instead
of iji in the previous equation, we obtain a partition of n into the sum of
parts that are at most k.
Using this procedure, each time a product on the right-hand side is equal
to xn, we obtain a partition of n into the sum of parts that are at most k.
Conversely, each partition of n into parts at most k can be associated to a
product on the right-hand side, and the statement follows.
In Chapter 5, we proved that p≤k(n) is also the number of partitions of
n into at most k parts. Thus k
i=1
1
1−xi is also the generating function of
those partitions.
You could ask what the use of all this is if the above generating function
does not yield a particularly nice closed formula for the numbers p≤k(n). A
quick answer is that any mathematics software can provide the expansion
of (8.11) up to several dozen terms, so (8.11) provides a painless way to
obtain a lot of numerical data.
A much deeper answer, and we will see examples of that soon, is that
the generating function of a sequence contains a lot of information about
the sequence, sometimes even more than an exact formula.
Example 8.10. If p(n) denotes the number of partitions of the integer n,
then
∞

n≥0
p(n)xn =
∞

k=1
1
1 −xk
(8.12)
= (1 + x + x2 + x3 + · · · )(1 + x2 + x4 + x6 + · · · )(1 + x3 + x6 + x9 + · · · ) · · · .

174
A Walk Through Combinatorics
Solution. Same as the proof of the previous example, just here there is
no limit on the size of the parts, and therefore, there are inﬁnitely many
parentheses on the right-hand side.
The reader may think that such a generating function, that is, the
inﬁnite product of sums, is not very useful.
Indeed, a computer would
have a hard time to handle an inﬁnite formula.
The following example
refutes that belief. It is a stunning example of a problem that is much
easier to handle with generating functions than without them.
Example 8.11. The number podd(n) of partitions of n into odd parts is
equal to the number pd(n) of partitions of n into all distinct parts.
Solution. The crucial idea is this. It suﬃces to show that the generating
functions of the two sequences are equal. It is clear that
F(x) =

n≥0
podd(n)xn =

i≥1
i odd
1
1 −xi
and
G(x) =

n≥0
pd(n)xn =

i≥1
(1 + xi) =

i≥1
1 −x2i
1 −xi .
Note that after cancellations, the denominator of G(x) will contain (1−xi)
if and only if i is odd, and will therefore be the same as the denominator
of F(x). As both numerators are equal to 1, the proof follows.
8.1.2.1
The Catalan Numbers
A student moves into a new room, and upon his arrival, he puts an empty
jar on his kitchen counter. From that on, every day he either puts a dollar
coin in the jar, or takes a dollar coin out of the jar. After 2n days, the jar
is empty again. In how many diﬀerent ways could this happen?
This easily deﬁned problem leads to a very famous, and exception-
ally well-studied sequence of positive integers. Let cn be the number of
ways in which the events described in the preceding paragraph could take
place, with c0 = 1.
Formally speaking, cn is the number of sequences
b1, b2, · · · , b2n so that bj = ±1 for all j, with 2n
j=1 bj = 0, and, crucially,
for all k ∈[2n], the inequality k
j=1 bj ≥0 holds. Indeed, the jar never
holds a negative number of coins. Let us call such sequences good sequences
of length 2n.

A Function Is Worth Many Numbers. Generating Functions
175
Let C(x) = 
n≥0 cnxn be the ordinary generating function of the se-
quence of the numbers cn.
The beauty of this example lies in the fact
that we can use the Product formula to get a functional equation for C(x).
Though it is not immediately obvious on the outset, good sequences have
a natural way of decomposing into an ordered pair of two structures, and
therefore, the Product formula is relevant here. Of further interest is the
fact that one of these structures will also have C(x) for its generating func-
tion, while the other structure will have xC(x) for its generating function.
In order to ﬁnd this decomposition, note that if n > 0, and the jar is
empty after 2n days, then there had to be a ﬁrst day other than the starting
day when the jar was empty. Let us say that the ﬁrst such day was day
2i, for some i ∈[n]. (The reader is asked to prove that the jar can only be
empty after an even number of days.) It is then clear that what happened
from day 2i to day 2n is equivalent to a good sequence of length 2(n −i).
However, we must be a little bit more careful when we describe what
happened during the ﬁrst 2i days. There, we do not simply have a good
sequence of length 2i, but a good sequence of length 2i in which all the
partial sums k
j=1 bj are positive if 0 < k < 2i. Let us call such sequences
very good. Indeed, this positivity is equivalent to the fact that day 2i is the
ﬁrst day when the jar is empty. Note that there is a bijective correspondence
between the very good sequences B = (b1, b2, · · · , b2i) of length 2i, and the
good sequences B′ = (b2, b3, · · · , b2i−1) of length 2(i −1). Indeed, a very
good sequence must start with a 1 and end in a −1; removing these two
entries we get a good sequence that is two bits shorter. By the removal of
these two entries, the sums of initial segments got only one smaller, so they
are still non-negative.
In other words, if n ≥1, then the number of very good sequences
of length 2i is ci−1.
Their number is 0 if i = 0 since there will be no
initial segments with positive sums then. So the generating function for
the numbers of very good sequences is 
n≥1 cn−1xn = xC(x).
Now we are ready to use the Product formula. The above discussion
shows that each good sequence of length 2n > 0 decomposes in a natural
and unique way into a very good sequence of length 2i and a good sequence
of length 2(n −i) for some i ∈[n]. Therefore, the Product formula implies
that
C(x) −1 = xC(x) · C(x).
Note that we wrote C(x) −1, and not C(x), on the left-hand side, since for
n = 0, the above decomposition does not exist.

176
A Walk Through Combinatorics
The last displayed equation can be rearranged as
xC(x)2 −C(x) + 1 = 0,
(8.13)
which is a quadratic equation for C(x). We can solve this equation using
the well-known formula for solving quadratic equations. However, there
is a last hurdle to clear. The quadratic formula implies that (8.13) has
two solutions, namely
1+√1−4x
2x
and
1−√1−4x
2x
.
How do we know which
one to choose for C(x)? In order to answer this question, note that C(x)
has constant term 1, so we have to choose the solution which also has
constant term 1. Substituting x = 0, we see that the second solution has
this property, therefore,
C(x) = 1 −√1 −4x
2x
.
(8.14)
Recall that we computed in Example 4.16 that √1 −4x = 1 −2x −
2 
n≥2
(
2n−2
n−1 )
n
xn. Comparing this with (8.14), we get
C(x) =

n≥0
2n
n

n + 1xn,
so cn = (2n
n )
n+1.
The numbers cn are called the Catalan numbers, named after the French
and Belgian mathematician Eug`ene Catalan. They count at least 150 dif-
ferent kinds of combinatorial objects, and we will mention a comprehensive
reference for these objects in the Notes section of this chapter. We have
already seen some of them, in Exercises 24 and 59 of Chapter 4. We will
see some more in the exercises of this chapter, and some in Chapters 14
and 16. Starting with n = 0, the ﬁrst few values of the sequence of the
Catalan numbers cn are 1, 1, 2, 5, 14, 42.
8.1.3
Compositions of Generating Functions
How could we possibly deﬁne the composition of two generating functions?
Let us, for simplicity, that F(x) = 1/(1 −x) = 1 + x + x2 + x3 + · · · , and
let G(x) be any generating function. Our knowledge of the composition
of functions suggests that F(G(x)) should be deﬁned as 1/(1 −G(x)) =
1 + G(x) + G(x)2 + G(x)3 + · · · . It is here that the problems could start.
The sum of inﬁnitely many power series is deﬁned only if for each n, the
coeﬃcient of xn is zero in all but a ﬁnite number of summands. In our case,

A Function Is Worth Many Numbers. Generating Functions
177
this will happen if and only if the constant term of G(x) is 0. Indeed, in
that case G(x)n is divisible by xn, thus there are at most n −1 summands
that contain xn−1, and this holds for all n > 0. (If n = 0, then there is
one such summand.) Therefore, F(G(x)) is deﬁned in this case. If F is a
formal power series other than 1/(1 −x), the same argument holds. This
is the basis of the following deﬁnition.
Deﬁnition 8.12. Let F(x) = 
n≥0 fnxn be a formal power series, and let
G be a formal power series with constant term 0. Then we deﬁne
F(G(x)) =

n≥0
fn(G(x))n = f0 + f1G(x) + f2(G(x))2 + · · · .
The following theorem is a major application of compositions of gener-
ating functions.
Theorem 8.13. Let an be the number of ways to build a certain structure
on an n-element set, and let us assume that a0 = 0. Let hn be the number
of ways to split the set [n] into an unspeciﬁed number of disjoint non-empty
intervals, then build a structure of the given kind on each of these intervals.
Set h0 = 1. Denote A(x) = 
n≥0 anxn, and H(x) = 
n≥0 hnxn. Then
H(x) =
1
1 −A(x).
Note that unlike in Theorem 8.5, here we do not allow empty intervals.
The reason for this is that if we did, we would have inﬁnitely many ways
to split up [n] as we could insert as many empty intervals as we like. This
problem did not arise in Theorem 8.5, because we only had a speciﬁed
number (two) of intervals there.
Proof. (of Theorem 8.13) It follows from Theorem 8.5 that A(x)k is the
generating function for the number of ways to split [n] into exactly k inter-
vals, then to build a structure of the given kind on each interval. Summing
over all k, we get 
k≥1 A(x)k. As a0 = 0, none of the power series A(x)k
has a nonzero constant term. On the other hand, H(x) has constant term
1 by deﬁnition. This shows
H(x) = 1 +

k≥1
A(x)k =

k≥0
A(x)k =
1
1 −A(x).

178
A Walk Through Combinatorics
Example 8.14. All n soldiers of a military squadron stand in a line. The
oﬃcer in charge splits the line at several places, forming smaller (non-
empty) units. Then he names one person in each unit to be the commander
of that unit. Let hn be the number of ways he can do this. Find a closed
formula for hn.
Solution. Denote by hk the number of ways the oﬃcer in charge can pro-
ceed. Let ak be the number of ways to choose a commander from a unit of
k people. Then clearly ak = k, and therefore A(x) = 
k≥1 kxk =
x
(1−x)2 ,
as we have computed in Example 8.6. Then Theorem 8.13 applies, and we
get that
H(x) =
1
1 −A(x) =
1
1 −
x
(1−x)2
= 1 +
x
1 −3x + x2 ,
where H(x) is the generating function of the sequence {hn}n≥0.
The evaluation of the fraction 1/(1 −3x + x2) is somewhat more com-
plicated than in the earlier examples. We will use the method of partial
fractions. The roots of x2 −3x+1 are α = (3+
√
5)/2, and β = (3−
√
5)/2.
Therefore, we want to obtain 1/(1 −3x + x2) in the following form.
1
1 −3x + x2 =
1
(x −α)(x −β) =
A
x −α −
B
x −β .
After cross-multiplying, we get
1 = (A −B)x −Aβ + Bα.
Therefore, we must have A = B, and B(α −β) = B
√
5 = 1. So A = B =
1/
√
5. This yields
1
1 −3x + x2 =
1
√
5
	
1
x −α −
1
x −β

.
Now note that α·β = 1. Therefore, we can multiply both the numerator and
the denominator of the ﬁrst (respectively, second) term in the parentheses
by α (respectively, β). After routine steps, we get
1
1 −3x + x2 =
1
√
5
	
α
1 −αx −
β
1 −βx

=
1
√
5
	
α
∞

k=0
αnxn −β
∞

k=0
βnxn
.
Therefore, the coeﬃcient of xn in
1
1−3x+x2 is
1
√
5(αn+1 −βn+1). Thus the
coeﬃcient of xn in H(x) is 1 if n = 0, and
hn =
1
√
5(αn −βn)
if n > 0.

A Function Is Worth Many Numbers. Generating Functions
179
Would you have guessed that our answer to this problem, that was
deﬁned totally within the kingdom of integers, will involve powers of α =
(3 +
√
5)/2, and β = (3 −
√
5)/2? The ﬁrst few values of the sequence hn
are, (starting at h1), 1, 3, 8, 21, 55. These numerical data may be helpful
in some of the exercises.
In Theorem 8.13, we ﬁrst split [n] into non-empty intervals, then we
take a structure of the same kind on each of these intervals. However, we
do not take a structure on the set of the intervals. Translating this to our
example, the oﬃcer in charge did not ask the units to choose a unit on duty,
or to form a new line. The following theorem generalizes Theorem 8.13 in
that direction.
Theorem 8.15 (The Compositional formula). Let an be the number
of ways to build a certain structure on an n-element set, and assume a0 = 0.
Let bn be the number of ways to build a second structure on an n-element
set, and let b0 = 1. Let gn be the number of ways to split the set [n] into
an unspeciﬁed number of non-empty intervals, build a structure of the ﬁrst
kind on each of these intervals, and then build a structure of the second
kind on the set of the intervals. Set g0 = 1. Denote by A(x), B(x), and
G(x) the generating functions of the sequences {an}, {bn}, and {gn}. Then
G(x) = B(A(x)).
Proof. Let us assume that we split [n] into k intervals. Then there are bk
ways to take a structure of the second kind on the k-element set of these
intervals. The product formula shows that the generating function for the
number of ways to take a structure of the ﬁrst kind on each interval is A(x)k.
Therefore, the contribution of this case to G(x) is bkA(x)k. Summing over
all k, we get that G(x) = 
k≥0 bkA(x)k, which was to be proved.
Example 8.16. All n soldiers of a military squadron stand in a line. The
oﬃcer in charge splits the line at several places, forming smaller (non-
empty) units.
Then he chooses a (possibly empty) subset of the newly
formed units for night duty. In how many diﬀerent ways can he do this?
Solution. Let us keep the notation of Theorem 8.15. Then ak = 1 for
all k ≥1, as there is one way to put the trivial structure (that is to say,
no structure at all) on the individual units.
Furthermore, bm = 2m as
we simply choose a subset of the set of all intervals. Therefore, A(x) =

180
A Walk Through Combinatorics
x/(1 −x), and B(x) = 1/(1 −2x). So
G(x) = B(A(x)) =
1
1 −
2x
1−x
= 1 −x
1 −3x =
1
1 −3x −
x
1 −3x,
G(x) =

n≥0
3nxn −

n≥1
3n−1xn = 1 +

n≥1
2 · 3n−1xn.
Consequently, if n ≥1, the oﬃcer in charge has 2 · 3n−1 options.
Quick Check
(1) Let a0 = 1, and let an+1 = 3an −1 for n ≥0. Find an explicit formula
for an.
(2) Let bn be the number of partitions of the integer n into even parts that
are at most 6, and at most one odd part (of any size). Find an explicit
formula for the ordinary generating function B(x) = 
n≥0 bnxn.
(3) Let us revisit Example 8.16 with the additional restriction that the
non-empty units that the oﬃcer forms cannot consist of more than
three people each. Let gn be the total number of the ways in which the
oﬃcer can proceed. Find an explicit formula for the ordinary generating
function Gn(x) = 
n≥0 gnxn.
8.2
Exponential Generating Functions
8.2.1
Recurrence Relations and Exponential Generating
Functions
Not all recurrence relations can be turned into a closed formula by using
an ordinary generating function.
Sometimes, a closed formula may not
exist. Some other times, it could be that we have to use a diﬀerent kind of
generating function.
Example 8.17. Let a0 = 1, and let an+1 = (n + 1)(an −n + 1), if n ≥0.
Find a closed formula for an.
If we try to solve this recurrence relation by ordinary generating func-
tions, we run into trouble. The reason for this is that this sequence grows
too fast, and its ordinary generating function will therefore not have a
closed form. Let us instead make the following deﬁnition.

A Function Is Worth Many Numbers. Generating Functions
181
Deﬁnition 8.18. Let {fn}n≥0 be a sequence of real numbers. Then the
formal power series F(x) = 
n≥0 fn xn
n! is called the exponential generating
function of the sequence {fn}n≥0.
The word “exponential” is due to the fact that the exponential gener-
ating function of the constant sequence fn = 1 is ex. Let us use this new
kind of generating function to solve the example at hand.
Solution. (of Example 8.17.) Let A(x) = ∞
n=0 an xn
n! be the exponential
generating function of the sequence {an}n≥0. From this point on, we pro-
ceed in a way that is very similar to the method of the previous section.
Let us multiply both sides of our recursive formula by xn+1/(n + 1)!, and
sum over all n ≥0 to get
∞

n=0
an+1
xn+1
(n + 1)! =
∞

n=0
an
xn+1
n!
−
∞

n=0
(n −1)xn+1
n! .
(8.15)
Note that the left-hand side is A(x)−1, while the ﬁrst term of the right-hand
side is xA(x). This leads to
A(x) −1 = xA(x) −x2ex + xex,
A(x) =
1
1 −x + xex =

n≥0
xn +

n≥0
xn+1
n! .
The coeﬃcient of xn/n! in 
n≥0 xn is n!, while the coeﬃcient of xn/n!
in 
n≥0
xn+1
n!
is n. Indeed, this second term has summand xn/(n −1)!.
Therefore, the coeﬃcient of xn/n! in A(n) is an = n! + n.
Example 8.19. Let f0 = 0, and let fn+1 = 2(n + 1)fn + (n + 1)! if n ≥0.
Find an explicit formula for fn.
Solution. Let F(x) = 
n≥0 fn xn
n! be the exponential generating function
of the sequence fn. Let us multiply both sides of our recursive formula by
xn+1/(n + 1)!, then sum over all n ≥0. We get

n≥0
fn+1
xn+1
(n + 1)! = 2x

n≥0
fn
xn
n! +

n≥0
xn+1.
(8.16)
As f0 = 0, the left-hand side of (8.16) is equal to F(x), while the ﬁrst
term of the right-hand side is 2xF(x), and the second term of the right-hand
side is x/(1 −x). Therefore, we get
F(x) = 2xF(x) +
x
1 −x,

182
A Walk Through Combinatorics
F(x) =
x
(1 −x)(1 −2x).
Therefore,
F(x) =

n≥0
(2n −1)xn,
and so the coeﬃcient of xn/n! in F(x) is fn = (2n −1)n!.
8.2.2
Products of Exponential Generating Functions
Just as we have seen for ordinary generating functions, the product of two
exponential generating functions has a very natural combinatorial meaning.
Lemma 8.20. Let {ai} and {bk} be two sequences, and let A(x) =

i≥0 ai xi
i! and B(x) = 
k≥0 bk xk
k! be their exponential generating func-
tions. Deﬁne cn = n
i=0
n
i

aibn−i, and let C(x) be the exponential gener-
ating function of the sequence {cn}. Then
A(x)B(x) = C(x).
In
other
words,
the
coeﬃcient
of
xn/n!
in
A(x)B(x)
is
cn
=
n
i=0
n
i

aibn−i.
Proof. Just as in the proof of Lemma 8.4, multiplying A(x) by B(x) in-
volves multiplying each term of A(x) by each term of B(x). A general term
in this product is of the form
ai
xi
i! · bj
xj
j! = aibj · xi+j
i!j! · (i + j)!
(i + j)! = aibj ·
xi+j
(i + j)! ·
i + j
i

.
Such a product is of degree n if and only if i + j = n, and the statement
follows.
Theorem 8.21 (Product formula, exponential version). Let an be
the number of ways to build a certain structure on an n-element set, and
let bn be the number of way to build another structure on an n-element set.
Let cn be the number of ways to separate [n] into the disjoint subsets S
and T , (S ∪T = [n]), and then to build a structure of the ﬁrst kind on
S, and a structure of the second kind on T . Let A(x), B(x), and C(x) be
the respective exponential generating functions of the sequences {an}, {bn},
and {cn}. Then
A(x)B(x) = C(x).

A Function Is Worth Many Numbers. Generating Functions
183
Note that while Theorems 8.5 and 8.21 sound very similar, they apply
in diﬀerent circumstances. Theorem 8.5 applies when [n] is split into two
parts so that one part is [i]. That is, [n] is split into intervals. Theorem 8.21
applies when [n] is split into two parts with no restrictions. In other words,
the ﬁrst theorem applies when our objects are linearly ordered (like days
in a calendar, or people in a line), and we cut that linear order somewhere
to get two subsets. The second theorem applies when we are free to choose
our two subsets, that is, they do not have to be consecutive objects in a
previously ordered line.
Proof. (of Theorem 8.21) If S has i elements, then there are
n
i

ways
to choose the elements of S. Then there are ai ways to build a structure
of the ﬁrst kind on S, and bn−i ways to build a structure of the second
kind on T , and this is true for all i, as long as 0 ≤i ≤n.
Therefore,
cn = n
i=0
n
i

aibn−i, and our claim follows from Lemma 8.20.
Example 8.22. A football coach has n players to work with at today’s
practice. First he splits them into two groups, and asks the members of
each group to form a line. Then he asks each member of the ﬁrst group to
take on an orange shirt, or a white shirt, or a blue shirt. Members of the
other group keep their red shirt. In how many diﬀerent ways can all this
happen?
Solution. Let us assume that the coach selects k people to form the ﬁrst
group. Let ak be the number of ways these k people can take on an orange
or white or blue shirt, and then form a line.
Then ak = k!3k, so the
exponential generating function of the sequence {ak} is
A(x) =

k≥0
k!3k xk
k! =
1
1 −3x.
Similarly, assume there are m people in the second group. Let bm be the
number of ways these m people can form a line. Then bm = m!, and the
exponential generating function of the sequence {bm} is
B(x) =

m≥0
m!xm
m! =
1
1 −x.
Let cn be the number of ways the players can follow the instructions of the
coach, and let C(x) be the exponential generating function of the sequence
{cn}. Then the Product formula implies
C(x) = A(x)B(x) =
1
1 −3x ·
1
1 −x.

184
A Walk Through Combinatorics
This leads to the partial fraction decomposition
C(x) = 3
2 ·
1
1 −3x −1
2 ·
1
1 −x.
Therefore,
C(x) = 3
2

n≥0
3nxn −1
2

n≥0
xn =

n≥0
3n+1 −1
2

xn.
So for all n ≥0, the coeﬃcient of xn/n! in C(x) is cn = n!(3n+1 −1)/2.
Example 8.23. Let k be a ﬁxed positive integer.
Find the exponetial
generating function Sk(x) = 
n≥k S(n, k)xn/n! of the Stirling numbers
S(n, k) of the second kind.
Solution. In order to obtain a partition of [n] into k blocks, we need to
partition [n] into k nonempty blocks, and then “do nothing” on each of
those blocks.
There is one way to do nothing on any nonempty block,
therefore, each individual task has generating function
A(x) =

k≥1
xk
k! = ex −1.
If the order of the blocks in a partition mattered, we could simply say
that the generating function of the combined task is Ak(x) by the Product
formula. However, the order of the blocks does not matter, therefore
Sk(x) = 1
k! (ex −1)k .
It goes without saying that we can now get an explicit formula for S(n, k)
by computing the coeﬃcient of xn/n! in Sk(x). The reader is invited to
carry out this computation and verify that the result agrees with that of
Theorem 7.5, that we proved using the Inclusion–Exclusion principle.
A particularly useful property of exponential generating functions is
that their derivatives are very easy to describe. Indeed,
	
xn+1
(n+1)!

′
= xn
n! ,
and therefore
	 
n≥0
an
xn
n!

′
=

n≥0
an+1
xn
n! .
The following example makes good use of this observation. Recall that the
Bell numbers and the recurrence relation used in the example were proved
in Chapter 5.
Example 8.24. Let B(x) be the exponential generating function of the
Bell numbers B(n). Prove that B(x) = eex−1.

A Function Is Worth Many Numbers. Generating Functions
185
Solution. We know that B(n+1) = n
i=0 B(i)
n
i

if n ≥0, and B(0) = 1.
Multiply both sides by xn/n! and sum over all n ≥0 to get

n≥0
B(n + 1)xn
n! =

n≥0
n

i=0
B(i)
n
i
xn
n! .
Now note that the left-hand side is B′(x), while the right-hand side is
B(x)ex by Lemma 8.20. Therefore, we get
B′(x) = B(x)ex,
B′(x)
B(x) = ex,
and, taking integrals,
ln B(x) = ex + C.
Setting x = 0, the left-hand side is ln 1 = 0, therefore we must choose C =
−1 on the right-hand side. Therefore, ln B(x) = ex −1, and B(x) = eex−1
as claimed.
8.2.3
Compositions of Exponential Generating Functions
The compositions of exponential generating functions can be deﬁned in the
same circumstances, and in the same way, as those of ordinary generating
functions. In this subsection we will see that the corresponding versions of
Theorems 8.13 and 8.15 also hold.
Theorem 8.25 (The Exponential formula). Let an be the number of
ways to build a certain structure on an n-element set, and assume a0 = 0.
Let hn be the number of ways to partition the set [n] into an unspeciﬁed
number of non-empty subsets, then build a structure of the given kind on
each of these subsets. Set h0 = 1. Denote by A(x) and H(x) the exponential
generating functions of these sequences. Then
H(x) = eA(x).
Proof. Since in a set partition the order of blocks is irrelevant, it follows
from Theorem 8.21 that A(x)k/k! is the exponential generating function
for the number of ways to partition [n] into exactly k subsets, then build
a structure of the given kind on each subset.
Summing over all k, we
get 
k≥1 A(x)k/k!. As a0 = 0, none of the power series A(x)k/k! has a

186
A Walk Through Combinatorics
constant term. On the other hand, H(x) has constant term 1 by deﬁnition.
This shows that
H(x) = 1 +

k≥1
A(x)k
k!
=

k≥0
A(x)k
k!
= eA(x).
Before our next example, let us recall that

1
1 −x dx = ln

1
1 −x

.
On the other hand,

1
1 −xdx =
 
n≥0
xn dx =

n≥0
xn+1
n + 1 =

k≥1
xk
k ,
where the integral of the formal power series 
n≥0 anxn is deﬁned to be

n≥0 an xn+1
n+1 .
Comparing the last two displayed equalities, we get the identity

k≥1
xk
k = ln

1
1 −x

,
which will be useful in the next example, and in many other situations.
Example 8.26. In how many diﬀerent ways can we arrange n people into
groups, and then have each group sit at a circular table?
Solution. There are (k−1)! ways for a k-member group to sit at a circular
table. Therefore, keeping the notation of Theorem 8.25, ak = (k−1)!. This
yields
A(x) =

k≥1
(k −1)! · xk
k! =

k≥1
xk
k = ln

1
1 −x

.
Therefore, the Exponential formula implies that
H(x) = eln(
1
1−x) =
1
1 −x =

n≥0
xn =

n≥0
n! · xn
n! .
This shows that there are hn = n! ways to arrange our n people around
circular tables.

A Function Is Worth Many Numbers. Generating Functions
187
The reader should try to ﬁnd an immediate combinatorial proof of this
result.
The following is an example of combined applications of the Product
formula and the Exponential formula.
Example 8.27. Find the exponential generating function F(x) for the
sequence {fn} that denotes the number of partitions of [n] into blocks of
size three, four, and nine.
Solution. Let an, bn, and cn denote the number of partitions of [n] into
blocks of size three only, size four only, and size nine only, and let A(x),
B(x), and C(x) denote the respective exponential generating functions. We
will determine these exponential generating functions by the Exponential
formula. To that end, consider the following very simple sequence. Let tn
be the number of ways an n-element set can form a block of size three.
Obviously, t3 = 1, and tn = 0 if n ̸= 3. Thus the exponential generating
function of this sequence is T (x) = x3/3!. It then follows by the Exponential
formula that
A(x) = eT (x) = ex3/3!.
An analogous argument shows that B(x) = ex4/4!, and C(x) = ex9/9!.
Now let us split n into three (possibly empty) subsets, and take a par-
tition with blocks of size three on the ﬁrst subset, a partition with blocks
of size four on the second subset, and a partition with blocks of size nine
on the third subset. Then the Product formula shows that
F(x) = A(x)B(x)C(x) = e
x3
3! + x4
4! + x9
9! .
Theorem 8.28 (Compositional formula, Exponential version).
Let an be the number of ways to build a certain structure on an n-element
set, and assume a0 = 0. Let bn be the number of ways to build a second
structure on an n-element set, and let b0 = 1. Let gn be the number of
ways to partition the set [n] into an unspeciﬁed number of non-empty sub-
sets, then build a structure of the ﬁrst given kind on each of these subsets,
then build a structure of the second kind on the set of the subsets. Denote
by A(x), B(x), and G(x) the generating functions of the sequences {an},
{bn}, and {gn}.
Then
G(x) = B(A(x)).

188
A Walk Through Combinatorics
Proof. Let us assume that we partition [n] into k subsets. Then there
are bk ways to take a structure of the second kind on the k-element set
of these subsets. Therefore, it follows from Theorem 8.21 that bkA(x)k/k!
is the exponential generating function for the number of ways to partition
[n] into exactly k subsets, then build a structure of the given kind on each
subset, and then take a structure of the second kind on the k-element set
of these subsets. As a0 = 0, none of the power series bkA(x)k/k! has a
constant term. On the other hand, G(x) has constant term 1 by deﬁnition.
This shows
G(x) = 1 +

k≥1
bk
A(x)k
k!
=

k≥0
bk
A(x)k
k!
= B(A(x)).
Example 8.29. We have n distinct cards. We want to split their set into
non-empty subsets so that each of them contains an even number of cards.
Then we want to order the cards within each subgroup. Finally, we want to
order these subgroups into a line. Find an explicit formula for the number
of ways gn we can do this.
Solution. Keeping the notation of Theorem 8.28, we see that an = n! if
n ≥2 is even, and an = 0 if n is odd, or n = 0. Moreover, bn = n! for all
n ≥0. Therefore,
A(x) =

n≥0
an
xn
n! =

n≥2
n even
xn =
x2
1 −x2 ,
and
B(x) =

n≥0
bn
xn
n! =

n≥0
xn =
1
1 −x.
Therefore, by the Compositional formula,
G(x) = B(A(x)) =
1
1 −
x2
1−x2
= 1 −x2
1 −2x2
= 1 +
x2
1 −2x2 = 1 + x2 
m≥0
(2x2)m = 1 +

m≥0
2mx2m+2.
So the coeﬃcient gn of xn/n! in G(x) is 0 if n is odd, and 2m−1(2m)! if
n = 2m and m > 0. Consequently, for even n, there are gn = 2
n
2 −1 · n!
ways to proceed.

A Function Is Worth Many Numbers. Generating Functions
189
Quick Check
(1) Find a closed formula for the exponential generating function of the
sequence {c(n, 2)}n≥2, that is, the sequence counting permutations of
length n that consist of two cycles.
(2) Let fn be the number of permutations of length n in which each cycle
is colored red, blue, or green. Find an explicit formula for the numbers
fn.
(3) Let s0 = 1, and for n > 0, let sn be the number of all surjections
from [n] to [k], where n is a ﬁxed positive integer, and k varies from
1 to n. Find a closed formula for the exponential generating function
S(x) = 
n≥0 sn xn
n! .
Notes
The theory of generating functions is certainly rich enough to be the sub-
ject of several books. A classic in that area is “Generatingfunctionology” by
Herb Wilf [59]. For a far-reaching analysis of exponential generating func-
tions, we recommend “Enumerative Combinatorics” Volume 2, by Richard
Stanley [52]. Chapter 6 of that book contains a very extensive list of ob-
jects that are counted by the Catalan numbers. Readers who want even
more information on Catalan numbers should consult Richard Stanley’s
book “Catalan numbers” [50].
An important feature of generating functions is that they often allow
us to ﬁnd the growth rate of a sequence without computing an explicit
formula for that sequence. The interested reader should consult Chapter 7
of “Introduction to Enumerative and Analytic Combinatorics” [11] for an
introductory discussion of the relevant technique. A high-level treatment of
the subject is the book “Analytic Combinatorics” [25] by Philippe Flajolet
and Robert Sedgewick.
Exercises
(1) Find an explicit formula for ak if a0 = 0 and ak+1 = ak + 2k for k ≥0.
(2) Let a0 = a, and let an+1 = pan + q, for n ≥0, for some ﬁxed real
numbers p and q, where p ̸= 0. What kind of function is the closed
form of the ordinary generating function A(x) = 
n≥0 anxn?
(3) Let {an}n≥0 and {bn}n≥0 be two sequences, and let bn = n
i=0 ai.
What is the relationship between the ordinary generating functions of

190
A Walk Through Combinatorics
these sequences?
(4) Let {an}n≥0 and {bn}n≥0 be two sequences, and let A(x) and B(x)
be their respective exponential generating functions. Let us assume we
know that B(x) = A(x)/(1 −x). What is the relationship between the
two sequences?
(5) A child wants to walk up a stairway. At each step, she moves up either
one or two stairs. Let f(n) be the number of ways she can reach the
nth stair. Find a closed explicit formula for f(n).
(6) Let hn be deﬁned as in Example 8.14.
Prove that if n ≥1, then
hn+2 = 3hn+1 −hn.
(7) If we consider the sequence of the numbers hn deﬁned in Example 8.14,
and that of the numbers f(n) deﬁned in Exercise 5, we note that the
equality f(2n −1) = hn seems to hold, for all n ≥1.
(a) Prove this fact (by any method).
(b) (+) Give a direct bijective proof of this fact. Do not use generating
functions, or recurrence relations.
(8) Let an be the number of ways to pay n dollars using ten-dollar bills,
ﬁve-dollar bills, and one-dollar bills only. Find the ordinary generating
function A(x) = 
n≥0 anxn.
(9) Find a simple, closed form for the generating function of the sequence
deﬁned by an = n2.
(10) Let f(n) be the number of subsets of [n] in which the distance of any
two elements is at least three. Find the generating function of f(n).
(11) Find the ordinary generating function of the sequence pk(n). Recall
that pk(n) is the number of all partitions of n into exactly k parts.
(12) [C] Use your favorite software package to ﬁnd the numbers p4(n) for
n ≤20.
(13) Find a combinatorial proof for the result of Example 8.6.
(14) Find a combinatorial proof for the result of Example 8.7.
(15) (+) Find a combinatorial proof for the result of Example 8.16.
(16) Let an be the number of monotonic functions f from [n] to [n] such
that f(i) ≤i for every i ∈[n]. Find a closed formula for an.
(17) (+) Let Mn denote the number of lattice paths from (0, 0) to (n, 0)
which never dip below y = 0 and are made up only of the steps (1, 0),
(1, 1), and (1, −1). Find the ordinary generating function 
n≥0 Mnxn.
The numbers Mn are called the Motzkin numbers.
(18) (+) Let fn be the number of paths with steps (1, 0), (1, 1) and (0, 1)
from (0, 0) to (n, n) that never run above the diagonal x = y. Find the

A Function Is Worth Many Numbers. Generating Functions
191
ordinary generating function F(x) = 
n≥0 fnxn. The numbers fn are
called the Schr¨oder numbers, or the large Schr¨oder numbers.
(19)(a) [C] Use your favorite software package to ﬁnd the Motzkin numbers
of Exercise 17, for n ≤10.
(b) [C] Use your favorite software package to ﬁnd the Schr¨oder numbers
of Exercise 18, for n ≤10.
(20) (+) Let r(n) be the number of n-permutations whose square is the
identity permutation. We proved in Exercise 5 of Chapter 6 that
r(n + 2) = r(n + 1) + (n + 1)r(n),
(8.17)
if n ≥0, while r(0) = r(1) = 1. Use this recurrence relation to ﬁnd an
explicit formula for the generating function R(x) = 
n≥0 r(n) xn
n! .
(21) Find the exponential generating function F(x) for the number of n-
permutations having cycles of length a1, a2, · · · , ak only.
(22) Let H2,3(n) be the number of n-permutations in which all cycles are of
length two or three. Use the result of the previous exercise to ﬁnd a
recurrence relation for H2,3(n).
(23) Let b(n) be the number of compositions of n in which each part is an
odd integer. Find a closed formula for 
n≥0 b(n)xn. Express b(n) by
the numbers f(n) deﬁned in Exercise 5.
(24) Let gn be the number of ways to take a partition of [n] into blocks of
size at most two, and then to order the set of blocks linearly. Find the
closed form of the exponential generating function G(n) of the sequence
gn.
Supplementary Exercises
(25) (-) Find an explicit formula for an if a0 = 1 and an+1 = 3an + 2n if
n ≥0.
(26) (-) Find an explicit formula for an if a0 = 1, a1 = 4, and an+2 =
8an+1 −16an for n ≥0.
(27) (-) A certain kind of insect population multiplies so that at the end
of each year, its size is the double of its size a year before, plus 1000
more insects. Assuming that originally we released 50 insects, how
many of them will we have at the end of the nth year?
(28) Let a0 = a, let a1 = b, and let an+2 = pan+1+qan+r for n ≥0, where
p and q are ﬁxed nonzero real numbers, and r is any real number.
(a) What kind of function is the closed form of the generating function
A(x) = 
n≥0 anxn?

192
A Walk Through Combinatorics
(b) Give a more precise answer to the question in part (a) in the special
case when r = 0.
(29) Let a0 = a, and let an+1 = p(n + 1)an + q · (n + 1)!, for n ≥0,
for some ﬁxed real numbers p and q, where p ̸= 0.
What kind of
function is the closed form of the exponential generating function
A(x) = 
n≥0 an xn
n! ?
(30) (-) A permutation is called indecomposable if it cannot be cut into
two parts so that everything before the cut is smaller than everything
after the cut. For example, 3142 is indecomposable, but 2143 is not
as you can cut it after the ﬁrst two elements.
Let f(n) be the number of indecomposable permutations of length n,
and set f(0) = 0. Find the generating function F(x) = 
n≥0 f(n)xn.
Note: you can give your result in terms of G(x) = 
n≥0 n!xn, the
generating function of all permutations.
(31) (-) Find an explicit formula for the numbers an if an+1 = (n + 1)an +
2(n + 1)! for n ≥0, and a0 = 0.
(32) Let a0 = a1 = 1, and let an = nan−1 + n(n −1)an−2 for n ≥2. Find
the exponential generating function of the numbers an. Compare your
result to the result of Exercise 5.
(33) Let a0 = 0, and let an+1 = (n + 1)an + n! for n ≥0. Find an explicit
formula for an. In what earlier chapter did you see your answer as
the answer to a combinatorial enumeration problem?
Explain the
connection.
(34) Exponential formula, permutation version. Let C = {c1, c2, · · · } be a
set of positive integers. Let gC(n) be the number of n-permutations
in which each cycle length belongs to C. Set g∅(n) = 0. Prove that
GC(x) =

n
gC(n)xn
n! = exp
⎛
⎝
i≥1
xci
ci
⎞
⎠.
(35)(a) Explain how the result of the previous exercise is a generalization
of Example 8.26.
(b) Use the result of the previous exercise to ﬁnd the exponential gen-
erating function for the number of n-permutations whose square is
the identity permutation.
(c) Use the result of the previous exercise to provide generating func-
tion proofs of the two formulae given in Theorem 6.5.
(36) Find a closed form (no summation signs) for the generating function
G(x) = 
n≥0 c(n, k) xn
n! .

A Function Is Worth Many Numbers. Generating Functions
193
(37) Find a closed form (no summation signs) for the generating function
G(x) = 
n≥0 S(n, k) xn
n! .
(38) Let h0 = 1, and let hn be the number of compositions of n into parts
equal to 2 or 3. Find a closed formula for H(x) = 
n≥0 hnxn.
(39) Let hn be the number of ways to tile a 1 × n rectangle with 1 × 1 tiles
that are red or blue and 1 × 2 tiles that are green, yellow, or white.
Find a closed formula for H(x) = 
n≥0 hnxn.
(40) Let hn be the number of sequences of length n consisting of letters A
and B in which there is no subsequence of two letters A in consecutive
positions. Find a closed formula for H(x) = 
n≥0 hnxn.
(41) (+) Let podd(n) denote the number of partitions of n into an odd
number of parts, and let peven(n) denote the number of partitions of
n into an even number of parts. Prove that |peven(n) −podd(n)| is
equal to the number of partitions of n into distinct odd parts.
(42) Let gn be the number of ways of selecting a permutation of length
n, and then selecting a cycle of that permutation. Use the Compo-
sitional formula to ﬁnd the exponential generating function G(x) =

n≥0 gn xn
n! , then deduce an explicit formula for gn.
What earlier
result does your formula conﬁrm?
(43) We have two bookshelves.
Let tn be the number of ways to ﬁrst
partition a set of n distinct books into two non-empty blocks, and
then to line up one block on the top bookshelf and to line up the
other block on the bottom bookshelf. Find a closed formula for tn.
(44) Find the exponential generating function D(x) for the number of de-
rangements, deﬁned in Example 7.4. Look for several diﬀerent ways
to obtain D(x).
(45) Let D(n) be the number of derangements of length n. Prove that for
n ≥1, the equality D(n) −nD(n −1) = (−1)n holds. Recall that
D(0) = 1 and D(1) = 0.
(46) Let De(n) (resp. Do(n)) denote the number of derangements of length
n that are even (resp. odd) permutations. Prove that De(n)−Do(n) =
(−1)n−1(n −1).
(47) We divide a group of people into subgroups A, B, and C, and ask
each subgroup to form a line. We also require that A have an odd
number of people, and that B have an even number of people. How
many ways are there to do this?
(48) We select an odd number of people from a group of n people, to serve
on a committee. Then we select an even number from this committee
to serve on a subcommittee. (Zero is an even number, too.) In how

194
A Walk Through Combinatorics
many diﬀerent ways can we do this?
(49) We have n cards.
We want to split them into an even number of
non-empty subsets, form a line within each subset, then arrange the
subsets in a line. In how many diﬀerent ways can we do this?
(50) Find a direct combinatorial proof for the result of the previous exer-
cise.
(51) Let f(n) be deﬁned as in Exercise 5. Prove that for all positive integers
n,
f(n) =
[n/2]

k=0
n −k
k

.
Do not use the closed formula proved in Exercise 5.
(52) (+) Generalize the result of Example 8.11.
(53)(a) Let a1, a2, · · · , ak be non-negative integers, and let a(n) be the
number of compositions of n into k parts so that ith part is not
larger than ai.
Find the ordinary generating function A(x) =

n≥0 a(n)xn.
(b) Let b(n) be the number of compositions of n into k + 1 parts so
that the ith part is not larger than ai, and there is no constraint
on the last part. Find the ordinary generating function B(x) =

n≥0 b(n)xn.
(54) (+) We say that a permutation p = p1p2 · · · pn is a has an ascent in
position i if pi < pi+1. How many permutations of length n are there
in which the ﬁrst ascent occurs in an even position? For the sake of
this problem only, let us say that p always has an ascent in position
n. (We can justify this convention by saying that pn is followed by an
inﬁnitely large last symbol.) What other class of n-permutations has
the same number of elements?
(55) Let gn be the number of ways in which n people can sit down around
an unspeciﬁed number of circular tables that are arranged in a line, so
that if k tables have people around them, then those will be the ﬁrst k
tables in the line. Two seating arrangements are considered identical
if each person has the same left neighbor in both of them, and each
person sits at the same table in both of them. Find the exponential
generating function G(x) of the sequence gn.
(56) Let hn be the number of ways to split a group of n children into non-
empty groups, have each group form a circle, and then have these
circles form a circle. Find the exponential generating function Hn of
the sequence cn. Two arrangements are considered identical if each

A Function Is Worth Many Numbers. Generating Functions
195
child has the same left neighbor in them, and each cycle has the same
left neighbor in them.
Solutions to Exercises
(1) Let A(x) = 
n≥0 akxk. Multiplying the recurrence relation by xk+1
and summing over all k ≥0 we get

k≥0
ak+1xk+1 =

k≥0
akxk+1 + x

k≥0
(2x)k.
This means, in the language of generating functions,
A(x) = xA(x) +
x
1 −2x,
A(x) =
x
(1 −x)(1 −2x) = x(1 + x + x2 + · · · )(1 + 2x + 4x2 + · · · ),
so ak = k−1
i=0 2i = 2k −1.
(2) Multiplying both sides of the recurrence relation by xn+1 and summing
over all n ≥0, we get the equality
A(x) −a = pxA(x) +
qx
1 −x.
This implies that
A(x) =
a + qx −ax
(1 −x)(1 −px).
So A(x) is a rational function in which the numerator is a polynomial
of degree at most 1, and the denominator is a polynomial of degree
two.
(3) If A(x) and B(x) are the two generating functions, then we have
B(x) = A(x)
1 −x = A(x)(1 + x + x2 + · · · )
= (a0 + a1x + a2x2 + · · · )(1 + x + x2 + · · · ).
Indeed, let us take a look at the exponent of xn in A(x)(1+x+x2+· · · ).
To get xn, we have to choose aixi from (a0+a1x+a2x2+· · · ), then we
must choose xn−i from (1 + x + x2 + · · · ). This results in the product
aixn. We can do this for all i such that 0 ≤i ≤n, and, on the other
hand, this is the only way we can obtain a constant multiple of xn in
our product A(x)(1 + x + x2 + · · · ). Therefore, the coeﬃcient of xn in
(a0 +a1x+a2x2 +· · · )(1+x+x2 +· · · ) is n
i=0 ai, and the statement
follows.

196
A Walk Through Combinatorics
(4) If you look at A(x) and B(x) as the ordinary generating functions
of sequences {an/n!}n≥0 and {bn/n!}n≥0, then the previous exercise
shows that
bn
n! =
n

i=0
ai
i! ,
bn =
n

i=0
ai(n)i.
(5) As the child can move at most two stairs at a time, she can get to
the nth stair either from the (n −1)st, or from the (n −2)nd stair.
Therefore, f(n) = f(n −1) + f(n −2), for n ≥2. In other words,
f(n + 2) = f(n + 1) + f(n) for all n ≥0, and f(0) = f(1) = 1.
Let F(x) = 
n≥0 f(n)xn be the ordinary generating function of the
numbers f(n).
Multiplying both sides of the (last version of the)
recurrence relation by xn+2, and summing over all n ≥0, we get

n≥0
f(n + 2)xn+2 =

n≥0
f(n + 1)xn+2 +

n≥0
f(n)xn+2,
which is equivalent to
F(x) −x −1 = x(F(x) −1) + x2F(x),
F(x) =
1
1 −x −x2 .
The two roots of 1−x−x2 are α = −1+
√
5
2
and β = −1−
√
5
2
. Therefore,
we look for the partial fraction decomposition
1
1 −x −x2 =
A
x −α +
B
x −β .
After rearranging, this yields
1 = (A + B)x + αB + βA,
therefore, we must have −B = A, and thus A(α −β) = −1, which
implies A = −1
√
5 and B =
1
√
5. So we have shown that
F(x) = −1
√
5
·
1
x −α + 1
√
5
·
1
x −β .
A computation similar to that of Example 8.14 then implies
fn =
1
√
5

1 +
√
5
2
n+1
−1
√
5

1 −
√
5
2
n+1
.

A Function Is Worth Many Numbers. Generating Functions
197
The ﬁrst few values of this sequence, starting at f(0) = 1, are 1, 1, 2,
3, 5, 8, 13, 21, 34, 55. This sequence is called the Fibonacci sequence.
Often, the shifted indexing is used. In that indexing, Fi = f(i −1),
leading to F0 = 0, F1 = F2 = 1, F3 = 2, etc. Then Fn is called the
nth Fibonacci number.
(6) Let us distinguish three diﬀerent cases according to the situation of
the last soldier in the line of n+2 soldiers. She can form a unit herself,
(and of course, be the commander of it), which happens in hn+1 cases.
She can be part of the last unit as a non-commander, which happens
again in hn+1 cases. Finally, she can be the commander of a unit that
has more than one person in it. If the ﬁrst soldier in the line who is
in her unit is in position i + 1, then there are hi ways to arrange the
ﬁrst i soldiers. Summing for i, we see that in this last case, there are
n
i=0 hi possibilities. This proves that
h(n + 2) = 2h(n + 1) +
n

i=0
hi,
(8.18)
h(n + 2) −h(n + 1) =
n+1

i=0
hi.
If we replace n by n −1 in this last equation, we get
n

i=0
hi = h(n + 1) −h(n),
adding this to (8.18) the proof follows.
(7)(a) Induction on n. If n = 1, then hn = h1 = 1, and f2n−1 = f1 = 1,
and the initial condition holds. Let us assume that the statement
is true for all positive integers smaller than n + 1. Then, using the
induction hypothesis, and the fact that fm = fm−1 + fm−2,
hn+1 = 3hn −hn−1 = 3f2n−1 −f2n−3 = 2f2n−1 + f2n−2
= f2n−1 + f2n = f2n+1,
and the statement is proved.
(b) Note that f2n−1 is in fact the number of all compositions of 2n −1
into parts that are equal to 1 or 2. We are going to deﬁne a bijection
from the set of all such compositions onto that of all arrangements
the oﬃcer in charge of Example 8.14 can make.
Let α be such
a composition, and say that α consists of 2k −1 parts equal to

198
A Walk Through Combinatorics
1, and n −k parts equal to 2. Now we start reading the string
of 1s and 2s in α, from left to right.
Every time we read a 2,
we will declare the corresponding soldier in the line to be a non-
commander. Therefore, we will get n −k non-commanders. The
ﬁrst time we read a 1, we declare the corresponding soldier in the
line to be a commander. The second time we read a 1, we make the
corresponding soldier (that is, the soldier who has just been named
a commander or non-commander) in the line the last soldier of his
unit by starting a new unit right after him.
Then we continue
this alternating procedure, that is, when we read the third, ﬁfth,
seventh, etc. 1, we declare the corresponding soldier in the line a
commander, and when we read the fourth, sixth, eighth, etc. 1,
we make the corresponding soldier in the line the last soldier of his
unit. This way, we create k units, and name k commanders, each
unit having a commander.
For example, if n = 8, and we have the composition α = 2 + 2 +
1 + 1 + 2 + 1 + 2 + 2 + 1 + 1 = 15, then we get a line of soldiers
b(α) = NNC|NCNN|C, where N denotes a non-commander, C
denotes a commander, and the bars denote the end of each unit.
To see that this is a bijection, it suﬃces to show that for each
arrangement β of the oﬃcer, there exists a unique composition α
so that b(α) = β. This unique preimage can be constructed easily,
by replacing all the N symbols in β by 2s, and all the C symbols
and bars by 1s. This completes the proof.
(8) It would be troublesome to ﬁnd a nice recurrence relation here as it
is clear that the number an of ways to pay n dollars with these bills
will strongly depend on the divisibility of n by ﬁve and ten. We will
instead obtain the ordinary generating function A(x) = 
n≥0 anxn
in a diﬀerent way.
Let f(n) be the number of ways to pay n dollars with ten-dollar bills
only. Then f(n) = 1 if n is divisible by 10, and f(n) = 0 otherwise.
Then F(x) = 
n≥0 f(n)xn = 1 + x10 + x20 + · · · =
1
1−x10 . Similarly,
let g(n) be the number of ways to pay n dollars with ﬁve-dollar bills
only. Then g(n) = 1 if n is divisible by 5, and g(n) = 0 otherwise.
Then G(x) = 
n≥0 g(n)xn = 1 + x5 + x10 + · · · =
1
1−x5 . Finally,
if h(n) is the number of ways to pay n dollars with one-dollar bills
only, then clearly h(n) = 1 for all n ≥0, and H(x) = 
n≥0 h(n)xn =
1 + x + x2 + · · · =
1
1−x.
It is high time we explained why we are interested in these seemingly

A Function Is Worth Many Numbers. Generating Functions
199
bland generating functions. Consider the product
F(x)G(x)H(x) =
1
(1 −x10)(1 −x5)(1 −x)
= (1 + x10 + x20 + · · · )(1 + x5 + x10 + · · · )(1 + x + x2 + · · · ).
Let us try to ﬁnd the coeﬃcient of, say x53 on the right-hand side. To
get a term whose coeﬃcient is 53, we must choose a member of each
of the three sums so that their exponents sum to 53. That means, one
exponent that is divisible by ten, one that is divisible by 5, and one
last exponent, say 30+20+3. However, this provides a way to pay 53
dollars with our bills: three ten-dollar bills (to pay 30 dollars), four
ﬁve-dollar bills (to pay 20 dollars), and three one-dollar bills (to pay
3 dollars). This way we can set up an obvious bijection between ways
to pay n dollars, and ways to choose one term from each of the three
parentheses so their product is xn. So the coeﬃcient of xn on the
right-hand side (which is precisely the number of ways we can pick
three such terms) is exactly an. So we have proved that
A(x) = F(x)G(x)H(x) =
1
(1 −x10)(1 −x5)(1 −x).
(9) Recall that
1
(1−x)3 = 
n≥0
n+2
2

xn. In other words,
x2
(1 −x)3 =

n≥0
n + 2
2

xn+2 =

n≥2
n
2

xn.
Also recall that
1
(1−x)2 = 
n≥1 nxn−1, in other words,
x
(1−x)2 =

n≥1 nxn. (If you need a reminder: these can be proved by either
taking the derivative of 1/(1 −x), or by considering the powers of
(1 + x + x2 + · · · ), and the coeﬃcient of xn there.)
Finally, note that n2 = 2
n
2

+ n, so

n≥0
n2xn = 2

n≥2
n
2

xn +

n≥1
nxn
= 2
x2
(1 −x)3 +
x
(1 −x)2 = x(x + 1)
(1 −x)3 .
(10) Try to construct such a subset. If n is part of the subset, then we
cannot have n −1 or n −2 in the subset, so we have f(n −3) ways
to choose such a subset. Indeed, we can append n to the end of any
good subset of [n−3]. If n is not part of our subset, then we obviously

200
A Walk Through Combinatorics
have f(n −1) choices. So f(n) = f(n −1) + f(n −3), for all integers
n ≥3. Moreover, f(0) = 1, f(1) = 2, and f(2) = 3.
Let F(x) = 
n≥0 f(n)xn. Multiplying the recurrence relation by xn
and summing over n ≥3, we get

n≥3
f(n)xn = x

n≥3
f(n −1)xn−1 + x3 
n≥3
f(n −3)xn−3.
In other words,
F(x) −3x2 −2x −1 = x(F(x) −2x −1) + x3F(x),
from where we get
F(x) = 1 + x + x2
1 −x −x3 .
(11) It follows from Exercises 6 and 7 of Chapter 5 that we always have
pk(n) = p≤k(n −k). Therefore,
∞

n≥0
pk(n)xn = xk
∞

n≥0
p≤k(n)xn =
xk
(1 −x)(1 −x2) · · · (1 −xk).
(12) The previous exercise shows that
∞

n≥0
pk(n)xn =
xk
(1 −x)(1 −x2) · · · (1 −xk).
Therefore, the numbers p4(n) are the coeﬃcients of the above power
series, with k = 4. To get the ﬁrst 20 coeﬃcients, type the following
in the software package Mathematica.
Series[x^4/((1-x)(1-x^2)(1-x^3)(1-x^4)),{x,0,20}],
then press Shift Return. (Do not type the last comma.) You will see
that the numbers p4(n) are, starting with p4(4), 1, 1, 2, 3, 5, 6, 9, 11,
15, 18, 23, 27, 34, 39, 47, 54, 64.
(13) We need to choose three holidays, and the last day of the ﬁrst part of
the semester. These four days will completely determine the structure
of the term. Out of these four days, the ﬁrst holiday may be the same
as the last day of the ﬁrst part of the semester, but there cannot
be any other coincidences. Thus we have to choose positive integers
a, b, c, d so that 1 ≤a ≤b < c < d ≤n. This is equivalent to choosing
non-negative integers 0 ≤a −1 < b < c < d ≤n, and that can be
done in
n+1
4

ways.

A Function Is Worth Many Numbers. Generating Functions
201
(14) We have to choose the set of all holidays, which can be done in 2n
ways, then the last day of the ﬁrst part of the semester, which can be
done in n + 1 ways as 0 is a choice, too. Thus the total number of
choices is (n + 1) · 2n.
(15) Each soldier can be either the ﬁrst soldier of a unit chosen for night
duty, the ﬁrst soldier of a unit not chosen for night duty, or not the
ﬁrst soldier of any unit. The only exception is the soldier who is at the
top of the line as he only has the ﬁrst two possibilities. This proves
that the number of all arrangements is 2 · 3n−1.
(16) Let f be such a function, and let i be the largest number in [n] so that
f(i) = i. There is always such a number, as f(1) = 1. Then we have, of
course, ai−1 possibilities for the restriction of f to [i]. The restriction
of f to {i+1, i+2, · · · , n} is a slightly diﬀerent function as f(j) = j is
not allowed there. In particular, we must have f(i+1) = i. In general,
f satisﬁes the criteria on this interval if and only if f(i + 1) = i, and
i + 1 ≤f(i + 2) + 1 ≤f(i + 3) + 1 · · · ≤f(n) + 1 ≤n,
or, in other words, f(i + 1) −(i −1) = 1, and
1 ≤f(i+2)−(i−1) ≤f(i+3)−(i−1) ≤· · · ≤f(n)−(i−1) ≤n−i.
If we set g(j) = f(j+i)−(i−1), we see that the latter clearly happens
in an−i cases. Therefore, we proved that if n ≥1, then
an =
n

i=1
ai−1an−i,
(8.19)
with a0 = 1. Now let C(x) = 
n≥0 anxn, and note that (8.19) is
equivalent to (8.13). Therefore an = cn =
2n
n

/(n + 1), and we have
found another occurrence of the Catalan numbers.
(17) If your ﬁrst step is horizontal, then you clearly have Mn−1 ways to
complete your path. If not, then let us say that you will ﬁrst touch the
line y = 0 at (k, 0). Then, to go from (k, 0) to (n, 0), you have Mn−k
ways to go. How many ways do you have to go from (0, 0) to (k, 0)
without touching the y = 0 line? Clearly, your ﬁrst step will be to
(1, 1), and the last one will be from (k−1, 1) to (k, 0). So the question
is the number of ways to get from (1, 1) to (k −1, 1) without dipping
below the y = 1 line, and that is clearly Mk−2. So M0 = M1 = 1 and
for n ≥2,
Mn = Mn−1 +
n

k=2
Mk−2Mn−k.

202
A Walk Through Combinatorics
Now let M(x) = 
n≥0 Mnxn. Multiply both sides of the previous
equation by xn, and sum for all non-negative n to get
M(x) = xM(x) + 1 + x2M 2(x).
Therefore,
M(x) = 1 −x −
√
1 −2x −3x2
2x2
.
(18) Let us ﬁrst ﬁnd a recursive formula for fn. If our ﬁrst step is (1, 1),
then we clearly have fn−1 ways to complete our path, from (1, 1) to
(n, n). Otherwise, let (i, i) be the ﬁrst point (other than the origin) on
the diagonal (x, x) that our path touches. Then there are fn−i ways
to complete this path, from (i, i) to (n, n). Moreover, the number of
ways we could go from (0, 0) to (i, i) without touching the diagonal
is fi−1. Indeed, we had to start with a (1, 0) step, and with a (0, 1)
step, and never go above the diagonal (x, x −1) that is spanned by
the points (1, 0) and (i, i −1).
Therefore, we proved that fn = fn−1 + n
i=1 fi−1fn−i if n ≥1, while
f0 = 1. Multiplying both sides by xn and summing over n ≥1, we
get
F(x) −1 −xF(x) = xF(x)2,
(8.20)
which yields
F(x) = 1 −x −
√
x2 −6x + 1
2x
.
Again, (8.20) has two solutions, so we had to choose the one in which
the constant term is 1.
(19)(a) We computed the generating function M(x) of the Motzkin num-
bers in Exercise 17. The numbers Mn are the coeﬃcients of M(x).
We can expand this M(x) by typing
Series[(1-x-Sqrt[1-2x-3x^2])/(2x^2),{x,0,10}]
in Mathematica, and then hitting Shift Return. We get that the
Motzkin numbers are, starting at M0, 1, 1, 2, 4, 9, 21, 51, 127, 323,
835, 2188.
(b) Using the result of Exercise 18, type
Series[(1-x-Sqrt[1-6x+x^2])/(2x),{x,0,10}]
in Mathematica. You get that the numbers we were looking for are,
starting with f0, 1, 2, 6, 22, 90, 394, 1806, 8558, 41586, 206098,
1037718.

A Function Is Worth Many Numbers. Generating Functions
203
(20) We deﬁne R(x) = 
n≥0 r(n) xn
n! , the exponential generating function
of the numbers r(n). Let us multiply both sides of equation (8.17) by
xn/n!, then sum over all positive integers n, to get

n≥0
r(n + 2)xn
n! =

n≥0
r(n + 1)xn
n! +

n≥0
(n + 1)r(n)xn
n! .
Now note that the left-hand side is R′′(x), and the ﬁrst member of the
right-hand side is R′(x). The second member of the right-hand side is
somewhat harder to recognize, but with a little practice, one can see
that it is in fact (xR(x))′. Therefore, we get
R′′(x) = R′(x) + (xR(x))′ = R′(x) + xR′(x) + R(x).
Solving this, we get R(x) = ex+x2/2.
(21) This is very similar to Example 8.27. The only diﬀerence is in the
deﬁnition of tn. Let tn be the number of ways an n-element set can
be arranged in an a1-cycle. Then ta1 = (a1 −1)!, and tn = 0 if n ̸=
a1. Therefore, the exponential generating function of that sequence
is T (x) = xa1/a1.
Then the same application of the Exponential
formula, and then the Product formula shows that
F(x) = exp
 k

i=1
xai
ai

.
(22) The previous exercise shows that the exponential generating function
of the sequence {H2,3(n)}n≥0 is H(x) = exp( x2
2 + x3
3 ).
Therefore,
H′(x) = (x + x2)H(x). This implies that the coeﬃcient of xn/n! on
the left-hand side is H2,3(n + 1), while the coeﬃcient of xn/n! on the
right-hand side is nH2,3(n −1) + n(n −1)H2,3(n −2).
Therefore,
H2,3(n + 1) = nH2,3(n −1) + n(n −1)H2,3(n −2), when n ≥4, and
H2,3(n) = 0 if n = 0, or n = 1, H2,3(2) = 1, and H2,3(3) = 2.
(23) A composition of n into odd parts is equivalent to splitting up [n] into
an unspeciﬁed number of nonempty intervals, and covering each inter-
val by a single tile of odd length. The number of ways of covering an
interval that way is one if the interval has odd length and 0 otherwise.
The generating function of these numbers is A(x) = x+x3 +x5+· · · =
x/(1 −x2), and hence the generating function of the combined task is
B(x) = 1/(1 −A(x)) =
1 −x2
1 −x −x2
by Theorem 8.13. Comparing this to the result of Exercise 5, we see
that b(n) = f(n) −f(n −2) = f(n −1).
In other words, b(n) is
the diﬀerence of two Fibonacci numbers, and so b(n) is a Fibonacci
number itself.

204
A Walk Through Combinatorics
(24) We use the Compositional formula for exponential generating func-
tions. We have A(x) = x + x2
2 , and B(x) = 1/(1 −x), so
G(x) = B(A(x)) =
1
1 −x −x2
2
.

Chapter 9
Dots and Lines. The Origins of Graph
Theory
In the eighteenth century, the city of K¨onigsberg consisted of islands where
two branches of the river Pregel joined. (Today the city is called Kalin-
ingrad, and is in Russia, on the Baltic Sea.) Seven bridges connected vari-
ous islands as shown in Figure 9.1. Mathematics for centuries to come was
greatly enhanced by this innocent fact. In 1736, the most proliﬁc math-
ematician of all time, Leonhard Euler, became interested in the following
question. Is it possible to walk through town, starting and ending at the
same place, so that we use each bridge exactly once?
River
River
River
A
B
C
D
Fig. 9.1
A map of K¨onigsberg.
9.1
The Notion of Graphs. Eulerian Trails
Euler understood that the shape of the islands and the river does not in-
ﬂuence the answer to this question. He recognized that the only relevant
pieces of information here are those of connectivity, that is, the number of
bridges between any two islands. Therefore, instead of using the map of
K¨onigsberg, he used the simple diagram shown in Figure 9.2.
Here the dots represent the land masses, and the lines represent the
bridges between them. It is clear that a trail Euler was looking for exists if
205

206
A Walk Through Combinatorics
A
B
C
D
Fig. 9.2
The graph of the K¨onigsberg bridges.
and only if you can draw the diagram of Figure 9.2 so that you never lift
your pencil, you go through each line exactly once, and you start and end
at the same point.
Such a diagram, made up from points and lines that connec some pairs
of those points, is called a graph. The dots are called the vertices of the
graph, and the lines are called the edges of the graph. In this book, we will
only discuss graphs with a ﬁnite number of vertices, and a ﬁnite number of
edges. The number of edges connected to vertex A is called the degree of
A.
This simple model proves to be incredibly useful. The theory of graphs
is a very extensive part of combinatorics as there are plenty of problems
of various nature that can be solved by this simple model. (Recall that
we have in fact used graphs in a surprisingly powerful way to solve the
problem of Example 1.7.) In our Walk through Combinatorics, we would
like to emphasize the diversity of these problems. First, however, we need
to introduce some basic terminology.
It is possible that in a graph, there are multiple edges joining the same
pair of points, or there are edges that start and end in the same vertex (such
edges are called loops). If a graph G has no loops, and has no multiple edges
between the same pair of points, then we will say that G is a simple graph.
Most of the graphs we discuss in this book will be simple graphs.
A sequence of distinct edges e1e2 · · · ek is called a trail if we can take a

Dots and Lines. The Origins of Graph Theory
207
continuous walk in our graph, ﬁrst walking through the edge e1, then the
edge e2, and so on. In other words, the endpoint of ei is the starting point
of ei+1. Note that this happens if and only if we can draw the set of edges
e1e2 · · · ek so that we never lift our pencil from the paper, and we ﬁrst draw
e1, then e2, and so on. A walk is like a trail, except that all edges do not
need to be distinct.
If, in addition, we start the drawing at the same vertex where we end
it, then we say that e1e2 · · · ek is a closed trail. If a trail uses all edges of G,
then we call it an Eulerian trail. If a trail does not touch any vertex twice,
then we call it a path.
If we put two or more graphs next to each other, we can certainly call
the union obtained this way a graph. Still, it is natural to think that this
new graph is not quite as good as the original graphs. For instance, there are
pairs of vertices so that you cannot get from one vertex to another through
a path. This is a very important diﬀerence, and motivates the following
deﬁnition.
Deﬁnition 9.1. If the graph G has the property that for any two vertices
x and y, one can ﬁnd a path from x to y, then we say that G is a connected
graph.
A subgraph H of a graph G is a graph whose set of vertices is a subset
of the set of vertices of G, and whose set of edges is a subset of the set
of edges of G. A signiﬁcantly diﬀerent notion is that of induced subgraphs.
We say that H is an induced subgraph of G if H is a subgraph of G, and
for any pair (x, y) of vertices of G, if both x and y are in H, then all the
edges of G between x and y are also in H.
If G is not connected, then let k be the smallest integer so that G can
be obtained as the union of k connected graphs. Then we say that G has
k connected components. We also say that vertices u and v are in the same
connected component if there is a path from u to v. In other words, the
connected components are the maximal connected subgraphs of G, that is,
connected subgraphs to which we cannot add any new vertex of G without
forcing them to lose the connected property. Now we are in a position to
state and prove Euler’s theorem.
Theorem 9.2. A connected graph G has a closed Eulerian trail if and only
if all vertices of G have even degree.
Proof. First we prove the “only if” part, that is, we show that if G has a

208
A Walk Through Combinatorics
closed Eulerian trail, then all vertices of G must have even degree. Indeed,
when we take the closed Eulerian trail W, we visit each vertex a certain
number of times. Let A be a vertex that was not where W started, and
assume we visited A exactly a times. This means we entered A exactly a
times, and we left A exactly a times. As we assumed W was a trail, we
had to do this using diﬀerent edges, so we used 2a edges. On the other
hand, W contains all edges of G, so A cannot have any additional edges,
therefore the degree of A is 2a. This shows that the degree of any vertex
other than the starting point S of W is even. Finally, note that S is not
only the starting point of W, but also the endpoint, so if we visit S exactly
t times between the start and the end of W, then we use 1+2t+1 = 2(t+1)
edges. Therefore, the degree of S is 2(t + 1), and our claim is proved.
Now let us assume that all vertices of G have even degree and prove that
G has a closed Eulerian trail. Take any vertex S, and start walking along
an edge e1, to the other endpoint A1 of that edge, then walk along any new
edge e2 that starts in A1. Continue this way, using new (previously unused)
edges at each step, until a closed trail C1 is formed. As G is ﬁnite, such
a closed trail will always be formed. The ﬁrst closed trail will be formed
when we ﬁrst revisit a vertex already visited. We cannot get stuck at some
vertex before completing a closed trail as each vertex has even degree, so
each time we enter a vertex, we can also leave it, except possibly the initial
vertex. If C1 = G, then we are done. If not, then choose a vertex V in C1
so that C1 does not contain all edges adjacent to V .
The alert reader can ask now how do we know that there is such a vertex
V . Let us assume that there is not. As C1 contains less edges than G, and
supposedly C1 contains all edges adjacent to all vertices it contains, there
must be a vertex A that is not in C1. However, G is a connected graph, so
there must be a path connecting A to any vertex in C1. Start walking on
this path from A to any given vertex of C1. When you reach C1 the ﬁrst
time, you will reach it in a vertex V that is in C1, but not all the edges
adjacent to it are in C1. Indeed, the one that has just ended in V is not.
This proves by contradiction that such a vertex V always exists. Figure 9.3
illustrates this situation.
Let us now remove all edges of C1 from G. We get a graph in which
again all vertices have even degree. Starting at V , let us take another closed
trail C2 in the remaining graph. We can then unite C1 and C2 into one
closed trail in G. Indeed, if we start walking by C1, we can stop at V , walk
through C2, then complete our trail by using the remaining part of C1. If
the new trail C1 ∪C2 contains all edges of G, we are done. If not, then let

Dots and Lines. The Origins of Graph Theory
209
1
C
V
A
Fig. 9.3
The cycle C1 does not contain all edges adjacent to V .
us omit C1 ∪C2 from G, and ﬁnd a new closed trail C3 in the remaining
graph.
As G has a ﬁnite number of edges, this procedure has to stop after a
ﬁnite number of steps. Therefore, after a ﬁnite number of steps, C1 ∪C2 ∪
· · · ∪Ck will be a closed trail containing all edges of G.
This proves that we cannot walk through all bridges of K¨onigsberg so
that we end where we started, and use each bridge exactly once. Indeed,
the graph shown in Figure 9.2 has four vertices of odd degree.
What happens if we relinquish the requirement that our trail start and
end at the same place? The answer to this question is a direct consequence
of Theorem 9.2.
Corollary 9.3. Let G be a connected graph. Then G has an Eulerian trail
starting at vertex S and ending at a diﬀerent vertex T if and only if S and
T have odd degree, and all other vertices of G have even degree.
Proof. Add a new edge joining S and T , and call the new graph obtained
H. Then H has a closed Eulerian trail if and only if G has an Eulerian trail
from S to T , so the claim follows from Theorem 9.2.
We have seen that the parity of the degrees is an important property of
a graph. The following theorem shows a basic fact about these parities.
Theorem 9.4. In a graph G without loops, the number of vertices of odd
degree is even.
Proof. Take such a graph with e edges. Let d1, d2, · · · , dn be the degrees
of the n vertices of G. We claim that
d1 + d2 + · · · + dn = 2e.

210
A Walk Through Combinatorics
Indeed, each edge contributes one to the degree of exactly two vertices,
namely its two endpoints. So a total of e edges will result in a total of
2e in the sum of degrees. Therefore, the sum of degrees is 2e, which is an
even number. This implies that there has to be an even number of odd
summands in d1 + d2 + · · · + dn.
Quick Check
(1) Let G be a graph in which the degree of each vertex is a positive even
number. Is it true that G has a closed Eulerian trail?
(2) Let d1, d2, · · · , dn be a set of positive integers so that n
i=1 di is even.
Is it true that there is a loopless graph G with vertices v1, v2, · · · , vi
so that the degree of vi is di?
(3) Let G be a graph that does not have a closed Eulerian trail, but it
is possible to walk through all edges of G so that we only repeat one
edge, and we only repeat that edge once. Is it true that G has only
two vertices of odd degree?
9.2
Hamiltonian Cycles
A cycle in a graph is a closed trail that does not touch any vertex twice,
except, of course the initial vertex, that must also be the ending vertex.
This implies that if a cycle has k vertices, then it has k edges. A cycle
that includes all vertices of a graph is called a Hamiltonian cycle, whereas
a path that includes all vertices of a graph is called a Hamiltonian path.
A real-life scenario in which Hamiltonian cycles are relevant is the fol-
lowing. Let us assume that many people are invited to a party, and they
will all be seated around a circular table.
Is it possible to ﬁnd seating
arrangements so that each guest knows both people seated next to him?
In this scenario, we can deﬁne a graph in which people are represented
by vertices, and two vertices are connected by an edge if the corresponding
people know each other. Then a Hamiltonian cycle in this graph, if it exists,
provides an appropriate seating.
Whether a Hamiltonian cycle exists in this graph depends, of course,
on the graph itself. For example, if there is a person who does not know
anyone, then it is clear that there is no Hamiltonian cycle. If there is no
such person, but the graph is not connected, there will not be a Hamiltonian
cycle either. If everyone knows everyone, then of course, there will be a
Hamiltonian cycle.

Dots and Lines. The Origins of Graph Theory
211
These were all very special situations.
What can be said about the
general case, though? That is, given a simple graph G, how can we quickly
decide whether it has a Hamiltonian cycle or not?
The answer to this question is that we cannot. It is easy to prove that an
appropriate seating exists (when it exists). Indeed, you can prove that by
simply exhibiting one. There is, however, no quick way known to prove that
no appropriate seating exists (when it does not). By “quick way” we mean
an algorithm that uses only f(n) steps, where n is the number of guests,
and f(n) is a polynomial function of n, such as n3, or n7 + 3n5 + 6n + 3.
We can certainly prove that no good seating exists by verifying all (n −1)!
possible seating arrangements, and concluding that none of them are good,
but that takes too long. The function g(n) = (n −1)! is not a polynomial
function of n.
This problem is interesting on its own, but it is also related to a vast
array of very important problems of an exciting area in Theoretical Com-
puter Science, called Complexity Theory, which is the topic of Chapter 20
of this book. (So it is well worth reading the book till the very end!) It
can be proved that the problem of deciding whether a given simple graph
has a Hamiltonian cycle is equivalent to about 5000 other problems, which
are all very diﬀerent at ﬁrst sight.
By “equivalent”, we mean that if a
polynomial-time algorithm were found for the Hamiltonian cycle problem,
then that would provide a polynomial-time algorithm for any of those 5000
problems, and vice versa. The set of all these equivalent problems is called
NP-complete problems. It is believed by most, but not all, researchers,
that such polynomial-time algorithm does not exist. You can try to ﬁnd
one, but do not try too hard...
There are nevertheless some nontrivial theorems about the existence of
Hamiltonian cycles.
Theorem 9.5. Let n ≥3, let G be a simple graph on n vertices, and let
us assume that all vertices in G are of degree at least n/2. Then G has a
Hamiltonian cycle.
Proof. Note that it follows from the conditions that G is connected. In-
deed, if G had more than one component, then it would have a component
of less than n/2 vertices, and vertices in that component would have degree
less than n/2.
Let us assume that G does not have a Hamiltonian cycle. Let us add
new edges to G as long as we can without creating a Hamiltonian cycle.
When we stop, we have a graph G′ in which all vertices have degree at least

212
A Walk Through Combinatorics
n/2, there is no Hamiltonian cycle, but adding any new edge would create
a Hamiltonian cycle.
Let P be a path of maximum length in G′. We claim that P contains
all vertices of G′. Indeed let x and y be two vertices in G′ that are not
connected by an edge. As adding the edge xy would create a Hamiltonian
cycle, it follows that G′ has a Hamiltonian path P that starts at x and ends
in y.
Let x = z1, z2, z3, · · · , zn−1, zn = y be the vertices of this path, from
x to y. Vertices x and y together have at least n neighbors. Therefore,
the Pigeon-hole Principle implies that there must be an index i so that
2 ≤i ≤n −1, while xzi is an edge, and also, zi−1y is an edge. (Otherwise
the set of neighbors of y and the set of vertices that immediately precede
a neighbor of x on the xy-path would be disjoint, which is impossible since
these sets are too large.) This is a contradiction, however, for this would
mean that xz2 · · · zi−1yzn−1 · · · zi is a Hamiltonian cycle as shown in Figure
9.4.
x
y
iz
z 2
z n-1
i-1
z
Fig. 9.4
The cycle xz2 · · · zi−1yzn−1 · · · zi is a Hamiltonian cycle.
There are several additional results proving that a simple graph in which
the degrees are, in some sense, large, has a Hamiltonian cycle. We will see
some of these results in the Exercises.
Quick Check
(1) If a simple graph G on n vertices has a Hamiltonian cycle, what can
we say about the number of Hamiltonian paths that G has?
(2) Let G be a simple graph. Let ¯G be the complement of G, that is, the
graph that has the same set of vertices as G, but has precisely the edges
that G does not. Show an example for a simple graph G so that both
G and ¯G have a Hamiltonian cycle.
(3) Find the graph G that satisﬁes the conditions of the previous question,
and has a minimum number of vertices with that property.

Dots and Lines. The Origins of Graph Theory
213
9.3
Directed Graphs
In the previous section, the edges of a graph were not assigned a direction.
We could walk through them in both ways. As anyone with big city driving
experience knows, this is not always the case in real life, that is, there are
one-way streets, too. A graph in which each edge is assigned a direction,
such as in Figure 9.5, is called a directed graph or digraph.
Fig. 9.5
A directed graph.
It is natural to wonder under what conditions does a directed graph
have a closed Eulerian trail. Of course, a trail in a directed graph must
contain all edges in the right direction, that is, we can only walk through
an edge from its “head” to its “tail”. Paths and closed trails are deﬁned in
an analogous way.
Clearly, in this case it is not enough to require that all vertices have an
even number of edges adjacent to them. For example, if no edge starts in
a given vertex, then there will be no Eulerian trail in that graph.
In order to answer this question, we introduce some new deﬁnitions.
We say that a directed graph G is strongly connected if for all vertices a
and b of G, there is a directed path from a to b. The in-degree of a vertex
of a directed graph is the number of edges that end at that vertex. The
out-degree of a vertex is the number of edges that start at that vertex. A
directed graph H is called balanced if for each vertex V of H, the equality
indegree(V ) = outdegree(V ) holds.
Theorem 9.6. A directed graph G has a closed Eulerian trail if and only
if it is balanced and strongly connected.

214
A Walk Through Combinatorics
Proof. First we prove that these conditions are necessary. As a closed
Eulerian trail W leaves each vertex as many times as it enters that vertex,
G must be balanced. Similarly, W provides a trail from any vertex to any
vertex, so G is strongly connected.
These two conditions are suﬃcient. To see this, copy the proof of The-
orem 9.2, replacing edges by directed edges.
A simple undirected graph is called complete if there is an edge between
every pair of distinct vertices. Thus a complete graph on n vertices has
n
2

edges. If we direct each edge of a complete graph, then the resulting
directed graph is called a tournament. The reason for this name is the
following. If n players participate at a round robin tennis tournament, and
we deﬁne a directed graph in which the vertices represent the players, and
ij is an edge if i has beaten j, then we get a tournament. We have met
tournaments before, in Exercises 2 and 3 of Chapter 2.
Hamiltonian paths and cycles can be deﬁned in directed graphs, too, in
the obvious way. While it is trivial that all complete (undirected) graphs
have Hamiltonian paths, the corresponding statement for directed graphs
is not that obvious. This is not surprising; while there is only one com-
plete undirected graph on n vertices, there are many, (in some sense, 2(
n
2))
tournaments. Nevertheless, they all have Hamiltonian paths. This is the
content of the next theorem.
Theorem 9.7. All tournaments have a Hamiltonian path.
Proof. We prove the claim by induction on n, the number of vertices of
our tournament T . If T has one, or two vertices, then the statement is
clearly true. Now assume that we know the statement for all tournaments
having n −1 vertices. Let T be any tournament on n vertices. Separate
any vertex V , and call the remaining graph on n −1 vertices T ′. By the
induction hypothesis, T ′ has a Hamiltonian path h = h1h2 · · · hn−1. The
question is how we can insert V into h. If there is an index i so that hiV is
an edge and V hi+1 is an edge, then we can insert V between hi and hi+1.
If no such i exists, then there must exist an index k so that 0 ≤k ≤n−1,
and for all j ≤k, V hj is an edge, and for all j > k, hjV is an edge.
Therefore, either V h1 is an edge, or hn−1V is an edge. So we can aﬃx V
either to the front, or to the end of h.
What can we say about the existence of Hamiltonian cycles in tour-
naments? Clearly, not all tournaments will contain them. For example,

Dots and Lines. The Origins of Graph Theory
215
if T has a vertex that has in-degree 0, or out-degree 0, then T does not
have a Hamiltonian cycle. It turns out that it is fairly easy to describe the
tournaments that do have Hamiltonian cycles.
Theorem 9.8. A tournament T has a Hamiltonian cycle if and only if it
is strongly connected.
Proof. If T has a Hamiltonian cycle, then that cycle provides a directed
path from any vertex to any vertex, so G is strongly connected.
Now let us assume that T is strongly connected, and let E(T ) denote
the set of edges of T . First we prove that T does contain a cycle. Indeed,
if it did not, then xy ∈E(T ) and yz ∈E(T ) would imply xz ∈E(T ), so T
would be a transitive tournament. In such a tournament, the vertices can
be listed from left-to-right so that ij ∈E(T ) if and only if j is on the right
of i. However, such a tournament is not strongly connected as no paths go
to the right. So T does have a cycle.
Let C = y1y2 · · · yk be a cycle of maximal length in T , and assume C is
not a Hamiltonian cycle. As T is strongly connected, it contains an edge
from C to some vertex x that is not in C. We can assume without loss of
generality that this edge is y1x. If xy2 were an edge, then y1xy2y3 · · · yk
would be a cycle having more vertices than C. Therefore, y2x has to be an
edge, and then similarly, y3x, y4x, · · · , ykx must all be edges.
Let Z be the set of all vertices z so that y1z ∈E(T ). Then yiz ∈E(T )
for all z ∈Z and all i ∈[k] by the same argument as the one we applied
for yix in the previous paragraph. Let zt be an edge, with z ∈Z, and
t /∈Z. Such an edge exists as T is strongly connected. Then t /∈C, and
therefore t /∈Z implies that ty1 ∈E(T ). Then, however, zty1y2y3 · · · yk is a
longer cycle than C. Figure 9.6 shows our construction. This contradiction
completes the proof.
Quick Check
(1) How many directed graphs are there on vertex set {1, 2, 3} that have
three edges? Loops and multiple edges are allowed.
(2) For which values of n does there exist a balanced tournament on n
vertices?
(3) Does there exist a tournament with exactly two Hamiltonian paths?

216
A Walk Through Combinatorics
y
x
z
t
y
y2
1
k
C
Z
Fig. 9.6
Constructing a cycle that is larger than C.
9.4
The Notion of Isomorphisms
When are two graphs considered the same? This question can be answered
in several diﬀerent ways. For the time being, we will only discuss two of
them.
We will say that the two graphs shown in Figure 9.7 are identical because
for any pair of vertices X and Y , the number of edges between X and Y is
the same in both graphs.
A
B
C
D
D
C
B
A
Fig. 9.7
Two identical graphs with labeled vertices.
The fact that the two graphs are not drawn in the same way does not
matter here. What matters is that exactly the same pairs of vertices have
edges between them.
Now consider Figure 9.8. The two graphs shown there are certainly not
identical. Indeed, the ﬁrst one contains the edge AB, and the second one

Dots and Lines. The Origins of Graph Theory
217
does not.
A
B
C
D
G
H
E
F
Fig. 9.8
Two isomorphic graphs with labeled vertices.
However, we certainly get the impression that these two graphs are not
completely unrelated either. For instance, if we omit all labels from the
vertices, then we get the two graphs shown in Figure 9.9, that surely look
the same.
Fig. 9.9
These two unlabeled graphs are identical.
We will express this by saying that the two graphs shown in Figure 9.8
are identical as unlabeled graphs, or, in one word, isomorphic. Let us make
this deﬁnition more precise.
Deﬁnition 9.9. We say that graphs G and H are isomorphic if there is a
bijection f from the vertex set of G onto that of H so that the number of
edges between any pair of vertices X and Y of G is equal to the number of
edges between vertices f(X) and f(Y ) of H. The bijection f is called an
isomorphism.
Example 9.10. Let G and H be the graphs shown in Figure 9.8. Then
the map f deﬁned by f(A) = H, f(B) = E, f(C) = F, f(D) = G is an
isomorphism, and therefore, the two graphs are isomorphic.
Note that an isomorphism maps a pair of connected vertices into a

218
A Walk Through Combinatorics
pair of connected vertices. In particular, if the degree of A is d, then the
degree of f(A) is d, for all isomorphisms f. Therefore, two graphs can be
isomorphic only if the multisets of their degrees are the same. Exercise 21
shows that this condition is not suﬃcient for isomorphism, indeed, there
are graphs with the same multiset of degrees that are not isomorphic.
In order to prove that two graphs are isomorphic, we have to exhibit an
isomorphism between them. To prove that two graphs are not isomorphic
is a more diﬃcult issue. In certain cases we get lucky. If the two graphs do
not have the same number of vertices, or the same multiset of degrees, or
they do not have the same number of cycles, or the same number of paths
of length k, and so on, then it is clear that they are not isomorphic. Indeed,
isomorphisms preserve all these parameters. (You should think about this
for a while.)
However, there is no general, and eﬃcient way to test whether two
graphs are isomorphic. The notion of “eﬃcient” will be made precise in
Chapter 20. One can of course verify all n! bijections from G to H, where
n is the number of vertices of each graph and see if any of them is an
isomorphism, but this is certainly not an eﬃcient algorithm. It is not known
whether this problem belongs to the class of NP-complete problems, the
class of problems that we mentioned when we discussed the problem of
deciding whether a graph has a Hamiltonian cycle. That said, a recent
paper of L´aszl´o Babai [5] has signiﬁcantly improved the eﬃciency of testing
whether two graphs are isomorphic or not.
To summarize, we have seen two diﬀerent answers to the question of
when two graphs are diﬀerent. In one of them, the vertices were distin-
guishable (labeled), in the other one, they were indistinguishable (unla-
beled). The way the graph was drawn did not matter in either case. We
will see situations, in Chapters 12 and 14, when that will matter.
Quick Check
(1) Let G and H be two simple graphs, both of them with seven vertices,
each of which is of degree 2. Are G and H necessarily isomorphic?
(2) Consider the undirected graph G whose vertices are all positive divisors
of 30, and there is an edge between a and b if either a/b or b/a is a
prime number. Let H be the graph whose vertices and edges are the
eight vertices and 12 edges of a cube. Is it true that G and H are
isomorphic?
(3) Is there a simple graph on seven vertices that is isomorphic to its com-

Dots and Lines. The Origins of Graph Theory
219
plement? (The complement of a simple graph is deﬁned in the Quick
Check part of Section 9.2.)
Notes
Graph Theory is the subject of Chapters 9–12 of this book. If the reader
wants a book-length treatment of the topic, an obvious place to start is
“Introduction to Graph Theory” by Douglas West [57]. The classic book
“Graphical Enumeration”, by Frank Harary and Edgar M. Palmer [30] is
devoted to counting graphs from numerous perspectives. For a recent, high-
level survey of that topic, the reader should consult the survey of Marc Noy
that is Chapter 6 of [12].
We will return to graphs in several later chapters as well, essentially in
all chapters following the Graph Theory part of the book. This shows how
omnipresent graphs are in combinatorics.
Exercise 18 contains the deﬁnition of graphical partitions. Let g(n) be
the number of all graphical partitions of the even integer n. Paul Erd˝os
conjectured that limn→∞
g(n)
p(n) = 0. This conjecture was open for twenty
years, and was then proved by Boris Pittel [41], who used sophisticated
techniques from Probability Theory in proving it.
Exercises
(1) Let G be a loopless undirected graph. Prove that the edges of G can be
directed so that no directed cycle is formed. (To put this into a real-life
context, it is possible to make all the streets of a city one-way so that
you can never return to a point you have left. This seems rather likely,
by experience....)
(2) Is it true that if a graph has a closed Eulerian trail, then it has an even
number of edges?
(3) Let G be a simple graph on 10 vertices and 28 edges. Prove that G
contains a cycle of length 4.
(4) Let G be a simple graph on 9 vertices, and assume we know that the
sum of all degrees in G is at least 27. Is it true that G has a vertex of
degree at least four?
(5) Let G be a graph. Recall that we say that H is an induced subgraph of
G if the vertex set of H is a subset of that of G, and if x and y are two
vertices of H, then xy is an edge in H if and only if xy is an edge in
G.

220
A Walk Through Combinatorics
Let G be a simple graph that has 10 vertices and 38 edges. Prove that
G contains K4 (the complete graph on four vertices) as an induced
subgraph.
(6) Let G be a simple graph in which all vertices have degree four. Prove
that it is possible to color the edges of G orange or blue so that each
vertex is adjacent to two orange edges and two blue edges.
(7) How many diﬀerent simple graphs are there on the vertex set [n]?
(8) An automorphism of a graph G is an isomorphism between G and G
itself. That is, the permutation f of the vertex set of G is an auto-
morphism of G if for any two vertices x and y of G, the number of
edges between x and y is equal to the number of edges between f(x)
and f(y). How many automorphisms do the following (labeled) graphs
have?
(a) The complete graph Kn on n vertices.
(b) The cycle Cn on n vertices.
(c) The path Pn on n vertices.
(d) The star Sn on n vertices. (This graph has one vertex of degree
n −1, and n −1 vertices of degree 1.)
(9) Prove that there are more than 6600 pairwise non-isomorphic graphs
on eight labeled vertices.
(10) Is it true that the number of people currently living on our planet and
having an odd number of siblings is even?
(11) Is it true that
(a) if a simple graph has a closed Eulerian trail, then it has a Hamilto-
nian cycle?
(b) if a simple graph has a Hamiltonian cycle, then it has a closed Eu-
lerian trail?
(12) A simple graph is called regular if all its vertices have the same degree.
Let G be a connected regular graph with 22 edges. How many vertices
can G have?
(13) The previous exercise deﬁnes a regular graph as a simple graph in which
each vertex has the same number of neighbors. Is it true that in such
a graph, each vertex will have the same number of second neighbors?
(The vertex X is a second neighbor of a vertex Y if XY is not an edge,
and there is a path of length 2 joining X and Y .)
(14) The graph shown in Figure 9.10 is called the Petersen graph. Does this
graph have a Hamiltonian cycle?
(15) Find all ways to omit edges from the Petersen graph shown in Figure

Dots and Lines. The Origins of Graph Theory
221
Fig. 9.10
The Petersen graph.
9.10 so that the remaining graph, that still has ten vertices, has a closed
Eulerian trail.
(16) The ordered degree sequence of a graph is the list of the degrees of its
vertices in non-increasing order. So if a graph G has e edges, then
the positive members of its degree sequence form a partition Π(G) of
the integer 2n. Prove that if G is a simple graph, then Π(G) is never
self-conjugate.
(17) Is there a simple graph on 6 vertices with ordered degree sequence 4,
4, 4, 2, 1, 1?
(18) Let p be a partition of the integer 2n. We say that p is graphical if there
exists a simple graph G (necessarily with n edges) that has ordered
degree sequence p. Prove that p = (4, 4, 3, 2, 1) is not graphical.
(19) (+) How many automorphisms does the graph shown in Figure 9.11
have?
(20) (+) How many automorphisms does the graph shown in Figure 9.12
have?
(21) Two graphs have the same ordered degree sequence. Show that they
are not necessarily isomorphic.
(22) Let c(n) be the number of connected graphs on the vertex set [n], and
let C(x) be the exponential generating function of the sequence {c(n)}.
Find C(x).
Do not look for a closed form.
Look for a functional
equation that enables us to compute the values c(n).
(23)(a) Prove that if in a simple graph G on ten vertices, each vertex has
degree ﬁve or more, then G is connected.
(b) Generalize the statement of part (a) for simple graphs on n vertices.

222
A Walk Through Combinatorics
A
B
C
D
E
F
G
H
Fig. 9.11
Find the number of automorphisms of this graph.
Supplementary Exercises
(24) (-)
(a) How many simple directed graphs are there on vertex set [n]?
(b) How many tournaments are there on vertex set [n]?
(25) (-) A tournament is called transitive if the fact that there is an edge
from i to j and an edge from j to k implies the fact that there is
an edge from i to k. How many transitive tournaments are there on
vertex set [n]?
(26) (-) Prove that a tournament is transitive if and only if it has only one
Hamiltonian path.
(27) (-) Is it true that a directed graph with a ﬁnite number of vertices
and with no directed cycles has at least one vertex whose outdegree
is zero?
(28)(a) (-) Prove that for any integers n ≥1, there exists a set S of
n
2

+ 1
simple graphs on vertex set [n] so that no two elements of S are
isomorphic.
(b) Prove that for any integers n ≥1, there exists a set T of p(n)
simple graphs on vertex set [n] so that no two elements of T are
isomorphic.
(29) Prove that if in a simple graph G, there is a trail or walk from vertex

Dots and Lines. The Origins of Graph Theory
223
A
B
C
E
F
D
Fig. 9.12
Find the number of automorphisms of this graph.
A to vertex B, then there is also a path from A to B.
(30) (+) A high school has 90 alumni, each of whom has ten friends among
the other alumni. Prove that each alumni can invite three people for
lunch so that each of the four people at the lunch table will know at
least two of the other three.
(31) Prove that in any simple graph, there are two vertices with the same
degree.
(32) There are several people in a classroom; some of them know each
other. It is true that if two people know the same number of people
in the classroom, then there is nobody in the classroom both of these
people know. Prove that there in someone in the classroom who knows
exactly one other person in the classroom.
(33) Prove that the number of people who have shaken hands at an odd
number of times (in their life so far) is even.
(34) Ten players participate at a chess tournament. Eleven games have
already been played. Prove that there is a player who has played at
least three games.
(35) Find all non-isomorphic simple graphs on four vertices.
(36) Find a simple graph G on n vertices so that G has no non-trivial auto-

224
A Walk Through Combinatorics
morphisms, n > 1, but otherwise n is minimal under these conditions.
Explain how your answer changes if we drop the requirement that G
be simple.
(37) Let G be the union of k disjoint cycles of length r. How many auto-
morphisms does G have?
(38) (+) At most how many edges can a simple graph G on n vertices have
if G is not to have a Hamiltonian cycle?
(39) (+) For what values of n can Kn be decomposed into a union of edge-
disjoint Hamiltonian cycles?
Note: In the following several exercises, we will ask how many Hamil-
tonian cycles various graphs have. All these graphs have labeled ver-
tices, and two Hamiltonian cycles are considered distinct if their set
of (undirected) edges are diﬀerent.
(40) How many Hamiltonian cycles does Kn have?
(41) Let Km,n be the simple graph whose vertex set consists of the m-
element vertex set A, and the n-element vertex set B, and which has
a total of mn edges, each between a vertex in A and a vertex in B.
Find the number of Hamiltonian cycles of Km,n. Note that in the
special case of m = n, the answer will diﬀer from the other cases.
We point out that Km,n is called a complete bipartite graph.
(42) For graph theoretical purposes, the n-dimensional hypercube Qn is a
simple graph whose vertices are the 2n points (x1, x2, · · · , xn) ∈Rn
so that for each i ∈[n], either xi = 0 or xi = 1, and in which two
vertices are adjacent if they agree in exactly n −1 coordinates.
Prove that if n ≥2, then Qn has a Hamiltonian cycle.
(43) Prove that if n ≥2, then Qn has at least n!/2 Hamiltonian cycles.
(44) Find the number of Hamiltonian cycles of Q3 (the regular, three-
dimensional cube).
(45) Is there a simple graph G on seven vertices such that it is not con-
nected, and each vertex of G has degree at least three?
(46) Each vertex of a simple graph G has degree k. Prove that G contains
a cycle of length at least k + 1.
(47) Prove that if G is a simple graph on n vertices, and for any two vertices
X and Y of G, it is true that dx + dz ≥n, then G has a Hamiltonian
cycle. (Here dz denotes the degree of the vertex z.)
(48) Prove that the statement of the previous exercise is not true if we only
assume that dx + dz ≥n −1.
(49) Let G be a simple graph on vertex set [n] in which each vertex has
degree two.

Dots and Lines. The Origins of Graph Theory
225
(a) Prove that G is a union of disjoint cycles.
(b) Let g(n) be the number of graphs described above, and set g(0) = 1.
Prove that

n≥0
g(n)xn
n! = e−x
2 −x2
4
√1 −x .
(c) Explain why the generating function computed in part (b) is dif-
ferent from the exponential generating function 
n≥0 n! xn
n! =
1
1−x
of the numbers of n-permutations, when permutations are in fact
also unions of disjoint cycles on the set [n].
(50) Let h(n) be the number of simple graphs G on vertex set [n] in which
no vertex has degree more than two. Find the exponential generating
function 
n≥0 h(n) xn
n! .
(51) Let z(n) be the number of simple graphs G on vertex set [n] in which
no connected component has more than three vertices. Find the ex-
ponential generating function 
n≥0 z(n) xn
n! .
(52) Let T be a tournament that is not strongly connected. Prove that
vertex set of T can be partitioned into two blocks A and B so that all
edges between A and B go from A to B.
(53) Generalize the results of Exercise 23 by stating and proving a theorem
which shows that if in a simple graph on n vertices, each vertex has
degree at least d, then the graph has at most k components. Here d
is to be replaced by a function of n and k only.
(54) An automorphism of a graph was deﬁned in Exercise 8. The automor-
phisms of G form a group, but that is not important for the purposes
of this exercise; we will discuss that in Chapter 18. We say that the
automorphism group of the graph G is transitive over G if for any
two vertices v and w of G, there exists an automorphism f of G so
that f(v) = w holds. Show two examples of a regular graph G whose
automorphism group is not transitive over G. At least one of your
examples should be a connected graph. Recall that a simple graph is
called regular if all its vertices have the same degree.
(55) Find a simple graph with exactly four automorphisms.
Solutions to Exercises
(1) Label the vertices of G by the integers 1, 2, · · · , |G| using each integer
once. Then orient the edges so that the arrow on the edge ij points to

226
A Walk Through Combinatorics
j if and only if i < j. This way, the labels increase along any directed
path, so no directed cycle can exist.
(2) No, that is not true. A triangle is a counterexample.
(3) The sum of all degrees of G is 56. Therefore, G has two vertices so that
the sum of their degrees is at least 12, by the pigeon-hole principle. Let
X and Y be these two vertices. They may be connected by an edge,
but even then, they are connected to ten other vertices. However, G
has only eight other vertices, so there must be at least two vertices,
C and D, that are connected to both A and B. Therefore, ACBD is
a cycle of length four.
(4) Yes, that is true. The sum of all degrees of a graph is always an even
number. Therefore, if this sum is at least 27, then it is at least 28,
and the statement follows by the pigeon-hole principle.
(5) There are
10
4

= 210 four-element vertex sets in G.
Denote by
a1, a2, · · · , a210 the number of edges in the subgraphs induced by each
of them. Then we have
a1 + a2 + · · · + a210
28
= 38
as the numerator of the left-hand side counts each edge 28 times.
Indeed, the edge xy is counted 28 times there, as there are
8
2

= 28
ways to add two vertices to xy, and obtain a four-element vertex set.
So a1+a2+· · ·+a210 = 28·38 = 1064. This implies, by the Pigeon-hole
Principle, that the largest of the ai must be at least 1064/210 = 5.07.
As the ai are all integers, this means that the largest ai is in fact at
least 6, which means that the corresponding induced subgraph is K4.
(6) Theorem 9.2 shows that G has a closed Eulerian trail W. Go through
C edge by edge, and color its ﬁrst edge orange, the second one blue,
the third one orange again, the fourth one blue again, and so on. As W
leaves a vertex right after entering it, the statement follows. Indeed,
each time W passes through a vertex, it contributes one orange edge
and one blue edge to that vertex. As W passes through each vertex
twice, the statement follows.
The only exception to this is the starting (and ending) vertex V . The
trail W passes through V only once, but it starts and ends in V , too.
To see that the starting and ending edges of W have diﬀerent colors,
we must prove that W, and therefore, G, has an even number of edges.
We know from the proof of Theorem 9.4 that in any loop-less graph,
e = 1
2
n
i=1 di. In our case, di = 4 for all i, therefore e = 1
24n = 2n,
which is indeed an even number. This completes the proof.

Dots and Lines. The Origins of Graph Theory
227
(7) There are
n
2

pairs of vertices in such a graph, and each of them
is connected by either 0 edges, or by 1 edge. Thus for each pair of
vertices, we have to make a choice of two possibilities. Therefore, the
total number of simple graphs on [n] is 2(n
2).
(8)(a) As any bijection from the vertex set of G onto itself is an automor-
phism, the answer is n!.
(b) Let us ﬁrst assume that n ≥3.
Let A and B be two adjacent
vertices of G, and let f be an automorphism of G. Then f(A) and
f(B) have to be adjacent vertices, and they completely determine
f. Indeed, if C is the other neighbor of B in G, then f(C) must be
the other neighbor of f(B) in G, and so on. If we choose f(A) ﬁrst,
then f(B), then we have n choices for f(A), and then 2 choices for
f(B). Therefore, we have 2n possibilities for f.
If n = 1, or n = 2, then there are only n automorphisms. (In these
cases, we are only free to choose the image of one vertex.)
(c) If E and F are the two endpoints of Pn, then an automorphism ei-
ther leaves them ﬁxed, or interchanges them. Indeed, these are the
only vertices of degree one in Pn, and any automorphism preserves
degree. Once we know f(E) and f(F), the rest of f is determined.
Therefore, Pn has two automorphisms.
(d) If C is the center (the only vertex of degree n −1) of Sn, then it is
clear that in any automorphism f of Sn, we must have f(A) = A.
There is no restriction on the other vertices; f can permute them
in any way. Thus Sn has (n −1)! automorphisms.
(9) As we saw in Exercise 7, the number of all simple graphs on [8] is
2(
8
2) = 228 = 268435456. On the other hand, the number of bijections
from [8] onto [8] is 8!. Therefore, any labeled graph on eight vertices
can be isomorphic to at most 8! = 40320 other graphs. It then follows
from the pigeon-hole principle that the number of isomorphism classes
must be at least 268435456/40320 = 6657.625.
(10) Yes, consider the graph whose vertices are all people currently living
on our planet, and two vertices are joined by an edge if and only if
the corresponding people are siblings.
(11)(a) No. A counterexample is shown in Figure 9.13.
(b) No.
A counterexample is a complete graph on 2n vertices, for
n ≥2.
(12) Let d be the common degree of the vertices of G, and let v be the
number of vertices of G. Then we have 44 = v · d. So v must be a

228
A Walk Through Combinatorics
Fig. 9.13
A graph with no Hamiltonian cycle.
divisor of 44, that is, it cannot be anything other than 1, 2, 4, 11,
22 or 44. As G is simple, it cannot have more edges than Kn, which
excludes the three smallest divisors of 44. If v = 22, then d = 2, and
this is indeed possible if G is a cycle of 22 vertices. If v = 11, then
we must have d = 4, and this is indeed possible. Simply take a cycle
on 11 vertices, then join each vertex to both of its second neighbors
by an edge. Finally, v = 44 is not possible, because that would mean
d = 1, so G would consist of vertex-disjoint edges, and thus it would
not be connected.
(13) No, that is not necessarily true. Figure 9.14 shows a regular graph
in which each vertex has three neighbors. However, vertices B, D, F
and H have four second neighbors, while vertices A, C, E, and G have
three.
(14) No, it does not. Call the ﬁve edges joining an outer vertex to an inner
vertex sticks. Then any Hamiltonian cycle would have to contain a
positive even number of sticks, that is, two or four of them. Two sticks
are impossible as then the Hamiltonian cycle would have to contain

Dots and Lines. The Origins of Graph Theory
229
A
B
C
D
E
H
G
F
Fig. 9.14
A regular graph.
four outer edges and four inner edges, that is, there would be a path of
length four between the two outer endpoints of the two sticks, and a
path of length four between their two inner endpoints. That is clearly
impossible. Four sticks are also impossible. Indeed, if AB is the only
stick that is not in our purported Hamiltonian cycle h, then both the
four non-stick edges adjacent to A and B must all be part of h. Indeed,
all vertices have degree two in h. If we continue reconstructing h using
this observation, we quickly run into a contradiction by obtaining a
cycle with less than ten vertices.
(15) It is not possible to omit edges so that the obtained graph has a
closed Eulerian trail. Indeed, for that, we would have to make all the
degrees even, which means two in this case. That, however, would
mean that our closed Eulerian trail is a Hamiltonian cycle, and the
previous exercise shows that the Petersen graph has no Hamiltonian
cycle.
(16) If G has n vertices, then G(Π) will have k ≤n parts, where k is the
number of vertices attached to at least one edge. On the other hand,
the largest part of G(Π) is at most k −1 as G is simple, so each vertex
can be connected to each other vertex at most once. So the number of
parts and the size of the largest part is not the same, therefore G(Π)
fails the ﬁrst test of self-conjugacy.

230
A Walk Through Combinatorics
(17) No, there is not. Let us assume that G is such a graph, and let S be
the set of vertices of G that have degree 4. Then S has three elements,
so there can be at most three edges that join two vertices of S. This
forces each vertex of S to be connected to at least two vertices of
G −S. That, however, would mean that there are at least six edges
between S and G −S, which is more than the sum of all degrees in
G −S. We reached a contradiction, so no such graph G can exist.
(18) Let us assume that G has degree sequence p = (4, 4, 3, 2, 1). Then G
has ﬁve vertices and seven edges. In particular, there are two vertices,
say A and B, that are connected to all other vertices. That, however,
would mean that all vertices have degree at least two as they are
connected to both A and B.
(19) Note that this graph is in fact the graph of a cube. Therefore, we will
talk about it as such. A cube has six faces. Once we know the image
of the vertices of one face by an automorphism f, we know the entire
automorphism. Indeed, assume that we know what f(A), f(B), f(C),
and f(D) are. Then these four vertices must form a face. Moreover,
f(E) must be the only unused vertex adjacent to f(A), f(F) must
be the only unused vertex adjacent to f(B), and so on. The question
is, therefore, how many diﬀerent possibilities are there for the images
f(A), f(B), f(C), and f(D). First count those automorphisms in
which the orientation of the cube does not change. In this case, there
are six faces into which the face ABCD can be mapped, and then
there are four ways the images f(A), f(B), f(C), and f(D) can be
rotated on each face. So there are 24 automorphisms that preserve
the orientation of the cube. After each of these, we can perform a
reﬂection through a plane that bisects the cube.
This provides 24
automorphisms that reverse the orientation of the cube. Therefore,
the graph of the cube has altogether 48 automorphisms.
(20) Note that this graph is in fact the graph of an octahedron. We can
get an octahedron by taking the center of each face of a cube (these
will be the vertices), and adding an edge between two vertices if the
corresponding cube-faces are adjacent. We can get a cube from an
octahedron the very same way.
This implies that there is a bijection between the automorphisms of a
cube and the automorphisms of an octahedron. The previous exercise
shows that the cube has 48 automorphisms, therefore the octahedron
also has 48 automorphisms.
(21) The ordered degree sequences of both graphs shown in Figure 9.15

Dots and Lines. The Origins of Graph Theory
231
are (3, 3, 2, 2, 2). However, they are not isomorphic. Indeed, if they
were, then any isomorphism f would have to map the set {A, B} of
vertices of the ﬁrst graph onto the set {A, B} of vertices of the second
graph. (Isomorphisms preserve degree, and these are the only vertices
of degree three in our graphs.) However, there is an edge between A
and B in the ﬁrst graph, but not in the second one, contradicting the
deﬁnition of isomorphism.
A
B
A
B
Fig. 9.15
Two non-isomorphic graphs with the same degree sequence.
(22) Let g(n) be the number of all simple graphs on [n], and let G(x) be
the exponential generating function of the sequence {g(n)}.
Then
g(n) = 2(
n
2), and therefore,
G(x) =

n≥0
2(
n
2) xn
n! .
Thus G(x) = 1+x+2x2+8x3 +64x4+1024x5+· · · . The exponential
formula (Chapter 8, Section 2) implies that
G(x) = eC(x),
C(x) = ln G(x).
Note that the power series ln G(x) is deﬁned using the identity
ln(1 + x) =

n≥1
(−1)n xn
n .
(23)(a) If G were not connected, there would be a connected component in
G with at most ﬁve vertices, but vertices in that component would
have degree at most four.
(b) Similarly to part (a), if each vertex has degree more than (n/2)−1,
then G is connected.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 10
Staying Connected. Trees
Being or not being connected is a crucial property of graphs, as any telecom-
munications company, airline, or railroad will tell you. It is certainly de-
sirable to be able to create a connected network with relatively few edges,
but we can intuitively feel that we will not be able to decrease the number
of edges too much. For example, one edge will certainly not suﬃce if the
graph has more than two vertices. In this chapter, we study minimally
connected graphs, which we will call trees.
10.1
Minimally Connected Graphs
Theorem 10.1. Let G be a connected simple graph on n vertices. Then
the following are equivalent.
(1) G is minimally connected, that is, if we remove any edge of G, then
the obtained graph G′ will not be connected.
(2) G does not contain a cycle.
Before proving the theorem, let us give a name to this extremely useful
class of graphs.
Deﬁnition 10.2. A connected simple graph G satisfying either, and there-
fore, both, criteria of Theorem 10.1 is called a tree.
Proof. (of Theorem 10.1)
(1)⇒(2) Let us assume that G is minimally connected, but it contains a cycle
C. Remove the edge ab of C. We claim that G is still connected.
Indeed, let x and y be two vertices in G.
As G is connected, G
contains a path p from x to y. If p does not contain the edge ab, then
233

234
A Walk Through Combinatorics
it still connects x and y. If p contains ab, then let us replace ab by
the other (longer) arc ab, to get a new walk from x to y. As there
is a walk from x to y in G′, there must also be a path, as we saw
in Exercise 29 of Chapter 9. Therefore, G′ is connected, which is a
contradiction.
(2)⇒(1) We prove that the opposite of (1) implies the opposite of (2). That
will suﬃce, because it will imply that if (2) holds, the opposite of (1)
cannot hold as that would imply the opposite of (2), therefore (1) has
to hold. So “(2) implies (1)” will follow.
Let us assume that G is not minimally connected. That means that
there is an edge in G, say AB, so that G′ = G−{AB} is still connected.
Then there is a path P from B to A in G′. However, AB ∪P must
then be a cycle in G as it deﬁnes a path that starts in A and ends in
A. So G contains a cycle.
Corollary 10.3. A connected graph H is a tree if and only if for each pair
of vertices (x, y), there is exactly one path joining x and y.
Proof. If for each pair of vertices (x, y), there is exactly one path joining x
and y, then H is minimally connected. Indeed, suppose you can omit edge
rs from H and get a connected graph. Then in the original graph H, there
are at least two paths from r to s, namely the edge rs, and the path that
joins them in the new graph.
Conversely, suppose H is a tree, but there are two paths P and Q joining
vertices x and y. Now take the symmetric diﬀerence of P and Q, that is,
the edges that are part of exactly one of P and Q. It is straightforward to
see (why?) that this symmetric diﬀerence will be a union of cycles, which
is impossible in a tree.
So trees are connected graphs that do not contain a cycle. An easy way
to obtain a tree on n vertices is to take a full (n-vertex) cycle on it, then to
delete one edge. This will be a tree with n −1 edges. We can experiment
for a while and draw trees of very diﬀerent structures, Some of these are
shown in Figure 10.1. After some time, we start suspecting that all trees on
n vertices have n −1 edges. The following theorem shows that even more
is true.
Theorem 10.4. All trees on n vertices have n −1 edges. Conversely, all
connected graphs on n vertices with exactly n −1 edges are trees.

Staying Connected. Trees
235
Fig. 10.1
Trees on six vertices.
In the proof of Theorem 10.4, we will need the following lemma.
Lemma 10.5. Let T be a tree on n vertices, where n ≥2. Then T has at
least two vertices whose degree is 1.
Proof. Take any path p of maximum length in T . The endpoints of p must
then be leaves. Indeed, if one of them, say a, were not a leaf, then p could
be extended by one of the edges that are adjacent to a but not currently
part of p.
Vertices of trees that have degree one are called leaves. Now we are
ready to prove Theorem 10.4.
Proof. (of Theorem 10.4) We use induction on n. If n = 1, the statement
is trivially true as a 1-vertex cycle-free graph has no edges. Let us assume
that the statement is true for trees on n vertices. Let T be a tree on n + 1
vertices. Find a leaf l in T (the previous lemma ensures the existence of
two leaves), then delete l and the only edge e adjacent to it from T , to
get a new tree T ′. (Note that T ′ is always a tree as it is connected and
cycle-free.) This new tree T ′ has n vertices, so by the induction hypothesis,
it has n −1 edges. But then T = T ′ ∪e has n edges, and the Theorem is
proved.
Just as in nature, a set of trees is called a forest. So a forest is a graph
in which each connected component is a tree. This hopefully explains the
cover page illustration of this book. Some of the following theorems might

236
A Walk Through Combinatorics
explain the wondering/lost facial expression of the person shown in that
picture as he is walking through the woods.
Proposition 10.6. Let F be a forest on n vertices with k connected com-
ponents. Then F has n −k edges.
Proof. By Theorem 10.4, the number of vertices exceeds that of edges by
one in each connected component, and the proof follows.
How many trees are there on n vertices?
After reading Section 9.3,
we know that there are at least two ways to interpret this question. One
is when the vertices are indistinguishable, and then the two trees shown
in Figure 10.2 are considered the same (we will return to this question in
Chapter 18), and the other is when the vertices are distinguishable. In this
case we can say that we are counting all trees with vertex set [n]. In this
case, the two trees in Figure 10.2 are considered diﬀerent.
1
2
3
4
5
6
6
5
4
3
1
2
Fig. 10.2
Two isomorphic trees.
Trying the ﬁrst few values of n, one sees that there is one tree on [1],
one tree on [2], there are three trees on [3], and 16 trees on [4]. After this,
we might ﬁnd enumerating all trees on [n] by hand cumbersome. These
scarce data suggest that there are nn−2 trees on [n], but the reader may
think that this was far too little data, and that it is very unlikely that
such an incredibly nice closed formula would exist for the number of things
as diverse as all trees on [n]. In most cases, the reader would be right to
make such an argument. The dreaded “Law of Small Numbers” says that
if you know just a few elements of a sequence, and those elements are small
numbers, then you can always ﬁnd a nice formula that is veriﬁed by those

Staying Connected. Trees
237
ﬁrst few elements, but is incorrect in general. This case, however, is an
exception.
Theorem 10.7 (Cayley’s formula). For any positive integer n, the
number of all trees with vertex set [n] is An = nn−2.
This beautiful result has received its fair share of attention and has at
least 16 known proofs. Many of them require additional knowledge. Here
we cover what may be the shortest proof on the books, and is due to Andr´e
Joyal. Several other proofs will be included in the Exercises, such as a
classic proof given by Heinz Pr¨ufer in 1918 (Exercise 6), and a spectacular
and recent proof, given by Jim Pitman in 1999 (Exercise 13).
While reading the proof, the reader is encouraged to study the example
immediately following it.
Proof. (of Theorem 10.7) Take all An trees on [n], and in each of them,
choose two vertices, which do not have to be diﬀerent, and call one of them
Start, and the other one End. Do this in all possible n2 ways for each tree.
Call the n2An objects obtained this way doubly rooted trees.
We are going to show that the number of doubly rooted trees on [n] is
nn by constructing a bijection from the set of all functions from [n] to [n]
to that of doubly rooted trees on [n]. This will prove our Theorem.
Let f be a function from [n] to [n]. Let C ⊆[n] be the subset of elements
x ∈[n] which are part of a cycle under the action of f, that is, for which
there is a positive integer i so that f i(x) = x. Let C = {c1 < c2 < · · · < ck}.
Now let di = f(ci), and write the integers d1, d2, · · · , dk in this order to the
nodes of a tree consisting of one line of k vertices. In other words, we write
down the elements of C in the order given by the permutation that is the
product of the cycles on C. Also, we mark d1 by Start, and dk by End.
Finally, if j ∈[n], but j /∈C, then join the vertex j to the vertex f(j)
by an edge. This way we always get a tree. Indeed, we get a connected
graph as the Start-End line is connected to all vertices, and we get a cycle-
free graph as the only cycles created by f involved vertices from C, and
C corresponds to a single line. The tree is doubly rooted, as the vertices
Start and End are marked.
To see that this is a bijection, take a doubly rooted tree on [n]. For
vertices j not on the Start-End line, deﬁne f(j) to be the ﬁrst neighbor of
j on the unique path from j to the Start-End line. For the vertices on the
Start-End line, deﬁne f so that the image of the ith smallest of them is the
one that is in the ith position from Start.

238
A Walk Through Combinatorics
This shows that there is exactly one function f : [n] →[n] corresponding
to each doubly rooted tree, and our theorem is proved.
Example 10.8. Let n = 8, and let f : [8] →[8] be the function deﬁned
by f(1) = 3, f(2) = 4, f(3) = 1, f(4) = 5, f(5) = 5, f(6) = 7, f(7) = 8,
f(8) = 6. Then the action of f is shown in Figure 10.3.
1
3
2
4
5
6
7
8
Fig. 10.3
The action of f.
The function f creates the cycles (13), (5), and (678). Therefore, C =
{1, 3, 5, 6, 7, 8}, and d1 = 3, d2 = 1, d3 = 5, d4 = 7, d5 = 8, and d6 = 6.
Therefore, our Start-End line will contain the integers 3, 1, 5, 7, 8, and 6,
in this order. As f(2) = 4, and f(4) = 5, we connect the vertex 2 to 4, and
the vertex 4 to 5. The obtained doubly rooted tree is shown in Figure 10.4.
3
6
8
7
2
4
5
1
Start
End
Fig. 10.4
The doubly rooted tree of f.
To the analogy of doubly rooted trees, we can deﬁne rooted trees, which
are trees with one vertex called the root. So the number of rooted trees on
[n] is nn−1. A rooted forest is a forest in which each component is a rooted
tree.

Staying Connected. Trees
239
Corollary 10.9. For all positive integers n, the number of rooted forests
on [n] is (n + 1)n−1.
Proof. Take a rooted forest on [n], and join all roots to the new vertex
n+ 1 by an edge. This transforms the original rooted forest to an unrooted
tree on [n + 1]. This map is a bijection: given a tree on [n + 1], we can
simply mark all neighbors of n + 1 as roots, then delete all edges adjacent
to n + 1, to get the original rooted forest on [n] back.
So the set of all rooted forests on [n] is in bijection with that of all trees
on [n+ 1], therefore they are equinumerous. Theorem 10.7 then shows that
each of them has (n + 1)n−1 elements.
There are several other structures that are in bijection with trees or
forests. See Exercises 7 and 8 for some examples.
Quick Check
(1) Let G be a connected simple graph with n vertices and n edges. Prove
that G contains exactly one cycle.
(2) Let n ≥9. How many trees are there on vertex set [n] in which at least
one vertex has degree n −3?
(3) How many trees are there on vertex set [n] that contain a given edge
ij?
10.2
Minimum-weight Spanning Trees.
Kruskal’s Greedy
Algorithm
Let us return to the applications of trees. If G is a connected graph, we
say that T is a spanning tree of G if G and T have the same vertex set, and
each edge of T is also an edge of G.
Clearly, any connected graph G will have at least one spanning tree.
Indeed, if G is a tree, then G is its own spanning tree; if not, then G is not
a minimally connected graph, so we can omit an edge from G so that we
get a connected graph G′. If G′ is still not a tree, then we can continue
this same procedure. We will only have to stop when we get a minimally
connected graph, that is, a tree.
In general, a connected graph will have many spanning trees. Theorem
10.7 shows for example that Kn has nn−2 spanning trees. Sometimes it can

240
A Walk Through Combinatorics
be quite diﬃcult to ﬁnd the number of all spanning trees of a connected
graph.
Spanning trees have a plethora of practical applications, especially in
graphs with weighted edges. A classic example is the following.
A railroad wants to expand into a 20-city area where presently they
have no lines. They thoroughly analyzed the relevant data, and for each
of the
20
2

= 190 pairs of cities they know the exact amount they would
have to spend to build a direct link between those two cities. The railroad
wants to build a connected network, that is every city should be reachable
from every city, but they want no redundant lines. How can the company
ﬁnd the cheapest possible network?
A graph theoretical description of this problem is the following.
Example 10.10. Let G be a connected simple graph. Let w : E(G) →R+
be a function. Find the spanning tree T of G so that 
e∈T w(e) is minimal.
The function w is usually called the weight function or cost function of
G, and w(e) is called the weight or cost of e, while 
e∈T w(e) is called the
weight of T . It is common practice to write the weights of the edges on the
edges, as shown in Figure 10.5. If G has only a few edges, then we might
try to ﬁnd its minimum-weight spanning tree by examining all spanning
trees. For only slightly larger graphs, however, this approach would take
too long. Indeed, if n = 20 and G = Kn as in the railroad example, then
we would have to compute the total weight of 2018 > 2.5 · 1023 spanning
trees. If our computer could handle one billion spanning trees per second,
it would still need 2.5 · 1014 seconds, or more than 91 years to do it!
3
2
1
6
8
2
4
2
1
3
5
Fig. 10.5
A graph and its weight function.
Therefore, the quest for a general method to ﬁnd the minimum weight

Staying Connected. Trees
241
spanning tree is undoubtedly well motivated. How would we start building
up such a tree T ? One can try the greedy way. That is, take the edge with
the smallest weight (or one of the edges with the smallest weight, if there
are several), and put it in T . Second, look for the edge that has the smallest
weight among those not in T , and add it to T . In the third step, and all
subsequent steps, we must be a little more careful. We have to make sure
that by adding the new edge, we will not create a cycle.
In general, in the ith step of this greedy algorithm we look for the edge
ei that has the following properties.
(i) The edge ei is not yet in T , and
(ii) if we add ei to T , the obtained graph does not contain a cycle, and
(iii) the weight of ei is minimal among all edges that have properties (i) and
(ii).
When we found this edge ei, we add it to T . It is clear that we can continue
this procedure until T has n −1 edges, as a graph on n vertices and less
than n −1 edges cannot be connected. However, G is connected, so if T
has less than n −2 edges, we can ﬁnd an edge of G that lies between two
connected components of T , and can therefore be added to T .
The alert reader could note that the graph T that we obtain this way
after i steps is not necessarily connected; all we know is that T is a cycle-
free graph, that is, a forest. However, if we continue this algorithm up to
step n −1, then T will be a forest with n −1 edges, that is, a tree.
Will the greedy algorithm give us the minimum weight spanning tree?
The answer to this question is not obvious. There are problems for which
the greedy algorithm does give the good answer, such as ﬁnding the three-
element subset with the largest sum in any ﬁnite set of integers. There are
also problems, however, for which the greedy algorithm does not give the
correct answer, because greedy steps at the beginning adversely inﬂuences
our choices later. An example for this is ﬁnding two vertex-disjoint edges
with minimum total weight in the graph shown in Figure 10.6.
Here the greedy algorithm results in a pair of disjoint edges with total
weight 11, though the correct answer is clearly 4. This problem, called the
minimum-weight matching problem is another very important problem. We
will learn about matchings in the next chapter.
For the task at hand, however, that is, for ﬁnding a minimum-weight
spanning tree, the greedy algorithm works. To prove this, we will need the
following interesting property of forests.

242
A Walk Through Combinatorics
1
2
2
10
Fig. 10.6
2 + 2 < 1 + 10.
Lemma 10.11. Let F and F ′ be two forests on the same vertex set V , and
let F have less edges than F ′. Then F ′ has an edge e that can be added to
F so that the obtained graph F ∪e is still a forest.
Proof. Let us assume that there is no such edge e ∈F ′. Then adding any
edge of F ′ to F would create a cycle in F. So all edges of F ′ are between
two vertices of the same component of F. Therefore, F ′ has at least as
many components as F. This is a contradiction, however, as we know that
a forest on n vertices and with k components has n −k edges, so if F ′ has
more edges than F, it must have less components.
Now we are in a position to prove the main result of this section.
Theorem 10.12. The greedy algorithm always ﬁnds the minimum-weight
spanning tree.
Proof. Again, we use an indirect argument. Assume the greedy algorithm
gives us the spanning tree T , whereas our graph G has a spanning tree
H whose total weight is less than that of T . Let h1, h2, · · · , hn−1 be the
edges of H so that w(h1) ≤w(h2) ≤· · · ≤w(hn−1) holds. Similarly, let

Staying Connected. Trees
243
t1, t2, · · · , tn−1 be the edges of T so that w(t1) ≤w(t2) ≤· · · ≤w(tn−1)
holds.
Let i be the step at which H ﬁrst “beats” T . That is, let i be the
smallest integer so that i
j=1 w(hj) < i
j=1 w(tj). Such an index i exist
as at the end of the entire selection procedure H beats T , so there has to
be a time H takes the lead. It is also clear that i > 1 as w(t1) is minimal
among all the edge-weights of G.
As i is the ﬁrst index at which H took the lead, the inequality w(hi) <
w(ti) must hold. Indeed, this is the only way
i

j=1
w(hj) <
i

j=1
w(tj)
and
i−1

j=1
w(hj) ≥
i−1

j=1
w(tj)
can both hold.
We will deduce a contradiction from this, that is, we will prove that with
w(hi) < w(ti) holding, the greedy algorithm could not possibly choose ti
at step i. Let Ti−1 be the forest the greedy algorithm produced in i −1
steps, that is, the union of the edges t1, t2, · · · , ti−1, and let Hi be the
forest formed by the edges h1, h2, · · · , hi. Applying Lemma 10.11 to Ti−1
and Hi, we see that there is an edge hj (for some j ≤i) that can be
added to Ti−1 without forming a cycle. However, our deﬁnitions show that
w(hj) ≤w(hi) < w(ti), so at step i, the greedy algorithm could not add ti
to Ti−1 as ti did not have minimum weight among the edges that could be
added to Ti−1 without forming a cycle.
This proves by contradiction that no spanning tree H can have a smaller
total weight than T , the tree obtained by the greedy algorithm.
We would like to point out that there are several ways to attack the
problem of ﬁnding a minimum-weight spanning tree with a greedy algo-
rithm. We could for instance insist on keeping the graph we are building
connected in each step. The particular algorithm we covered in this sec-
tion is called Kruskal’s algorithm, or the Kruskal algorithm, named after
his inventor, the American mathematician Joseph Kruskal.
Quick Check
(1) Let G be a connected simple graph. Let us say that we want to use
Kruskal’s algorithm to ﬁnd a spanning tree of G that does not contain

244
A Walk Through Combinatorics
a given edge e. Under what conditions can we achieve that and how
should we proceed?
(2) Answer the previous question assuming that we want to avoid several
edges e1, e2, · · · , ek of G.
(3) This question shows that the property of forests that was crucial in
proving that Kruskal’s algorithm ﬁnds the minimum cost spanning tree
can be found in other structures as well. Let B1 = {v1, v2, · · · , vk} and
B2 = {w1, w2, · · · , wk+1} be two linearly independent sets of vectors
from the same vector space U. Prove that there exists an index i ∈
[k + 1] so that the set B1 ∪wi of vectors is linearly independent.
10.3
Graphs and Matrices
There are several ways to associate a matrix to a graph. These matrices are
often useful for enumerating graphs. Perhaps the most widely used such
matrix is the adjacency matrix of a graph.
10.3.1
Adjacency Matrices of Graphs
Deﬁnition 10.13. Let G be an undirected graph on n labeled vertices,
and deﬁne an n × n matrix A = AG by setting Ai,j equal to the number of
edges between vertices i and j. Then A is called the adjacency matrix of
G.
Example 10.14. If G is the graph shown in Figure 10.7, then
AG =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0 1 1 1
1 0 0 1
1 0 0 0
1 1 0 0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
If G is directed, then we can deﬁne its adjacency matrix by setting Ai,j
equal to the number of edges from i to j. Thus the adjacency matrix of
a directed graph is not necessarily symmetric, while that of an undirected
graph is.

Staying Connected. Trees
245
A
B
C
D
Fig. 10.7
The graph whose adjacency matrix is AG.
Example 10.15. If H is the directed graph shown in Figure 10.8, then
AH =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0 1 1 0
0 0 0 1
0 0 0 0
1 0 0 0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
A
B
C
D
Fig. 10.8
The directed graph whose adjacency matrix is AH.
The adjacency matrix of a graph comprises almost all properties of that
graph. There are several situations when it is actually easier to solve an

246
A Walk Through Combinatorics
enumeration problem working with AG than working with G. A basic result
in that direction is the following.
Theorem 10.16. Let G be a graph on labeled vertices, let A be its adjacency
matrix, and let k be a positive integer. Then Ak
i,j is equal to the number of
walks from i to j that are of length k.
Proof. By induction on k. For k = 1, the statement is true as a walk of
length one is an edge. Now let us assume that the statement is true for k,
and prove it for k + 1. Let z be any vertex of G. If there are bi,z walks of
length k from i to z, and there are az,j walks of length one (in other words,
edges) from z to j, then there are bi,zaz,j walks of length k + 1 from i to j
whose next-to-last vertex is z. Therefore, the number of all walks of length
k + 1 from i to j is
c(i, j) =

z∈G
bi,zaz,j.
It follows from the induction hypothesis that the matrix B deﬁned by Bi,j =
bi,j fulﬁlls B = Ak. It is immediate from the deﬁnition of the adjacency
matrix A of G that Ai,j = ai,j.
Therefore, it follows from the deﬁnition of matrix multiplication that
c(i, j) = 
z∈G bi,zaz,j is in fact the (i, j)-entry of BA = Ak+1, (indeed, it
is the scalar product of the ith row of B and the jth column of A), and our
claim is proved.
The adjacency matrix of a graph provides a quick way of testing whether
the matrix has certain properties. We will discuss testing of connectivity
here.
Theorem 10.17. Let G be a simple graph on n vertices, and let A be the
adjacency matrix of G.
Then G is connected if and only if (I + A)n−1
consists of strictly positive entries.
Proof. We know from Exercise 29 of Chapter 9 that if there is a walk from
i to j in G, then there is a path, too. The length of a path in G is at most
n −1. Therefore, G is connected if and only if, for any pair of distinct
vertices i and j, there is a positive integer k ≤n −1 so that Ak
i,j > 0. As
(I + A)n−1 =
n−1

k=0
n −1
k

Ak,
the statement follows.

Staying Connected. Trees
247
Quick Check
(1) Let A be the adjacency matrix of the graph G. What parameter of G
do we obtain by adding all entries of A?
(2) Let A be the adjacency matrix of the simple graph G, and let us assume
that vertices v and w of G have the same set of neighbors. Prove that
det A = 0.
(3) Let A be the adjacency matrix of the simple graph G, and let S be a
subset of the vertices of G. Let N(S) be the set of all vertices of G that
have at least one neighbor (adjacent vertex) in S, and let us assume
that |S| > |N(S)|. Prove that det A = 0.
10.4
The Number of Spanning Trees of a Graph
The adjacency matrix of a graph, surprisingly, can be used to compute the
number of all spanning trees of that graph. To see this, we ﬁrst need to
extend our investigation to directed graphs. If G is a directed graph, then
we say that H is a spanning tree of G if H is a subgraph of G, and if we
remove the orientations of all edges, obtaining the undirected graphs G1
and H1, then H1 is a spanning tree of G1. We need one additional deﬁnition
before we can enumerate spanning trees.
Deﬁnition 10.18. Let G be a directed graph without loops.
Let
{v1, v2, · · · , vn} denote the vertices of G, and let {e1, e2, · · · , em} denote
the edges of G. Then the incidence matrix of G is the n × m matrix A
deﬁned by
• ai,j = 1 if vi is the starting vertex of ej,
• ai,j = −1 if vi is the ending vertex of ej, and
• ai,j = 0 otherwise.
Theorem 10.19. Let G be a directed graph without loops, and let A be
the incidence matrix of G. Remove any row from A, and let A0 be the
remaining matrix. Then the number of spanning trees of G is det A0AT
0 .
This is very surprising.
At ﬁrst sight, it is not even obvious why
det A0AT
0 will always be the same, no matter which row we remove, let
alone have such a nice combinatorial meaning.
Proof. Let us assume, without loss of generality, that it was the last row
of A that we removed. Let B be an (n −1) × (n −1) submatrix of A0. (If

248
A Walk Through Combinatorics
m < n −1, then G cannot be connected, and it has no spanning trees.) We
claim that | det B| = 1 if and only if the subgraph G′ corresponding to the
columns of B is a spanning tree, and det B = 0 otherwise.
We prove this claim by induction on n.
(a) Let us ﬁrst assume that there is a vertex vi (i ̸= n) of degree one in
G′. (The degree of a vertex in an undirected graph is the number of all
edges adjacent to that vertex.) Then the ith row of B contains exactly
one nonzero element, and that element is 1 or −1. Expanding det B by
this row, and using the induction hypothesis, the claim follows. Indeed,
G′ is a spanning tree of G if and only if G′ −vi is a spanning tree of
G −vi.
(b) Now let us assume that G′ has no vertices of degree one (except possibly
vn, the vertex associated to the deleted last row). Then G′ is not a
spanning tree. Moreover, as G′ has n −1 edges, and is not a spanning
tree, there must be a vertex in G′ that has degree zero. If this vertex
is not vn, then B has a zero row, and det B = 0. If this vertex is vn,
then each column of B contains one 1, and one −1 as each edge has a
head and a tail. Therefore, the sum of all rows of B is 0, so the rows
of B are linearly dependent, and det B = 0.
So we have proved that indeed, | det B| = 1 exactly if the subgraph G′ cor-
responding to the columns of B is a spanning tree, and det B = 0 otherwise.
Now we can ﬁnish the proof of Theorem 10.19.
The Binet–Cauchy
formula, that can be found in most Linear Algebra textbooks, says that
det A0AT
0 =

(det B)2,
where the sum ranges over all (n −1) × (n −1) submatrices B of A0.
However, we have just seen that (det B)2 = 1 if and only if B corresponds
to a spanning tree of A, and (det B)2 = 0 otherwise. Therefore, we have
proved Theorem 10.19.
You could have several remarks at this point. First, you could say, “fair
enough, but it could take a long time to compute det A0AT
0 , or even A0AT
0
for a given graph”. More generally, you could say, “what about undirected
graphs?” These concerns will be simultaneously alleviated by the following
theorem.
Theorem 10.20 (Matrix-Tree theorem). Let U be a simple undirected
graph. Let {v1, v2, · · · , vn} be the vertices of U. Deﬁne the (n−1)×(n−1)

Staying Connected. Trees
249
matrix L0 by
li,j =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
the degree of vi if i = j,
−1 if i ̸= j, and vi and vj are connected, and
0 otherwise,
where 1 ≤i, j ≤n −1. Then U has exactly det L0 spanning trees.
Note that while U has n vertices, L0 is an (n−1)×(n−1) matrix, since
it does not contain the row and column that would belong to vn. This
does not mean that L0 does not contain information about vn. Indeed,
if a vertex vi is connected to vn, then the edge between vi and vn counts
towards the degree of vi, hence towards the entry li,i. Therefore, if we are
given L0, we can ﬁnd out which vertices of U are adjacent to vn.
Proof. (of Theorem 10.20) First we turn U into a directed graph G by
replacing each edge of U by a pair of directed edges, one edge going in each
direction.
Let A0 be the incidence matrix of G with the last row removed. We
claim that A0AT
0 = 2L0. The entry of A0AT
0 in position (i, j) is the scalar
product of the ith and jth row of A0. If i = j, then every edge that starts
or ends at vi contributes 1 to this inner product. Therefore, the entry of
A0AT
0 in position (i, i) is the degree of vi in G, or, in other words, twice
the degree of vi in U.
If i ̸= j, then every edge that starts at vi and ends at vj, and every
edge that starts at vj and ends at vi contributes −1 to this inner product.
Recall that U is simple, so there is either no edge or one edge from vi to vj
in G. So the entry of A0AT
0 in position (i, j) is −2 if vivj is an edge of U,
and 0 otherwise. This proves that indeed, A0AT
0 = 2L0.
This implies that 2n−1 det L0 = det(A0AT
0 ). Note that each spanning
tree of U can be turned into 2n−1 diﬀerent spanning trees of G by orienting
its n−1 edges. Therefore, our statement immediately follows from Theorem
10.19.
Let us use our fresh knowledge for our classic example, the number of
all trees on [n].
Example 10.21. The number of spanning trees of Kn is nn−2.

250
A Walk Through Combinatorics
Solution. The matrix L0 associated to Kn will have the following simple
structure
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
n −1
−1
· · ·
−1
−1
n −1 · · ·
−1
· · ·
−1
−1
· · · n −1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
To compute the determinant of this matrix, add all rows to the ﬁrst, to
get
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1
1
· · ·
1
−1 n −1 · · ·
−1
· · ·
−1
−1
· · · n −1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
Now add the ﬁrst row to all other rows to get the upper triangular
matrix
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1 1 · · · 1
0 n · · · 0
· · ·
0 0 · · · n
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
This shows that det L0 = nn−2 as claimed.
Theorem 10.20 is a powerful tool. Let us use it to compute the number
of spanning trees of some interesting graphs.
Example 10.22. Let A be a set of m vertices, and let B be a set of n
vertices. Connect each vertex of A to each vertex of B by an edge. Denote
this graph by Km,n. Find the number of spanning trees of Km,n.
The graph Km,n is called a complete bipartite graph. We will learn more
about these graphs in the next chapter. For now, note that there is no edge
within A or within B in Km,n.

Staying Connected. Trees
251
Solution. (of Example 10.22) The matrix L0 associated to Km,n has the
following block structure
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
n · · ·
0 −1 · · · −1
· · ·
0 · · · n −1 · · · −1
−1 · · · −1 m · · ·
0
· · ·
−1 · · · −1 0 · · · m
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
that is, the ﬁrst m rows look “similar”, then the last n −1 rows look
“similar”. The same is true for columns.
To compute this determinant, use the same trick as in the proof of
Theorem 10.20. That is, add all rows to the ﬁrst one to get a row of the
form (1, 1, · · · 1, 0, · · · , 0), then add this row to each of the last n −1 rows,
to get
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1 · · · 1 0 · · ·
0
· · ·
0 · · · n −1 · · · −1
0 · · · 0 m · · ·
0
· · ·
0 · · · 0 0 · · · m
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
This shows that det L0 = nm−1mn−1.
Your sense of symmetry might be slightly disturbed by our disregarding
the vertex vn.
You may be thinking that in situations when our graph
has many vertices of diﬀerent degree, it may not be obvious which vertex
should be chosen for the role of vn. Of course, Theorem 10.20 is true with
any choice of vn, but the computation of det L0 may become more complex
if we do not make the right choice.
One way of getting around this problem is to use the following alterna-
tive form of the Matrix-tree theorem.
Theorem 10.23 (Matrix-Tree theorem, eigenvalue version). Let U
be a graph as in Theorem 10.20, and let L be deﬁned the same way as L0 in

252
A Walk Through Combinatorics
Theorem 10.20, except that let L be an n×n matrix. Denote λ1, λ2, · · · , λn
the eigenvalues of L, with λn = 0. Then the number of spanning trees of U
is
1
nλ1 · λ2 · · · · · λn−1.
Remarks. By now, you should be asking “how do we know that 0 is
always an eigenvalue of L?” The answer is that the rows of L sum to a
zero row, and therefore, they are linearly dependent. So det L = 0, which
implies that 0 is an eigenvalue of L. The matrix L is called the Laplacian
of U.
We do not prove Theorem 10.23 here. It can be proved from Theorem
10.20 by algebraic manipulations that do not involve additional combina-
torics.
In order to be able to use Theorem 10.23, we have to be able to ﬁnd the
eigenvalues of L. You may remember from your studies in Linear Algebra
that there is no universal method for this if L is larger than 4 × 4. For
nice graphs, however, that is, for graphs that have a lot of automorphisms,
we can ﬁnd these eigenvalues by some clever tricks, and then use Theorem
10.23 to compute the number of spanning trees of U. We will see examples
for this in the Exercises.
For now, let us discuss one particular situation. If U is a regular graph,
that is, all vertices of U have degree d, then we see that dI −A = L,
where A is the adjacency matrix of U.
Therefore, if α1, α2, · · · , αn are
the eigenvalues of A, then d −α1, d −α2, · · · , d −αn are the eigenvalues
of L. This means that to ﬁnd the eigenvalues of L, it suﬃces to ﬁnd the
eigenvalues of A.
Example 10.24. Let U = Kn.
Then the eigenvalues of the adjacency
matrix A of U are n −1, −1, −1, · · · −1, therefore the eigenvalues of L are
n, n, · · · , n, 0, showing again that Kn has nn−2 spanning trees.
Solution. Note that A + I = J, the matrix whose entries are all equal
to 1. This matrix is obviously of rank 1, therefore n −1 of its eigenvalues
are equal to 0. As the trace of J is n, and we know that the trace of any
matrix is equal to the sum of its eigenvalues, the remaining eigenvalue must
be n. However, A = J −I, so the eigenvalues of A are the eigenvalues of J
decreased by 1, and the statement is proved.

Staying Connected. Trees
253
Quick Check
(1) Theorem 10.20 was stated as a theorem for simple undirected graphs.
However, there is a way to slightly modify the deﬁnition of L0 in that
theorem so that the theorem holds for graphs that can contain loops
and multiple edges. What is that modiﬁed deﬁnition?
(2) Let G be a connected graph, and let A0 be the incidence matrix of G
with the last row omitted. Can it happen that det A0AT
0 = 0?
(3) Let G be a simple graph in which each vertex has degree d. What is
the largest eigenvalue of the adjacency matrix A of G?
Notes
A more general discussion of the Matrix-Tree theorem, as well as a sur-
vey of results connecting the number of spanning trees of a graph to the
number of certain Eulerian cycles can be found in Enumerative Combina-
torics, Volume 2, by Richard Stanley [52]. Additional proofs of Cayley’s
formula can be found in Combinatorial Problems and Exercises by L´aszl´o
Lov´asz [33], which is a comprehensive source of diﬃcult exercises in graph
theory anyway.
A recent survey of the enumeration of trees, written by Michael Dr-
mota, can be found in Chapter 4 of [12]. The textbook Random Trees: An
interplay between Combinatorics and Probability [22] by the same author
contains a lot of information, though, as its subtitle suggests, the reader
should take a course in probability before trying to read it.
Structures for which the greedy algorithm works are so important in
Combinatorics (and other ﬁelds) that they have their own name, and are
the subject of several books on their own. They are called matroids. The
reason for this name is that in some sense, matroids are generalizations of
matrices. The interested reader is encouraged to consult [43].
Exercises
(1) Let n ≥2 be an integer, and let a1 ≥a2 ≥· · · ≥an be a sequence of
positive integers satisfying a1 +a2 +· · ·+an = 2n−2. Prove that there
exists a tree T on n vertices so that the ordered degree sequence of T
is a1, a2, · · · , an.
(2) A complete k-ary tree is a rooted tree in which every vertex has either
k or 0 children. Let T be such a tree with m non-leaf vertices. How

254
A Walk Through Combinatorics
many leaves does T have?
(3) Let d be the highest degree of any vertex in a tree T , and let ℓbe the
number of leaves of T . What is the relation between d and ℓ? When
does d = ℓhold?
(4) Prove that for all n ≥3, the number tn of non-isomorphic trees on n
vertices is at least p(n −2).
(5) Prove that if n is suﬃciently large, then there exists a lower bound for
tn that is better than that of the previous exercise. Find such a lower
bound.
(6) Let T be a tree on [n], with n ≥3. Cut oﬀthe leaf of T that has the
smallest label, and write down the label of its single neighbor. Then
continue this same procedure on the remaining tree until there are only
two vertices (and one edge) left. This procedure results in a sequence
of elements of [n] that has length n −2, called the Pr¨ufer sequence, or
Pr¨ufer code of T , in honor of its inventor, the German mathematician
Heinz Pr¨ufer.
Prove that this algorithm deﬁnes a bijection from the set of all trees
on [n] onto that of sequences of length n −2 with elements from [n].
Deduce Theorem 10.7.
(7) A function f : [n] →[n] is called acyclic if there are no cycles longer
than one under its action on [n].
Prove that the number of acyclic
functions on n is (n + 1)n−1.
(8) There are n parking spots 1, 2, · · · , n on a one-way street.
Cars
1, 2, · · · , n arrive in this order. Each car i has a favorite parking spot
f(i). When a car arrives, it ﬁrst goes to its favorite spot. If the spot is
free, the car will take it, if not, it goes to the next spot. Again, if that
spot is free, the car will take it, if not, the car goes to the next spot. If
a car had to leave even the last spot and did not ﬁnd the space, then
its parking attempt has been unsuccessful.
If, at the end of this procedure, all cars have a parking spot, we say
that f is a parking function on [n]. Prove that the number of parking
functions on [n] is (n + 1)n−1.
(9) How many parking functions are there on [n] without like consecutive
elements? That is, we want to enumerate all parking functions on [n]
in which there is no i ∈[n] so that f(i) ̸= f(i + 1).
(10) Prove that if G is a simple graph on [n], then at least one of G and
its complement is connected. Show an example when they are both
connected. The complement ¯G of G has the same vertex set as G and
xy is an edge in ¯G if and only if it is not an edge in G.

Staying Connected. Trees
255
(11) How many edges can a simple graph G on [n] have if it is not connected?
(12) Let H be a simple graph on n vertices that has m edges. Prove that
H contains at least m −n + 1 cycles.
(13) Let F be a rooted forest on n vertices, and view F as a directed graph,
in which all edges are directed away from the root. If F ′ is another
rooted forest, then we say that F contains F ′ if F contains F ′ as a
directed graph. Clearly, in that case F has less components than F ′.
We say that F1, F2, · · · , Fk is a reﬁning sequence if, for all i ∈[k], Fi is
a rooted forest on [n] having i components, and Fi contains Fi+1. Now
ﬁx Fk.
(a) Find the number N ∗(Fk) of reﬁning sequences ending in Fk.
(b) Find the number N(Fk) of rooted trees containing Fk.
(c) Deduce Cayley’s formula.
This proof of Cayley’s formula is due to Jim Pitman.
(14) Find a formula for the number of rooted forests on [n] having k com-
ponents.
(15) Let S ⊆[n]. Generalize the method of Exercise 6 to ﬁnd a formula for
the number of rooted forests on [n] in which the set of roots is S.
(16) Let G be a simple undirected graph, and let A be the adjacency matrix
of G. Decide whether the following statements are true or false.
(a) A has only real eigenvalues.
(b) The sum of the eigenvalues of A is 0.
(c) The determinant of A is always positive.
(17) Let G be a simple directed graph, and let A(G) be the adjacency matrix
of G. Is it true that the eigenvalues of G are always real?
(18) Let G be a graph on n > 1 vertices having no isolated vertices, and let
A be the incidence matrix of G. Prove the following statements.
(a) For all i, we have (A4)i,i > 0.
(b) If both (A5)i,j and (A6)i,j are positive for some ﬁxed indices i < j,
then G contains a cycle of odd length.
(c) Let i < j be two ﬁxed indices. If (Ak)i,j = 0 for all k ≤n −1, then
(Ak)i,j = 0 for all k.
(19) Let G be the complete bipartite graph of Example 10.22, and let A be
the adjacency matrix of G. For any positive integer m, explain which
entries of Am have to be equal to 0.
(20) A complete tripartite graph is a simple graph deﬁned as follows. The
vertices are split into three subsets, A, B, and C, and there is an edge

256
A Walk Through Combinatorics
between two vertices if and only if they belong to diﬀerent subsets.
This graph is denoted K|A|,|B|,|C|. Find a formula for the number of
spanning trees of the complete tripartite graph Km,m,n.
(21)(a) Find the eigenvalues of the adjacency matrix A1 of the two-vertex
tree.
(b) Find the eigenvalues of the adjacency matrix A2 of the square (cycle
of four edges).
(c) Find the eigenvalues of the adjacency matrix A3 of the cube.
(d) Find the eigenvalues of the adjacency matrix An of the n-
dimensional cube. (The n-dimensional cube is obtained by taking
two copies of the (n −1)-dimensional cube, and then joining the
corresponding vertices.)
(22) Find the exponential generating function F(x) for the numbers fn of
forests on vertex set [n] having components of size at most three.
(23) Let G(x) be the exponential generating function for the numbers gn of
all rooted trees on vertex set [n]. Prove that G(x) = xeG(x).
Supplementary Exercises
(24) (-) Find a simple combinatorial proof showing that the number of
forests on vertex set [n] is at least the Bell number B(n).
(25) (-) Let us call a vertex v of the graph G a cut vertex if the removal
of v and the edges adjacent to it from G increases the number of
components of G. Prove that any graph with at least two vertices has
at least two vertices that are not cut vertices.
(26) (-) How many diﬀerent labeled trees are there on [n] that have no
vertices with degree more than 2?
(27) (-) How many non-isomorphic forests are there on vertex set [5]?
(28) (-) Prove that the number of non-isomorphic labeled forests on vertex
set [n] is at least p(n) (the number of partitions of the integer n).
(29) Prove that in any tree T , any two longest paths cross each other.
(30) Prove that in any tree T , all longest paths cross one another in one
vertex.
(31) Let T be a tree, and let P(T ) be the induced subgraph of T whose
vertices are the vertices of T that form the intersection of all longest
paths of T . What kind of graph can P(T ) be?
(32) A unicycle is a simple graph that contains exactly one cycle. Let un
be the number of unicycles on vertex set [n]. Find a formula for un.

Staying Connected. Trees
257
Your formula may contain one summation sign.
(33) The distance d(x, y) between two vertices x and y of the graph G is
deﬁned as the number of edges in the shortest path from x to y. For
every vertex v ∈G, let us deﬁne
td(v) =

w∈G
d(v, w).
In other words, td(v) measures the total distance of v from all vertices
of G. Now deﬁne the center of G as the set of vertices v for which td(v)
is minimal. Prove that if G is a tree, then the center of G consists of
either a vertex, or two adjacent vertices.
(34) Show an example for a tree on vertex set [n] that has more than 2n−1
induced subgraphs that are trees. Try to ﬁnd an example that works
for all n ≥2.
(35) Find the smallest tree that has at least one edge and has no non-trivial
automorphisms.
(36) Let a be any positive real number so that a < e. Prove that there
exists a natural number N so that if n > N, then there exist at least
an non-isomorphic trees on n vertices.
(37) How many non-isomorphic trees are there on seven vertices?
(38) Let T be a tree on 101 vertices so that the largest degree in T is ten.
Is it true that T contains a path of length ﬁve?
(39) Prove that a tree always has more leaves than vertices of degree at
least three.
(40) Find two non-isomorphic trees with the same ordered degree sequence.
(41) At most how many automorphisms can a tree with n vertices have?
(42) Prove that if n is large enough, then the following statement is true.
For all graphs G on n vertices, at least one of G and ¯G contains a
cycle. How large must n be for this to hold?
(43) Decide whether the following statements are true or false.
(a) If G is a connected simple graph and e is an edge of G, then there
is a spanning tree of G that contains e.
(b) If G is a connected simple graph and e and f are edges of G, then
there is a spanning tree of G that contains e and f.
(c) If G is a connected simple graph and e, f and g are edges of G,
then there is a spanning tree of G that contains e, f and g.
(d) If G is a connected simple graph and F is a cycle-free set of edges
in G, then there is a spanning tree of G that contains F.

258
A Walk Through Combinatorics
(44) Let G be a connected graph, and let T1 and T2 be two of its spanning
trees. Prove that T1 can be transformed into T2 through a sequence
of intermediate trees, each arising from the previous one and adding
another.
(45) (+) (Knowledge of linear algebra required.) Let T be a tournament
on n vertices. Prove that the adjacency matrix of T is either of rank
n or of rank n −1. Give an example for both.
(46) (++) (Knowledge of linear algebra required.) Prove that for any con-
nected undirected graph G, the number of diﬀerent eigenvalues of
A(G) is larger than the diameter of G. The diameter of G is given by
max
x,y∈Gd(x, y),
where d(x, y) is the distance between x and y as deﬁned in Exercise
33.
(47) Describe all trees that have n > 2 vertices and diameter 2.
(48) Let A be the graph obtained from Kn by deleting an edge. Find a
formula for the number of spanning trees of A.
(49) Let G be a regular graph, that is, let all vertices of G have degree d.
Express the eigenvalues of L(G) by the eigenvalues of A(G).
(50) Use the result of the previous exercise to ﬁnd the number of all span-
ning trees for each graph of Exercise 21.
(51) What is the number of forests on vertex set [n] in which each compo-
nent is of size at most two? What other combinatorial numbers are
counted by the same sequence of numbers?
Solutions to Exercises
(1) We use induction on n. For n = 2, the statement is trivially true.
Now let us assume the statement is true for n. Take the sequence
a1 ≥a2 ≥· · · ≥an+1 satisfying a1 + a2 + · · · + an+1 = 2n. The last
two elements, an and an+1 must be equal to one, otherwise the sum
of all the ai would be at least 2n + 1. So we have an+1 = 1. Delete
an+1. Let j be the largest index so that aj > 1. (There must be
such an index as long as n > 2, otherwise the sum of the ai is only
n + 1 < 2n.) Decrease aj by one. This way we obtain a new sequence
S which has only n elements, and sums to 2n −2.
Therefore, the induction hypothesis applies, so there is a tree T whose
ordered degree sequence is S. Now add a new leaf to T by joining

Staying Connected. Trees
259
it to the vertex corresponding to aj. This new tree T ′ will have the
desired ordered degree sequence.
(2) After trying a few speciﬁc trees, one can easily conjecture that T will
have (k −1)m + 1 leaves. This can be proved by induction on m as
follows. If m = 1, then T has k leaves, and the claim is true. Now
let us assume that the claim is true for m. Let T have m + 1 non-leaf
vertices. Pick a non-leaf vertex V that has k successors, and all of
them are leaves. (As T is ﬁnite, there is always such a vertex.) Omit
all the k successors of V , to get a new tree T ′. This new tree T ′ has
m non-leaf vertices (as V has just become a leaf), so by the induction
hypothesis, it must have (k −1)m + 1 leaves. Since T had k leaves
more than T ′, it is indeed true that T had km + 1 leaves, and the
proof is complete.
(3) We claim that ℓ≥d. Indeed, let V be a vertex of maximal degree d.
Then we can start walking at V , going in ℓdiﬀerent directions, until
we hit a leaf. All these leaves will be diﬀerent, implying that ℓ≥d.
On the other hand, ℓ= d will hold if each of our walks can end in only
one leaf, that is, if removing V , our tree falls apart to a collection of
paths. In other words, ℓ= d holds if and only if all vertices non-leaf
vertices other than V have degree 2.
(4) By Exercise 1, it suﬃces to show that there are p(n −2) ordered
degree sequences d1 ≥d2 ≥· · · ≥dn so that n
i=1 di = 2n −2, and
dn−1 = dn = 1. The number of these sequences is clearly the same as
that of the number of ordered sequences d1 ≥d2 ≥· · · ≥dn−2 whose
sum is 2n −4. Now let ci = di −1, then the positive numbers ci form
a partition of (2n −4) −(n −2) = n −2. Conversely, if (c1, c2, · · · , ck)
is a partition of n −2, then k ≤n −2.
Add zeros to the end of
(c1, c2, · · · , ck) if necessary to have n−2 entries, then add 1 to each of
them to get d1 ≥d2 ≥· · · ≥dn−2 back. This shows that the number
of valid ordered degree sequences is exactly p(n −2). As trees with
diﬀerent ordered degree sequences are non-isomorphic, the statement
follows.
(5) There are nn−2 labeled trees, and no isomorphism class can contain
more than n! of them. Therefore, the number of non-isomorphic trees
is at least nn−2/n!, which is larger than
en
n2 , if n is large enough.
Formula (3.1) shows that this is a much larger number than the p(n−2)
we got in the previous exercise.
(6) We show that for each such sequence S = {s1, s2, · · · , sn−2}, there
exists a unique tree T whose Pr¨ufer code is s. Take S, and note that

260
A Walk Through Combinatorics
the elements of [n] that do not occur in S must precisely be the leaves
of the purported tree T . Indeed, if j ∈S, then there was a leaf that
was cut oﬀfrom j, so j is not a leaf. If j is not a leaf, then there are
two possibilities. Either j is cut oﬀfrom the tree at some point, but
then at some point of time before that j had to be made a leaf, and
that was made by cutting oﬀone of the neighbors of j, and therefore,
by putting j into S. Or, j is one of the two vertices that are never
cut oﬀ. However, in this case, the degree of j in the ﬁnal, 2-element
tree is one, while its degree in the original tree T was at least two as
j was not a leaf. So again, at some point a vertex was cut oﬀfrom j,
putting j into S.
So S tells us what the leaves of the original tree were; denote them
by b1, b2, · · · , bk in increasing order. We know that ﬁrst we have cut
oﬀthe leaf with the smallest label (in what follows, the smallest leaf).
Therefore, we must start reconstructing the tree by joining b1 to a1,
as a1, by deﬁnition, is the single neighbor of the smallest leaf. We
must continue this way, but carefully. It could be that after cutting
oﬀb1 from T , the smallest leaf of the new tree T ′ was not b2 but a1,
that might have become a leaf after b1 was cut oﬀ. How do we know
whether a1 became a leaf after that ﬁrst step? If and only if it did,
it does not occur in S any additional times, as in that case nothing
else can be cut oﬀfrom it. So if the integer a1 occurs in S after the
ﬁrst position, then in the second step of our reconstruction, we join
min(a1, b2) to a2 by an edge. Otherwise, we simply join b2 to a2 by
an edge.
In general, in the ith step of recovering T , we have to ﬁnd the minimal
element bj that has not yet been assigned to any edge (then necessarily
j ≤i), and the minimal element ak that has not been assigned to any
edge yet, and does not occur in S anywhere after position ai−1. Then
we join min(ak, bj) to ai by an edge. This is the only thing we can do
as the ith step of the Pr¨ufer coding algorithm has cut oﬀthe smallest
leaf of the tree that remained after i −1 steps, and this is precisely
what we are reversing here.
So we have shown that for any S, the set of leaves of any tree with
Pr¨ufer sequence S is unique. Then we showed that there was a unique
sequence of edges that could lead to S, so there was a unique tree with
Pr¨ufer sequence S. So these two sets are in bijection. As the number of
Pr¨ufer sequences is clearly nn−2, we have reproved Cayley’s theorem.
(7) Take any acyclic function on [n], and for all i ∈[n], draw an arrow

Staying Connected. Trees
261
from i to f(i). This way we get a graph G whose edges are directed.
As f is acyclic, the connected components of G will be tree-like graphs
except that each of them will have a one-element cycle (loop) at one
of its vertices. Mark these vertices as roots, and delete all the loops,
and delete the arrows from the edges. Then G will become a rooted
forest on [n].
To see that this is a bijection, take a rooted forest on [n] and deﬁne f
by f(i) = i if i is a root and f(i) = j if j is the parent of i (the ﬁrst
vertex on the unique path from i to the root of its component).
So there are as many acyclic functions as rooted forests, and the state-
ment follows from Corollary 10.9.
(8) Let us assume that instead of a linear street, the cars arrive at a
circular street with n + 1 parking spots. The parking procedure is
the same, except that if a car leaves spot n + 1, it does not give up,
but goes to spot 1, and keeps trying. There are still n cars, but their
favorite spots can be anything from 1 to n + 1.
At the end of this procedure, all cars will always have a spot (as
nobody is ever forced to give up), and one spot will be left empty.
The crucial observation is that if that one spot is spot n+1, then that
spot has never been used in the procedure, (indeed, cars do not leave
a spot that they have already taken), so the procedure would have
worked without spot n + 1, that is, in the original linear street. So f
is a parking function on [n] if and only if n + 1 is the empty spot at
the end.
On the other hand, all spots have the same chance to remain empty
for symmetry reasons. Indeed, adding 1 to the parking preference of
each car shifts the empty spot by one. Therefore, spot n+1 will be left
empty in exactly 1/(n + 1) of all cases, that is in (n+1)n
n+1
= (n + 1)n−1
cases.
(9) Same argument as in Exercise 8, except that only the ﬁrst car can
have n + 1 parking preferences.
The other cars can have only n,
as they cannot have the same one as the previous car.
Therefore,
the number of parking functions without like consecutive elements is
(n+1)nn−1
n+1
= nn−1.
(10) Let us assume G is not connected. Let G1, G2, · · · , Gk be its con-
nected components. Then in the complement of G, all vertices of Gi
are connected to all vertices of Gj (if i ̸= j) by an edge. So in the
complement of G, any vertex is reachable from any vertex, either by a

262
A Walk Through Combinatorics
path of length one (if the two vertices are in two diﬀerent components
of G), or by a path of length two (if not, the path can go through any
vertex of a diﬀerent component).
For an example when both G and its complement are connected, take
a pentagon and its complement (which is another pentagon). For an
example on four vertices, take a tree that consists of a single path and
its complement.
(11) If a vertex of G has degree 0, then G is certainly not connected, even
if the remaining n −1 vertices form a complete subgraph. So G can
certainly have
n−1
2

edges without being connected.
We are going to show that this is the maximum number of edges that
will not cause G to be connected. In other words, we prove that if G
has
n−1
2

+ 1 edges, then G must be connected.
We proceed by induction on n. For n = 2, the statement is true. Now
let us assume that the statement is true for n, and prove it for n + 1.
Take a graph G on [n + 1] with
n
2

+ 1 edges. It is clear that G has
no isolated vertices, otherwise it could not have that many edges. If
G has a vertex of degree n, then we are done, since there is a path
of length at most two from every vertex to every vertex, through G.
Otherwise, take any vertex V , and remove it from G, together will all
edges adjacent to V . This leaves a graph G′ that has n vertices, and
at least
n−1
2

+ 1 edges, since at most n −1 edges were removed with
V . So the induction hypothesis applies to G′, and G′ is connected.
Therefore, G is connected since V is connected to at least one vertex
in G′.
(12) We prove the statement by induction on m, the number of edges. If
m ≤n −1, then the statement is trivial. Therefore, we can restrict
our attention to the case when m ≥n. Now assume that we know the
statement for m, and prove it for m + 1. Let H have m + 1 edges.
As m ≥n, there is at least one cycle C in H. Let e be an edge of
this cycle. Remove e, then the remaining graph H′ has m edges, and,
by the induction hypothesis, it contains at least m −n −1 cycles.
However, H contains C as well, therefore, H contains at least m −n
cycles.
(13)(a) Let us build the reﬁning sequence from Fk up. First, we need to
choose Fk−1 by adding one edge e to Fk. The starting vertex of
e can be any of our n vertices. The ending vertex of e, however,
must be the root of one of the components of Fk not containing e.
Therefore, we have n(k−1) choices for e, and thus we have n(k−1)

Staying Connected. Trees
263
choices for Fk−1. Repeating this argument, we have n(k−2) choices
for Fk−2 (for each choice of Fk−1), and so on. Therefore, repeating
this argument k −1 times, we get N ∗(Fk) = nk−1(k −1)!.
(b) If F1 is a rooted tree containing Fk, then F1 has k −1 more edges
than Fk. We can remove these k−1 edges in (k−1)! diﬀerent ways,
showing
N ∗(Fk) = (k −1)!N(Fk),
(10.1)
and comparing this to the result of part a, we see that N(Fk) =
nk−1.
(c) Choose k = n, then Fk is the empty forest (n isolated vertices), and
all rooted trees contain Fk. Then (10.1) shows that N(Fk) = nn−1,
so this is the number of all rooted trees on [n]. The number of
unrooted trees on [n] is therefore nn−2.
(14) Keeping the notation of the previous exercise, N ∗(Fn) = nn−1(n−1)!
as a special case of (10.1). Now let N ∗∗(Fk) be the number of those
reﬁning sequences F1, F2, · · · , Fn whose kth term is Fk.
There are
N ∗(Fk) choices for the part F1, F2, · · · , Fk of such a sequence, then
there are (n−k)! diﬀerent orders to remove the remaining n−k edges.
This shows that
N ∗∗(Fk) = N ∗(Fk)(n −k)! = nk−1(k −1)!(n −k)!,
using (10.1). This number does not depend on the choice of Fk. On
the other hand, each reﬁning sequence F1, F2, · · · , Fn contains ex-
actly one rooted forest of k components. Therefore, the number of
rooted forests on [n] with k components is the number of all reﬁning
sequences divided by the number of reﬁning sequences each of these
rooted forests with k components occur, that is,
nn−1(n −1)!
nk−1(k −1)!(n −k)! =
n
k

knn−1−k.
(15) Given a rooted forest with root set S, remove the leaf that has the
smallest label that is not a root, and write down the label of its unique
neighbor. Keep doing this until only the set of roots remain. If |S| = k,
then n −k vertices will be removed, leading to a sequence of length
n −k over [n]. The proof of the fact that this map is bijective is very
similar to the proof of bijectivity in the solution of Exercise 6. This
proves that the number of our forests is nn−k.
(16)(a) True as A is always symmetric.

264
A Walk Through Combinatorics
(b) True as the trace of A is always zero as G has no loops, and the
trace of a matrix is equal to the sum of its eigenvalues.
(c) False. For example, if G is the only tree on two vertices, then A
has determinant −1.
(17) No. A counterexample is the graph G on vertex set {u, v, w} whose
edges are (u, v), (v, w), and (w, u).
(18)(a) As there are no isolated vertices, each vertex is adjacent to at least
one edge. Therefore, there is a walk of length four from i to i as
we can walk back and forth twice on any edge adjacent to i.
(b) Let W and W ′ be two walks from i to j that are of length 5, resp. 6.
Then the symmetric diﬀerence of W and W ′ (that is, the edges that
are contained in exactly one of W and W ′) is a set of cycles, that
have altogether an odd number of edges. Indeed, they altogether
have 11 −2e edges, where e = |W ∩W ′|. Therefore, one of these
cycles must consist of an odd number of edges.
(c) The claim says that if there is a walk from i to j, then there is also
a walk from i to j that is of length at most n −1. This is true as
we know from Exercise 29 of Chapter 9 that if there is a walk from
i to j, then there is a path from i to j, and that has at most n −1
edges in it.
(19) The answer depends on the parity of m. Note that there is no walk
of even length from A to B or vice versa, and there is no walk of odd
length that starts in A and ends in A, or starts in B and ends in B.
(20) We will use the eigenvalue version of the Matrix-Tree theorem. The
Laplacian L of this graph has an obvious block structure, the diagonal
blocks being (m + n)Im, (m + n)Im, and 2mIn, and the other blocks
consisting of −1s only. This means that L −(m + n)I2m+n has a set
of m rows that are equal, and another set of m rows that are equal.
Therefore, its rank is at most 2m+n−(2m−2), and so it has at least
2m−2 eigenvalues equal to zero. Similarly, L−2mIn has n equal rows,
and therefore, n −1 eigenvalues equal to zero. Thus L has 2m −2
eigenvalues equal to m + n, and n −1 eigenvalues equal to 2m. One
eigenvalue of L is certainly 0, so we are still missing two eigenvalues.
Note that the vector (1, 1, · · · , 1, −1, −1, · · · , −1, 0, 0, · · · , 0), consist-
ing of m entries equal to 1, then m entries equal to −1, then n entries
equal to 0, is an eigenvector of L −(m + n)I2m+n with eigenvalue m.
Thus 2m + n is an eigenvalue of L. Therefore, the last eigenvalue of
L must also be 2m + n, to fulﬁll the trace condition.

Staying Connected. Trees
265
This yields that the number of all spanning trees is
(m + n)2m−2 · (2m)n−1 · (2m + n)2
2m + n
= (m + n)2m−2 · (2m)n−1 · (2m + n).
(21)(a) We know that A1 =
⎛
⎝0 1
1 0
⎞
⎠. Therefore, it follows from elementary
linear algebra that the eigenvalues are λ1 = 1, and λ2 = −1. The
corresponding eigenvectors are v1 =
⎛
⎝1
1
⎞
⎠, and v2 =
⎛
⎝1
−1
⎞
⎠.
Note that multiplying a vector x by A simply interchanges the
coordinates of x.
(b) We know that A2 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0 1 0 1
1 0 1 0
0 1 0 1
1 0 1 0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
Note that this is in fact four
copies of A1, arranged in a block. As the square is a regular graph
in which each vertex is of degree 2, we have λ1 = 2. As A2 has only
two linearly independent rows, the rank of A2 is 2, and therefore
we have λ2 = 0, and λ3 = 0. As the trace of A2 is 0, it follows that
λ4 = −2. Knowing all this, it is a routine linear algebra exercise
to ﬁnd the eigenvectors.
They are v1 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1
1
1
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
, v2 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1
0
−1
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
v3 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
1
0
−1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
, and v4 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1
−1
1
−1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
. Note the similarities between
this answer and that of part (a)
(c) and (d) We answer part (d)ﬁrst. Let Qn be the n-dimensional cube. The
adjacency matrix An of Qn can be obtained by putting two copies

266
A Walk Through Combinatorics
of A2n−1 in the diagonal, and two identity matrices of size 2n−1 in
the remaining two corners. In other words, An is obtained from A1
by replacing the diagonal elements by An−1, and replacing the 1’s
by copies of I2n−1. Thus the characteristic polynomial of An arises
from that of A1 by replacing the −1s by −I2n−1, and replacing the
λ’s by λI −An−1.
A little computation then yields that the characteristic polynomial
of An is
2

i=1
2n−1

j=1
(λ −λi −μj),
where the λ’s are the eigenvalues of A1 and the μ’s are those of
A2n−1. So the eigenvalues of An are the sums of these.
The eigenvalues of A1 are +1 and −1. To get those of An, you
can use induction, or you can note that Qn can be obtained by
multiplying Q1 by itself n times. So the eigenvalues of An are all the
numbers that can be obtained by choosing one of +1 and −1 from
each component, then adding them. Therefore, the eigenvalues are
n, n −2, n −4, · · · , −n, and the multiplicity of n −2k is
n
k

. So for
A3, we get 3, 1, 1, 1, −1, −1, −1, −3.
(22) There is one tree on one labeled vertex. There is one tree on two
labeled vertices. There are three trees on three labeled vertices. Now
any forest in which the connected components have size at most three
partitions our set [n] into three subsets in a natural way: for each
i ∈[3], vertices that are part of a component of size i will be in the
same block. Let Ei(x) be the exponential generating function for the
number of graphs that are possible on the ith block, that is, that have
components of size exactly i only.
It is easy to ﬁnd the generating function Ei(x) by the exponential
formula. Indeed, Ei(x) counts forests in which each component has
size exactly i. That is, we ﬁrst partition our set into blocks, then put
one of fi(j) diﬀerent structures on each block, where fi(j) = 0 if j ̸= i.
If i = j, then fi(j) equals the number of trees on i vertices, that is,
1,1, and 3, respectively. Then it follows by the exponential formula
that Ei(x) = exp Efi(x). Finally, by the product formula,
F(x) =
3

i=1
Ei(x) = exp

x + x2
2 + x3
2

.

Staying Connected. Trees
267
(23) If we cut oﬀthe root r of a rooted tree, we get two diﬀerent structures,
one of which is the root itself, and the other is a rooted forest, in
which the vertices that were adjacent to r became the roots of their
respective components.
Therefore, to get a rooted tree on n, we ﬁrst split n into two parts.
One part will have only one vertex r, and that will be the root of the
tree; the other part will have n −1 vertices, and will be the vertex
set of a rooted forest. These two parts completely determine a rooted
tree as the root of each tree in the forest is to be connected to r. The
exponential generating function of the ﬁrst part is obviously x, and
that of the second part is eG(x) by the exponential formula. Therefore,
the product formula implies G(x) = xeG(x).

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 11
Finding A Good Match. Coloring and
Matching
11.1
Introduction
A cellular phone company provides service on three diﬀerent frequencies.
They expand into a new area, and they plan to build ten communication
towers there, at locations already selected. Each tower will broadcast sig-
nals on one frequency only. The company has to make sure that the distance
between any two towers broadcasting on the same frequency is more than
50 miles. Let us decide (knowing the exact locations of the towers) if this is
possible, in other words, whether a proper assignment of frequencies exist.
How can we translate this problem into the language of combina-
torics? The reader probably conjectures that we will somehow ﬁnd a graph-
theoretical representation for this problem, otherwise we would not have
brought it up in this chapter. The natural candidates for the vertices of
the graph G representing a given set of towers are the towers themselves.
And when should two vertices be connected by an edge? There are only
two kinds of pairs of towers for the purposes of this problem: those whose
distance from each other is at most 50 miles (such pairs of towers cannot
broadcast on the same frequency), and those whose distance from each
other is more than 50 miles (such pairs of towers can do so). Therefore, it
is plausible to deﬁne the edge set of G by requiring that there be an edge
between A and B if and only if the distance between the corresponding two
towers is at most 50 miles.
Fine, you could say, we ﬁgured out how to express all relevant informa-
tion about the distances between our towers by a graph G. However, does
this help us decide whether the frequencies can be assigned to the towers in
a proper way? After all, G does not contain any information about diﬀerent
frequencies, not even their number.
269

270
A Walk Through Combinatorics
This is a valid concern. So that we could incorporate more information
into G, we will color its vertices. If frequency 1 gets assigned to a tower,
we will color the corresponding vertex red, if frequency 2 gets assigned
to a tower, we will color the corresponding vertex blue, if frequency 3 gets
assigned to a tower, we will color the corresponding vertex green, and ﬁnally
if frequency 4 gets assigned to a tower, we will color the corresponding
vertex yellow.
Now the following Proposition is a direct consequence of the deﬁnition
of our graph G.
Proposition 11.1. Let C be any set of ten towers, and let G be the graph
deﬁned by C as described above. Then one can assign the four frequencies
to the ten towers of C if and only if it is possible to color the vertices of G
with four colors so that there are no two monochromatic vertices that are
adjacent.
The following deﬁnition provides a simple way to describe how diﬃ-
cult it is to color the vertices of a given graph without creating adjacent
monochromatic pairs.
Deﬁnition 11.2. The chromatic number of a graph H, denoted by χ(H),
is the smallest integer k for which the vertices of H can be colored by k
colors so that adjacent vertices are colored by diﬀerent colors.
A coloring of the vertices of a graph in which adjacent vertices are of
diﬀerent color is called a proper vertex coloring, or just a proper coloring.
If the vertices of a graph can be colored by k colors so that there are no
adjacent monochromatic vertices, then that graph is called k-colorable.
Example 11.3. The chromatic number of the pentagon is three. Indeed,
two colors do not suﬃce, while three colors do as shown in Figure 11.1.
In the remainder of this section and the next, we will assume that all
graphs are connected.
This will not result in any loss of generality as
colorings of diﬀerent connected components of an unconnected graph are
certainly independent from each other. Similarly, we can assume that our
graphs are simple, as adding one or more new edges between the same
pair of adjacent vertices does not impose any new restriction on those two
vertices (they could not be the same color anyway).

Finding A Good Match. Coloring and Matching
271
Red
Red
Blue
Blue
Green
Fig. 11.1
The pentagon is 3-colorable.
Quick Check
(1) How many colors do we need to color the vertices of a cube so that
adjacent vertices are of diﬀerent color?
(2) Show an example for two simple graphs G and H that are not iso-
morphic, but for which it is true that for any positive integers n, the
graphs G and H have the same number of proper colorings using colors
from [n].
(3) Let G and H be as in the previous question. Show that then G and
H must have the same number of vertices.
11.2
Bipartite Graphs
The most important special case of k-colorable graphs is when k = 2. This
case is so omnipresent in combinatorics that it has its own name.
Deﬁnition 11.4. A 2-colorable graph is called bipartite. Equivalently, G
is bipartite if the vertex set of G can be split into the disjoint sets A and
B (the color classes) so that each edge of G is adjacent to one vertex of A
and one vertex of B.
A generic example of a bipartite graph is shown in Figure 11.2. Note
that there are no edges within either color class.
For example, all trees are bipartite as one can start at any given vertex,
color it red, then color all its neighbors blue, then color all the second

272
A Walk Through Combinatorics
B
A
Fig. 11.2
A generic bipartite graph.
neighbors red, and so on.
This coloring algorithm works as there is no
cycle in the tree, so we will never get back to a vertex that has already been
colored. Another example of a bipartite graph is, say, a square, hexagon,
or octogon, where we can color vertices alternatingly.
An easy example of a graph that is not bipartite is a triangle. Indeed,
if a triangle has a red vertex A, then one of the two neighbors of A can be
colored blue, but the third vertex of the triangle cannot be properly colored.
It is also clear that no graph that contains a triangle can be bipartite (as
not even that triangle could be 2-colored, let alone the whole graph).
Is it true that if a graph does not contain a triangle, then it is bipartite?
As we can see in Figure 11.1, this is not true as the pentagon provides
a counterexample. There is nothing magic about the pentagon here, the
reader can easily see that no cycle of odd length can be 2-colored, and
therefore no graph containing an odd cycle can be 2-colored.
The following theorem shows that the above discussion completely char-
acterizes bipartite graphs.
Theorem 11.5. A graph G is bipartite if and only if it does not contain a
cycle of an odd length.
Proof. As we have mentioned, the “only if” part is easy. Let us assume
that G contains the odd cycle A1A2 · · · A2m+1. Let us assume without loss
of generality that A1 is red. Then A2 must be blue, therefore A3 must be
red, A4 must be blue, and so on, and at the end, A2m+1 must be red, too.

Finding A Good Match. Coloring and Matching
273
This is not allowed, however, as A1A2m+1 is an edge.
To prove the “if” part, let G be a graph with no odd cycles. Let V be
a vertex of G, and color V red. Deﬁne the color of any other vertex W
as follows. If the shortest path from V to W has even length, then let W
be red, and if the shortest path from V to W has odd length, then let W
be blue. We show that this is a good coloring, that is, there are no two
adjacent vertices that are the same color.
Let us assume the contrary, by ﬁrst assuming that P and Q are two red
vertices that are joined by an edge. Let the shortest path from V to P be
p, and let the shortest path from V to Q be q. Then p and q both have
an even number of edges, so walking from V through p to P, then through
PQ, then back from Q through q to V , we get a closed walk C with an odd
number of edges. Taking away edges that were used both by p and q, this
walk C splits into the union of edge-disjoint cycles. As the total number of
edges in these cycles is still odd, there has to be at least one cycle with an
odd number of edges, which is a contradiction.
If we assumed instead that both P and Q were blue, the same proof
would work as the sum of two odd numbers is still even, so C would still
have an odd number of edges.
How many edges can a simple bipartite graph G on n vertices have? The
alert reader should have an intuition at this point that the answer to this
question will be some kind of an upper bound. Indeed, it is not diﬃcult to
create bipartite graphs with few edges. For example, forests have no cycles
at all, so they cannot have odd cycles either. Thus all forests are bipartite.
We could think, however, that if we keep adding new edges, without adding
new vertices, then sooner or later an odd cycle will be formed. In fact, the
complete graph Kn certainly has an odd cycle if n ≥3.
So where is the threshold? How many edges can we have in G without
having an odd cycle? The forests only allow us to go to n −1 edges. Will
the ﬁnal answer be some linear function of n, or maybe around nα, where
1 ≤α < 2, or will it be just a constant factor below
n
2

, the number of
edges in the complete graph? The following theorem shows that the answer
to this question is closer to the maximum.
Theorem 11.6. Let G be a simple bipartite graph on n vertices. Then G
has at most n2/4 edges if n is even, and at most (n2 −1)/4 edges, if n is
odd.
Proof. Choose G so that no other simple bipartite graph on n vertices has

274
A Walk Through Combinatorics
more edges than G. Denote by a and b the sizes of the two color classes
of G. It is clear that each vertex of one color class is connected to each
vertex of the other color class in G. Indeed, if there was a missing edge
between the two color classes, we could add it to G, contradicting to our
assumption. So G has ab = a(n −a) edges, and the proof follows from
elementary calculus.
(One simply has to ﬁnd the integer a ∈[1, n] for
which the number f(a) = a(n −a) is maximal.)
The class of bipartite graphs we used in this proof, that is, bipartite
graphs in which each vertex of one color class is connected to each vertex
of the other color class, is an important one, therefore, such graphs have a
name. They will be called complete bipartite graphs. These graphs played
a role in several exercises of earlier chapters. If a complete bipartite graph
has color classes of size a and b, then we will denote that graph by Ka,b.
So bipartite graphs can have a lot more edges than trees. We will see
that accordingly, they have a much richer structure, too. To start, let us
take a closer look at the consequences of Theorem 11.6. Let H be a simple
graph on 2m vertices. If H has only m2 edges, then H can be bipartite;
indeed, H can be Km,m. If H has more than m2 edges, then Theorem 11.6
implies that H is not bipartite, in other words, H has an odd cycle. The
following Lemma shows that more is true.
Lemma 11.7. Let H be a simple graph on 2m vertices (m ≥2) and at
least m2 + 1 edges. Then H contains a triangle.
Proof. We prove our statement by induction on m. If m = 2, then H is a
subgraph of K4 with at least ﬁve edges. Theorem 11.6 shows that H is not
bipartite, so it must have an odd cycle. This odd cycle must be a triangle
as H has only four vertices.
Now assume we know that the statement is true for all integers that are
smaller than m, and are at least 2. Let H be as in the statement of the
Theorem, and let F and G be two adjacent vertices in H. If the sum of the
degrees of F and G is more than 2m, then they have a common neighbor
T , and so FGT is a triangle. If, on the other hand, the sum of the degrees
of F and G is at most 2m, then deleting F, G, and all the edges adjacent
to them from H will decrease the number of edges in our graph by at most
2m −1. (Note that the edge FG is contained twice in the sum of the two
degrees.) Therefore, after the deletion of these vertices and edges, we are
left with a graph of 2m −2 vertices, and at least m2 + 1 −(2m −1) =
m2 −2m + 2 = (m −1)2 + 1 edges. Such a graph contains a triangle by the

Finding A Good Match. Coloring and Matching
275
induction hypothesis, so our claim is proved.
Thus we know that graph on 2m vertices with just one more edge than
what is possible in bipartite graphs does not simply have an odd cycle,
but also has a triangle, the shortest odd cycle possible. The real surprise,
however, comes now.
Theorem 11.8. Let H be a simple graph on 2m vertices (m ≥2) and at
least m2 + 1 edges. Then H contains at least m triangles.
So if H has m2 edges, it may not have any odd cycles at all, but with
only one more edge, H must have at least m triangles! Note that there is
nothing similar that would be true for trees on m vertices. A connected
graph on m vertices and m−1 edges is a tree. Adding an extra edge we get
a cycle (in fact, exactly one cycle), but that cycle can be of many diﬀerent
lengths depending on the tree.
Proof. Clearly, we can assume that H has exactly m2 + 1 edges as addi-
tional edges will not destroy any triangles.
We prove our statement by induction on m. If m = 2, then our graph
has four vertices and ﬁve edges, so it is K4 with an edge missing, and
therefore does contain two triangles.
Now let us assume that the statement is true for all positive integers
smaller than m, but at least 2. Let H be as in the statement of the theorem.
Lemma 11.7 shows that H contains at least one triangle ABC. We have to
ﬁnd m −1 other triangles.
We will distinguish three cases based on the number of edges connecting
outside vertices to the vertices of the triangle ABC. We claim that if the
number of all these edges is 2m −3 + x for some x ≥1, then there are x
triangles formed by two vertices of the triangle ABC, and a third vertex
that comes from outside that triangle. Indeed, if such an outside vertex is
connected to two vertices of ABC, then it forms a triangle with them. As
there are 2m−3 outside vertices, our claim follows by pigeon-hole principle.
The outline of the proof will be this. If there are many edges between
ABC and the outside vertices, then there are many triangles spanned by
two vertices of ABC and an outside vertex. If, on the other hand, there are
only a few such edges, then there have to be so many edges among outside
vertices that we can apply the induction hypothesis for their subgraph (and
an extra vertex).
(1) If x ≥m−1, then we are done as we found our missing m−1 triangles.

276
A Walk Through Combinatorics
(2) If 1 ≤x < m −1, then the total number of edges between ABC
and the outside vertices is at most (2m −3) + (m −2) = 3m −5.
As ABC itself contains three edges, it follows that there are at least
m2 + 1 −(3m −5) −3 = m2 −3m + 3 = (m −1)(m −2) + 1 edges
within the subgraph R spanned by all 2m −3 outside vertices. If we
omit the vertex of R which has the smallest degree in R, it follows by
the Pigeon-hole Principle that we get a graph R′ on 2m −4 vertices
that still has more than
(m −1)(m −2) · 2m −4
2m −3 = (m −2)2 · 2m −2
2m −3 > (m −2)2
edges. So R′ has strictly more than (m −2)2 edges, that is, it has at
least (m −2)2 + 1 of them. Therefore, by the induction hypothesis,
there are at least m −2 triangles within R′. As we said in the previous
paragraph, there are x triangles spanned by two vertices of ABC and
an outside vertex. In our case, x ≥1, so we have again found the m−1
needed triangles.
(3) Finally, consider the case when the number of edges connecting outside
vertices to ABC is not more than 2m −3. Note that we can assume
that there is at least one such edge, otherwise R has m2 −2 edges, so
adding any vertex of ABC to R creates a graph on 2m −2 vertices
and m2 −2 ≥(m −1)2 + 1 vertices, and the proof follows by the
induction hypothesis. That said, the number of edges within R is at
least m2 + 1 −(2m −3) −3 = (m −1)2. Adding a vertex of ABC
that is adjacent to at least one outside vertex to R creates a graph
with 2m −2 vertices and at least (m −1)2 + 1 edges, and again, the
induction hypothesis shows that such a graph must contain at least
m −1 triangles.
In other words, if we start with the empty graph on 2m vertices, and
keep adding edges to it at random, then as soon as we can be sure (without
looking) that our graph has one triangle, we can also be sure that it has m
triangles!
Quick Check
(1) Show an example for a graph G that is not bipartite that has exactly
one edge e such that removing e from G we obtain a bipartite graph.

Finding A Good Match. Coloring and Matching
277
(2) Let A be the adjacency matrix of a simple bipartite graph. What can
we say about the diagonal entries of Ak, where k is an odd positive
integer?
(3) Let G be a bipartite graph such that there is more than one way to
partition the vertex set of G into two blocks so that there is no edge in
each block. What does that reveal about G?
11.3
Matchings in Bipartite Graphs
Bipartite graphs abound in real life. Consider for example m job openings
and n applicants for these jobs.
Deﬁne the graph G on m + n vertices
as follows. The ﬁrst m vertices correspond to the jobs, and the second
n vertices correspond to the applicants, and two vertices are connected
by an edge if and only if the corresponding applicant is qualiﬁed for the
corresponding job. Then G is certainly bipartite as edges are only possible
between the sets of the ﬁrst m and last n vertices, not within these sets.
Figure 11.3 shows an example for such a graph.
JOBS
APPLICANTS
Fig. 11.3
Try to ﬁll all jobs with qualiﬁed applicants.
We have to ﬁll each job opening by hiring exactly one qualiﬁed person
for that opening. How can we translate this problem to the language of
graph theory? Just as in Section 11.1, we will reﬁne our existing model
so that it can encode more information. If we ﬁll a given opening A by
hiring applicant a, then we will represent this by changing the edge aA of
G to a bold edge. Then, if we ﬁll another opening B by hiring the qualiﬁed
candidate B, then we will represent this by changing the edge bB to a bold
edge, and so on. As the hiring procedure goes ahead, we will have more
and more bold edges. The crucial property of the set of bold edges is that
at any point of time throughout the hiring process it will always consist of

278
A Walk Through Combinatorics
vertex-disjoint edges. Indeed, no job opening can be ﬁlled by more than
one person, and no person can accept more than one job oﬀer.
If the hiring process is complete, and we ﬁlled all m positions, there will
be m bold edges. If we ﬁlled less than m positions, but cannot ﬁnd any
qualiﬁed candidates for any of the remaining openings, then that means
that we cannot change any non-bold edge to a bold edge so that all bold
edges are still pairwise vertex disjoint. Therefore, the following Proposition
is immediate.
Proposition 11.9. Let S be an instance of the hiring problem, that is, a
set of m job openings and n applicants, and all the relevant information
about the qualiﬁcations of each applicant. We can simultaneously ﬁll all m
job openings in S if and only if, in the graph G deﬁned above, we can ﬁnd
m vertex-disjoint edges.
In our running example, the graph shown in Figure 11.3, we can ﬁll all
openings, as shown in Figure 11.4.
JOBS
APPLICANTS
Fig. 11.4
A maximal set of vertex-disjoint edges.
We see that for a set of edges in a graph, it can be an important ques-
tion whether they are pairwise vertex-disjoint or not. This warrants the
following deﬁnition.
Deﬁnition 11.10. Let G be any graph, and let S be a set of edges in G
so that no two edges in G have a vertex in common. Then we say that S
is a matching in G. If each vertex in G is covered by an edge in S, then we
call S a perfect matching.
A matching is also called an independent set of edges in certain contexts.
Note that the above deﬁnition does not require that G be a bipartite graph.

Finding A Good Match. Coloring and Matching
279
For the time being, however, we will restrict our discussion to matchings in
bipartite graphs, which are very useful in the practice.
Deﬁnition 11.11. Let G = (X, Y ) be a bipartite graph. If S is a matching
in G that covers all vertices of X, then we say that S is a perfect matching
of X into Y .
If we are not particularly interested in the matching S, just the fact
that there is a perfect matching of X into Y , then we will say that X has
a matching into Y or X can be matched into Y .
11.3.1
Bipartite Graphs with Perfect Matchings
Let G = (X, Y ) be a bipartite graph. At least two questions are in order.
Does X have a perfect matching into Y ? (In the language of the previous
discussion this is the question whether all job openings can be ﬁlled at the
same time.) How do we ﬁnd the largest matching of G?
First let us try to decide if X has a perfect matching into Y . Let us look
for necessary conditions ﬁrst; for properties G certainly must have if it is to
have a perfect matching. For one thing, |X| ≤|Y | is a necessary condition
as all edges in our purported matching S would have to have a vertex in
X, and one in Y , setting up an injection from X to Y . For another trivial
observation, if there are two vertices a and b of X that are both of degree
1, and they are both connected to the same vertex y ∈Y , then we are in
trouble. Indeed, X cannot have a perfect matching into Y as we cannot
even match the two vertices a and b into Y . One of them can be matched
into y, by an edge e, but that would leave no possibility to ﬁnd any edge
starting at the other one that is vertex-disjoint from e.
It is not hard to generalize these easy necessary conditions. If T ⊆X is
a subset of vertices in X, then let N(T ) denote the set of all neighbors of
the vertices in T . In other words, y ∈Y is an element of N(T ) if and only
if there is a vertex x ∈T so that xy is an edge. The neighbor set N(T )
is relevant to matchings because if we just want to match T into Y , then
we can certainly restrict our attention to the bipartite graph (T, N(T )).
Indeed, N(T ) contains all possible Y -endpoints of the edges of a matching
of T into Y .
If there is a danger of confusion as to in which graph we count the
neighbors of a vertex set, we use the notation NG(T ) to identify the graph.
Proposition 11.12. Let G = (X, Y ) be a bipartite graph. Then X has a

280
A Walk Through Combinatorics
perfect matching into Y only if for all T ⊆X, the inequality |T | ≤|N(T )|
holds.
Proof. Let us assume that there is a T ⊆X so that |T | > |N(T )|. Then
T certainly cannot be matched to N(T ) as T has more vertices than N(T ).
However, this means that T cannot be matched into Y either as any such
matching would match T into N(T ). Finally, this means that X cannot be
matched into Y as any such matching would obviously contain a matching
of T into Y .
This Proposition was, after all, not too surprising.
It basically said
that if, among our job openings, there are k for which we only have k −1
qualiﬁed applicants, then we cannot ﬁll all positions. This is pretty clear.
What is much more interesting is that the converse of Proposition 11.12 is
also true. This remarkable result is known as Philip Hall’s theorem.
Theorem 11.13 (Philip Hall’s theorem). Let G = (X, Y ) be a bipar-
tite graph. Then X has a perfect matching into Y if and only if for all
T ⊆X, the inequality |T | ≤|N(T )| holds.
Proof. As we provided a proof of the “only if” part when we proved Propo-
sition 11.12, we only have to prove the “if” part. The proof we present is
due to Halmos and Vaughn, dated 1950.
We prove the statement by induction on |X|, the initial case being
trivial. Now assume we know the statement for all nonnegative integers
less than |X|, and prove it for |X|. Let us assume that for all T ⊆X, the
inequality |T | ≤|NG(T )| holds. We distinguish two cases.
(1) First let us assume that for each proper subset T ⊂X, even the strict
inequality |T | < |NG(T )| holds. Let x and y be adjacent vertices, with
x ∈X. Let G′ = G −x −y, and let A be any nonempty subset of
X −x.
Our assumption then shows that |A| < |NG(A)|, therefore
|NG′(A)| ≥|NG(A)| −1 ≥|A|. Consequently, the induction hypothesis
implies that X −x can be matched into Y −y in G′. Adding the edge
xy to this matching, we get a perfect matching of X into Y .
(2) Now assume there is a subset B ⊂X so that |B| = |NG(B)| holds.
We split G into two smaller subgraphs G1 and G2, and then show that
each of these subgraphs satisﬁes the induction hypothesis separately.
Let G1 be the subgraph induced by B ∪N(B), and let G2 be the graph
obtained from G by deleting all vertices that belong to B ∪N(B).

Finding A Good Match. Coloring and Matching
281
To see that G1 satisﬁes the induction hypothesis, choose any subset
T ⊆B. Then NG(T ) ⊆NG(B), and therefore, NG1(T ) = NG(T ), (all
neighbors of T are within G1), and therefore, |NG1(T )| = |NG(T )| ≥
|T |.
To see that G2 satisﬁes the induction hypothesis, choose any subset
U ⊆X −B.
Then NG(U ∪B) = NG2(U) ∪NG(B), and because
this is a union of disjoint sets, |NG2(U)| = |NG(U ∪B)| −|NG(B)| ≥
|U ∪B| −|B| = |U|.
If we apply the induction hypothesis to both G1 and G2, we see that
B can be matched into (and therefore, onto), NG(B), and X −B can
be matched into Y −NG(B). Therefore, X can be matched into Y as
claimed.
This theorem has many interesting applications to problems that look
unrelated at ﬁrst. Exercise 9 is one of them.
While Theorem 11.13 is undoubtedly useful, it does not answer all our
questions. It does not tell us how to ﬁnd a perfect matching if there is one,
or how to ﬁnd a maximum matching in any given graph.
The last sentence brings up an important issue in our terminology.
Henceforth, the words maximal and maximum will have diﬀerent mean-
ings. In a graph G, a matching M is called maximal if we cannot extend
M by adding a new edge to it. A matching N is called maximum if no
matchings of G contain more edges than N.
At this point, the reader should test her understanding of this subtle
diﬀerence by showing that a maximum matching is always maximal, but a
maximal matching is not always maximum. After doing that, the reader can
ﬁnd one example for the latter in Figure 11.5. We need two more deﬁnitions
in order to characterize maximum matchings in bipartite graphs.
Deﬁnition 11.14. Let G be a graph, and let M be a matching in G. A
path P = v1v2 · · · vr is called an M-alternating path if vivi+1 is in M if and
only if vi+1vi+2 is not in M.
In other words, every other edge of P belongs to M. If, in addition, P
starts and ends at vertices that are not adjacent to any edge of M, then
M is clearly not a maximum matching. Indeed, we get a larger matching
if we discard the edges in P ∩M and replace them by the edges P −M.
Therefore, if this happens, we call P an M-augmenting path. Let us make

282
A Walk Through Combinatorics
Fig. 11.5
A maximal, but not maximum, matching.
this deﬁnition formal.
Deﬁnition 11.15. An M-alternating path is called an M-augmenting path
if it starts and ends in vertices that are not adjacent to any edge in M.
See Figure 11.6 for an example. The bold lines are the edges of M, and
the dotted lines are the edges of P −M.
Fig. 11.6
Extending a matching by an augmenting path.
Note that we have not used the fact that G is bipartite, so all we said
about alternating and augmenting paths holds for all simple graphs.
The non-existence of augmenting paths actually characterizes maximum
matchings.

Finding A Good Match. Coloring and Matching
283
Theorem 11.16. Let G be any simple graph, and let M be a matching in
G. Then M is maximum if and only if G has no M-augmenting paths.
Proof. We have already shown the “only if” part in our discussion preced-
ing Figure 11.6.
To prove the “if” part, assume there is no M-augmenting path in G,
and let M ′ ̸= M be any maximum matching in G. Consider M ⊕M ′, the
set of edges that are part of exactly one of M and M ′. As M and M ′ are
both matchings, the connected components of M ⊕M ′ can only be even
cycles or alternating paths. However, M ′ is maximum, and there is no M-
augmenting path, therefore all these alternating paths are of even length.
This implies |M| = |M ′|, and our claim is proved.
11.3.2
Stable Matchings in Bipartite Graphs
Let us assume that in a small city, there are n job openings, and there are
a total of n candidates available for those openings. Each candidate has an
ordered list of preferences for the n jobs, and the hiring manager responsible
for each job has an ordered list of preferences for the n candidates. All these
lists are of length n, so the question is not how to ﬁnd a perfect matching,
but how to ﬁnd a stable perfect matching. The notion of stable matchings
is crucial to this problem, so we are going to make it formal.
Deﬁnition 11.17. Let G(X, Y ) be a bipartite graph with a perfect match-
ing M, with each vertex of X given an ordered list of preferences for the
vertices of Y , and each vertex of Y given an ordered list of preferences for
the vertices of X. We say that M is stable if the following two conditions
do not both hold.
(a) There is a vertex x ∈X so that xy ∈M, but x prefers y′ ∈Y to y, and
(b) if y′ and x are the vertices deﬁned in part (a), and y′x′ ∈M, then y′
prefers x over x′.
In other words, a matching is stable if one cannot ﬁnd a vertex in each
color class that would mutually dump their current matches for each other.
Fortunately, there is a fairly simple process that will produce a stable
matching. First, each candidate applies for their most preferred job. Sec-
ond, each manager will tell their preferred applicant that she is temporarily
hired, and reject all other applicants. After this, these same steps will be
iterated. Candidates who did not get their ﬁrst choice will apply for the
job that is second on their preference list, then for the job that is the third

284
A Walk Through Combinatorics
on their preference list, and so on. If candidate A applies for a job that
is temporarily ﬁlled by candidate B, and the hiring manager for that job
prefers A over B, then she will temporarily hire A, and will reject B. The
process goes on until all candidates ﬁnd a job, at which point all temporary
hires will be made permanent. Note that this always happens. Indeed, if
there is a candidate C without a job, then there is a job J that C is not
ﬁlled yet, and that means that C has not yet applied for J, so the process
is not over yet.
While it is obvious that the process produces a perferct matching of the
bipartite graph G(X, Y ) whose vertices are, of course, the candidates and
the job openings, we make the stronger claim that it will always produce a
stable matching of that graph.
Indeed, let us say that in our graph G(X, Y ), the color class X represents
the candidates, and the color class Y represents the job openings. Let us
assume that our process results in the perfect matching M that is not
stable, that is, there exist vertices x ∈X and y′ ∈Y so that xy ∈M, and
x′y′ ∈M, but x prefers y′ over y, and y′ prefers x over x′. That would
mean that both x and y′ would dump their current matches for each other.
However, as x prefers y′ over y, it follows that x′ applied for y′ before y.
Now there are two possibilities.
(1) If, at that point, x was accepted by y′, then the fact that they are not
matched at the end means that later y′ dumped x for someone that
was higher on the preference list of y′. So, at the end y′ ended up with
a candidate x′ that she liked more than she liked x. This contradicts
the assumption that y′ prefers x to x′.
(2) If, at that point, x was rejected by y′, that means that even at that
point, y′ had a better candidate than x, and so the candidate who
was permanently hired at the end by y′ was higher on her list than x.
Again, this contradicts the assumption that y′ prefers x to x′.
The process we have described above is called the Gale-Shapley algo-
rithm or deferred acceptance algorithm.
The reader may point out that in real life, it is rare to have exactly
as many job openings as applicants. However, a very minor modiﬁcation
of the Gale-Shapley algorithm will work in situations when the two color
classes are not of the same size. Indeed, if there are n candidates and m
jobs, with n > m, then we can create n −m ﬁctional jobs that are at the
bottom of the preference list of all applicants, and if n < m, then we can
introduce m −n ﬁctional candidates that are similarly unattractive for all

Finding A Good Match. Coloring and Matching
285
hiring managers.
Quick Check
(1) Let G be a graph that has a perfect matching, but if we remove any
edge from G (without removing any vertices), then the obtained graph
G−no longer has a perfect matching. What can G be?
(2) Let G be a graph whose vertices are those of a cube, labeled bijectively
with the elements of [8], and whose edges are the edges of the cube.
How many perfect matchings does G have?
(3) Let G be a bipartite graph that does not have a perfect matching, but
if we add any new edge to G (not adding any new vertices), then the
new graph G+ is no longer bipartite, but has a perfect matching. What
can G be?
11.4
More Than Two Colors
We have seen in Theorem 11.6 that a bipartite graph cannot have too many
edges. We have also seen that if we want the bipartite graph on n vertices
that has the largest number of edges, we have to take the bipartite graph
in which the numbers of vertices in the two color classes are equal (if n is
even), or diﬀer by 1 (if n is odd).
Let us generalize this question into k-colorable graphs instead of bipar-
tite (2-colorable) graphs. Is it still true that the best strategy to maximize
the number of edges is to split the vertices among the color classes as equally
as possible? The following famous theorem of P´al Tur´an shows that this is
indeed the case.
To prepare the statement and proof of Tur´an’s theorem, let n = tk + r,
with 0 ≤r ≤k −1, and divide the n vertices into k subsets, r of them of
size t + 1, and the rest of size t. In other words, we divided the n vertices
into k blocks, whose sizes are “as equal as possible”. Let two vertices be
joined by an edge if and only if they are in diﬀerent subsets. The graph H
that we obtain in this way is called a complete k-partite graph. The number
of its edges (see Exercise 1) is
T (n, k) = k −1
2k
· n2 −r(k −r)
2k
.
(11.1)
It goes without saying that H is k-colorable as we can assign color 1 to
the vertices of the ﬁrst subset, color 2 to the vertices of the second subset,
and so on. Now we are going to show that no k-colorable simple graph on
n vertices can have more edges than H.

286
A Walk Through Combinatorics
Theorem 11.18. Let G be a simple graph on n vertices that contains more
than T (n, k) edges. Then G contains a Kk+1 subgraph. In particular, G is
not k-colorable.
Proof. Let G have n vertices, let G contain no Kk+1, and let it have the
maximum number of edges possible with these conditions. We will prove
that G can contain at most T (n, k) edges.
We will proceed by induction on t, where t has been deﬁned in the
paragraph preceding the Theorem. If t = 0, then the statement is obvious.
Now let us assume that we know that the statement is true for t −1. Our
conditions imply that adding any edge to G would create a Kk+1 subgraph.
Therefore, G must contain a Kk subgraph, say S.
Now we will count how many edges G can have. The edges of G can be
• within S, or
• between a vertex of S and a vertex of G −S, or
• within G −S.
There are
k
2

edges within S. Each of the vertices of G −S can be
connected to at most k −1 of the vertices of S. Finally, G −S has n −k =
(t −1)k + r vertices, so the induction hypothesis implies that there are at
most T (n −k, k) edges within G −S. Therefore, the number of edges in G
is at most
k
2

+ (n −k)(k −1) + T (n −k, k) = T (n, k).
(11.2)
This shows that if G has more than T (n, k) edges, it must contain a Kk+1,
and therefore, it cannot be k-colorable.
We admit that we swept two technicalities under the rug here. One was
the computation of the number T (n, k) of edges in our complete k-partite
graph H. The other is the proof of equality (11.2). See Exercises 1 and 2
for these details.
Theorem 11.18 proved in a rather strong way that certain graphs are
not k-colorable. Indeed, it proved that graphs containing too many edges
will always contain a Kk+1-subgraph, and therefore are not k-colorable.
We certainly know that a graph does not have to contain Kk+1 in order
to have chromatic number at least k + 1. Indeed, if G is an odd cycle of
length more than three, then it does not contain K3 and still has chromatic
number three. What is interesting is that in some sense, odd cycles and
complete graphs are alone in forcing high chromatic numbers. This is the

Finding A Good Match. Coloring and Matching
287
content of the following theorem of Brooks. We do not prove this theorem
in the text, but the three Quick Check questions at the end of the section
will lead you to a proof.
Theorem 11.19. Let G be a connected graph which is not an odd cycle,
and not a complete graph, and let d ≥3 be a positive integer, so that each
vertex of G has degree at most d. Then χ(G) ≤d.
On the other hand, note that for all n, there exists a graph that contains
no triangles, but has chromatic number n. This is the content of Exercise
6. In other words, if a graph has a high chromatic number, then it has a
vertex with a high degree, but it may or may not have a large complete
subgraph.
Quick Check
The following three questions are a roadmap to a proof of Brooks’ theorem.
For each of these questions, let G be a graph in which the highest vertex
degree is d ≥3, and assume that G is not a complete graph.
(1) Let us assume that G has a vertex v so that removing v and the edges
adjacent to it from G, the obtained graph is disconnected. Prove that
χ(G) ≤d.
(2) Let us assume that G has two vertices u and v so that removing them
and all the edges adjacent to them from G, the adjacent graph is dis-
connected. Prove that χ(G) ≤d.
(3) Now let us assume that the situations described in the previous two
questions do not hold, and recall that G is not a complete graph.
Let w be a vertex d in G. Show that w has two neighbors u and v
that are not adjacent to each other.
Then list the vertices of G as
v1, v2, · · · , vn, so that v1 = w, vn−1 = u, vn = v, and otherwise the
vertices v2, v3, · · · , vn−2 are in non-decreasing order of their distance
from w in the graph G −u −v. Now color the vertices in the order
vn, vn−1, · · · , v1 with colors from [d], always using the smallest color
that keeps the coloring proper. Prove that d colors will suﬃce.
11.5
Matchings in Graphs That Are Not Bipartite
There are many real-life situations when ﬁnding a matching (a set of vertex-
disjoint edges) in a non-bipartite graph is needed. Let us assume for ex-
ample that a big company wants to form pairs of employees for certain

288
A Walk Through Combinatorics
assignments, and wants to do it in a way that the two employees within
each pair know each other. Or take a set of football teams, and ﬁnd pairings
for this week-end so that teams that have played each other within the last
two years do not play each other again.
In these examples, we have a graph that is not necessarily bipartite, but
we still want to ﬁnd a set of vertex-disjoint edges in it. Fortunately, there
is a suﬃcient and necessary condition for a perfect matching to exist. If
G is a graph, and S is a subset of the vertex-set of G, then let G −S be
the graph obtained from G by deleting the elements of S, and all the edges
that are adjacent to them. Let co(G −S) be the number of components of
G −S that have an odd number of vertices.
Theorem 11.20 (Tutte’s theorem). A graph G has a perfect matching
if and only if, for all subsets S of the vertex set of G, the inequality co(G −
S) ≤|S| holds.
There are several proofs of this theorem. We will present one that is
due to G´abor Hetyei Sr. (1972) and L´aszl´o Lov´asz (1975). We will need
some tools for the proof of the “if” part. The “only if” part, however, is
trivial. Indeed, if there is an S violating the conditions, then no perfect
matching could exist. In order to see this, let us assume that M is a perfect
matching, then each odd component of G −S must contain at least one
vertex M matches with a vertex of S. This would imply co(G −S) ≤|S|,
contradicting our assumption.
Let us call the graph G saturated non-factorizable if G has no perfect
matching, but added any new edge, the resulting graph does. To prove the
“if” part of Tutte’s theorem, we need the following, somewhat technical,
Lemma.
Lemma 11.21. If the graph G is saturated non-factorizable, and if S is
the set of vertices of G that are joined to every other point of G, (that is,
the set of vertices of degree |G| −1), then the components of G −S are
complete graphs.
Proof. Let ab and bc be two adjacent edges in G −S. To prove our state-
ment, it suﬃces to show that a and c are adjacent vertices. Let us assume
the contrary, that is, that a and c are not adjacent. Then there must be a
vertex d in G so that bd is not an edge. Indeed, otherwise b would be in S.
As G is saturated non-factorizable, G ∪ac has a perfect matching F1.
Since G itself does not have a perfect matching, this implies that ac ∈F1.

Finding A Good Match. Coloring and Matching
289
Similarly, G ∪bd has a perfect matching F2. As G itself does not have
a perfect matching, F2 contains bd. Just as we did in proofs concerning
matchings in bipartite graphs, let us take the symmetric diﬀerence of F1
and F2. This consists of alternating, (and therefore, even) cycles. Let C1
be the cycle containing ac, and let C2 be the cycle containing bd.
We
distinguish between two cases.
(a) First let us assume that C1 ̸= C2. In this case, form the symmetric
diﬀerence F3 = F1
 C1. Then we claim that F3 is a perfect matching
of G. Indeed, ac ∈(F1 ∩C1), so ac /∈F1
 C1. On the other hand,
F3 has the same number of edges of F1, and is a matching, so it is
a perfect matching of G.
This is a contradiction as G is saturated
non-factorizable, and as such, has no perfect matching.
(b) Now let us assume that C1 = C2. Traverse C1 starting at b through d,
until one of a and c, say a, is reached. Let the path from b to a just
traversed be P. Recall that ab ∈G, and note that therefore, P ∪ab
is an alternating path (in fact, a cycle), for F2. Form the symmetric
diﬀerence F4 = F2
(P ∪ab).
Then we claim that F4 is a perfect
matching for G. Indeed, F4 contains the same number of edges as F2,
but does not contain bd as bd ∈(F2 ∩(P ∪ab)). This shows that F4 is
a perfect matching of G, which is a contradiction.
Therefore, if ab and bc are edges in G−S, then so is ac, and the components
of G −S are complete graphs.
The following theorem will characterize saturated non-factorizable
graphs.
Theorem 11.22. A graph G is saturated non-factorizable if and only if it
has the following structure.
(a) Either G has an odd number of vertices, and is complete, or
(b) G has an even number of vertices and consists of vertex-disjoint com-
plete subgraphs S0, G1, G2, · · · , Gk so that k = |S0| + 2, each Gi has an
odd number of vertices, and each vertex of each Gi is connected to each
vertex of S0.
Proof. If G has an odd number of vertices, then it does not have a perfect
matching. Therefore, only the complete graph satisﬁes the requirement of
saturated non-factorizability as that is the only graph to which no edge can
be added.

290
A Walk Through Combinatorics
If G has an even number of vertices, then let S be deﬁned as in Lemma
11.21. Let us set S0 = S. Let G1, G2, · · · , Gk be the connected components
of G −S. Lemma 11.21 shows that all the Gi are complete graphs, and so
is S, and by deﬁnition, each vertex of S is connected to each vertex of each
Gi.
Recall that G has no perfect matching. Therefore, the number of Gi
with odd components must be more than |S|. In fact, as G has an even
number of vertices, the number of Gi with odd components must be at
least |S + 2|. On the other hand, G cannot have more than |S + 2| odd
components, otherwise we could add a new edge connecting two of them.
That would lead to a contradiction, because the resulting graph G1 would
satisfy co(G1 −S) > |S|, and would therefore have no perfect matching.
Therefore, G has exactly |S + 2| odd components. Finally, G has no even
components, otherwise we could again add an edge connecting that com-
ponent to another component without creating a perfect matching.
Now we are in a position to prove Tutte’s theorem.
Proof. (of Tutte’s theorem) All we have left to do is to prove the “if” part.
Let us assume that G satisﬁes the criteria but has no perfect matching. Add
new edges to G until a graph with perfect matching is obtained. Let G′ be
the saturated non-factorizable graph that was created by this procedure.
If G has an odd number of vertices, then choosing S = ∅we see that
G does not satisfy the criteria. Thus we can assume that G has an even
number of vertices. Let S′ be the set of vertices of G′ that are adjacent
to any other vertex of G′. Theorem 11.22 then describes the structure of
G′ −S′. Let H′ be the set of vertices of this graph. Then H is not empty
as G was not complete (it did not have a perfect matching). Moreover,
H′ = G1 ∪G2 ∪· · · ∪Gk,
where the Gi are vertex-disjoint complete subgraphs, and k = |S′| + 2.
Our last sentence shows that G′−S′ has more than |S′| (in fact, |S′|+2)
components. Remove all the edges of G′−G that we inserted to our original
graph G. Then some of our components may split, but each of these odd
components will give rise to at least one odd component of G −S′. This
shows that co(G−S′) > |S′|, so G violates the condition. This contradiction
completes the proof.

Finding A Good Match. Coloring and Matching
291
Quick Check
(1) Show an example for a connected graph G on an even number of vertices
that does not have a perfect matching, but in which, for all subsets S
of vertices, the inequality |S| ≤|N(S)| holds.
(2) Let G be a saturated non-factorizable graph that is tripartite. Describe
the structure of G.
(3) How many perfect matchings does K2m have?
Notes
If you want to know more about matchings, you should see Matching Theory
by L´aszl´o Lov´asz and Michael D. Plummer [34] for an extensive text.
One way to generalize our results concerning k-colorability is to ask the
following question. Let G be a given graph on n vertices. At most how
many edges can a graph H on n vertices have so that it does not contain
a subgraph that is isomorphic to G? This leads to the area of Extremal
Graph Theory, and you can read more about that ﬁeld in the identically
titled book of B´ela Bollob´as [8]. For an introductory treatment to Extremal
Combinatorics, you may consult Chapter 6 of Introduction to Enumerative
Combinatorics [11].
In Exercise 5, we deﬁne the chromatic polynomial of a graph.
This
polynomial tells us the number of ways the properly n-color the vertices
of a given graph G. At ﬁrst sight, it seems unlikely that p(−1) has some
direct combinatorial meaning, but amazingly, it does. In fact, p(−1) is the
number of acyclic orientations of G, that is, the number of ways to turn
G into a directed graph so that no directed cycles are formed. For details,
see [49] or Chapter 5 of [11].
Exercises
(1) Prove formula (11.1).
(2) Prove formula (11.2).
(3) A round robin football tournament has 2n participating teams. Two
rounds have been played so far. Prove that we can still split the teams
into two groups of n teams each so that no teams of the same group
have played each other yet.
(4) Let G = (X, Y ) be a bipartite graph in which any vertex of X has
degree at least as large as the degree of any vertex of Y . Prove that X

292
A Walk Through Combinatorics
has a perfect matching into Y .
(5) Let G be any simple graph with labeled vertices, and let p(n) be the
number of ways to properly n-color G. Prove that p is a polynomial
function of n. What is the degree of that polynomial? We note that
p(n) is called the chromatic polynomial of G.
(6) (+) Prove that for all positive integers n, there exists a graph that does
not contain any triangles and whose chromatic number is n.
(7) Prove that the number of ways to properly color an n-vertex cycle with
x colors is
(a) (x −1)[(x −1)n−1 + 1] if n is even.
(b) (x −1)[(x −1)n−1 −1] if n is odd.
(8) Let G be a bipartite graph. Prove that G has a perfect matching if
and only if for all subsets X of the vertex set of G, the inequality
|X| ≤|N(X)| holds. Note that unlike in Philip Hall’s Theorem, here
we do not require that X be a subset of one color class.
(9) Let A be a square matrix with nonnegative integer entries in which the
sum of each line, that is, each row and column, is the same positive
integer r. Such a matrix is called a doubly stochastic matrix or magic
square. Prove that A is a sum of permutation matrices.
(10) Let A be an n × n × n “magic cube” with line sum 2. That is, A is a
3-dimensional matrix with nonnegative integer entries so that each line
has sum 2. Is it true that A = B + C where B and C are both magic
cubes of line sum 1?
(11) Explain why the results of Exercise 9 and Exercise 10 are not exactly
the same. Try to predict what happens in higher dimensions.
(12) Let G be a regular bipartite graph. Prove that G has a perfect match-
ing.
(13) There are n children and n toys in a room. Each child wants to play
with r speciﬁc toys, and for each toy, there are r children who want
to play with that toy. Prove that we can organize r playing rounds so
that in each of them, each child plays with a toy he wanted to, and
no child plays with the same toy twice? (Contradicting real life a little
bit, but not much, we assume that only one child can play with a toy
at any one time.)
(14) (-) A graph G is called factor-critical if G−v has a perfect matching for
any vertex v of G. Prove that a bipartite graph is never factor-critical.
(15) Let Gn be the bipartite graph whose color classes consist of the vertices

Finding A Good Match. Coloring and Matching
293
A1, A2, · · · , An and B1, B2, · · · , Bn, and in which AiBj is an edge if and
only if i + j ≤n + 1. How many matchings does Gn have? (Note that
the question is not the number of perfect matchings, but the number
of matchings of any size.)
(16) (Knowledge of Linear Algebra required.) Let G(A, B) be a bipartite
graph with A = {A1, A2, · · · , An} and B = {B1, B2, · · · , Bn}. Let M
be the n × n matrix deﬁned by the rule Mi,j = 1 if AiBj is an edge
of G, and Mi,j = 0 otherwise. Prove that if det M ̸= 0, then G has a
perfect matching.
Supplementary Exercises
(17) (-) What is the chromatic number of a tree?
(18) (-) What is the chromatic polynomial of a tree?
(19) A graph is called color-critical if it has chromatic number k, but if we
delete any vertex of the graph, we get a graph of chromatic number
k −1. Show an example of a color-critical graph of chromatic number
three and of a color-critical graph of chromatic number four. Do not
use complete graphs as examples.
(20) (-) Is there a bipartite graph with ordered degree sequence 3, 3, 3, 3,
3, 5, 6, 6, 6?
(21) (-) A school has n student clubs denoted by c1, c2, · · · , cn, and some
students are members of more than one of them. Each club can send
one representative to the general assembly, but no student can rep-
resent more than one club. Find a suﬃcient and necessary condition
that assures that n distinct representatives r1, r2, · · · , rn can be found
so that ri is a member of ci for all i ∈[n].
(22) (-) Find the size of the smallest vertex cover and of a maximum match-
ing in an odd cycle and an even cycle.
(23) Find the chromatic polynomial of K3,3.
(24) A wheel is a cycle and an extra vertex that is connected to each vertex
of the cycle.
Find the chromatic polynomial of a wheel on n + 1
vertices.
(25) (+) A medium-size city has three high schools, each of them attended
by n students. Each student knows exactly n + 1 who attend a high
school diﬀerent from his. Prove that we can choose three students,
one from each school, so that any two of them know each other.
(26) Fix two positive integers k and n so that k < n/2. Let G = (X, Y )

294
A Walk Through Combinatorics
be the bipartite graph in which the vertices of X are the k-element
subsets of [n], the vertices of Y are the (k + 1)-element subsets of [n],
and there is an edge between x ∈X and y ∈Y if and only if x ⊂y.
Prove that X has a perfect matching into Y by
(a) using Philip Hall’s theorem,
(b) ﬁnding a perfect matching of X to Y .
(27) Deduce Philip Hall’s Theorem from Tutte’s theorem.
(28) A school has various student associations.
The principal wants to
hold a meeting, and she wants each student association to send one
representative to this meeting.
No student can participate at the
meeting as a representative of more than one organization. Find a
suﬃcient and necessary condition on such a meeting being possible.
(29) Prove that G is factor-critical if and only if G has an odd number of
vertices and co(G −S) ≤|S| for all non-empty set S of vertices.
(30) Let G be a bipartite graph, and let uv be an edge of G. Prove that at
least one of u and v have the following property.
“All maximum matchings of G contain an edge adjacent to this ver-
tex”.
Note that this is a stronger requirement than just requiring that each
maximum matching contain an edge adjacent to u or v.
(31) For a graph G, let ν(G) denote the size of its maximum matching. A
set of vertices S of G is called a vertex cover, if all edges of G have at
least one of their vertices in S. Let τ(G) be the size of the smallest
vertex cover of G. In other words, if you think of the edges as non-
intersecting tunnels, τ(G) is the smallest number of lights we need to
provide lighting for all tunnels.
(a) Prove that in any graph G, the inequality ν(G) ≤τ(G) holds.
(b) Prove that in any bipartite graph G, the equality ν(G) = τ(G)
holds. (Hint: Use the result of the previous exercise, and induction
on the number of vertices.)
Note that the result of part (b) is often referred to as K¨onig’s theorem,
in honor of the Hungarian mathematician D´enes K¨onig.
(32) Deduce Philip Hall’s theorem from K¨onig’s theorem. (The latter is
stated in the previous exercise.)
(33) Deduce K¨onig’s theorem from Philip Hall’s theorem.
(34) For any graph G on n vertices, let α(G) denote the size of the largest
empty subgraph of G. That is, α(G) is the largest number k so that

Finding A Good Match. Coloring and Matching
295
G has k vertices, no two of which are adjacent. Prove that
α(G) + τ(G) = n,
where τ(G) is deﬁned in Exercise 31.
(35) In a graph G, an edge cover is a set S of edges so that each vertex
of G is incident to at least one edge in S. Let ρ(G) be the smallest
number k so that G has an edge cover consisting of k edges. Let G be
a graph on n vertices so that each vertex of G has degree at least 1.
Prove that then
ν(G) + ρ(G) = n,
where ν(G) was deﬁned in Exercise 31. What does this result imply
for bipartite graphs?
Solutions to Exercises
(1) Recall that n = tk + r. Now we prove the statement by induction on
t. For t = 0, the statement is true. Now let us assume that we know
the statement for t −1, that is, for T (n −k, k), formula (1) is correct.
To prove that the statement is true for t, that is, that formula (1) is
correct for T (n, k), it suﬃces to prove that the diﬀerence of the two
equations given by formula (1) for T (n, k) and T (n−k, k) holds. That
is, we have to prove that
T (n, k) −T (n −k, k) = n2 −(n −k)2
2k
· (k −1)
= (2n −k)(k −1)
2
=
k
2

+ (n −k)(k −1).
Let us identify the edges counted by T (n, k) that are not counted by
T (n −k, k). The graph H belonging to T (n, k) has k more vertices,
one in each color class, than the smaller graph H′.
There are
k
2

edges among these extra vertices, and each of the remaining n −k
vertices is connected to all of these extra vertices but one, the one in
its own color class. This yields (n −k)(k −1) additional edges, and
the statement follows.

296
A Walk Through Combinatorics
(2) As we have computed in the solution of the previous exercise, the
deﬁnitions of T (n, k) and T (n −k, k) yield
T (n, k) −T (n −k, k) =
k
2

+ (n −k)(k −1).
This is precisely formula (11.2).
(3) If we join teams who played with each other, we get graphs in which
each vertex has degree two. In such graphs, all components must be
cycles. Also, all these cycles must be of even length for no team has
ever been idle. Then we can pick every other vertex of all cycles and
get a set of teams with the desired property.
(4) Let us assume that the contrary is true. Then, by Philip Hall’s theo-
rem, there would be a set T ⊆X of vertices so that |T | > |N(T )|. Let
a1, a2, · · · , at be the degrees of the vertices in T , and let b1, b2, · · · , bn
be the degrees of the vertices in N(T ). Our assumptions imply t > n,
and also, ai ≥bj for any i and j. As each edge between T and N(T )
has a vertex in T and one in N(T ), we must have
a1 + a2 + · · · + at ≤b1 + b2 + · · · + bn.
However, this is impossible, as the left-hand side has more members,
and they are at least as large as the members of the right-hand side.
(5) Let G have k vertices, and let p1, p2, · · · , pk denote the number of ways
to properly color G using exactly 1, 2, · · · , k colors. Now let n > k.
Then we cannot use all n colors to color G. We ﬁrst have to choose
the i colors (i ∈[k]) that we will actually use, which we can do in
n
i

ways. Then, we have to use the chosen i colors, which we can do in
pi ways. Therefore,
p(n) =
k

i=1
pi
n
i

.
Here the pi are constants, and the
n
i

are polynomials of n, of degree
i. Therefore, p(n) is a polynomial of degree k.
(6) By induction on n. For n = 2, a single edge is such a graph. For
n = 3, the pentagon is. Suppose we know the statement for n −1,
and let G be a graph with no triangles and chromatic number n −1.
For any vertex x ∈G, create a new vertex x′ whose neighbors are
the same as those of x. Do this for all vertices of G. Then take yet
another new vertex y and join it to all the vertices that we added to
G. The graph obtained this way has chromatic number n and has no
triangles.

Finding A Good Match. Coloring and Matching
297
(7)(a) Let n be even. The proof is by induction on n, with n = 2 being
the initial case. If n = 2, then the statement is true, for an edge
can be colored in x(x −1) ways, and that agrees with our claim.
Now suppose that the statement is true for n, and try to prove it
for n + 2. Let A1, A2, · · · , An+2 be the vertices of our polygon.
Then I have x choices for the color of A1, x−1 choices for the color
of A2, x −1 choices for the color of A3, and so on, x −1 choices for
the color of An+1, and most of the time -we will explain this later-
x −2 choices for the color of An+2 as it cannot have the color of
A1 or An+1. This gives us x(x −1)n(x −2) colorings. The most of
the time above refers to the possibility that A1 and An+1 can have
the same color, and in this case, only that color is forbidden for
An+2, so when this happens, we have x −1 choices for the color of
An+2, not just x −2. So any time this happens, we have to add 1
to the number of proper colorings. To determine how many times
does this happen, note that any time this happens, we can delete
An+2 and contract A1 and An+1 to get a properly colored n-gon.
And, by the induction hypothesis, the number of such n-gons is
(x −1)[(x −1)n−1 + 1].
Therefore, we get that the total number of proper colorings for our
n + 2-gon is
x(x −1)n(x −2) + (x −1)[(x −1)n−1 + 1] = (x −1)[(x −1)n+1 + 1],
and the theorem is proved.
(b) If n is odd, the proof is analogous. The initial case is that of n = 3,
and indeed, a triangle can be colored in x(x −1)(x −2) ways.
Then, to prove the induction step, we repeat the same argument
and conclude that
x(x −1)n(x −2) + (x −1)[(x −1)n−1 −1] = (x −1)[(x −1)n+1 −1],
and the proof follows.
(8) Let us assume that the condition does not hold, and let X be a coun-
terexample. Let X = A ∪B be the decomposition of X into two color
classes. Then we have |A| + |B| = |X| > |N(X)| = |N(A)| + |N(B)|,
and therefore, we must have either |A| > |N(A)|, or |B| > |N(B)|.
Then Philip Hall’s theorem shows that G does not have a perfect
matching.
Now let us assume the condition holds for all X. Then in particular,
it holds for all subsets that are within one color class. Philip Hall’s
Theorem then shows that G has a perfect matching.

298
A Walk Through Combinatorics
(9) We prove the statement by induction on r. If r = 1, then our matrix
is a permutation matrix, and the statement is true. Now let us assume
that we know the statement for r, and prove it for r + 1. Let A be a
magic square with line sum r + 1. It suﬃces to show that there exists
an n× n permutation matrix B so that A−B has nonnegative entries
only.
To see this, we deﬁne a bipartite graph G in which both color classes
consist of n vertices. The elements of one color class will represent the
rows of A, and the elements of the other color class will represent the
columns of A. Two vertices will be joined by an edge if and only if the
intersection of the corresponding row and column of A is a positive
entry.
Note that if we can prove that G has a perfect matching, then we are
done as that perfect matching speciﬁes n positions in A, all contain-
ing positive entries, so that no two are in the same row or column.
Therefore, the permutation matrix B having its entries equal to 1 in
these n positions is just the permutation matrix we were looking for.
Therefore, our task is reduced to proving that G has a perfect match-
ing. We will do this using Hall’s theorem. We must show that the
conditions of that theorem are satisﬁed, that is, any k-element subset
of vertices from one color class has at least k neighbors in the other
color class. Translated to the language of matrices, this means that
any k rows of A must contain nonzero entries in at least k diﬀerent
columns. Suppose this does not hold, that is, there are k rows that
contain nonzero elements only in s < k columns. Then the sum of all
kn elements in these k rows is kr (if you add them row by row), and
at most sr (if you add them column by column). This contradicts to
s < k, and our claim is proved.
(10) This is not true in general. A counterexample is shown below.
⎛
⎜
⎜
⎜
⎝
0 1 1
1 1 0
1 0 1
⎞
⎟
⎟
⎟
⎠
⎛
⎜
⎜
⎜
⎝
2 0 0
0 1 1
0 1 1
⎞
⎟
⎟
⎟
⎠

Finding A Good Match. Coloring and Matching
299
⎛
⎜
⎜
⎜
⎝
0 1 1
1 0 1
1 1 0
⎞
⎟
⎟
⎟
⎠.
The second level can only be decomposed in one way, and its 2 × 2
minor in the bottom right corner makes any further decomposition
impossible.
(11) The result of Exercise 9 was built on Philip Hall’s Theorem for bipar-
tite graphs. We could not use the same argument in Exercise 10 as
there was no corresponding theorem for tripartite graphs. There is no
corresponding theorem for general k-partite graphs either. Therefore,
it is not true that a k-dimensional magic cube with line sum r is the
sum of r magic cubes of dimension k having line sum 1.
(12) Let us assume that G does not have a perfect matching. By Hall’s
theorem, that would imply that there is a vertex set T within one color
class such that |T | > |N(T )|. Denote by d the degree of all vertices in
G. Then there are |T |d edges adjacent to at least one vertex in T . The
opposite endpoints of these |T |d edges must be in N(T ). Therefore, it
follows by the pigeon-hole principle that at least one vertex in N(T )
has degree more than d, which contradicts the assumption that G is
regular.
(13) Represent children and toys with a bipartite graph G the obvious way.
You get a regular bipartite graph with all vertices having degree r. The
previous problem shows that G has a perfect matching M1. Then M1
deﬁnes the ﬁrst playing round, and G−M1 is a regular graph with all
vertices having degree r −1. Again, this graph has a perfect matching
M2, and so on.
This fact can also be stated as follows. It is possible to color the edges
of a regular bipartite graph of degree r with r colors so that each
vertex is adjacent to one edge of each color.
(14) Let G be bipartite, and let its two color classes consist of m and n
vertices, with m ≤n.
Then we cannot omit any vertex from the
color class with m elements so that the resulting graph has a perfect
matching.
Indeed, we would get a bipartite graph with two color
classes of diﬀerent size.
(15) Consider a staircase Ferrers shape of row lengths (n, n −1, · · · , 2, 1),
similarly to the solution of Exercise 4 of Chapter 5.
Let the rows
correspond to the vertices Ai, and let the columns correspond to the

300
A Walk Through Combinatorics
vertices Bj. Then each matching of Gn corresponds to a placement
of non-attacking rooks on this Ferrers shape. We have seen in the
solution of Exercise 4 of Chapter 5 that there are B(n + 1) such rook
placements, where B(n) is the nth Bell number.
(16) If M has a non-zero determinant, then it has a non-zero expansion
term, that is, a nonzero product of the form n
i=1 Mi,p(i) for some
permutation p ∈Sn. That means that AiBp(i) is an edge for each
i ∈[n], so the set of these edges is a perfect matching in G.

Chapter 12
Do Not Cross. Planar Graphs
12.1
Euler’s Theorem for Planar Graphs
Let us assume that a farming community has three houses and three wells.
The families living in the three houses cannot stand each other, so they
prefer not to meet when they walk to the wells. Can we build roads from
each of the houses to each of the wells so that there will be no two roads
among the needed nine roads that intersect? We are not allowed to build
bridges or tunnels.
Figure 12.1 shows a credible, but failed, attempt to build such roads.
A
B
C
X
Z
Y
Fig. 12.1
A and Z cannot be connected.
Now you could think that maybe another attempt will succeed. Or, after
many unsuccessful tries, you may think that arranging the houses and the
wells diﬀerently might help. Both of these hopes are false, however. The
301

302
A Walk Through Combinatorics
three houses, three wells problem cannot be solved. In this section, we will
develop a theory to prove this claim.
It is clear that we are dealing with graphs from a new aspect here. That
is, we want to draw them so that their edges do not intersect. This property
is central to our chapter.
Deﬁnition 12.1. Let G be a graph that can be drawn on a plane surface
so that no two of its edges intersect. Then G is called a planar graph.
Let G be a planar graph, and draw G on a plane with no intersecting
edges. Then the edges of G partition the plane into regions; we will call
these regions the faces of G. See Figure 12.2 for an example.
1
2
3
4
8
7
6
5
Fig. 12.2
This graph has eight faces.
The number of faces of a planar graph is just as important a parameter
of that graph as the number of edges or vertices. The following theorem
shows the close connection between these three parameters.
Theorem 12.2 (Euler’s Theorem on Planar graphs). Let
G
be
a
connected planar graph with V vertices, E edges, and F faces.
Then
V + F = E + 2.
Proof. We prove the statement by induction on E, the number of edges of
G. If E = 1, then G is either the tree of one edge, and then V = 2, F = 1,
and the statement is true, or G is the one-vertex graph with a loop, and
then V = 1, F = 2, and the statement is true again.
Now let us assume that we know the statement for all graphs with E −1
edges, and let G have E edges. We distinguish two cases.

Do Not Cross. Planar Graphs
303
If we can remove an edge e from G so that the new graph G′ is still
connected, then e is in a cycle in G, and therefore there are two diﬀerent
faces on the two sides of e in G. Then G′ has E −1 edges, V vertices, and
F −1 faces as the removal of e turned the two faces on the two sides of e
into one. Therefore, V + F −1 = E −1 + 2, so V + F = E + 2.
If there is no e with the mentioned property, then G is a cycle-free
connected graph, that is, a tree. Then we know from Theorem 10.4 that
V = E + 1. On the other hand, F = 1, so the claim is again true.
Now we are in a position to settle the problem of three houses and three
wells. Indeed, that problem is equivalent to the problem of drawing K3,3
on a plane surface without crossings.
Example 12.3. The graph K3,3 is not planar. Therefore, there is no solu-
tion for the three houses, three wells problem.
Solution. Let us suppose that K3,3 is planar. As it has nine edges and six
vertices, it follows from Theorem 12.2 that it must have ﬁve faces. However,
K3,3 is a complete bipartite graph, so all its faces must be quadrilaterals.
Five quadrilaterals have a total of twenty edges, but in a planar graph,
each edge is contained in two faces. Therefore, our graph would need ten
distinct edges, but it has only nine.
Note that in particular this means that it does not matter where the
houses and the wells are located with respect to each other. No arrangement
will work. As K3,3 is a subgraph of K6, it follows from Example 12.3 that
K6 is not planar. On the other hand, K3, the triangle is obviously planar,
and so is K4 as the reader can see by drawing a square and its two diagonals,
then replacing one diagonal by an “outer” edge. It is less obvious to decide
whether K5 is planar.
Example 12.4. The graph K5 is not planar.
Solution. Again, let us suppose that K5 is planar. As it has ﬁve vertices
and ten edges, it follows from Theorem 12.2 that it must have seven faces.
As K5 is a complete graph, all its faces must be triangles. Seven triangles,
however, would need 21 edges, which is impossible as each of the ten edges
of K5 are used in exactly two faces.
It is not by accident that we chose K5 and K3,3 for our examples of
graphs that are not planar. Certainly, if G contains K5 or K3,3 as subgraph,

304
A Walk Through Combinatorics
then G cannot be planar as we cannot even draw a particular subgraph (the
K5 subgraph, or the K3,3 subgraph) of G without crossings. The interesting
fact is, however, that in some sense these two graphs are the only ones that
can cause a graph to be not planar.
Let us make this statement more precise.
It is clear that if H is a
graph that is not planar, and we remove a vertex V of degree two from
H, contracting the edges AV and V B into a single edge AB, the obtained
graph is still not planar. Similarly, if we split an edge CD of H into two
edges by inserting a vertex F into the middle of CD, and thus replace the
edge CD by the edges CF and FD, we again get a non-planar graph. If
a graph T can be obtained from H by repeated applications of these two
operations, then we say that H and T are edge-equivalent.
Then the following theorem, that we will not prove, characterizes planar
graphs.
Theorem 12.5 (Kuratowski’s Theorem). A graph is not planar if and
only if it contains a subgraph that is edge-equivalent to K5 or K3,3.
Quick Check
(1) Is the complete bipartite graph K2,4 planar?
(2) Is the complete tripartite graph K2,2,2 planar?
(3) Is the complete 4-partite graph K2,2,2,2 planar?
12.2
Polyhedra
A polyhedron is a solid whose boundary is a union of polygons. We meet
polyhedra every day in our lives. Common examples of polyhedra are cubes,
tetrahedra, and prisms.
Polyhedra have some nice properties that are not shared by all planar
graphs. Most importantly, all their faces have at least three edges, and all
their vertices are part of at least three edges. It is also easy to verify that
in all polyhedra, there must be at least four vertices, four faces, and six
edges. We do not have to worry about loops or multiple edges in polyhedra,
either.
In geometry, a polyhedron is called regular if it is “absolutely symmet-
ric”, that is, all its faces have the same number ℓof edges, all vertices
are contained in the same number d of edges (d is called the degree of the
polyhedron), all edges have the same length, all angles within the faces are

Do Not Cross. Planar Graphs
305
equal, and all angles between the faces are equal. For example, the cube is
a regular polyhedron. In combinatorics, we can disregard the conditions on
the length of edges, and the size of angles, but we keep the graph-theoretical
conditions that each face is a cycle with ℓedges, and each vertex has degree
d. One could think about regular polyhedra as three-dimensional general-
izations of regular polygons.
There is, however, a striking diﬀerence between regular polygons and
regular polyhedra. Clearly, for all integers n ≥3, there exists a regular
polygon with n vertices. So the number of regular polygons that are diﬀer-
ent as graphs is inﬁnite. In this Section we will show that this is not true
in three dimensions. In fact, and our goal in this section will be a proof for
this, there are only ﬁve diﬀerent regular polyhedra, which is very diﬀerent
from the two-dimensional situation.
One of our main tools in proving this result will be Euler’s theorem for
planar graphs. It is not hard (see Exercise 2) to show that this theorem
also holds for polyhedra by showing that polyhedra are essentially planar
graphs. More precisely, the set of vertices and edges of a polyhedron form a
planar graph. This planar graph is called the 1-skeleton of the polyhedron,
but with a slight abuse of language, in this section, when we talk about a
polyhedron, we will actually mean its 1-skeleton.
Nevertheless, we provide an additional proof for Euler’s theorem for
polyhedra only. The beauty of this proof lies in its simplicity as it does not
use induction, or properties of trees; it only requires high school knowledge
of geometry. Some of the formulae that we ﬁnd on the way will be useful
on their own.
Theorem 12.6. Let P be a convex polyhedron with V vertices, F faces,
and E edges. Then V + F = E + 2.
Proof. Let p be a plane that is not perpendicular to any faces of P, and
let us project P onto p, to get the projected image P ′. As P was a convex
polyhedron, the projection of a face with k edges will be a convex k-gon.
Let us count the sum of angles in all the F faces of P ′ (the boundary B
of P ′ is considered a face, too). There are two ways to do this, namely we
can count by the vertices, or by the faces.
First we count by the vertices. Let us say that B is a convex v1-gon,
and there are v2 vertices of P whose projected image is inside this v1-gon.
Then v1 + v2 = V .
The sum of angles around each of the v2 interior vertices is 360 degrees,

306
A Walk Through Combinatorics
so the total sum of these angles is 360v2. The boundary of P ′ is a convex
v1-gon, so its sum of angles is (v1 −2)180. However, the sum of these angles
must be counted twice as each angle is used by two diﬀerent faces of P ′.
Therefore, we obtain that the total sum S of angles is
S = (v1 −2)360 + 360v2 = (V −2)360.
(12.1)
On the other hand, we can count the angles by the faces, too. If a face
of P ′ is a convex k-gon, then the sum of its angles is (k −2)180 degrees.
Let f1, f2, · · · , fF be the number of edges of the F faces of P. As each edge
is contained in exactly two faces,
F

i=1
fi = 2E.
(12.2)
Therefore, the sum of the angles in all these faces is certainly
S =
F

i=1
(fi −2)180 = 180
 F

i=1
fi

−360F = 360(E −F).
(12.3)
Comparing (12.1) and (12.3), the proof of our theorem is immediate.
Formula (12.2) is a useful byproduct of this proof. Note that fi ≥3 for
all i as the fi denote the number of edges of various polygons. Therefore,
the left-hand side of (12.2) is at least as large as 3F, proving the following
Corollary.
Corollary 12.7. In any convex polyhedron with F faces and E edges, 3F ≤
2E.
It is not too diﬃcult to prove a similar relation between the numbers of
vertices and edges of a convex polyhedron.
Proposition 12.8. In any convex polyhedron with V vertices and E edges,
3V ≤2E.
Proof. Let c1, c2, · · · , cV denote the number of edges adjacent to each ver-
tex. As each edge is adjacent to exactly two vertices,
V

i=1
ci = 2E.
(12.4)
As each vertex is contained in at least three faces, ci ≥3 for all i, so the
left-hand side is at least as large as 3V , which was to be proved.

Do Not Cross. Planar Graphs
307
The reader may think that after ﬁnding relations between the number
of faces and edges, as well as the number of vertices and edges, we can
probably ﬁnd a similarly simple relation between the number of vertices
and that of faces. This is, however, not so simple. The problem is that
in the two previous proofs we heavily relied on the fact that each edge is
contained in exactly two faces, and contains exactly two vertices. Faces and
vertices do not have such a uniform property.
We now have lower bounds on the number of edges in terms of the
number of vertices, and also in terms of the number of faces. On the other
hand, we have not proved upper bounds yet. It is plausible to conjecture
that such an upper bound should exist in terms of the number of vertices.
Indeed, if we have a simple graph on V vertices, and keep adding new edges
to it, then we eventually reach KV , which is not planar if V > 4. Our task
is to ﬁgure out “how many edges are too many”.
Lemma 12.9. In any convex polyhedron, E ≤3V −6, and also, E ≤3F −6.
Proof. We know from Corollary 12.7 that F ≤2E
3 . Comparing this to
Euler’s theorem, we get
E + 2 = F + V ≤2E
3 + V,
E
3 ≤V −2,
and the claim E ≤3V −6 follows by rearranging. Similarly, Proposition
12.8 implies V ≤2E
3 , and comparing this to Euler’s theorem,
E + 2 = F + V ≤F + 2E
3 ,
E
3 ≤F −2,
and again, the claim E ≤3F −6 follows by rearranging.
The attentive reader has probably noticed the symmetric role of V and
F in our results so far: these two parameters play symmetric roles in Euler’s
theorem, in Lemma 12.9, in Corollary 12.7 and in Proposition 12.8. Even
the proofs concerning these two kinds of results were very similar. There
is a deep, structural reason for this, and we will explain it shortly. First,
however, we are going to use our recent results. We start with a somewhat
surprising application.
Lemma 12.10. All convex polyhedra have at least one face that has at most
ﬁve edges.

308
A Walk Through Combinatorics
Proof. We know from Lemma 12.9 that E ≤3F −6. Comparing this to
(12.2) we obtain
F

i=1
fi = 2E ≤6F −12.
(12.5)
Therefore, it cannot be that fi ≥6 for all i as that would imply the in-
equality F
i=1 fi ≥6F.
It should come no longer as a surprise that there is a similar result for
vertices. We could tell the promised deep structural reason for this right
now, but we prefer making the reader curious.
Lemma 12.11. All convex polyhedra have at least one vertex that is con-
tained in at most ﬁve edges.
Proof. We know from Lemma 12.9 that E ≤3V −6. Comparing this to
(12.4) we obtain
V

i=1
ci = 2E ≤6V −12.
(12.6)
Therefore, it cannot be that ci ≥6 for all i as that would imply the in-
equality V
i=1 ci ≥6V .
Note that the statement of Lemma 12.9 holds for all planar graphs, not
just polyhedra. You are asked to prove this fact in Exercise 12.
Lemmas 12.10 and 12.11 are of pivotal importance in our quest for all
regular polyhedra. They show that in regular polyhedra, the degree d of
each vertex can be only one of three values, namely 3, 4, or 5, and the same
goes for ℓ. That would leave us with only 3 · 3 = 9 cases to check. The
following discussion will simplify that task.
Let G be any planar graph, and let us construct a new graph G∗as
follows. The vertices of G∗are the centers of the faces of G. (Any interior
point would do.) Two vertices A and B of G∗are connected by k edges if
and only if the corresponding faces in G had k edges in common; in this
case each common edge of those two faces will be crossed by one AB edge.
This sets up a bijection between the vertices of G∗and the faces of G, and
another bijection between the edges of G∗and G. Therefore, if G had E
edges, V vertices and F faces, then G∗will also have E edges, but it will
have F vertices, and V faces. The reader is invited to verify that G∗is also
planar. See Figure 14.28 for an example.

Do Not Cross. Planar Graphs
309
Deﬁnition 12.12. The graph G∗deﬁned in the above paragraph is called
the dual graph of the planar graph G.
Fig. 12.3
A graph and its dual.
The reader should verify that the dual of a convex polyhedron is a convex
polyhedron, and the dual of a regular polyhedron is a regular polyhedron.
The notion of the dual graph of a planar graph explains the similarity
between results on the number of vertices and results on the number of
faces. Indeed, if a theorem on parameters V and E is true for a polyhedron
P, it is also true for the dual P∗of P, where these two parameters indicate
the number of faces and the number of edges.
Now we are ready to ﬁnd all regular polyhedra. Recall that their degrees
must be 3, 4 or 5. Also remember that in a regular polyhedron, all faces
have l edges, so the total number of edges is, by (12.2),
E = Fℓ
2 .
(12.7)
(A) Let us assume ﬁrst that d = 3. This means that ci = 3 for all i, which
implies by (12.4) that 3V = 2E. Comparing this to Euler’s theorem,
we get 3F = E + 6, which, together with (12.7) implies
3F −6 = Fℓ
2 ,
(6 −l)F = 12.

310
A Walk Through Combinatorics
All three permitted values of ℓyield an integer solution to this equation.
(a) If ℓ= 3, then F = 4, therefore E = 3F −6 = 6, and V = 4.
There indeed exists a polyhedron with these parameters, namely
the tetrahedron.
(b) If ℓ= 4, then F = 6, therefore E = 3F −6 = 12, and V = 8. These
are the parameters of the cube.
(c) If ℓ= 5, then F = 12, therefore E = 3F −6 = 30, and V = 20. That
is, we are looking for a regular polyhedron with 12 faces, that are all
pentagons. It is easy to see that such a polyhedron indeed exists: it
has one pentagonal face “at the bottom”, one “at the top”, and to
each side of these two faces we attach a new face. This polyhedron
is called the dodecahedron.
(B) If d = 4, then (12.4) yields 4V = 2E, therefore E = 2F −4. Together
with (12.7), this implies
2F −4 = Fℓ
2 ,
(4 −ℓ)F = 8.
The only permitted value of l that leads to a positive integer solution
is l = 3. Then we get F = 8, so E = 12, and V = 6. To see that such a
polyhedron indeed exists, take the dual of the cube. This polyhedron
is called the octahedron.
(C) If d = 5, then (12.4) yields 5V = 2E, therefore 3E = 5F −10. Com-
paring this to (12.7) yields
5F −10 = 3Fℓ
2 ,
F(10 −3ℓ) = 20.
The only permitted value of ℓthat gives a positive integer solution to
this equation is ℓ= 3. Then F = 20, so E = 30, and V = 12. So
our purported polyhedron has 20 triangular faces, 30 edges, and 12
vertices. To see that such a polyhedron indeed exists, note that we can
construct one by taking the dual of the dodecahedron. This polyhedron
is called an icosahedron. Just as the names of other discussed polyhedra
referred to the number of faces, this name comes from the Greek word
for twenty.

Do Not Cross. Planar Graphs
311
As we have examined all permitted values of d, we have proved the
following theorem.
Theorem 12.13. There are ﬁve regular polyhedra: the tetrahedron, the
cube, the dodecahedron, the octahedron, and the icosahedron.
Quick Check
(1) Prove the in any convex polyhedron, the number of faces that have an
odd number of edges is even.
(2) Let P be a convex polyhedron in which every face is a quadrilateral.
Prove that the average degree of the vertices of P is less than 4.
(3) Let P be a convex polyhedron in which the average of all vertex degrees
is 5. Let D be the average number of edges in all faces of P. Prove
that D < 10/3.
12.3
Coloring Maps
World maps usually color the territories of neighboring countries by diﬀer-
ent colors for obvious reasons. If two countries having a common border
were the same color, the viewer of the map may overlook the border between
them.
This simple problem from everyday life gave rise to one of the most
famous problems in Mathematics. Take any map, with the countries still
uncolored, and try to color the countries so that no two neighboring coun-
tries get the same color, using as few colors as possible. What is the smallest
number of colors that will suﬃce no matter what the map looks like?
From a graph theoretical point of view, all maps are planar graphs,
so we need to ﬁnd a proper coloring of the faces of a planar graph. By
proper coloring, we mean the faces that have an edge in common must get
diﬀerent colors. Note that faces that only have vertices in common may
get the same color. Also note that by duality, this is the same question
as asking how many colors do we need to properly color the vertices of a
planar graph. Indeed, a proper coloring of the faces of the planar graph
G naturally deﬁnes a proper coloring of the vertices of G∗, and vice versa.
When coloring the vertices of G∗, the criterion to fulﬁll is, of course, that
adjacent vertices get diﬀerent colors.
This question was probably asked ﬁrst by Francis Guthrie in 1852, and
got soon passed along to well-known mathematicians as Augustus DeMor-

312
A Walk Through Combinatorics
gan, and Augustin Cauchy. A little bit of thinking yields that at least four
colors are needed as K4 is planar. Trying several maps, one is led to the
conjecture that four colors always suﬃce. as long as all countries on the
map are contiguous, that is, one can walk from any point of a country to
any other point of that country without crossing into another country. For
instance, the United States is not contiguous since one cannot walk from a
point in Alaska to a point in California without crossing into Canada in be-
tween. Since four colors seem to suﬃce for maps with contiguous countries,
this problem had been called the “Four-Color Conjecture”.
For a warm-up, let us prove that six colors always suﬃce. We will use
the dual (vertex-coloring) form of the problem as it makes induction proofs
easier to describe.
Proposition 12.14. The vertices of any planar graph can be properly col-
ored with six colors.
Proof. Induction on V , the number of vertices of the planar graph G.
If V = 1, then the statement is obviously true. Let us assume that we
know that the statement is true for graphs with V −1 vertices. Let G
have V vertices. Then we know from Exercise 12, (which is the generalized
version of Lemma 12.11 to all simple planar graphs) that G has a vertex
A of degree at most ﬁve. Remove A from G to get the graph G′. By our
induction hypothesis, G′ has a proper coloring with six colors. Take such a
coloring of G′, then color A with a color that is not the color of any of its
(at most ﬁve) neighbors.
This means, by duality, that all maps can be properly colored using
six colors. The situation is signiﬁcantly harder if we only want to use ﬁve
colors. The result, however, is the same.
Theorem 12.15. The vertices of any planar graph can be properly colored
with ﬁve colors.
Proof. Just as in proving the previous proposition, we use induction. The
only case in which the previous proof does not work is when A has ﬁve
neighbors, and they are all of diﬀerent colors. In this case, denote by 1,
2, 3, 4 and 5 the colors of the ﬁve neighbors y1, y2, y3, y4, y5 of A as they
follow clockwise. Let G′ be the graph obtained from G by removing A
and all the edges adjacent to A. If G′ has a proper 5-coloring in which
y1 and y3 are the same color, then we are done. If not, then any proper
5-coloring of G′ must contain a path from y1 to y3 along which the vertices

Do Not Cross. Planar Graphs
313
are alternatingly colored 1 and 3. By similar argument, if y2 and y4 cannot
be the same color, then any proper 5-coloring of G′ must contain a path
from y2 to y4 along which the vertices are alternatingly colored 2 and 4.
This, however, is a contradiction, as a path from y1 to y3 and a path from
y2 to y4 must always intersect. See Figure 12.4.
A
y
y
y
y
1
3
4
5
y2
Fig. 12.4
The paths y1y3 and y2y4 intersect.
Again, this means by duality that any map can be properly colored
using ﬁve colors.
Quick Check
(1) Let G be a simple bipartite graph in which every vertex has degree
three. Prove that it is possible to color each edge of G red, blue, or
green so that each vertex is adjacent to an edge of each color.
(2) Show that the statement of the previous question is not true in general
if G is not bipartite.
(3) Let G be a planar graph. Construct a planar graph G′ in which every
vertex has degree three and which has the property that if the faces of
G′ can be properly colored using four colors, then the faces of G can
also be properly colored using four colors.
Notes
How about the big question, that of four colors? The Four-Color conjec-
ture remained a conjecture until the 1970s. Then in 1976, Kenneth Appel

314
A Walk Through Combinatorics
and Wolfgang Haken developed a strategy to use a computer to split the
problem into several cases, and check the 4-colorable property in each case.
When they started running the computer program, it was not sure that the
computer would ever ﬁnish. It could have happened that the cases lead
to subcases, which in turn lead to subcases of subcases, and never end.
This did not happen, however. After 1200 hours of running time, and the
veriﬁcation of 1936 cases, the computer returned the verdict “four colors
suﬃce”. (Good that there were no power outages in Urbana, Illinois in
those weeks!) Therefore, we can now call this statement the Four-Color
Theorem. The proof also involved 400 pages worth of checking some other
cases by humans.
A signiﬁcant problem with the proof of Appel and Haken was that
one did not really learn from it why the statement is true.
Numerous
mathematicians have kept trying to simplify the proof ever since. The 1936
cases of the Appel-Haken proof were later reduced to 1476. In 1996, a new,
simpler proof was given by Neil Robertson, Daniel Sanders, Paul Seymour
and Robin Thomas. It involved only 633 cases, and all of these cases could
be checked by a computer. The same four researchers also found an eﬃcient
algorithm to actually give a 4-coloring of a planar graph, as opposed to
simply proving that one exists. Another computer-based proof was given
by Georges Gonthier and Benjamin Werner in 2005.
In this chapter, we were interested in deciding whether a certain graph
can or cannot be drawn in the plane without its edges intersecting each
other. We have not tried to count all planar graphs with a given set of
parameters.
Readers who would like to know more about that subject
should consult the survey of Gilles Schaeﬀer, in Chapter 5 of [12].
Another avenue of generalizations is the following. Let G be a graph
that is not planar, and let us try to draw G in the plane so that there
are as few crossing pairs of edges as possible. How many crossings will be
necessary? This number is called the crossing number of G, and it is the
subject of extensive research.
Exercises
(1) Generalize Theorem 12.2 for graphs that are not necessarily connected.
(2) Deduce Theorem 12.6 from Theorem 12.2.
(3) Find the only convex polyhedron for which equality holds both in Corol-
lary 12.7 and in Proposition 12.8.
(4) Prove that in any polyhedron, there are two vertices that are adjacent

Do Not Cross. Planar Graphs
315
to an equal number of edges.
(5) Prove that every polyhedron has two faces that have the same number
of vertices.
(6) Prove the result of the previous exercise without using Euler’s theorem,
or its consequences.
(7) Prove that the faces of planar graph G are 2-colorable if and only if all
vertices of G have even degree.
(8) Let n and k be positive integers so that the vertices of any n-vertex
planar graph all of whose faces are triangles have a proper k-coloring.
Prove that then the vertices of any n-vertex planar graph have a proper
k-coloring.
(9) State the dual of the result of the previous exercise.
(10) Let B be a simple, bipartite, and planar graph. If each vertex of G has
degree at least d, at most how large can d be?
(11) Prove that for all connected simple planar graphs, the inequality E ≤
3V −6 holds.
(12) Prove that all simple planar graphs have a vertex of degree at most
ﬁve.
Supplementary Exercises
(13) (-) Explain why the method we used in the text to prove Theorem
12.15 would not work if we tried to use it to prove the Four-Color
Theorem.
(14) (-) The faces of a convex polyhedron are all triangles or pentagons.
Prove that the number of faces is even.
(15) Let P be a polyhedron with no triangular faces.
Prove that E ≤
2V −4.
(16) How many connected simple planar graphs are there for which the
inequality of the previous exercise does not hold?
(17) (-) Is it true that if a connected graph satisﬁes E ≤3V −6, then that
graph is planar?
(18) (-) Take K6, the complete graph on 6 vertices, and delete two of its
edges. Prove that the obtained graph G is never planar.
What about three edges?
(19) Let P be a convex polyhedron whose faces are all either a-gons or b-
gons, and whose vertices are each adjacent to three edges. Let pa, pb,
and n respectively denote the number of a-gonal faces, b-gonal faces,

316
A Walk Through Combinatorics
and vertices of P.
(a) Express the number of edges of P in two diﬀerent ways.
(b) Prove that pa(6 −a) + pb(6 −b) = 12.
Note that a polyhedron satisfying the conditions of this exercise is
called a trivalent, (a, b)-faced polyhedron.
(20) Keep the notation of the previous exercise, and assume that 3 ≤a ≤
b ≤5. Within these limits, does there exist a trivalent (a, b)-faced
polyhedron for each pair (a, b)?
(21) Keeping the notation of the two previous exercises, let P be a trivalent
(5, 6)-faced polyhedron.
(a) Prove that with these conditions, all polyhedra P will contain the
same number of pentagons.
(b) Find the smallest value of n so that there exists a trivalent (5, 6)-
faced polyhedra on n vertices in which no two pentagonal faces
share an edge.
(22) Let G be a planar graph in which each face is either a 2-gon, or a 3-
gon, or a 4-gon, and let p2, p3, and p4 respectively denote the number
of these faces. Let us assume furthermore that each vertex of G has
degree four, and that p2 + p3 = 8, just like in an octahedron.
(a) Prove that with the given conditions, p2 = 0.
(b) Prove that with the given conditions, p3 = 8.
Note that a planar graph (or polyhedron, which we can now say as we
know that p2 = 0) satisfying the conditions of this exercise is called
an octahedrite.
(23) Let G be a convex octogon, and let us select ten points inside G in
general position (no three on the same line).
Let S be the set of
these ten points. Now draw some non-intersecting straight segments
so that these segments partition G into triangles, and the vertices of
these triangles are the vertices of G and the elements of S.
How many triangles are formed?
(24) (+) Is it possible to partition a square into a ﬁnite number of concave
quadrilaterals?
(25) (+) (Sperner’s Lemma) Let T be a triangle that is partitioned into
smaller triangles by line segments. Let S be the set of these triangles.
Assume that none of the triangles in S that are in the interior of T
contain a vertex of another triangle on the interior of their sides. Now
color all the vertices of all these triangles red, blue, or green so that

Do Not Cross. Planar Graphs
317
the three vertices of T are all diﬀerent, and the vertices on the three
sides of T are not colored the same as the opposite vertex of T . See
Figure 12.5 for an example. Prove that there is a triangle in S whose
vertices are all of diﬀerent colors.
red
blue
green
red
red
red
blue
blue
blue
green
green
green
red
Fig. 12.5
A possible partition and coloring.
(26) State and prove a version of Theorem 12.2 for planar graphs with k
connected components.
(27) Prove that the statement of Exercise 12 is not necessarily true for
non-simple graphs.
Solutions to Exercises
(1) For connected graphs, we have F + V = E + 2. For graphs with k
connected components, we will have F + V = E + (k + 1). Indeed,
take the equation of the Euler theorem for each connected component,
and then take the sum of these equations, each of which is of type
Vi +Fi = Ei +2. As the inﬁnite faces of the k components is common,
that face is counted k times on the left-hand side. Taking that into
account, our claim immediately follows.
(2) Comparing the known formulae 3F ≤2E and E = V + F −2, we get
3(E −V + 2) ≤2E,
E ≤3V −6
as claimed.

318
A Walk Through Combinatorics
(3) If equality holds in both formulae, then we have V = F = 2E/3. On
the other hand, Euler’s theorem forces V + F = E + 2. Comparing
these two relations, we get V = F = 4, and E = 6. The only convex
polyhedron with these parameters is the tetrahedron. (Indeed, no face
can have more than three vertices.)
(4) In a polyhedron, each vertex is adjacent to at least three edges. So if
our claim is not true, then there exists a polyhedron with V vertices
and at least 3 + 4 + · · · + (V + 2) =
V (V +5)
2
edges. On the other
hand, we have seen in Lemma 12.9 that the number of edges is at
most 3V −6. Thus we must have
V 2 + 5V ≤E ≤6V −12.
A routine computation shows that this is not possible as V 2 + 5V >
6V −12 for all positive integers. Thus our claim is true.
(5) Our claim is equivalent to saying that every polyhedron has two faces
that have the same number of edges. Assume not, and let P be a
counterexample. Then the dual of P would be a counterexample for
the result of the previous exercise.
(6) Let P be a polyhedron, and let L be a face of P with a maximal
number n of edges. Then L shares an edge with n other faces. Each
of these n faces has at least three and at most n edges. Therefore,
the pigeon-hole principle implies that there must be two of them that
have the same number of edges.
(7) The “only if” part is easy. If V has odd degree, then there are an odd
number of faces around V , and they cannot be properly colored by
two colors.
We prove the “if” part by strong induction on F, the number of faces
of G. If F = 1 (empty graph), or F = 2 (cycle), then the statement is
obviously true. Now assume we know the statement for planar graphs
with at most F −1 faces, and let G have F faces. Take a face T of
G. Remove all edges of T to get the graph G′. This decreased the
number of faces of G by at least one, and decreased the degrees of
vertices of T by two. Therefore, the induction hypothesis applies to
G′, and G′ can be properly 2-colored. Let us take a proper 2-coloring
of the faces of G′, and assume without loss of generality that the face
T ′ that contains the former face T is red. Let us put the edges of T
back to the graph, and color T the other color, say blue. This is a
proper 2-coloring of G as T shares edges with parts of T ′, and those
are all red. See Figure 12.6 for an example.

Do Not Cross. Planar Graphs
319
T
T’
red
red
blue
blue
blue
blue
blue
blue
T
blue
red
red
red
red
blue
blue
blue
blue
blue
blue
Fig. 12.6
The induction step.
(8) Induction on m, the number of non-triangular faces of our graph G. If
m = 0, then the claim is identical to the condition, so the initial step
is trivial. Now let us assume that we know the statement for m −1,
and prove it for m. We can assume G has no vertices of degree 1 as
if it does, we can remove them without loss of generality. Therefore,
G has a face that is a cycle C consisting r edges. Let V1, V2, · · · , Vr
be the edges of this cycle. Draw (possibly curved) lines from V1 to
V3, V4, · · · , Vr−1. (If all edges are straight lines, then C is a polygon,
and these lines are diagonals of C cutting C into triangles.) The new
graph G′ we obtain has one less non-triangular faces than G, so by
induction, it has a proper coloring p with k colors. Note that the set
of edges of G′ contains that of G, therefore p is also a proper coloring
of G.
(9) For any positive integers n and k, if the faces of all n-vertex regular
planar graphs with vertex degree 3 have a proper k-coloring, then the
faces of all n-vertex planar graphs have a proper k-coloring.
(10) We claim that the largest possible value of d is 3. Indeed, d = 3 is
possible, as is shown by noting that the graph give by the edges and
the vertices of a cube is planar and bipartite (check this!).
On the other hand, d = 4 is not possible. Let us assume that there
were such a graph. Then counting the edges by their endpoints, 4V ≤
2E, so 2V ≤E. As our purported graph is simple and bipartite, each
of its faces would have to consist of at least 4 edges, forcing 4F ≤2E,
so 2F ≤E. Therefore, using Euler’s theorem,
E + 2 = V + F ≤E
2 + E
2 = E
would follow, which is a contradiction.
(11) As G is planar, each of its faces has at least three edges, and each edge
is in at most two faces, so 3F ≤2E, and the proof can be ﬁnished as
we ﬁnished the proof of Lemma 12.9.

320
A Walk Through Combinatorics
(12) Let us assume that G is a simple graph in which each vertex has degree
at least six. Then adding the degrees of all vertices, we get at least
6v, so G as at least 3V edges, contradicting the result of Exercise 11.

Chapter 13
Does It Clique? Ramsey Theory
Instead of coloring the vertices of our graphs, in this chapter we will color
their edges. We will see that this leads to a completely diﬀerent set of
problems. Our ﬁrst excursion into the land of inﬁnite graphs is also part of
this chapter.
13.1
Ramsey Theory for Finite Graphs
Example 13.1. Six people are waiting in the lobby of a hotel. Prove that
there are either three of them who know each other, or three of them who
do not know each other.
This statement is far from being obvious. We could think that maybe
there is some case in which everyone knows roughly half of the other people,
and in the company of any three people there will be two people who know
each other, and two people who do not. We will prove, however, that this
can never happen.
Solution. (of Example 13.1) Take a K6 so that each person corresponds
to a vertex. Color the edge joining A and B red if A and B know each
other, and blue if they do not. Do this for all 15 edges of the graph. The
claim of the example will be proved if we can show that there will always
be a triangle with monochromatic edges in our graph.
Take any vertex V of our bicolored graph. As V is of degree ﬁve, it
must have at least three edges adjacent to it that have the same color. Let
us assume without loss of generality that this color is red. Let X, Y and Z
be the endpoints of three red edges adjacent to V . (The reader can follow
our argument in Figure 13.1, where we denoted red edges by solid lines.)
Now if any edge of the triangle XY Z is red, then that edge, and the
321

322
A Walk Through Combinatorics
two edges joining (the endpoints of) that edge to V are red, so we have
a triangle with three red edges. If the triangle XY Z does not have a red
edge, then it has three blue edges.
X
Y
Z
V
Fig. 13.1
The colors of the edges of the triangle XY Z are crucial.
This beautiful proof is our ﬁrst example in Ramsey theory. This ﬁeld
is named after Frank Plumpton Ramsey, who was the ﬁrst person to study
this area at the beginning of the twentieth century.
We point out that the result is tight, that is, if there were only ﬁve
people in the lobby of the hotel, then the same statement would be false.
Indeed, take a K5, and draw it as a regular pentagon and its diagonals.
Color all ﬁve sides red, and all ﬁve diagonals blue. As any triangle in this
graph contains at least one side and at least one diagonal, there can be no
triangles with monochromatic edges.
Instead of taking a K6, and coloring its edges red and blue, we could
have just taken a graph H on six vertices in which the edges correspond
to people who know each other. In this setup, the edges of H correspond
to the former red edges, and the edges of the complement of H correspond
to the former blue edges. As a complete subgraph is often called a clique,

Does It Clique? Ramsey Theory
323
the statement of Example 13.1 can be reformulated as follows. If H is a
simple graph on six vertices, then at least one of H and the complement of
H contains a clique of size three.
The arguments used in the proof of Example 13.1 strongly depended
on the parameter three, the number of people we wanted to know or not
to know each other. What happens if we replace this number three by a
larger number? Is it true that if there are suﬃciently many people in the
lobby, there will always be at least k of them who know each other, or k
of them who do not know each other? The following theorem answers this
question (in fact, a more general one), in the aﬃrmative.
Theorem 13.2 (Ramsey theorem for graphs). Let k and ℓbe two
positive integers, both of which is at least two. Then there exists a (min-
imal) positive integer R(k, ℓ) so that if we color the edges of a complete
graph with R(k, ℓ) vertices red and blue, then this graph will either have a
Kk subgraph with only red edges, or a Kℓsubgraph with only blue edges.
Note that any non-empty set of positive integers has a smallest element.
Therefore, if we can show that there exists at least one positive integer with
the desired property, then we will have shown that a smallest such integer
exists.
Example 13.3. Example 13.1, and the discussion after it shows that
R(3, 3) = 6. We also have trivial fact R(2, 2) = 2 relating to the graph
with one edge.
Proof. (Of Theorem 13.2) We prove the statement by a new version of
mathematical induction on k and ℓ. This induction will run as follows.
First we prove the initial conditions that R(k, 2) and R(2, ℓ) exist for all
k, and all ℓ. Then we take the induction step, proving that if R(k, ℓ−1)
exists, and also R(k −1, ℓ) exists, then R(k, ℓ) also exists.
To see that the initial conditions hold, note that R(k, 2) = k, and simi-
larly, R(2, ℓ) = ℓ. Indeed, either all edges of a Kk are red, and then it has
a Kk subgraph with all edges red, or at least one of its edges is blue, in
which case it has a K2 subgraph with all edges blue. Analogous argument
works for R(2, ℓ).
We prove the induction step by showing that
R(k, ℓ) ≤R(kℓ−1) + R(k −1, ℓ).
(13.1)
Indeed, take a complete graph with R(k, ℓ−1)+R(k−1, ℓ) vertices. Take
one of its vertices, and call it V . As V has degree R(k, ℓ−1)+R(k−1, ℓ)−1,

324
A Walk Through Combinatorics
it has either at least R(k, ℓ−1) blue edges adjacent to it, or it has at least
R(k −1, ℓ) red edges adjacent to it.
In the ﬁrst case, let b denote the R(k, ℓ−1)-element set of the other
endpoints of these blue edges. Then, by the deﬁnition of R(k, ℓ−1), the set
b either contains a monochromatic red Kk and we are done, or a monochro-
matic blue Kℓ−1, which can be completed to a monochromatic blue Kℓby
adding the vertex V , and we are done.
In the second case, let r denote the R(k −1, ℓ)-element set of the other
endpoints of these red edges. Then again, r either contains a monochro-
matic blue Kℓand we are done, or a monochromatic red Kk−1, which can
be completed to a monochromatic red Kk by adding the vertex V , and we
are done again.
So (13.1) is proved, therefore the induction step is proved, and therefore
the theorem is proved.
Inequality (13.1) is an important result, therefore, we announce it as
a corollary. Note that it would have been inappropriate to announce this
result before proving that the numbers R(k, ℓ) actually exist.
Corollary 13.4. For all positive integers k ≥2 and ℓ≥2, the inequality
R(k, ℓ) ≤R(kℓ−1) + R(k −1, ℓ)
(13.2)
holds.
Theorem 13.2 does show that the Ramsey number R(k, l) always exists,
but it does not tell us its exact value. Let us try to use this theorem to ﬁnd
R(4, 3), the smallest Ramsey number we have not discussed yet. Corollary
13.4 yields
R(4, 3) ≤R(4, 2) + R(3, 3) = 4 + 6 = 10.
The following Example shows that the upper bound obtained from Theorem
13.2 is not tight, even for such small values of k and ℓ.
Example 13.5. The equality R(4, 3) = 9 holds.
Solution. As we have just seen, it follows from (13.1) that R(4, 3) ≤10.
To prove our claim, we have to show two things: that all 2-colorings of the
edges of K9 will result in either a red K4 or a blue K3, and that the same
will not hold for K8.

Does It Clique? Ramsey Theory
325
(1) To see the ﬁrst statement, take a K9 with two-colored edges. We claim
that there has to be a vertex V so that either (i) at least six of the
edges adjacent to V are red, or (ii) at least four of the edges adjacent to
V are blue. If neither statements were true, then all vertices of this K9
would have ﬁve red edges adjacent to them, which is a contradiction
as the sum of the degrees in the subgraph of all red edges must be
even, so it cannot be 9 × 5 = 45.
(a) If there are six red edges adjacent to V , then denote by A the
six-element set of their other endpoints. By Example 13.1, there
is either a red triangle, or a blue triangle on A. So our K9 either
contains a blue triangle, or, together with V , a red K4.
(b) If, on the other hand, there are four blue edges adjacent to V , then
denote by B the four-element set of their other endpoints. If all
edges on B are red, then there is a red K4. If not, then there is a
blue edge on B, which will form a blue triangle, together with V .
(2) In order to see that R(4, 3) > 8, take a K8, and label its vertices by the
elements of [n], in clockwise direction, say. Let the edge (i, j) (with
j > i) be blue if j −i is 1, 4, or 7, and red otherwise. This graph
will not contain a blue triangle. Indeed, such a triangle would have to
contain a smallest vertex i, and two of the three vertices i + 1, i + 4,
i + 7, but no matter which two we choose, there will be a red edge
between them.
Red edges are present between vertices i and j so that j > i and j −i
is 2, 3, 5 or 6. To get a red K4, we would need a smallest vertex i,
then three of the four vertices i + 2, i + 3, i + 5 and i + 6. This is
impossible as neither i + 2 and i + 3, nor i + 5 and i + 6 can be chosen
together.
This completes the proof of the equality R(4, 3) = 9.
The following example takes the ideas seen in the preceding proof one
step further.
Example 13.6. The equality R(4, 4) = 18 holds.
Solution. Corollary 13.4 shows that
R(4, 4) ≤R(4, 3) + R(3, 4) = 9 + 9 = 18.
For an example of a 2-coloring of K17 without a monochromatic K4,
take the quadratic residue graph. That is, label the vertices from 0 to 16,

326
A Walk Through Combinatorics
and let the edge (i, j) be red if and only if i−j is a quadratic residue modulo
17. For those not familiar with this notion, this means that if j > i, then
the edge (i, j) is red if and only if j −i is 1, 2, 4, 8, 9, 13, 15, or 16. (Since if
we divide the square of an integer by 17, the remainder will always be one
of these eight values.) A tedious, but conceptually not diﬃcult, analysis of
all cases shows that there will be no K4 with monochromatic edges in this
graph.
We have seen that R(2, 2) = 1, R(3, 3) = 6, and R(4, 4) = 18. The exact
values of R(k, k) are not known if k ≥5. The diﬃculty of this problem is
illustrated by the following famous quote of Paul Erd˝os. “Assume an evil
spirit orders us to compute R(5, 5), or else he will destroy all mankind. It
may then be best if all mathematicians and computers start working on the
answer. If, however, he orders us to compute R(6, 6), then we had better
think about how to destroy him before he destroys us.”
Can we at least ﬁnd some bounds for the symmetric Ramsey numbers
R(k, k)? With the methods of this section, we can mostly hope for upper
bounds. They will be consequences of Corollary (13.4).
Theorem 13.7. Let k and ℓbe positive integers larger than one. Then
R(k, l) ≤
k + ℓ−2
k −1

.
(13.3)
Proof. As the reader probably guessed, we will prove this statement by the
same kind of induction on k and ℓas we proved Theorem 13.2. If k = 2, our
claim reduces to R(2, ℓ) ≤
l
1

= ℓ, which is trivially true. By symmetry,
the statement is also true if ℓ= 2.
Now let us assume that the statement is true for R(k, ℓ−1) and for
R(k −1, ℓ), and prove it for R(k, ℓ).
Applying Corollary 13.4 and the
induction hypothesis, we get
R(k, ℓ) ≤R(k, ℓ−1)+R(k−1ℓ) ≤
k + l −3
k −1

+
k + ℓ−3
k −2

=
k + ℓ−2
k −1

,
which is precisely what we wanted to prove.
Corollary 13.8. For all integers k ≥2, the inequality R(k, k) ≤4k−1
holds.
Proof. By Theorem 13.7, we obtain
R(k, k) ≤
2k −2
k −1

≤4k−1.

Does It Clique? Ramsey Theory
327
A technique for proving lower bounds for Ramsey numbers will be in-
troduced in Chapter 15.
Quick Check
(1) Is it possible to color the edges of K5 red or blue so that there will be
no 4-cycle with monochromatic edges?
(2) Is it possible to color the edges of K5 red or blue so that there will not
be four distinct vertices A, B, C and D so that each edge of the path
ABCD is of the same color?
(3) Is it possible to color the edges of K8 red and blue so that no K2,3
subgraph will have monochromatic edges?
13.2
Generalizations of the Ramsey Theorem
Example 13.9. A circle of 17 friends has the property that no matter
how we choose two from these 17 friends, those two people correspond with
each other on one of three given subjects. Prove that there are three friends
among the circle of these 17 friends such that any two of the three of them
correspond with each other on the same subject.
This example generalizes Example 13.1 in the hotel lobby in a major
aspect. Now the relation between two people can be of not only two kinds
(they either know each other or not), but of three kinds. So if we represent
our people by a K17, then we have to color the edges of this K17 by three
colors.
Solution. (of Example 13.9) As we have just explained, we have to show
that if we color each of the edges of a K17 either red, or blue, or green, there
will always be a triangle with monochromatic edges. Choose any vertex V
of our K17. As V has degree 16, it follows by pigeon-hole principle that
there is a color so that at least six of the edges adjacent to V have the same
color, say green. Let g be the set of the other endpoints of these green
edges. If there is any green edge between two vertices of g, then we are
done as those two vertices of g and V span a green triangle. If not, then all
the edges among the vertices of g are red or blue. However, g has at least
six elements, so it follows from Example 13.1 that the vertices of g span
either a red triangle, or a blue triangle.

328
A Walk Through Combinatorics
Theorem 13.7 can be generalized to more than two colors in the following
way.
Theorem 13.10. Let n1, n2, · · · , nk be positive integers, with k ﬁxed. Then
there exists a minimal positive integer N = R(n1, n2, · · · , nk) so that if
n > N, and we color all edges of G = Kn with colors 1, 2, · · · , k, then there
will always be at least one index i ∈[k] so that G has a Kni subgraph whose
edges are all of color i.
We only provide a sketch of a proof. After reading it, you should be
able to see how to proceed in the general case. You can check your work
by reading the solution of Exercise 1.
Proof. (of Theorem 13.10) We prove the statement by induction on n1 +
n2 + · · · + nk.
The initial case of n1 = n2 = · · · = nk = 1 is trivial.
Now let us assume that we know the statement for all positive integers
n1, n2, · · · , nk whose sum is less than m, and prove it for the case when
their sum is m.
Note that by our induction hypothesis, we know that the positive integer
R(n1 −1, n2, · · · , nk) exists. Set N = k(R(n1 −1, n2, · · · , nk) −1) + 2.
Let us assume that G has a vertex V so that the color that occurs most
frequently among the edges adjacent to V is color 1. That means that at
least R(n1 −1, n2, · · · , nk) edges adjacent to that vertex are of color 1. Let
S be the set of the endpoints of these edges (other than V ), and let KS the
complete graph with vertex set S.
By the deﬁnition of R(n1 −1, n2, · · · , nk) either there exists a vertex
i ∈{2, 3, · · · , k} so that KS has a Kni subgraph with all edges colored i
and we are done, or KS has a Kn1−1 subgraph with all edges colored 1,
and then we are done again, adding V to this subgraph.
Another direction in which the Ramsey theorem can be generalized is
that of hypergraphs, or set systems.
To make long story short, in that
generalization, we color not the edges of Kn, but the Kr-subgraphs of Kn,
for some ﬁxed r. The special case of r = 2 corresponds to the traditional
situation, that is, when the edges are colored. Then the following is true.
Theorem 13.11. We color each Kr-subgraph of Kn with one of the colors
1, 2, · · · , k.
Let n1, n2, · · · , nk be positive integers.
Then there exists a
minimal positive integer N = Rr(n1, n2, · · · , nk) so that if n ≥N, then
there exists an index i ∈[k] so that Kn contains a Kni subgraph whose Kr
subgraphs are all colored i.

Does It Clique? Ramsey Theory
329
The proof is omitted. It is conceptually not more diﬃcult than that of
Theorem 13.10, but it involves more notations.
The following is a very surprising application of Theorem 13.11. So far
our studies in Ramsey theory did not involve any geometry at all. Still, we
will be able to use our last theorem to prove a result of geometric nature.
Theorem 13.12 (The Erd˝os-Szekeres theorem). Let n be a positive
integer. Then there exists a (minimal) positive integer ES(n) so that if
there are N ≥ES(n) points given in the plane, no three of which are
collinear, then we can choose n points from them that form a convex n-gon.
Before reading further, you should check your understanding of the def-
inition of ES(n) by proving that ES(4) = 5.
Proof. We claim that R3(n, n) will always be such a positive integer (not
necessarily the minimal one). Take the complete graph whose vertices are
our R3(n, n) points in the plane. Color its triangles red or blue according
to the following rule. Number the points from 1 to R3(n, n), and color a
triangle red if the path from the smallest number via the middle one to the
largest one is clockwise. Color a triangle blue if that path is counterclock-
wise.
As our graph has R3(n, n) vertices, there will be a Kn subgraph with
monochromatic triangles. We claim that the vertices of this Kn subgraph
form a convex n-gon. To see this, it suﬃces to show that there are no four
vertices in this subgraph so that one is within the triangle spanned by the
other three. In other words, we need to show that the conﬁguration shown
in Figure 13.2 does not occur.
Let us assume without loss of generality that A < B < C, and that all
triangles of our K4 at hand are red. Then the fact that triangle ADB is
red forces D < A < B. (Indeed, A < D < B would mean that the triangle
ADB is blue, and A < B < D would mean that either the triangle BCD
is blue, or D > C, in which case triangle ACD is blue.) Then, however,
D < A < C, and triangle DAC is blue, which is a contradiction. This
completes the proof.
The above proof, beautiful as it is, does not say much about how large
the number ES(n) is. Paul Erd˝os and George Szekeres provided another
proof in 1935, and that proof showed that ES(n) ≤
2n−4
n−2

+1. Note that it

330
A Walk Through Combinatorics
A
D
C
B
Fig. 13.2
This conﬁguration cannot occur.
follows from Stirling’s formula that
2n−4
n−2

+1 ∼c 4n
√n for a positive constant
c that can be computed.
After this initial result, a series of small improvements have been dis-
covered in the course of the following 81 years, but these only improved
the constant c in the last asymptotic formula. However, in 2016, a Andrew
Suk found a much better upper bound by proving that if n is large enough,
then ES(n) ≤2n+4n4/5. See the paper [53] for a proof of this upper bound,
and references for earlier results on this problem.
As far as a lower bound goes, Erd˝os and Szekeres [23] proved that
ES(n) ≥2n−2 + 1, and they conjectured that in fact ES(n) = 2n−2 + 1.
This conjecture is known to hold for n ≤6. The case of n = 6 was proved
by the help of a computer as it involved the veriﬁcation of a large number
of cases.
Quick Check
(1) We colored each edge of K66 red, blue, green or yellow. Prove that
there will be a triangle with monochromatic edges.
(2) Consider the previous question again, but now with ﬁve colors. How
large should n be for the argument of the previous question to imply
that Kn contains a triangle with monochromatic edges?
(3) We colored each of the ten triangle subgraphs of K5 red or blue. Is it
always true that there will be a copy of K4 in which all four triangle
subgraphs are of the same color?

Does It Clique? Ramsey Theory
331
13.3
Ramsey Theory in Geometry
Example 13.13. Let us assume all points of the plane are colored either
red or blue. Prove that there exists a unit segment with monochromatic
endpoints.
This problem is certainly diﬀerent from all other problems discussed so
far. The number of points in the plane is inﬁnite, in fact, it is uncountably
inﬁnite.
All our previously discussed problems dealt with ﬁnite graphs.
Moreover, in this problem, and in what follows, we will state and prove
theorems of geometric nature, making our ﬁrst excursion to combinatorial
geometry.
Solution. (of Example 13.13) Take a regular triangle T with side length
one. Then by the pigeon-hole principle, T must have two vertices of the
same color. Those two vertices will form a segment with the required prop-
erty.
The statement of the previous example can be strengthened as follows.
Example 13.14. Let us assume that all points of the plane are colored
either red or blue or green. Prove that there exists a unit segment with
monochromatic endpoints.
Solution. Again, take any regular triangle T with side length 1, and ver-
tices A, B, C. If A, B, and C are not all of diﬀerent colors, then we are done.
If they are, then append another regular triangle T ′ with side length 1 to
one of the sides of T , say BC, as shown in Figure 13.3. Now the new vertex
D of T ′ must be the same color as A, say red, otherwise a monochromatic
unit segment is formed, either BD, or CD. Thus we have showed that the
segment AD, that is of length
√
3, has monochromatic (red) endpoints.
Note that we have not used any special property of T other than being
a regular triangle of unit side lengths.
Therefore, we could repeat this
argument for any regular triangle in the plane, and show this way that
all segments of length
√
3 have monochromatic endpoints, otherwise there
exists a unit segment with that property.
Finally, take any red vertex R, and take the circle k whose center is R,
and whose radius is
√
3. Then all points of k must be red, which means

332
A Walk Through Combinatorics
A
B
D
C
k
Fig. 13.3
All points of k must have the color of A.
that there is a unit segment with red endpoints. Indeed, k has radius
√
3,
so k certainly has arcs of unit length.
Example 13.15. We colored all the points of the plane either red or blue.
Let T be a triangle whose angles are equal to 30, 60, and 90 degrees, and
whose hypotenuse is of unit length. Prove that there exists a triangle with
monochromatic vertices that is congruent to T .
Solution. It follows from Example 13.13 that there exists a unit segment
with monochromatic vertices.
Call that segment s, and let us assume,
without loss of generality, that the endpoints A and B of s are red. Now
take the circle C with diameter s, and consider the four points D1, D2, D3,
and D4 so that A, B and these four points divide the perimeter of C into
six equal parts as shown in Figure 13.4.
If any of the Di is red, then we are done as A, B, and this red Di form
a monochromatic (red) triangle with the required parameters. If not, then
all the Di are blue, and they form four blue triangles with the required
parameters.

Does It Clique? Ramsey Theory
333
A
B
Red
Red
s
D
D
D
C
1
2
4
3
D
Fig. 13.4
The colors of the points Di are crucial.
Note that some of the problems in this section can be formulated in the
language of coloring the vertices of a graph. Let us take Example 13.14.
Deﬁne a graph G whose vertices are the points of the plane, and in which
two vertices are connected by an edge if their distance is equal to 1. Then
we are asked to show that the vertices of this graph cannot be colored by
three colors so that adjacent vertices are never monochromatic. Using our
deﬁnition from Chapter 11, this means that we are asked to prove that the
chromatic number of G is more than three. This fact is often expressed
(with a slight abuse of language) by the sentence the chromatic number of
the plane is more than three. So the chromatic number of the plane is at
least four. On the other hand, it is known that the chromatic number of
the plane is at most seven. See [37] for a proper 7-coloring of the plane. It
is not known whether the chromatic number of the plane is 4, 5, 6, or 7.
The same question can be asked for the space as well. In Exercise 8, you
are asked to prove that the chromatic number of the space is at least 5. In
2002, Oren Nechushtan [37] proved that the chromatic number of the space
is at least 6, while in 2003, G´eza T´oth and Rados Radoicic [42] proved that
it is at most 15.
Quick Check
(1) We color each point on the circumference of a circle red or blue. Prove
that there will be three points, A, B, and C, so that B is the midpoint
of the arc AC, oriented clockwise.
(2) Is it possible to color each point of the plane red or blue so that no

334
A Walk Through Combinatorics
square with unit side length and monochromatic vertices is formed?
(3) We color each point of the plane with integer coordinates using a ﬁnite
number of colors. Prove that all such colorings will contain a rectangle
with monochromatic vertices.
Notes
The ﬁrst textbook on Ramsey theory was “Ramsey Theory” by Ronald
Graham, Bruce Rothschild, and Joel Spencer, which has a recent edition
[28]. It is an advanced book. For questions of geometric ﬂavor, the reader
is encouraged to consult “Combinatorial geometry” [38] by J´anos Pach and
Pankaj Agarwal.
Finally, for questions related to coloring integers, the
most comprehensive source is “Ramsey theory on the integers”, by Bruce
Landman and Aaron Robertson [32].
Exercises
(1) Complete the proof of Theorem 13.10.
(2) Prove that in a permutation p of length nm + 1, there is either an
increasing subsequence of length n + 1, or a decreasing subsequence of
length m + 1. (The elements of the subsequences do not have to be in
consecutive positions in p.)
(3) Each point of the space is colored either red or blue. Prove that either
there is a unit square whose vertices are all blue, or there is a unit
square that has at least three red vertices.
(4) Let ABC be a regular triangle, and let E be the set containing all
points of the closed segments AB, AC, and BC. We color each point
of E red or blue. Prove that no matter what coloring we choose, there
will always be a right-angled triangle with monochromatic vertices.
(5) Eighteen teams participate at a round-robin soccer tournament. Prove
that after eight rounds are played, we can still ﬁnd three teams no two
of which have played each other yet.
(6) Let
nk = k!

1 + 1
1! + 1
2! + 1
3! + · · · + 1
k!

+ 1.
We color all edges of Knk with one of k colors. Prove that there will
be a triangle with monochromatic edges.
(7) Let n > 1 be a positive integer. Prove that R(n + 2, 3) > 3n.

Does It Clique? Ramsey Theory
335
(8) We colored each point of the space either red, or blue, or green, or yel-
low. Prove that there is a segment of unit length with monochromatic
vertices.
(9) Prove that it is possible to color each point of the plane either red, or
blue so that there is no regular triangle with sides of unit length and
monochromatic vertices.
(10) (+++) We colored each point of the plane either red, or blue. Let
T be any right-angled triangle. Prove that there is a triangle that is
congruent to T and has monochromatic vertices.
(11) We colored each point of the space either red or blue. Let T be a regular
triangle. Prove that there is a triangle that is congruent to T and has
monochromatic vertices.
(12) (+) We colored each point of the space either red or blue. Let T be
any triangle. Prove that there is a triangle that is congruent to T and
has monochromatic vertices.
(13) (++) We colored each point of the space either red or blue or green.
Let T be as in Example 13.15. Prove that there is a triangle that is
congruent to T and has monochromatic vertices.
(14) (+++) We colored each point of the space either red or blue or green.
Let T be any right-angled triangle. Prove that there is a triangle that
is congruent to T and has monochromatic vertices.
(15) A company has 2000 employees, from six diﬀerent countries.
Each
employee has a company identiﬁcation card (ID), and these cards are
numbered from 1 to 2000. Prove that there is either an employee whose
ID number is equal to the sum of the ID numbers of two of his compa-
triots, or there is an employee whose ID number is twice that of one of
his compatriots.
(16) Let us color each positive integer by one of the colors 1, 2, · · · , k. Prove
that there exists an integer N = N(k) so that if n > N, then there
are three integers a, b, c that are less than n, are of the same color, and
satisfy a + b = c. (We allow a = b.)
(17) Let N(k) be deﬁned as in the previous exercise. Determine N(2).
(18) Prove that N(3) > 13.
Supplementary Exercises
(19) The following are true for the n guests of a Christmas party.
• In any group of three guests, there are two guests who do not know

336
A Walk Through Combinatorics
each other, and
• in any groups of seven guests, there are two guests who do know
each other.
At the end of the party, everyone gives a present to all the guests he
or she knows. Prove that the total number of gifts given is at most
6n.
(20) Prove that if we color the edges of K6 red or blue, then there will be
at least two triangles with monochromatic edges.
(21) Prove that if we color the edges of K9 red or blue, then we will get at
least twelve triangles with monochromatic edges.
(22) Prove that there do not exist three irrational numbers so that no
matter how we choose two of them, their sum is always rational.
(23) Let k and n be positive integers satisfying 1 ≤k < n. Prove that there
do not exist n irrational numbers so that no matter how we choose k
of them, their sum is always rational.
(24) There are nine passengers on a bus. Among any three of them, there
are two who know each other. Prove that there are ﬁve people on the
bus who know at least four of the other passengers.
(25) Continuing the previous exercise, is it true that there are ﬁve people
on the bus who all know each other?
(26) Is it true that on the bus of Exercise 24 there are always six people
who know at least four others?
(27) Generalize Exercise 24 for a bus with 2n + 1 passengers, keeping the
condition that among any three of them, there are two who know each
other.
(28) Five vertices of a regular 10-gon are colored red, and ﬁve are colored
blue. Prove that there is a triangle T1 with red vertices and a triangle
T2 with blue vertices that are congruent.
(29) Each vertex of a regular 13-gon is colored either red or blue. Prove
that there exists an isosceles triangle with monochromatic vertices.
(30) We colored the edges of K6 red or blue. Prove that there is a cycle of
length four with monochromatic edges.
(31) We colored the edges of K7 red or blue. Prove that there are at least
three cycles of length four with monochromatic edges.
(32) Prove that R(3, 5) = 14.
(33)(a) (+) Let Tm be any tree on m vertices. Let us color all vertices of
K(m−1)(n−1)+1 red or blue. Prove that there will be either a copy
of Tm with all edges red, or a copy of Kn, with all edges blue.

Does It Clique? Ramsey Theory
337
(b) Prove that the result of part (a) is optimal.
(34) We color each vertex of the plane red or blue.
Let n ≥3 be an
integer. Prove that there exist n points so that all these points and
their centroid have the same color.
Try to ﬁnd a proof that only
considers 2n + 1 points. (Recall that the centroid of a set of n points
in a (vector) space, viewed as the vectors v1, v2, · · · , vn is the point
given by the vector (v1 + v2 + · · · + vn)/n.)
(35) We color each point of the n-dimensional plane having integer coordi-
nates red or blue. Prove that there will be a segment with monochro-
matic vertices whose centroid has the same color as its two endpoints.
(36) Prove that the statement of Exercise 34 remains true even if we only
color the vertices of the plane that have integer coordinates.
(37) Prove that for all integers n ≥1, there exists a permutation of length
n that does not contain an arithmetic progression of length 3. Note
that an arithmetic progression can be increasing or decreasing.
(38) Prove that each permutation of the set of all positive integers contains
an increasing arithmetic progression of length three. (A permutation
of an inﬁnite set S is an arrangement of all the elements of S in a
line.)
Solutions to Exercises
(1) Proceed as in the proof provided in the text, except for the choice
of N. Set N = R(n1 −1, n2, · · · , nk) + R(n1, n2 −1, n3, · · · , nk) +
· · · + R(n1, n2, · · · , nk −1) −k + 2. Then it follows by the Pigeon-
hole Principle that there exists an i ∈[k] so that there are at least
R(n1, · · · , ni−1, · · · , nk) edges adjacent to V that are colored i. Then
the proof is completed as in the text.
(2) Let p = p1p2 · · · pnm+1, and let ai denote the length of the longest
increasing subsequence ending in pi. Similarly, let bi denote the length
of the longest decreasing subsequence ending in pi. It is then clear
that if i ̸= j, then the ordered pairs (ai, bi) and (aj, bj) are diﬀerent.
Indeed, either pi < pj, and then ai < aj, or pi > pj, and then bi < bj.
Thus we have nm+1 diﬀerent ordered pairs, and the statement follows
by the pigeon-hole principle.
(3) First assume that there is no segment of length b =
√
2 whose end-
points are both red. Then take any red point, and take the sphere S
of radius b that is centered at that point. Clearly, S consists of blue

338
A Walk Through Combinatorics
points only, and therefore, any unit square on S has four blue vertices.
Now let us assume that there is a segment AB that is of length b
and has two red endpoints.
Take the circle C whose center is the
midpoint of AB, whose radius is b/2, and that lies in the plane that
is perpendicular to AB. If any point P of C is red, then the triangle
ABP has three red vertices, and can be completed to a unit square. If
not, then C consists of blue points only, and contains inﬁnitely many
unit squares.
(4) Denote by C1 and C2 the points that divide the segment AB into three
equal parts. Deﬁne A1, A2, B1, and B2 analogously. There are at least
two points among A1, B1, and C1 that are of the same color; we can
assume without loss of generality that A1 and B1 are both red. Now
assume there is no right-angled triangle with monochromatic vertices.
Then C and B2 must both be blue. Then we cannot ﬁnd a color for
C2. If C2 is blue, then the triangle CB2C2 has three blue vertices,
and if C2 is red, then the triangle A1B1C2 has three red vertices. So
in any case, a triangle with monochromatic vertices is formed.
(5) Let us consider a K18 whose vertices correspond to the eighteen teams.
After eight rounds have been played, we color the edge between two
teams red if they have met, and blue if they have not. We have to
show there is a blue triangle in our graph. Take any team A, and
look at the nine teams A has not played yet. If there are two teams
B and C among them that have not met yet, then ABC is a blue
triangle, and we are done. If there were no two such teams, that would
mean that any two of the nine teams that have not played A have
played each other, in other words, these teams completed a round-
robin tournament among themselves. However, that is impossible for
nine teams in just eight rounds. Indeed, in one round, they could only
play 4 games among themselves, therefore in eight rounds, they could
play at most 32. That is less than the total number of
9
2

= 36 games
needed for a round robin tournament with nine teams.
(6) We prove the statement by induction on k. If k = 1, then nk = 3,
and if we color the edges of a triangle by one color, then of course this
triangle will have monochromatic edges.
Now assume that the statement is true for k, and prove it for k + 1.
Take a complete graph on nk+1 vertices, and select one of its vertices,
say V . Then all edges adjacent to V are colored by one of k+1 colors.
It is easy to verify that
(k + 1)(nk −1) = nk+1 −2 < nk+1 −1,

Does It Clique? Ramsey Theory
339
so it follows by pigeon-hole principle that at least nk of these edges
are of the same color, say black. Let B be the set of the vertices that
are connected to B by a black edge. If there is a black edge joining
two vertices X and Y of B, then XY V is a triangle with all edges
black. If there is no such X and Y , then all edges within B are of one
of the remaining k colors. As B has at least nk edges, the statement
follows by the induction hypothesis.
(7) It suﬃces to construct one graph G on 3n vertices that does not con-
tain a Kn+2, but among any three of its vertices, there are two that
are adjacent (so the complement of G does not contain a triangle).
Such a G can be given as follows. Let the vertex set of G be [3n], and
draw these vertices around a cycle in increasing order. Connect i to
its n left and n right “neighbors” along the cycle. This means that
two vertices are joined if their diﬀerence is either at most n or at least
2n. However, Exercise 11 of Chapter 1 shows that no matter how we
choose n of these vertices, there will be two of them with diﬀerence
more than n but less than 2n. So G cannot contain a Kn+2.
It is easy to see that among any three vertices of G, there are two that
are adjacent. Indeed, let a < b < c be three vertices. If neither ab nor
bc is an edge, then we must have b −a > n, and also c −b > n, which
implies c −a > 2n, and therefore ac is an edge.
(8) This is a generalization of Example 13.14 to three dimensions. Sup-
pose there is no such segment. Take a regular tetrahedron ABCD
with sides of unit length. This tetrahedron must have vertices of four
diﬀerent colors. Say A is red, and append another regular tetrahedron
BCDE to the triangle BCD. Then E must also be red, otherwise it
would agree in color with one of B, C and D.
So if m is the altitude of a regular tetrahedron, then all vertices of
length 2m have to be of the same color. In particular, the sphere
whose center is A and radius is 2m must be red. However, there are
pairs of points on that sphere whose two points are at a unit distance
from each other, and therefore the claim is proved.
(9) For shortness, let m =
√
3/2, and note that m is the altitude of such
a regular triangle. Color a point (x, y) red if [y/m] is even, and blue
if [y/m] is odd. We get monochromatic stripes of width m so that
no triangle of the required size ﬁts within one stripe, and no triangle
of the required size is large enough to have vertices in two diﬀerent
stripes of the same color.
(10) This result is due to Leslie E. Shader, and can be found in the article

340
A Walk Through Combinatorics
All right triangles are Ramsey in the plane, Journal of Combinatorial
Theory, Series A, 20 (1976), 385–390.
(11) Let us assume that there is no such triangle. Choose the side length
of T to be the unit length. Let AB be a unit segment with monochro-
matic vertices. We can then assume without loss of generality that A
and B are both red.
Take a regular triangle ABC, and rotate it around its side AB. Then
images of the vertex C form a circle c. Clearly, all points on c must
be blue. The radius of c is
√
3/2, therefore c has pairs of points at
distance 1 from each other. Let D and E be two such points. Then
we can repeat the previous argument. That is, take a regular triangle
DEF and rotate it around its side DE. The rotated images of the
vertex F form a circle f, and they must all be red. If we do this for
all possible choices of D and E, we get a torus that consists of red
points only, and it is easy to see that this torus will contain a regular
triangle with sides of unit length.
(12) This result can be found in P. Erd˝os, R. L. Graham, P. Montgomery,
B. L. Rothschild, J. H. Spencer and E. G. Straus: Euclidean Ramsey
theorems I, Journal of Combinatorial Theory, Series A, 14 (1973),
341–363.
(13) This problem can be solved with methods similar to Example 13.15.
For a full solution, see M. B´ona: A Euclidean Ramsey theorem, Dis-
crete Mathematics, 122 (1993), 349–352.
(14) The solution of this problem can be found in M. B´ona, G. T´oth,
A Ramsey-type problem on right-angled triangles in space. Selected
papers in honor of Paul Erd˝os on the occasion of his 80th birthday
(Keszthely, 1993). Discrete Math. 150 (1996), no. 1-3, 61–67.
(15) Take a complete graph on 2000 vertices, and let the edge between
vertices i and j (where i < j) be of color k if the person with ID
number j −i is of country k. This deﬁnes a coloring of K2000 by six
colors. Keeping the notation of Exercise 6, we have n6 = 1958, so
there will be a triangle with monochromatic edges. Let the vertices of
this triangle be a < b < c. Then people with ID numbers c −a, c −b,
and b −a are all from the same country. As (b −a) + (c −b) = c −a,
our claim is proved. (If b −a and c −b are diﬀerent, then the ﬁrst
criterion is satisﬁed, and if b −a and c −b are equal, then the second
criterion is satisﬁed.)
(16) Denote by C the given coloring of the positive integers.
Take the
complete graph KN whose vertex set is [N], and whose edges are k-

Does It Clique? Ramsey Theory
341
colored as follows. The edge between x and y is of the color of the
integer |x −y| in C. It follows from Theorem 13.10 that if N is large
enough, then any, and therefore, this, k-coloring of KN contains a
triangle with monochromatic edges. Let that triangle have vertices
x < y < z. Then we know that y −x, z −y, and z −x have the same
color in C, so they can play the role of a, b, and c.
(17) We prove that N(2) = 5. Indeed, try to 2-color [5] without creating a
monochromatic triple so that a+ b = c. Let us assume without loss of
generality that 1 is red, then 2 is blue (for 1 + 1 = 2), and 4 is red (for
2 + 2 = 4). Then 3 must be blue (for 1+3=4), and then we cannot
ﬁnd a color for 5, as 5 = 1 + 4 = 2 + 3. Therefore, N(2) ≤5. On
the other hand, we have just seen that R, B, B, R is a 2-coloring of
[4] without a monochromatic triple of the desired kind. This proves
N(2) = 5.
(18) We show a 3-coloring of [13] without a monochromatic triple of the
desired kind. Denote by R, B, and G the red, blue, and green color.
Then R, B, B, R, G, G, G, G, G, G, B, B, R is a good coloring.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 14
So Hard To Avoid. Subsequence
Conditions on Permutations
14.1
Pattern Avoidance
Let us assume that there are n children playing in our backyard, no two
of whom have the same height. For the next game, they need to stand in
a line so that everyone faces the back of the preceding person. Moreover,
each child must be able to see all children that are shorter than him and
precede him in the line. How many such lineups exist?
At this point, the reader certainly suspects that we will have to enumer-
ate permutations of [n] with some new conditions. Let 1, 2, · · · , n denote
the children playing in our backyard, in increasing order of height, so 1 is
the shortest and n is the tallest.
Would for example 1423567 be a good lineup for n = 7? No, it would
not, as 2 or 3 could not see 1, even if he is smaller than them and precedes
them. They could not see him as their view would be blocked by 4, who is
taller than them. On the other hand 6723415 would be a good lineup.
So when is a lineup good? It is good if there are no three elements a, b, c
so that they are in this order (but not necessarily in consecutive positions),
and a < c < b. Indeed, if there were three elements like that, then b could
not see a.
The enumeration of permutations with subsequence conditions like this
is a very active area of contemporary combinatorics. Before we continue,
we make two deﬁnitions to simplify our arguments.
Deﬁnition 14.1. Let a, b, and c be three entries of a permutation that
follow in this order from left to right, but are not necessarily consecutive.
If a < c < b, then we say that the entries a, b, and c form a 132-pattern.
Why do we call this structure a 132-pattern? Because the entries a,
343

344
A Walk Through Combinatorics
3
5
6
1
2
4
7
Fig. 14.1
The permutation 3561247 contains the pattern 132.
b, and c relate to each other the same way as the numbers 1, 3, and 2.
That is, the leftmost one is the smallest, and the middle one is the largest.
Similarly, if we had a < b < c, then we would say that the entries a, b, and
c form a 123-pattern, and if we had c < a < b, then we would say that the
entries a, b, and c form a 231-pattern.
Deﬁnition 14.2. Let p be a permutation. If there are no three entries in
p that form a 132-pattern, then p is called 132-avoiding.
Our task is therefore to ﬁnd the number f(n) of permutations of length
n (or, in what follows, n-permutations) that are 132-avoiding.
Let us suppose that we have a 132-avoiding n-permutation in which the
entry n is in the ith position. Then we claim that any entry to the left of
n must be larger than any entry to the right of n. In order to see this, let
us assume the contrary is true, that is, there is an entry x on the left of n
and an entry y on the right of n so that x < y. Then the entries x, n, and
y form a 132-pattern, which is a contradiction. This implies that entries
1, 2, · · · , n−i are on the right of n, and entries n−i+1, n−i+2, · · · , n−1
are on the left of n. Now the i −1 entries on the left of n must also form a
132-avoiding permutation, which they can do in f(i −1) ways. Similarly,
the n −i entries on the right of n must form a 132-avoiding permutation,
and they can do it in f(n −i) ways. So there are exactly f(i −1)f(n −i)
132-avoiding n-permutations in which n is in the ith position. Here we set
f(0) = 1, in order to make the recurrence work.

So Hard To Avoid. Subsequence Conditions on Permutations
345
Summing over all i ∈[n] (as n can be in any position) we get the
recurrence relation for
f(n) =
n

i=1
f(i −1)f(n −i),
(14.1)
if n ≥1, and f(0) = 1.
We have met this recurrence relation before, in formula (8.19), when we
solved Exercise 16 of Chapter 8. We solved that recurrence relation using
generating functions. The conclusion was that the solution of (8.19), and,
equivalently, of (14.1) is the sequence of Catalan numbers.
Corollary 14.3. The number of permutations of length n that avoid the
pattern 132 is cn =
2n
n

/(n + 1), which is the nth Catalan number.
So we know that the number of n-permutations avoiding the pattern 132
is cn =
2n
n

/(n+1). How about the number of permutations avoiding other
patterns? Before addressing that question, let us formally announce the
deﬁnition of pattern avoidance for general patterns, even if we mentioned
it in the text before.
Deﬁnition 14.4. Let p be an n-permutation, and let q = q1q2 · · · qk be a
k-permutation, with n ≥k. Let us choose k entries of p, and denote them
by a1, a2, · · · , ak, as they follow from left to right. If qi < qj exactly for
those indices i and j for which ai < aj, then we say that the elements
a1, a2, · · · , ak form a q-pattern.
Deﬁnition 14.5. Let p be an n-permutation, and let q = q1q2 · · · qk be a
k-permutation, with n ≥k. If no k entries of p form a q-pattern, then we
say that p is a q-avoiding permutation.
The number of q-avoiding n-permutations is denoted by Sn(q), or, in
more recent literature, Avn(q).
Let us return to our main task of determining Sn(q) for patterns other
than 132. We start with patterns of length three as the problem is trivial
for shorter patterns.
We claim that Sn(231) = Sn(132). Indeed, note that 231 is precisely
the reverse of 132. So if an n-permutation avoids 132, its reverse avoids
231, and vice versa. This sets up a natural bijection between the set of
132-avoiding n-permutations, and that of 231-avoiding n-permutations.
We also claim that Sn(312) = Sn(132). To see this, deﬁne the comple-
ment of an n-permutation p = p1p2 · · · pn to be the n-permutation ¯p whose

346
A Walk Through Combinatorics
ﬁrst entry is n + 1 −p1, whose second entry is n + 1 −p2, and in general,
whose ith entry is n + 1 −pi. So for example, the complement of 34152 is
32514.
Now observe that 312 is the complement of 132. Moreover, note that if p
avoids 312, then pc avoids 132, and vice versa, proving Sn(312) = Sn(132).
So far we have seen that Sn(132) = Sn(231) = Sn(312). It is easy to
extend this chain of equalities one further. Indeed, 213 is the reverse of
312, so Sn(132) = Sn(231) = Sn(312) = Sn(213).
There are two more patterns of length three, namely 123 and 321. It
is clear by taking reverses, or by taking complements, that Sn(123) =
Sn(321).
This leaves us with one last question.
Is it also true that
Sn(123) = Sn(132)?
If it is, that means that all permutation patterns
of length three are avoided by the same number of n-permutations, and
this number is cn, the nth Catalan number. The answer to this question
is in the aﬃrmative. The proof of this is slightly harder than the previous
symmetry arguments, and is the content of the following Lemma.
Lemma 14.6. For all positive integers n, the equality
Sn(123) = Sn(132)
holds.
We need some machinery before we start proving this Lemma. Recall
that an entry of a permutation which is smaller than all the entries that
precede it is called a left-to-right minimum.
Note that the left-to-right
minima of a permutation form a decreasing subsequence.
For example,
in the permutation 4531762, the entries 4, 3, and 1 are the left-to-right
minima. Note that the leftmost entry, and the entry 1 are always left-to-
right minima.
Proof. (of Lemma 14.6) We will construct a bijection f from the set
of all 123-avoiding n-permutations onto the set of all 132-avoiding n-
permutations which leaves all left-to-right minima ﬁxed. (This last property
is not needed for the proof of our Lemma, but it will be useful later.)
The bijection f is deﬁned as follows.
We take any 123-avoiding n-
permutation p, ﬁx all its left-to-right minima, and remove all the elements
that are not left-to-right minima, leaving their places empty. Then going
from the left to the right, we put the elements which are not left-to-right
minima into the empty slots between the left-to-right minima so that in
each step we place the smallest element we have not placed yet which is

So Hard To Avoid. Subsequence Conditions on Permutations
347
larger than the previous left-to-right minimum. In other words, in each
step, we place the smallest entry that is both available (that is, it is not
a left-to-right minimum) and eligible (that is, it is not smaller than the
previous left-to-right minimum). The reader is invited to verify that there
is always at least one such entry, so the process will never get stuck.
For example, if p = 4 6 5 1 3 2, then the left-to-right minima are the
entries 4 and 1, thus we leave them in the ﬁrst and fourth positions. The
ﬁrst empty slot is the second position and we put there the smallest entry
which is larger than 4, that is to say, the entry 5. Similarly, we put 6 to the
third position as it is the smallest of the entries not yet used which is larger
than 4 (in fact, this is the only such entry). Then by the same reasoning
we put 2 into the ﬁfth position and 3 into the sixth position. This way we
get the permutation f(p) = 4 5 6 1 2 3.
Note that f(p) is 132-avoiding, because if there were a 132-pattern in
f(p), then there would be one which starts with a left-to-right minimum,
but that is impossible as elements larger than any given left-to-right mini-
mum and to the right of it are written in increasing order.
The inverse of f is even easier to describe: keep the left-to-right minima
of p ﬁxed and put all the other elements into the empty slots between them
in decreasing order. Note that this procedure will not change the set of left-
to-right minima of p (why?). We obtain a permutation which is the union
of two decreasing subsequences and is therefore 123-avoiding. If we apply
this operation to f(p), then we must get p back, as the left-to-right minima
have not changed, and the other elements must have been in decreasing
order in p, otherwise p would not have been 123-avoiding. This completes
the proof of the lemma.
Theorem 14.7. Let q be any permutation pattern of length three. Then
for all positive integers n,
Sn(q) = cn =
2n
n

n + 1.
Proof. Lemma 14.6 and the preceding easy symmetry arguments show
that Sn(q) is the same for all patterns q of length three. As we know that
Sn(132) = cn, the statement follows.
So we can enumerate permutations avoiding a given pattern q if the
length of q is three. However, for longer patterns q, the problem becomes
harder at a drastic speed. There are very few patterns q such that an exact
formula is known for Sn(q). To see one of the reasons for this, consider

348
A Walk Through Combinatorics
patterns of length four. There are 24 of them, but using reverses, comple-
ments, and some less obvious tricks, one can deduce that there are only
three of them that are really diﬀerent, namely 1234, 1342, and 1324. Com-
puter calculations provide the following fascinating numerical evidence for
these patterns (the values of Sn(q), for n ≤8).
• for Sn(1342): 1, 2, 6, 23, 103, 512, 2740, 15485
• for Sn(1234): 1, 2, 6, 23, 103, 513, 2761, 15767
• for Sn(1324): 1, 2, 6, 23, 103, 513, 2762, 15793.
We see that unlike for patterns of length three, it is no longer true here
that Sn(q) does not depend on q. It also seems that for n ≥7,
Sn(1342) < Sn(1234) < Sn(1324).
This is actually true. It is very surprising, and not well understood, that
the monotone increasing pattern is in the middle of this chain. It would
have been plausible to think that the monotonic pattern is the easiest, or
the hardest, to avoid.
We prove the second part of this inequality. The ﬁrst part follows from
Exercise 7.
Theorem 14.8. For all n ≥7, the inequality Sn(1234) < Sn(1324) holds.
Proof. We are going to classify all permutations of n according to the
set and position of their left-to-right minima and right-to-left maxima. A
right-to-left maximum is an entry that is larger than all entries on its right.
This is the content of the following deﬁnition.
Deﬁnition 14.9. Two permutations x and y are said to be in the same
class if
• the left-to-right minima of x are the same as those of y, and
• the left-to-right minima of x are in the same positions as the left-to-
right minima of y, and
• the same holds for the right-to-left maxima.
For example, x = 5 1 2 3 4 and y = 5 1 3 2 4 are in the same class, but
z = 2 4 3 1 5 and v = 2 4 1 3 5 are not, as the third entry of z is not a
left-to-right minimum whereas that of v is.
The outline of our proof is going to be as follows: we show that each
nonempty class contains exactly one 1234-avoiding permutation and at least

So Hard To Avoid. Subsequence Conditions on Permutations
349
one 1324-avoiding permutation. Then we exhibit some classes which contain
more than one 1324-avoiding permutation and complete the proof.
Lemma 14.10. Each nonempty class contains exactly one 1234-avoiding
permutation.
Proof. Let us assume that we have already picked a class, that is, we ﬁxed
the positions and values of all the left-to-right minima and right-to-left max-
ima. We claim that if we put all the remaining elements into the remaining
slots in decreasing order, then we get a 1234-avoiding permutation.
Indeed, the permutation obtained this way consists of three decreasing
subsequences, that is, the left-to-right minima, the right-to-left maxima,
and the remaining entries. If there were a 1234-pattern in this permutation,
then by the Pigeon-hole Principle two of its entries would be in the same
decreasing subsequence, which would be a contradiction.
On the other
hand, if two of these elements, say a and b, were in increasing order, then
together with the rightmost left-to-right minimum on the left of a and the
leftmost right-to-left maximum on the right of b they would form a 1234-
pattern. Finally, if the chosen class is nonempty, then we can indeed write
the remaining numbers in decreasing order without conﬂicting with the
existing constraints— otherwise the class would be empty. (In other words
it is the decreasing order of the remaining elements that violates the least
number of constraints.)
Now comes the harder part. Recall that an inversion in a permutation
p = p1p2 · · · pn is a pair (pi, pj) so that i < j but pi > pj.
Lemma 14.11. Each nonempty class contains at least one 1324-avoiding
permutation.
Proof. First note that if a permutation contains a 1324-pattern, then we
can choose such a pattern so that its ﬁrst element is a left-to-right minimum
and its last element is a right-to-left maximum. Indeed, we can just take
any existing pattern and replace its ﬁrst (last) element by its closest left
(right) neighbor which is a left-to-right minimum (right-to-left maximum).
Therefore, to show that a permutation avoids 1324, it is suﬃcient to show
that it does not contain a 1324-pattern having a left-to-right minimum for
its ﬁrst element and a right-to-left maximum for its last element. (Such
a pattern will be called a good pattern.)
Also note that a left-to-right
minimum (right-to-left maximum) can only be the ﬁrst (last) element of a
1324-pattern.

350
A Walk Through Combinatorics
Now take any 1324-containing permutation. By the above argument, it
has a good pattern. Interchange its second and third elements. Observe
that we can do this without violating the existing constraints, that is, no
element x goes on the left of a left-to-right minimum y such that x < y,
and no element x goes on the right of a right-to-left maximum z such that
z < x. The resulting permutation is in the same class as the original because
the left-to-right minima and right-to-left maxima have not been changed.
Let us repeat this procedure as long as we can. Note that each step of
the procedure decreases the number of inversions of our permutation by at
least 1. Therefore, we will have to stop after at most
n
2

steps. Then the
resulting permutation will be in the same class as the original one, but it
will have no good pattern and therefore no 1324-pattern, as we claimed.
Notation (by example): in what follows, we write a1 ∗a2 ∗∗b1 for
the class of permutations of length six which have two left-to-right minima,
a1 and a2, which are in the ﬁrst and third position, and one right-to-left
maximum, b1, which is in the last position.
Finally, we must show that “at least one” in the above lemma does not
always mean exactly one. If n = 7, then the class 3 ∗1 ∗7 ∗5 contains
two 1324-avoiding permutations, 3 6 1 2 7 4 5 and 3 4 1 6 7 2 5. This proves
S7(1234) < S7(1324). For larger n we can extend this example in an easy
way, such as taking the class n (n −1) · · · 8 3 ∗1 ∗7 ∗5. This shows
that there are more 1324-avoiding permutations than 1234-avoiding ones
and completes the proof of the theorem.
As we said, there are very few patterns q that are longer than three
so that an exact formula is known for Sn(q).
Therefore, even good ap-
proximations or upper bounds for Sn(q) would be interesting. The famous
Stanley–Wilf conjecture claimed that for any pattern q, there exists a con-
stant cq so that Sn(q) ≤cn
q for all n. This conjecture resisted numerous
solution attempts in the last twenty years. Finally, the conjecture has been
proved [36] using a spectacular argument, by Adam Marcus and G´abor
Tardos in 2003. The best possible value of the constant cq is still unknown.
(The Marcus-Tardos proof, beautiful as it is, does not provide a constant
that would seem to be close to the actually needed value of cq.)
In some special cases, however, we can ﬁnd a small constant cq so that
Sn(q) ≤cn
q for all n. The easiest case is when q is monotonic.
Theorem 14.12. For all positive integers k ≤n, the inequality
Sn(1234 · · ·k) ≤(k −1)2n

So Hard To Avoid. Subsequence Conditions on Permutations
351
holds.
Proof. Let us say that an entry x of a permutation is of rank i if x is the
top of a rising subsequence of length i, but there is no rising subsequence
of length i + 1 whose top is x. Then for all i, elements of rank i must
form a descending subsequence. Therefore, a q-avoiding permutation can
be decomposed into the union of k −1 descending subsequences. There are
(k −1)n ways to partition the elements into k −1 classes and there are
less than (k −1)n ways to assign each position to one of the subsequences,
completing the proof.
Note that this result is completely in line with our earlier results, show-
ing that Sn(123) = cn < 4n.
Additional patterns q for which an exact formula is known for Sn(q)
will be mentioned in the Notes. We conclude this section by presenting a
recursive result. We will need the following deﬁnition.
Deﬁnition 14.13. Let p ∈Sa, and q ∈Sb, with p = p1p2 · · · pa and
q = q1q2 · · · qb. Then the direct sum of p and q is the pattern p ⊕q ∈Sa+b
where
(p ⊕q)i =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
pi
if i ≤a ,
qi−a + a
if i > a.
In other words, we increase each entry of q by a before placing q after
p.
Example 14.14. If p = 132 and q = 2431, then p ⊕q = 1325764.
Now we are in a position to announce and prove the recursive result
that we promised.
Theorem 14.15. Let q1 and q2 be patterns so that Sn(q1 ⊕1) ≤cn
1 for all
n, and that Sn(1 ⊕q2) ≤cn
2 for all n. Then
Sn(q1 ⊕1 ⊕q2) ≤(√c1 + √c2)2n
for all n.
Example 14.16. Let q1 = 213, and let q2 = 132. Then Exercise 32 and
Theorem 14.12 imply that Sn(q1 ⊕1) = Sn(2134) < 9n, and also, Sn(1 ⊕
q2) = Sn(1243) < 9n. Therefore,
Sn(q1 ⊕1 ⊕q2) ≤(3 + 3)2n = 36n.

352
A Walk Through Combinatorics
Proof. (of Theorem 14.15) Let p ∈Sn be a permutation that avoids q =
q1 ⊕1 ⊕q2. Color all entries of p that can play the role of the last (and
largest) entry of a q1 ⊕1-pattern red, and color all other entries blue.
Then the string of all red entries must avoid 1 ⊕q2. Indeed, if did not,
then any copy C of 1 ⊕q2 made up by red entries could be turned into a
copy of q by using the entries on the left of C that make the leftmost entry
of C red. (This is the point where we use the structure of q = q1 ⊕1 ⊕q2,
that is, the property that each entry in the ﬁrst part is smaller than each
entry in the second part.)
Furthermore, the string of blue entries must be (q1⊕1)-avoiding. Indeed,
if it contained a copy D of that pattern, then the last entry of that pattern
would have to be a red entry, which would be a contradiction.
Therefore, if there are k blue entries and n −k red entries, then there
are at most
n
k
2ck
1cn−k
2
permutations of length n that avoid q.
Indeed,
there are at most
n
k

possibilities for the set of blue entries, and the same
number of possibilities for the positions of these entries. Summing over all
k, this yields
Sn(q) ≤
n

k=1
n
k
2
ck
1cn−k
2
≤
 n

k=1
n
k

ck
1cn−k
2
2
≤(√c1 + √c2)2n.
We have used the fact that the sum of the squares of positive real numbers
is at most as large as the square of their sum, as well as the Binomial
Theorem.
Quick Check
(1) Find a formula for the number of 132-avoiding permutations of length
n that start with a descent.
(2) Find a formula for the number of 123-avoiding permutations of length
n that start with an ascent.
(3) Find two patterns q and q′ that are both of length more than two so
that if the permutation p avoids both q and q′, then p is necessarily
an involution.

So Hard To Avoid. Subsequence Conditions on Permutations
353
14.2
Stack Sortable Permutations
The initial setup of our topic for this section sounds similar to the well-
known game of Hanoi towers. Let us assume that we have a permutation
p = p1p2 · · · pn and we want to sort its entries, to get the identity permuta-
tion 12 · · ·n. Our only tool is a stack, a vertical array that can hold entries
in increasing order, that is, the smallest one on top, and the largest one at
the bottom.
The numbers enter the stack in the order in which they occur in the
input permutation p. We take p1, and put it in the stack. Now take p2. If
p2 < p1, then it is allowed for p2 to go in the stack on top of p1, so we will
put it there. If p2 > p1, however, then ﬁrst we take p1 out of the stack,
and put it to the ﬁrst position of the output permutation, and put p2 into
the stack. We continue this way: at step i, we compare pi with the element
r = pai−1 currently on top of the stack. If pi < r, then pi goes on the top of
the stack, if not, then r goes to the leftmost empty position of the output
permutation, and pi gets compared to the new element that is currently on
the top of the stack. The algorithm ends when all n entries passed through
the stack and are in the output permutation s(p). See Figure 14.2 for an
example of this procedure.
Example 14.17. Let p = 2413. Then the stages of our sorting procedure
are shown in Figure 14.2.
If the image s(p) of p under this stack sorting operation is the identity
permutation, then we say that p is stack sortable. So the previous example
shows that 2413 is not stack sortable.
Which permutations are stack sortable? To answer this natural ques-
tion, we ﬁrst analyze the eﬀect of the stack sorting operation s to pairs of
entries in p.
Proposition 14.18. Let p be a permutation, and let a < b be two entries
of p. Then
(1) if a precedes b in p, then a precedes b in s(p),
(2) if b precedes a in p, and there is no element c located between a and b
in p so that c > b > a, then a precedes b in s(p),
(3) if b precedes a in p, and there is an element c located between a and b
in p so that c > b > a, then b precedes a in s(p). Note that this happens
when the entries a, b, and c form a 231-pattern.

354
A Walk Through Combinatorics
      INPUT                                          STACK                                    OUTPUT
2413
413
2
413
2
13
4
2
3
1
4
2
3
21
4
3
4
21
213
4
2134
Fig. 14.2
Sorting 2413.
Proof. (1) As a precedes b in p, a will enter the stack before b. As a < b,
this means that b cannot even enter (let alone, leave) the stack before
a does, so a precedes b in s(p).
(2) In this case the string of p between b and a is a decreasing subsequence
S. The elements of S enter the stack starting with b, then they pile
up on top of each other, with a entering the stack last, and getting
therefore to the top of the stack. So a will be the ﬁrst element of S to
leave the stack. In particular, a leaves the stack before b, and thus a
precedes b in s(p).
(3) In this case, b has to leave the stack before c enters it. On the other
hand, c has to enter the stack before a does. Therefore, b leaves the
stack before a could even enter it, so b precedes a in s(p).
Theorem 14.19. A permutation p is stack sortable if and only if it avoids
the pattern 231.
Proof. If there is a 231-pattern in p, formed by the entries a < b < c, then
part 3 of the previous Proposition shows that b will precede a in s(p), so

So Hard To Avoid. Subsequence Conditions on Permutations
355
s(p) cannot be the identity permutation. If there is no 231-pattern in p,
then any pair a < b of entries falls either into part 1, or into part 2 of the
previous proposition, and will therefore be sorted.
So most permutations are not stack sortable. To increase the number
of permutations that can be sorted using our stack, we can take s(p), and
pass it through the stack again, following the same rules. If the obtained
permutation s(s(p)) is the identity permutation, then we say that p is two-
stack sortable.
Two-stack sortable permutations are more diﬃcult to characterize, let
alone enumerate, than stack sortable permutations. One reason for this
diﬃculty is that the two-stack sortable property is not monotonic. That is,
there are instances when p is two-stack sortable, but a subsequence p′ of p
is not.
Example 14.20. Let p = 35241. Then s(p) = 32145, and s(s(p)) = 12345,
so p is two-stack sortable. Now let p′ = 3241. Then s(p′) = 2314, and
s(s(p′)) = 2134, so p′ is not two-stack sortable.
For this reason, we cannot hope for a characterization of two-stack
sortable permutations by pattern avoidance only. However, we can still
use a similar concept if we stretch the deﬁnition of pattern avoidance a
little bit.
Theorem 14.21. A permutation p is two-stack sortable if and only if it
does not contain a 2341-pattern, and it does not contain a 3241-pattern,
except as a part of a 35241-pattern.
Proof. First we prove the “only if” part. Assume entries a < b < c < d of p
form a 2341 pattern. Then it follows from Proposition 14.18 that entries a,
b, and c form a 231-pattern in s(p), implying that s(p) is not stack sortable.
Now assume that entries w < x < y < z form a 3241-pattern in p that
is not part of a 35241-pattern. Proposition 14.18 then implies that both
x and y precede w in s(p). If there are no entries between x and y in p
that are larger than both of them, then Proposition 14.18 also implies that
x precedes y in s(p), and we are done as w, x, and y form a 231-pattern
in s(p). If there is an entry t between x and y that is larger than both
of them, then, keeping in mind that the 3241-pattern yxzu is not part of
any 35241-pattern, the pattern ytxzu must be a 34251-pattern. However,
that implies that entries y, t, z, and u form a 2341-pattern, and we have

356
A Walk Through Combinatorics
seen in the previous paragraph that such a pattern prevents p from being
two-stack sortable.
Now we prove the “if” part. It suﬃces to show that if s(p) is not stack
sortable, then p had to contain one of the two forbidden conﬁgurations
mentioned in the theorem. If s(p) is not stack sortable, then it contains a
231-pattern. Let e < f < g be the entries of one such pattern. Then by
Proposition 14.18, e was the rightmost of these three entries in p, and there
had to be an entry h in p that separated both f and g from the entry e.
If f preceded g in p, then fghe was a 2341-pattern in p, and we are done.
If not, then g preceded f in p. We know that f precedes g in s(p), which
implies that there was no entry between g and f in p that was larger than
both of them. So gfhe formed a 3241-pattern in p that was not part of a
35241-pattern, completing the proof.
The number of two-stack sortable n-permutations is known to be
2
(n + 1)(2n + 1) ·
3n
n

.
This formula has at least four diﬀerent proofs, all of which are somewhat
complicated.
We can certainly generalize our deﬁnitions. We say that a permutation
p is t-stack sortable if st(p) is the identity permutation. In other words,
passing p through the stack t times, we get the identity permutation. Note
that all t-stack sortable permutations will necessarily be u-stack sortable
permutations, for all u > t.
While we are not able to enumerate t-stack sortable permutations, we
will prove several interesting statements concerning them. To that end,
we need to have a deeper understanding of the eﬀects of the stack sorting
operation.
Lemma 14.22. Let p = LnR be an n-permutation, where L denotes the
string on the left of the entry n, and R denotes the string on the right of
the entry n. Then we have
s(p) = s(L)s(R)n.
Proof. As p passes through the stack, ﬁrst the entries that belong to L
enter the stack. They all leave the stack before n enters, creating s(L) at
the front of the output permutation. Then n enters the stack. Then all the
entries belonging to R pass through the stack, creating s(R) in the output
permutation, while n stays in the bottom of the stack. Finally, n leaves the
stack.

So Hard To Avoid. Subsequence Conditions on Permutations
357
We mention that the property s(p) = s(L)s(R)n in fact deﬁnes the stack
sorting operation. That is, the stack sorting operation is the only operation
deﬁned on all ﬁnite permutations that has this property.
Corollary 14.23. All n-permutations are (n −1)-stack sortable.
Proof. We prove this statement by induction on n. For n = 1, the state-
ment is trivial. Now suppose the statement is true for n −1, and prove it
for n.
Let p = LnR be any n-permutation.
Lemma 14.22 means in par-
ticular that s(p) always ends with its largest entry, and also, if R is
empty, then s(Ln) = s(L)n. Iterating this, sn−1(p) = sn−2(s(L)s(R)n) =
sn−2(s(L)s(R))n. This latter is the identity permutation as s(L)s(R) is a
permutation of length n −1, and therefore is (n −2)-stack sortable by the
induction hypothesis.
Corollary 14.24. For all n-permutations p, the t-sorted image st(p) ends
in the string (n −t + 1)(n −t + 2) · · · n.
Proof. Immediate by induction on t.
The property that s(p) = s(L)s(R)n enables us to translate the stack
sorting operation into the language of binary plane trees.
If p is an n-
permutation, we associate a rooted tree T (p) to p as follows.
The root of T (p) is a vertex labeled n, the largest entry of p. If a is
the largest entry of p on the left of n, and b is the largest entry of p on the
right of n, then the root will have two children, the left one will be labeled
a, and the right one labeled b. If n was the ﬁrst (resp. last) entry of p, then
the root will have only one child, and that will be a left (resp. right) child,
and it will necessarily be labeled n −1 as n −1 must be the largest of all
remaining elements.
Deﬁne the rest of T (p) recursively, by taking T (p′) and T (p′′), where p′
and p′′ are the substrings of p on the two sides of n, and aﬃxing them to
a and b.
Example 14.25. If p = 263498175, then T (p) is the tree shown in Figure
14.3.
The tree T (p) is called the decreasing binary tree of p. It is indeed a
binary tree, that is, each vertex has 0, 1, or 2 children. We repeat, for

358
A Walk Through Combinatorics
9
6
2
3
4
8
1
7
5
Fig. 14.3
The decreasing binary tree of p = 263498175.
emphasis, that each child is a left child or a right child of its parent, even if
that child is an only child. Given T (p), we can easily recover p by reading T
according to the tree traversal method called in-order. In other words, ﬁrst
we read the left subtree of T (p), then the root, and then the right subtree
of T (p). We read the subtrees according to this very same rule.
Now let us read the tree T (p) in postorder instead. In other words, let
us ﬁrst read the left subtree of T (p), then the right subtree of T (p), and
ﬁnally the root.
Example 14.26. The tree shown in Figure 14.3 is the decreasing binary
tree of p = 263498175.
Read in postorder, it yields the permutation
234615789.
9
6
2
3
4
8
1
7
5
Fig. 14.4
Read in postorder, this tree yields 234615789.
The alert reader might have noted that reading T (p) in postorder we
precisely got the permutation s(p), the image of p under the stack sorting

So Hard To Avoid. Subsequence Conditions on Permutations
359
operation. This is no accident.
Proposition 14.27. Let p be any n-permutation. The decreasing binary
tree T (p) of p, read in postorder, yields the permutation s(p).
Proof. We prove the statement by induction on n, the initial case of n = 1
being trivial. Assume the statement is true for all positive integers less
than n. Let p = LnR, and let us read T (p) in postorder. We start with
the left subtree, which is in fact T (L). Reading that in postorder, we get
s(L) by the induction hypothesis. Then we have to read the right subtree,
which is T (R). Reading that in postorder, we get s(R) by the induction
hypothesis. (Both L and R are shorter than p.) Finally, we read the root,
which is n. So we obtain the permutation s(L)s(R)n, and we are done by
Proposition 14.22.
Recall that we say that i is a descent of the permutation p = p1p2 · · · pn
if pi > pi+1. Similarly, we say that i is an ascent of the permutation p if
pi < pi+1. Let d(p) denote the number of descents of p. Note that if p is
an n-permutation, then n −1 −d(p) is equal to the number of ascents of
p. Moreover, if i is a descent of p, then i is an ascent of the complement
of p. It follows immediately that there are as many n-permutations with k
descents as there are with n −1 −k descents.
If we consider decreasing binary trees again, it is straightforward to
verify that p has k descents if and only if T (p) has k edges connecting a
vertex to the right child of that vertex.
Let us now enumerate t-stack sortable n-permutations according to their
descents. Let Wt(n, k) be the number of t-stack sortable n-permutations
with k descents. The following table shows the numbers Wt(n, k) for small
values of the parameters.
These data seem to suggest that Wt(n, k) = Wt(n, n −1 −k), for all
positive integers n, k, t.
If true, this would be a surprising theorem, as
there seems to be nothing “symmetric” about t-stack sortable permutations,
these obscure creatures. The complement, or reverse, of a t-stack sortable
permutation does not need to be t-stack sortable (try 213, or 132, with
t = 1), so these easy bijections will not work.
In the rest of this chapter, we prove this nice symmetry. We will also see
the tree interpretation of the stack-sorting operation at work. The following
simple map will be our main tool.
Deﬁnition 14.28. Let f be the map deﬁned on all ﬁnite permutations as
follows

360
A Walk Through Combinatorics
n=4
t=1
t=2
t=3
n=5
t=1
t=2
t=3
t=4
   k=0           k=1            k=2           k=3             k=4
1
6
6
1
10
10
1
1
1
1
1
1
11
11
10
1
1
1
1
10
20
49
20
20
26
26
66
25
25
62
1
1
Fig. 14.5
The numbers Wt(n, k) for n = 4 and n = 5.
• f(1) = 1,
• if p is an n-permutation, and p = LnR, and neither L nor R is empty,
then f(p) = f(L)nf(R),
• if p is an n-permutation and p = Ln, then f(p) = nf(L), and
• if p is an n-permutation and if p = nR, then f(p) = f(R)n.
In words, if the maximal entry n is at neither endpoint of p, then we keep
n ﬁxed and apply f recursively on both sides of n. If n is at either endpoint,
then we put n into the opposite endpoint, and apply f recursively. When
we apply f recursively to L and R, then we treat L and R as permutations.
This means that the maximum element of L will take over the role of n
when f(L) is formed, and the maximum element of R takes over the role
of n when f(R) is formed.
Example 14.29. If p = 123, then f(p) = 321.
So if p = 4123, then
f(p) = 3214.
Example 14.30. If p = 1423, then f(p) = 1432.
Example 14.31. As a consequence of the preceding examples, if p =
412395867, then f(p) = 321495876.
The following Proposition shows that the eﬀect of f on the number of
descents of a permutation is precisely what we will need.
Proposition 14.32. For any n-permutation p, the equality d(p)+d(f(p)) =
n −1 holds.

So Hard To Avoid. Subsequence Conditions on Permutations
361
Proof. We prove this claim by induction on n, the initial case being trivial.
First assume that n is at neither endpoint of p, so p = LnR, and f(p) =
f(L)nf(R). Say that n is in the ith position of p. Then we have d(p) =
d(L) + d(R) + 1, and d(f(p)) = d(f(L)) + d(f(R)) + 1. So
d(p) + d(f(p)) = d(L) + d(R) + 1 + d(f(L)) + d(f(R)) + 1
= (i −2) + (n −i −1) + 2 = n −1,
which was to be proved. We used the facts that d(L) + d(f(L)) = i −2 and
d(R) + d(f(R)) = n −i −1 by the induction hypothesis.
Now let us assume that n is in the last position, and p = Ln. Then
clearly, d(p) = d(L), while d(f(p)) = d(nf(L)) = d(f(L))+1, and the proof
follows by induction. Similarly, if n is in the ﬁrst position, and p = nR,
then d(p) = d(nR) = 1 + d(R), while d(f(p)) = d(f(R)n) = d(f(R)), and
again, the proof follows by induction.
Our f maps permutations with k descents into permutations with n−1−
k descents. So that we could use f to prove that the sequence Wt(n, k), 0 ≤
k ≤n −1 is symmetric, we must show that f preserves t-stack sortability.
The following Lemma is the key element of the proof of this.
Lemma 14.33. For any permutation p, the equality s(p) = s(f(p)) holds.
Proof. We prove the statement by induction on n, the length of p. The
statement is trivially true if n = 1. Now let us suppose it is true for all
positive integers less than n.
(1) Suppose ﬁrst that the entry n is at neither end of p, and let p = LnR.
Then
s(p) = s(L)s(R)n = s(f(L))s(f(R))n = s(f(L)nf(R)) = s(f(p)).
(2) Now suppose that the entry n is in the ﬁrst position, so p = nR. Then
s(p) = s(R)n = s(f(R)n) = s(n(f(R))) = s(f(p)).
(3) Finally, if the entry n is in the last position, so p = Ln, then
s(p) = s(L)n = s(f(L))n = s(n(f(L))) = s(f(p)).
So the statement is true in all cases. Again, we used the facts that
s(L) = s(f(L)) and s(R) = s(f(R)) by the induction hypothesis.
Corollary 14.34. The permutation p is t-stack sortable if and only if f(p)
is t-stack sortable.

362
A Walk Through Combinatorics
Proof. Both statements are true if and only if the permutation s(p) =
s(f(p)) is (t −1)-stack sortable.
Now the proof of our duality theorem is immediate.
Theorem 14.35. For all positive integers n, k, t, the equality
Wt(n, k) = Wt(n, n −1 −k)
holds.
Proof. Corollary 14.34 and Proposition 14.32 show that f bijectively maps
the set of t-stack sortable n-permutations with k descents onto that of t-
stack sortable n-permutations with n −1 −k descents.
In order to get a deeper understanding of this proof, let us try to go
through it in terms of decreasing binary trees. A right (left) edge is an edge
between a vertex and its right (left) child. What we want to prove is that
there are as many decreasing binary trees on n vertices corresponding to
t-stack sortable permutations with k right edges as there are with k left
edges.
Our map f takes a tree T (p), and goes through its vertices starting at
the root. If the root has two children, then the two edges adjacent to the
root are unchanged. However, if the root has only a left edge, then the
entire left subtree of the root will be moved to the right of the root and
become its right subtree. Similarly, if the root has only a right edge, then
the entire right subtree of the root will be moved to the left of the root
and become its left subtree. Then we proceed to the vertices immediately
below the root, and apply the same rule. We continue this way until all
vertices have been treated.
This procedure clearly turns vertices with only a left child into vertices
with only a right child. If a vertex had two children in T (p), it will have the
same two children in T (f(p)). This proves again that d(p)+d(f(p)) = n−1
as the number of left edges of T (p) is equal to the number of right edges of
T (f(p)).
To see that s(p) = s(f(p)), we need to show that the trees T (p) and
T (f(p)) yield the same permutation when read in postorder. To see this,
note that if a vertex x has only one child y, then as far as the result of
the postorder reading is concerned, it does not matter whether y is a left
child or a right child of x. In both cases, the postorder reading will ﬁrst go
through the subtree rooted at y, then go to x. On the other hand, the only
eﬀect of the map f on p is precisely this, that is, f turns each single left

So Hard To Avoid. Subsequence Conditions on Permutations
363
child into a single right child and vice versa. So f has no eﬀect on s(p), as
we have claimed.
Note that we have proved a little more than we planned. We proved
that each entry x of p has the property that the subtree of T (p) rooted at
x, and the subtree of T (f(p)) rooted at x yield the same result when read
in postorder. Originally we only wanted to prove this for the full trees, that
is, the subtrees of the entry n.
Example 14.36. The decreasing binary trees of p = 356124 and f(p) =
536421 yield the same permutation 351246 when read in postorder. The
same is true for the subtrees of any given entry.
6
5
3
4
2
1
6
5
4
1
2
3
Fig. 14.6
Trees T(p) and T(f(p)).
Quick Check
(1) How many stack sortable permutations of length n have exactly one
descent?
(2) Let us consider a weaker version of the stack sorting operation in which
every time the top element of the stack goes into the output, the entire
stack has to go into the output, in the top-to-bottom order of the entries
in the stack. We call a permutation p pop-stack sortable if this sorting
algorithm maps p into the identity permutation. Which permutations
are pop-stack sortable?
(3) Let n be even. Prove that the number of t-stack sortable permutations
of length n is even.

364
A Walk Through Combinatorics
Notes
As pattern avoidance is the youngest of all areas covered in this book, it
is also the one whose progress is the fastest. For this reason, this is the
chapter that changed most since the publication of the ﬁrst edition.
For a more thorough treatment of the topics discussed in this Chap-
ter, the reader is advised to consult “Combinatorics of Permutations” by
the present author [13], which devotes Chapters 4, 5, and 8 to the sub-
ject. Chapter 4 contains the proof of the Stanley-Wilf conjecture, by Adam
Marcus and G´abor Tardos.
An even higher level treatment is Vincent Vatter’s survey, which is
Chapter 12 of [12].
The solution of the Stanley-Wilf conjecture implies that the limit L(q) =
limn→∞
n
Sn(q) exists. This limit provides a good way of measuring the
growth rate of the sequence Sn(q). It was previously conjectured that if
q ∈Sk, then L(q) ≤(k −1)2. However, this conjecture was disproved in
2005 [2], when a counterexample was given by the inequality L(1324) >
9.47.
This lower bound has recently been improved to L(1324) > 9.81
by David Bevan [6]. On the other hand, the best known upper bound is
L(1324) < 13.7318 (see [9], [10]). Note that for all patterns q of length
three, and for all patterns q of length four other than 1324 and its reverse
4231, we have an exact formula for Sn(q), but for q = 1324, we cannot even
tell the growth rate of the sequence Sn(q) with exponential precision!
As far as a lower bound for all patterns is concerned, it is known [31]
that L(q) ≥k2/e3 for all q ∈Sk.
Exercises
(1) Find a formula for the number of n-permutations that avoid both 132
and 123. We will denote this number by Sn(132, 123).
(2) Find a formula for Sn(132, 231).
(3) Find a formula for Sn(132, 321).
(4) Find a formula for Sn(132, 213).
(5) A permutation is called layered if it consists of decreasing subsequences
(the layers) so that while the entries decrease within each such subse-
quence, they increase from one subsequence to the other. For instance,
32154, 21543768, and 1234 are all layered permutations. In the ﬁrst
example, the layer lengths are three and two, in the second one, the
layer lengths are two, three, two, and one, and in the last example,

So Hard To Avoid. Subsequence Conditions on Permutations
365
there are four layers of length one each.
(a) Characterize layered permutations in terms of pattern avoidance.
(b) How many layered permutations of length n are there?
(6) Prove that all layered permutations are involutions.
(7) (+++) Prove that for all positive integers n,
Sn(1342) = (7n2 −3n −2)
2
· (−1)n−1
= +3
n

i=2
2i+1 · (2i −4)!
i!(i −2)! ·
n −i + 2
2

· (−1)n−i.
(8) (++) Prove that for all positive integers n, we have Sn(1423) =
Sn(2413).
(9) Prove that the number of ways to partition a convex n + 2-gon into
triangles by non-crossing diagonals is cn.
(10) Prove that the number of ways to partition a convex n+1-gon into any
number of triangles and one quadrilateral by non-crossing diagonals is
2n−3
n−3

.
(11) (+) Let bn be the number of n-permutations containing exactly one
copy of the pattern 132. Find a recursive formula for bn.
(12) Prove that bn =
2n−3
n−3

, for all positive integers n ≥3, where bn is
deﬁned in the previous exercise.
(13) (+) Let dn be the number of n-permutations containing exactly one
copy of the pattern 123. Prove that dn = 3
n
 2n
n+3

.
(14) Find a formula for Sn(132, 123, 312).
(15) A partition π of [n] having blocks β1, β2, · · · , βk, is called non-crossing
if there are no four elements 1 ≤a < b < c < d ≤n so that a, c ∈βi
and b, d ∈βj for some distinct blocks βi and βj. Prove that the number
of non-crossing partitions of [n] is cn.
(16) Prove that for k ∈[n], the number of non-crossing partitions of [n]
having k blocks is equal to the number of 132-avoiding n-permutations
that have k −1 descents.
(17) Let N(n, k) be the number of 132-avoiding n-permutations with k left-
to-right minima. Prove that for all k ∈[n], the equality
N(n, k) = N(n, n + 1 −k)
holds.
(18) (+) For S ⊆[n −1], let Permn(S) denote the number of 132-avoiding
n-permutations with descent set S. Let α(S) denote its “reverse com-
plement,” that is, i ∈α(S) ⇐⇒n−i /∈S. Prove that for all S ⊆[n−1],
the equality Permn(S) = Permn(α(S)) holds.

366
A Walk Through Combinatorics
(19) Let n ≥3. Find all n-permutations that are not (n −2)-stack sortable.
(20) Find a necessary condition for a permutation to be t-stack sortable.
(21) Prove that if p does not have t + 2 entries (not necessarily consecutive
ones) so that rightmost one of them is the smallest, and the one pre-
ceding it is the largest, then p is t-stack sortable. Note that this means
p avoids all t! patterns of length t + 2 that end in (t + 2)1.
(22) Let n be an even positive integer. Find all n-permutations p for which
there is no permutation q ̸= p so that s(p) = s(q). Here s denotes the
stack sorting operation.
(23) Is it true that an n-permutation is two-stack sortable if and only if
there is at most one entry on the left of the entry n that is larger than
the smallest entry on the right of the entry n?
(24) What is the number of unlabeled binary trees on n vertices? These
trees are similar to decreasing binary trees in that they are rooted,
each vertex has 0, 1, or 2 children, and each child is either a left child
or right child of its parent, even if it is a only child.
However, the
vertices are not labeled.
Supplementary Exercises
(25) Prove that for any pattern q, and any positive integers m and n, the
inequality
Sn(q)Sm(q) ≤Sn+m(q)
holds.
(26) (+) Let q be any pattern, and let
L(q) = lim
n→∞
n
Sn(q).
Prove that L(q) exists and is ﬁnite.
(27) Prove that L(132) = 4.
(28) Prove that L(1342) = 8.
(29) (Knowledge of basic deﬁnitions from group theory required.) Prove
that if p is a q-avoiding permutation, then p−1 is a q−1-avoiding per-
mutation. Here t−1 denotes the inverse of the n-permutation t in the
symmetric group Sn.
(30) Let p = p1p2 · · · pn be a 132-avoiding permutation. Prove that for all
i ∈[2, n], the entry pi is a left-to-right minimum if and only if i −1 is
a descent of p.

So Hard To Avoid. Subsequence Conditions on Permutations
367
(31) Let q1 and q2 be two diﬀerent patterns of length three.
Is it true
that Sn(q1, q2) is always given by one of the formulae computed in
Exercises 1 – 4?
(32) Prove that for all positive integers k ≤n, the equality
Sn(123 · · · k) = Sn(123 · · ·k k −1)
holds.
(33) Find an upper bound for Sn(3124675).
(34) (+)
Find
the
ordinary
generating
function
of
the
numbers
Sn(1324, 2413).
(35) Let q be any pattern of length k that has exactly one inversion. Prove
that
Sn(q) ≥Sn(12 · · · k).
(36) A circular translate of the permutation p = p1p2 · · · pn is a permuta-
tion pipi+1 · · · pnp1p2 · · · pi−1. In other words, we get a circular trans-
late of p by moving any initial segment of p to the end of p.
Find a formula for the number of n-permutations p so that no circular
translate of p contains the pattern 132.
(37) Find a recurrence relation for the sequence an = Sn(132, 4321). Then
use that recurrence relation to prove that for all non-negative integers,
an = 2
n
4

+
n + 1
3

+ 1.
(38) (-) Show an example of a permutation of length n2 that contains all n!
patterns of length n. Such a permutation is called an n-superpattern.
(39) (-) Show an example of an n-superpattern of length n2 −n + 1.
(40) (-) Create a word of length n2 −n + 1 over the alphabet [n] that
contains all n! permutations of length n as a subword. (Letters of a
subword do not have to be in consecutive positions.)
(41) Find a simple characterization for the set of permutations avoiding all
of the patterns 1324, 1423, 2314, 2413, and 3412.
(42) Count the permutations of length n that avoid all ﬁve patterns listed
in the previous exercise.
(43)(a) Show an example of a pair of patterns so that for all n ≥2, the
number Sn(p, q) is even.
(b) Show that Sn(132) is odd if and only if n = 2k −1.
(44) Let us assume that we have a computer program that decides whether
a given m-permutation is an n-superpattern or not. We would like to

368
A Walk Through Combinatorics
use this program to ﬁnd the number of m-permutations that are n-
superpatterns. Let us assume for simplicity that m is odd. Prove that
it suﬃces to test a suitably chosen set of m!/3 permutations with our
program, and then the number of n-superpatterns of length m can be
deduced.
(45) An unlabeled plane tree is a rooted tree that is embedded in the plane.
Two unlabeled plane trees A and B are considered the same if the
following hold:
(a) the roots of A and B have the same number k of children, denoted
from the left to right by A1, A2, · · · , Ak, and B1, B2, · · · , Bk, and
(b) the subtrees rooted at Ai and Bi are isomorphic as unlabeled plane
trees by this same deﬁnition.
Prove that the number of unlabeled plane trees on n+1 vertices is cn.
(46) Prove that there are as many unlabeled plane trees on n + 1 vertices
with k leaves as there are with n + 1 −k leaves.
(47) Prove that there are as many non-crossing partitions of [n] with k
blocks as there are with n + 1 −k blocks.
(48) Describe the set of permutations p for which no vertex of T (p) has
two children.
(49) Let p and q be two n-permutations so that T (p) and T (q) become
identical if we remove the labels of their vertices.
Prove that the
stack-sorting operation has the same eﬀect on p and q. That is, prove
that there is a permutation s so that ps = qs.
(50) A permutation p is called sorted if there is a permutation q so that
s(q) = p. Is p = 61374528 sorted?
(51) Let p be an involution so that all patterns contained p are also invo-
lutions. What involution can p be?
Solutions to Exercises
(1) We claim that Sn(132, 123) = 2n−1, and we are going to prove this by
induction on n. The initial case is trivial. Assume the statement is
true for n −1. Take any permutation of length n −1 that avoids both
these patterns. Create two n-permutations from it by adding 1 to all
its entries, then insert a new entry 1 to either its last or its next-to-last
position. Clearly, these two new n-permutations avoid both 132 and
123.

So Hard To Avoid. Subsequence Conditions on Permutations
369
We show that we obtain all n-permutations that avoid both these
pattern by this procedure. We claim that such a permutation must
contain the entry 1 at its last or next-to-last position.
Indeed, if
there are two elements on the right of 1, then they must be in either
increasing or decreasing order, and must therefore form either a 123
or a 132 pattern together with the entry 1.
This proves that Sn(132, 123) = 2 · Sn−1(132, 123), and the proof
follows by induction.
(2) Try to construct an n-permutation that avoids both 132 and 231.
Then it is clear that the entry n must be either at the ﬁrst or at the
last position. Indeed, if there are two elements x and y bracketing
n, then together with n they form either a 231-pattern, or a 132-
pattern. Once n is placed, by similar argument we must place n −1
either in the ﬁrst or the last empty position. We continue this way,
having two choices at each step. Finally, we have to place 1 into the
only empty spot left. So this procedure can result in 2n−1 diﬀerent
permutations. All these permutations will look like the letter V , that
is, ﬁrst they will decrease steadily, then they will increase steadily.
Therefore, all of them will indeed avoid both 132 and 231. So we
proved that Sn(132, 231) = 2n−1.
(3) Let p be an n-permutation avoiding both these patterns. In order to
avoid 132, all entries on the left of n must be larger than all entries
on the right of n.
In order to avoid 321, all entries on the right
of n must be in increasing order. Moreover, unless n is in the last
position, all entries on the left of n must be in increasing order, too,
otherwise two of them in decreasing order and any entry on the right of
n would form a 321-pattern. So if n is in the ith position, and i ̸= n,
then there is only one such permutation, namely the permutation
(n −i + 1) (n −i + 2)
· · · n 1 2 · · ·
n −i.
If n is in the last
position, then n cannot participate in any 132- or 321-patterns, so we
can prepend it by any (132,321)-avoiding (n −1)-permutation. This
yields the recurrence Sn(132, 321) = (n −1) + Sn−1(132, 321), for
n ≥2, with the initial condition S1(132, 321) = 1. Solving this, we
get Sn(132, 321) = 1 +
n
2

.
(4) We claim that Sn(132, 213) = 2n−1. We prove this by induction on
n, the initial case being trivial. Assume the statement is true for all
integers smaller than n.
To avoid 132, all entries on the left of n must be larger than all entries
on the right of n. To avoid 213, all entries on the left of n must be in

370
A Walk Through Combinatorics
increasing order. On the right of n, we must have a permutation that
avoids both 132 and 213. One checks easily that these conditions to-
gether are not only necessary, but also suﬃcient for an n-permutation
to avoid both 132 and 213.
Now assume n is in the ith position. Then the above conditions give
rise to 2n−i−1 permutations if i < n, and one permutation if i = n.
Indeed, the only freedom we have once the position of n is known is to
permute the elements on the right of n, and the induction hypothesis
says that we can do that in 2n−i−1 diﬀerent ways.
So Sn(132, 213) = 1 + n
i=1 2n−i−1 = 2n−1.
(5)(a) Layered permutations are precisely those permutations that avoid
both 231 and 312.
(b) As layered permutations of length n naturally correspond to com-
positions of n, their number is 2n−1.
(6) For each layer, the ith largest and the ith smallest entry of that layer
form a 2-cycle, unless they are the same entry, in which case that entry
is a ﬁxed point. So layered permutations have no cycles longer than
two.
(7) This result is due to the present author and can be found in Exact
enumeration of 1342-avoiding permutations. A close link with labeled
trees and planar maps, Journal of Combinatorial Theory, Series A,
80 (1997), 257–272.
(8) This result is due to Zvezdelina Stankova, and can be found in For-
bidden Subsequences, Discrete Mathematics, 132 (1994), 291–316.
(9) Label the vertices of our (n+2)-gon by integers from 1 through n+2 in
increasing order. Let dn be the number of ways to partition a convex
n+2-gon into triangles by non-crossing diagonals, and set d0 = 1. We
are going to ﬁnd the number of partitions in which i is the smallest
index in [3, n + 1] so that 1i is a diagonal in our partition π (if there
is such an index).
In this scenario, 2i must be a diagonal π, otherwise the polygon con-
taining 2 would have more than three sides. We have di−3 possibilities
for the part of π that partitions the i −1-gon 23 · · · i, and we have
dn−i+2 possibilities for the part of π that partitions the n −i + 4-gon
1i(i + 1) · · · (n + 2). So the number of all possibilities for such a π is
di−3 · dn−i+2.
Let us not forget that it can also happen that such an index i does
not exist. In that case, vertex i is not part of any diagonal that is in
π, so the diagonal 2(n + 2) must be in π. Then there are dn−1 ways

So Hard To Avoid. Subsequence Conditions on Permutations
371
for the part of π that partitions the (n + 1)-gon 23 · · ·(n + 2).
Summing over all cases, we get the formula
dn = dn−1 +
n+1

i=3
di−3 · dn−i+2 =
n

j=1
dj−1 · dn−j.
This is identical to the recurrence relation (14.1) that we proved for
132-avoiding permutations, so the proof follows.
(10) By the previous exercise, an (n + 1)-gon can be triangularized in any
of cn−1 ways, using n −2 diagonals. The removal of any one of these
n −2 diagonals forms a quadrilateral from two adjacent triangles.
Further, there are two ways to triangularize this quadrilateral: with
the diagonal we removed and the only other diagonal.
Therefore,
each way of partitioning the (n + 1)-gon into one quadrilateral and
n −3 triangles is yielded by exactly two triangularizations. Hence,
the number of such ways to partition the (n + 1)-gon is the number
of triangularizations multiplied by the number of diagonals that can
be chosen for removal, divided by two. This yields that the number
of all such partitions is
cn−1
n −2
2
= 1
n
2n −2
n −1
n −2
2
=
(2n −2)!(n −2)
2n(n −1)!(n −1)!
=
(2n −2)!
2n(n −1)!(n −1)(n −3)!
=
(2n −2)!
2(n −1)n(n −1)!(n −3)!
= (2n −3)!
n!(n −3)!
=
2n −3
n −3

.
This solution is due to Christian Jones (personal communication).
(11) Clearly, b0 = b1 = b2 = 0. Take any n-permutation p and suppose
that the entry n is in the ith position in p. For shortness, call entries
preceding n front entries, and call entries that n precedes back entries.
Then there are three ways p can contain exactly one subsequence S
of type 132.

372
A Walk Through Combinatorics
(i) When all elements of S are front entries. Then any front entry must
be larger than any back entry for any pair violating this condition
would form an additional 132-subsequence with n. Therefore, the i
largest entries must be front entries n (in fact, these are the entries
n −1, n −2, · · · , n −i + 1), while the n −i smallest entries must be
back entries (these are the entries 1, 2, · · ·n −i). Moreover, there
can be no subsequence of type 132 formed by back entries. So all
we can do is to take a 132-avoiding permutation on the n −i back
entries in cn−i ways and take a permutation having exactly one
132-subsequence on the i −1 front entries. This yields bi−1cn−i
permutations of the desired property.
(ii) When all elements of S are back entries.
The argument of the
previous case holds here, too, we must only swap the roles of the
front and back entries. In this case we have ci−1bn−i permutations
with the desired property.
(iii) Finally, it can happen that the leftmost element x of S is a front
entry and rightmost element z of S is a back entry. This case is
slightly more complicated. Note that here 2 ≤i ≤n −1, otherwise
either the set of front entries or that of back entries would be empty.
First note that there is exactly one pair (x, z) so that x is a front
entry, z is a back entry and x < z.
(For any such pair and n
form a 132-subsequence.) This implies that the front entries are
n−1, n−2, · · · , n−i+2, n−i and the back entries are 1, 2, · · · , n−i−
1, n−i+1, the only pair with the given property is (n−i, n−i+1) =
(x, z), and any other front entry is larger than both x and z.
Let us take these entries x and z. Clearly, all 132-subsequences
of the given type must start with x and must end with z.
We
claim that the middle entry of S must be n. Indeed, if the middle
element were some other w, then x n z and x w z would both be
132-subsequences. (Recall that x < z and they both are smaller
than any other front entry.) Moreover, we claim that x must be
the rightmost front entry, in other words, it must be in the position
directly on the left of n. Indeed, if there were any entry y between
x and n, then x y z and x n z would both be 132-subsequences for
y is a front entry and thus larger than x and z.
Therefore, all we can do is put the entry n −i in position (i −1),
then take any 132-avoiding permutation on the ﬁrst i −2 elements
in ci−2 ways and take any 132-avoiding permutation on the n −i
back entries in cn−i ways. This gives us ci−2cn−i permutations of

So Hard To Avoid. Subsequence Conditions on Permutations
373
the desired property.
Summing over all permitted i in each of these three cases we get that
bn =
n−1

i=1
bi−1cn−i +
n−1

i=1
ci−1bn−i +
n−1

i=2
ci−2cn−i.
(14.2)
Note that the ﬁrst two sums are equal for they contain the same
summands. Moreover, we can easily see by (8.19) or the equivalent
(14.1) that the last sum equals cn−1−cn−2. Thus the above recurrence
relation for bn simpliﬁes to
bn = 2 ·
n−1

i=1
bi−1cn−i

+ cn−1 −cn−2.
(14.3)
(12) We prove that the number rn of partitions of a convex (n + 1)-gon
P into triangles and one quadrilateral also satisﬁes the recurrence
relation (14.3).
(I) First, we consider the case when there is no diagonal going into
1. Then it can be that 2(n + 1) is a diagonal, and the problem is
reduced to one lesser in size, with rn−1 partitions. Or, it can be
that 2(n + 1) is not a diagonal, and in that case, vertices 1, 2, n + 1
and a fourth vertex i form a quadrilateral. Then, to complete the
partitioning, we have to triangulate the (i −1)-gon 2 · · · i in ci−3
ways, and the (n−i+2)-gon i(i+1) · · ·n+1 in cn−i ways. Summing
this we get that in this ﬁrst case there are
rn−1 +
n

i=3
ci−3cn−i = rn−1 + cn−2
diﬀerent partitions.
(II) Now we look at the case when there is a diagonal going into 1. Let
i be smallest number so that 1i is a diagonal. Again, there are two
cases: the quadrilateral is either in the part 12 · · · i, or in the part
i(i + 1) · · · (n + 1)1. Let us ﬁrst handle the second case, as that is
easier. We need to triangulate the part 12 · · · i, without having a
diagonal touching 1 in ci−3 ways, (we have computed this in the
solution of Exercise 9), then partition the i(i+ 1) · · ·n(n+ 1)1 part
in rn−i+2 ways.
Let us return to the ﬁrst case. We have to partition the ﬁrst part
without having a diagonal touching 1. As we have computed in case

374
A Walk Through Combinatorics
I, there are ri−2 +ci−3 possibilities, then we have to triangulate the
second part in cn−i+1 ways. So here there are
n−1

i=3
ci−3rn−i+2 +
n

i=3
(ri−2 + ci−3)cn−i+1
partitions.
These two cases together yield the following recurrence
rn = cn−1 −cn−2 + 2
n−1

i=3
ci−3rn−i+2,
or, writing j = i −2, we get
rn = cn−1 −cn−2 + 2
n−3

j=1
cj−1rn−i,
which is equivalent to (14.3) as rk = 0 for k ≤3.
Therefore, the sequences {bn} and {n} satisfy the same recurrence
relations, so they must be the same as their initial values are the
same.
(13) This result is due to John Noonan, and can be found in his article
entitled “The number of permutations containing exactly one increas-
ing subsequence of length three,” Discrete Math. 152 (1996), no. 1-3,
307–313.
(14) Let f(n) = Sn(123, 132, 312). Then in a permutation counted by f(n),
the entry 1 must be in one of the last two positions. If it is in the
last position, then there are f(n −1) possibilities for the rest of the
permutation. If it is in the next-to-last position, then last position
must contain the entry n, yielding f(n −2) permutations. This shows
that f(n) = f(n −1) + f(n −2), with f(0) = 1 and f(1) = 1. This
recurrence relation has been solved in Exercise 5 of Chapter 8. Recall
that the numbers f(n) are called Fibonacci numbers.
(15) The result of this exercise certainly follows from that of the next one,
but we sketch a direct solution. Let π be a non-crossing partition of
[n], and let B be the block of π that contains the element 1. Let i be
the largest element of B. Then π deﬁnes a non-crossing partition on B,
and another one on [n]−B. It is easy to show that this decomposition
leads to the same recurrence relation (14.1) that was satisﬁed by 132-
avoiding n-permutations.

So Hard To Avoid. Subsequence Conditions on Permutations
375
(16) This result was ﬁrst published in [15]. We prove our statement by
ﬁnding an appropriate bijection. Let π be a non-crossing partition of
[n]. We construct the 132-avoiding permutation p = f(π) correspond-
ing to π as follows. Let k be the largest element of π which is in the
same block of π as 1. Put the entry n of p in the kth position, i.e.,
set pk = n. As p is to be 132-avoiding, this implies that the entries
larger than n −k are on the left of n in p, and the entries smaller
than or equal to n −k are on the right of n. Delete k from π and
apply this procedure recursively, with obvious minor adjustments, to
the restrictions of π to the sets {1, . . ., k−1} and {k+1, . . . , n}, which
are also non-crossing partitions. Namely, if j is the largest element in
the same block as k + 1, we set pj = n −k, so that the restriction
π1 of π to {k + 1, k + 2, . . . , n} yields a 132-avoiding permutation of
{1, 2, . . ., n −k} placed on the right of n in p = f(π). Similarly, if in
the restriction π2 of π to the set {1, 2, . . ., k −1} the largest element
in the same block as 1 is equal to j, we set pj = n −1. Thus, recur-
sively, π2 yields a 132-avoiding permutation which we realize on the
set {n −k + 1, n −k + 2, . . . , n −1} and we place it to the left of n in
p = f(π). In other words, with a slight abuse of notation, f(π) is the
concatenation of f(π2), n, and f(π1), where f(π2) permutes the set
{n −k + 1, n −k + 2, · · · , n −1} and f(π1) permutes the set [n −k].
To see that this is a bijection note that we can recover the maximum
of the block containing the element 1 from the position of the entry n
in p, and then proceed recursively.
For example, If π
=
({1, 4, 6}, {2, 3}, {5}, {7, 8}), then f(π)
=
64573812.
(17) As the reader is asked to prove in Supplementary Exercise 30, in a
132-avoiding permutation p = p1p2 · · · pn the entry pi is a left-to-
right minimum if and only if either i = 1 or i −1 is a descent. So
N(n, k) is also the number of 132-avoiding n-permutations with k −1
descents, and we need to show that this number is equal to the number
N(n, n + 1 −k) of 132-avoiding n-permutations with n −k descents.
For symmetry reasons, in the last sentence, the words “132-avoiding”
can be replaced by “231-avoiding”, and our claim then immediately
follows from Theorem 14.35 by setting t = 1.
(18) We use induction on n. For n = 1, 2, 3 the statement is true. Now
suppose we know it for all positive integers smaller than n. Denote by
t the smallest element of S, and let p be a 132-avoiding n-permutation
whose descent set is S.

376
A Walk Through Combinatorics
(a) Suppose that t > 1. Then we have p1 < p2 < · · · < pt and, because
p avoids the pattern 132, the values of p1, p2, . . . , pt are consecutive
integers. So, for given values of p1 and t, we have only one choice
for p2, p3, . . . , pt. This implies
Permn(S) = Permn−(t−1)(S −(t −1)),
(14.4)
where S −(t −1) is the set obtained from S by subtracting t −1
from each of its elements.
On the other hand, we have n −t + 1, n −t + 2, · · · , n −1 ∈α(S),
meaning that in any permutation q counted by Permn(α(S)) the
chain of inequalities qn−t+1 > qn−t+2 > · · · > qn holds.
In
order to avoid forming a 132-pattern in q, it has to hold that
(qn−t+2, · · · , qn) = (t −1, t −2, · · · , 1). Therefore,
Permn(α(S)) = Permn−(t−1)(α(S)|n −(t −1))
(14.5)
where α(S)|n −(t −1) denotes the set obtained from α(S) by re-
moving its last t −1 elements. Then
Permn−(t−1)(S −(t −1)) = Permn−(t−1)(α(S)|n −(t −1))
by the induction hypothesis, so equations (14.4) and (14.5) imply
Permn(S) = Permn(α(S)).
(b) If t = 1, but S ̸= [n −1], then let u be the smallest index which is
not in S. Then again, to avoid forming a 132-pattern, the value of
pu must be the smallest positive integer a which is larger than pu−1
and is not equal to any pi for i ≤u −1. So again, we have only one
choice for pu. On the other hand, the largest index in α(S) will
be n −u. Therefore, in permutations q counted by Permn(α(S)),
we must have qn−u = 1 as qn−u must be the rightmost left-to-right
minimum in such permutations, and that is always the entry 1.
However, we have to be careful when we delete the entry pu from p,
and when we delete the entry 1 from q, because these deletions can
have one of two diﬀerent eﬀects on the descent set of p and q. If the
entries pu−1pupu+1 form a 213-pattern, then deleting pu will result
in losing the ﬁrst descent of p, while if these entries form a 312-
pattern, then no descent is lost. If the entries qn−u−1qn−uqn−u+1
form a 213-pattern, then deleting qn−u removes the last descent of
q, while if these entries formed a 312-pattern, then no descent is
lost.
In order to use this information to reduce our permutations in size,
we deﬁne two subsets S′, S′′ ⊂[n −2] as follows. First we deﬁne

So Hard To Avoid. Subsequence Conditions on Permutations
377
S′, the set corresponding to the case when no descents got lost.
Let i ∈S′ if and only if either i < u and then, by the deﬁnition
of u, i ∈S, or i > u and i + 1 ∈S. In other words, we decrease
elements larger than u by 1; intuitively, we remove u from [n −1],
and translate the interval on its right one notch to the left. Note
that |S′| = |S| as we removed u, and u was not a descent anyway.
If we now take α(S′), that will consist of entries j so that j < n−u
and (n −1) −(j −1) = n −j /∈S. So in other words, we simply
remove n −u from [n −1] (there has been nothing on the right
of n −u in α(S) to translate). Note that |α(S′)| = |α(S)| −1 as
n −u ∈α(S).
The set S′′ is the set corresponding to the case when descents are
lost. Therefore, we deﬁne i ∈S′′ if and only if either i < u −1 and
then, by the deﬁnition of u, i ∈S, or, i > u and i+ 1 ∈S. In other
words, we decrease elements larger than u −1 by 1; intuitively, we
remove u −1 from [n −1], and translate the interval on its right
one notch to the left. If we now take α(S′′), that will consist of
entries j so that j < n −u + 1 and (n −1) −(j −1) = n −j /∈S.
Note that |S′′| = |S| −1, and |α(S′′)| = |α(S)|.
Therefore,
Permn(S) = Permn−1(S′) + Permn−1(S′′),
and also
Permn(α(S)) = Permn−1(α(S′)) + Permn−1(α(S′′)).
By the induction hypothesis, the right-hand sides of these two equa-
tions agree, and therefore the left-hand sides must agree, too.
(c) Finally, if S = [n −1], then the statement is trivially true as
Permn(S) = Permn(α(S)) = 1.
So we have shown that Permn(S) = Permn(α(S)) in all cases.
(19) We prove by induction that these are precisely the permutations that
end in the string n1. For n = 3, the statement is true.
Now assume the statement is true for n −1. Let p = p1p2 · · · pn be
an n-permutation that is not (n −2)-stack sortable. That means that
sn−2(p) = 21345 · · ·n as Proposition 14.24 implies that sn−2(p) must
end in 345 · · ·n. As each stack sorting operation moves the entry 1
up by at least one notch by Proposition 14.18, it follows that pn = 1.
Similarly, if pn−1 ̸= n, then during the ﬁrst stack sorting operation
the entry 1 passes more than one entries, so in n −2 operations, it
moves ahead more than n −2 notches. Therefore pn−1 = n.

378
A Walk Through Combinatorics
To see that all such permutations are good, note that for such a p, we
have s(p) = Ln, where L is an (n −1)-permutation that ends by the
string (n −1)1. Therefore, by the induction hypothesis, s(p) is not
(n −3)-stack sortable, and the proof follows.
This result, and that of the next Exercise, is due to Julian West, who
proved them in his thesis, Permutations with forbidden subsequences;
and, Stack sortable permutations, PHD-thesis, Massachusetts Insti-
tute of Technology, 1990.
(20) Such a permutation p cannot contain the pattern 23 · · · (t + 2)1. If it
did, then the entry a that plays the role of 1 in that 23 · · · (t + 2)1-
pattern could move up only one notch within the string of the entries
of that pattern during each stack-sorting operation. Therefore, after t
operations, it would still be behind the ﬁrst entry of that pattern.
(21) Let us denote the condition given in the exercise by Ct, and let us
denote the set of the t! patterns discussed in the exercise by Pt.
We are going to prove our claim by induction on t. If t = 1, then the
condition simpliﬁes to the 231-avoiding condition, and the statement
is true. Now suppose it is true for t −1. Let p be as speciﬁed by
the conditions of the theorem.
Then s(p) satisﬁes condition Ct−1.
Indeed, if s(p) contained a pattern q from Pt−1, then it follows from
Proposition 14.18 that p would have to contain a pattern from Pt.
(There had to be something large between the entries playing the role
of t + 1 and 1 in q.) Therefore, s(p) is (t −1)-stack sortable by the
induction hypothesis, so p is t-stack sortable.
(22) We claim that there are no such permutations. We know by Lemma
14.33 that s(p) = s(f(p)), where f is the map given by Deﬁ-
nition 14.28.
On the other hand, Proposition 14.32 shows that
d(p) + d(f(p)) = n −1. Therefore, if n is even, then one of p and
f(p) must have an odd number of descents, and the other one must
have an even number of descents. So p ̸= f(p), while s(p) = s(f(p)).
(23) No, that is not true. A counterexample is 163452. This permutation
is not 2-stack sortable because of the 2341-pattern 3452.
The “only if” part is true. If there are at least two entries on the left
of n that are larger than the entry c located on the right of n, then
let a and b be the leftmost two entries with this property. If a < b,
then abnc is a 2341-pattern, and if b < a, then abnc is a 3241-pattern
that is not part of a 35241-pattern. (There is nothing between a and
b that is larger than c.)
(24) We claim that the number of such trees is the Catalan number cn

So Hard To Avoid. Subsequence Conditions on Permutations
379
since these trees are in bijective correspondence with 231-avoiding n-
permutations. Indeed, given an unlabeled binary tree B on n vertices,
there is exactly one way to turn it into the decreasing binary tree T (p)
for a 231-avoiding permutation p. In order to see this, note that the
root of B must be labeled n, and, in order to avoid 231-patterns, all
vertices in the left subtree of the root must have smaller labels than
all vertices in the right subtree of the root. So the sets of labels in the
two subtrees are uniquely determined. This argument can be iterated
for the subtrees, until we uniquely determine the label of each vertex.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 15
Who Knows What It Looks Like, But
It Exists. The Probabilistic Method
We use the words “likely” or “probable” and “likelihood” or “probability”
every day in informal conversations. While making these concepts abso-
lutely rigorous can be a diﬃcult task, we will concentrate on special cases
when a mathematical deﬁnition of probability is straightforward, and con-
forms to common sense.
15.1
The Notion of Probability
Let us assume that we toss a coin four times, and we want to know the
probability that we will get at least three heads. The number of all out-
comes of the four coin tosses is 24 = 16.
Indeed, each coin toss can
result in two possible outcomes. On the other hand, the number of fa-
vorable outcomes of our coin tossing sequence is ﬁve.
Indeed, the ﬁve
favorable outcomes, that is, those containing at least three heads, are
HHHH, HHHT, HHT H, HT HH, and T HHH. Our common sense now
suggests that we deﬁne the probability of getting at least three heads as the
ratio of the number of favorable outcomes to the number of all outcomes.
Doing that, we get that the probability of getting at least three heads is
5/16.
This common sense approach is the basis of our formal deﬁnition of
probability. It goes without saying that we will have to be a little more
careful. For instance, the above argument assumed, without mentioning it,
that our coin is fair, that is, a coin toss is equally likely to result in a head
or tail.
Deﬁnition 15.1. Let Ω be a ﬁnite set of outcomes of some sequence of
trials, so that all these outcomes are equally likely. Let A ⊆Ω. Then Ω is
381

382
A Walk Through Combinatorics
called a sample space, and A is called an event. The ratio
P(A) = |A|
|Ω|
is called the probability of A.
In particular, P is a function that is deﬁned on the set of all subsets of
Ω, and 0 ≤P(A) ≤1 always holds.
There are, of course, circumstances when this deﬁnition does not help,
namely when Ω and A are not ﬁnite sets. An example of that situation is
to compute the probability that a randomly thrown ball hits a given tree.
As the ball could be thrown in inﬁnitely many directions, and would hit the
tree in an inﬁnite number of cases, the above deﬁnition would be useless.
We will not discuss that situation in this book; we will only study ﬁnite
sample spaces.
Note that if A and B are disjoint subsets of Ω, then |A∪B| = |A|+ |B|,
and therefore, P(A ∪B) = P(A) + P(B). In general, we know from the
Sieve formula that |A ∪B| = |A| + |B| −|A ∩B|, implying P(A ∪B) =
P(A)+P(B)−P(A∩B). A generalization of this observation is the following
simple, but extremely useful inequality.
Proposition 15.2. Let A1, A2, · · · , An be events from the same sample
space. Then
P(A1 ∪A2 ∪· · · ∪An) ≤P(A1) + P(A2) + · · · + P(An).
Proof. We simply have to show that
|A1 ∪· · · ∪An| ≤|A1| + · · · + |An|.
This is true as the left-hand side counts each element of the sample space
that is part of at least one of the Ai exactly once, while the right-hand side
counts each element of the sample space that is part of at least one of the
Ai at least once.
The reader has already been subjected to some training in basic enumer-
ation in Chapters 3–7. Most exercises in those chapters can be formulated
in the language of probability. For example, the question “how many six-
digit integers contain the digit 6” can be asked as “what is the probability
that a randomly chosen six-digit integer contains the digit 6”. Therefore,
we do not cover these basic questions again here. Instead, we close this
section by two examples that show how counterintuitive probabilities can
be.

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
383
Example 15.3. In one of the lottery games available in Florida, six num-
bers are drawn from the set of numbers 1, 2, · · · , 36. What is the probability
that a randomly selected ticket will contain at least one winning number?
Some people tend to answer
6
36 = 1
6 to this question. They are wrong.
That answer would be correct if only one number were drawn. Then the
number of favorable outcomes would indeed be six, and the number of all
outcomes would indeed be 36. However, when six numbers are drawn, the
situation is more complicated.
Solution. (of Example 15.3) Let A be the event that a ticket contains
at least one winning number, and let B be the event that a ticket does
not contain any winning number. Then clearly, A and B are disjoint, and
A ∪B = Ω, so P(A) + P(B) = 1. Therefore, it suﬃces to compute P(B).
For a ticket not to contain any winning numbers, it has to contain six non-
winning numbers. The number of ways that can happen is
30
6

. Therefore,
P(A) = 1 −P(B) = 1 −
30
6

36
6
 = 1 −0.3048 = 0.6952.
So with almost 70 percent probability, a randomly chosen ticket will contain
at least one winning number! No wonder you must have more than one
winning number to actually win a prize.
Note that when A and B are two disjoint events, then we say that A
and B are mutually exclusive. In other words, it is not possible that A and
B happen together. If, in addition, we also have A ∪B = Ω, then we say
that B is the complement of A. We denote this by writing ¯A = B.
Example 15.4. Forty people are present at a party, and there is nobody
among them who was born on February 29. Adam proposes the following
game to Bill. Each guest writes his or her birthday (just the day and month,
not the year) on a piece of paper. If there are two pieces of paper with the
same date on them, then Adam wins, if not, then Bill wins. When Bill
heard this proposal, he looked around, and said “Fine, there are only forty
people here, much less than the number of days in a year, so I am bound
to win.” What do we think about Bill’s argument?
Solution. The problem with Bill’s argument is that he fails to note the
diﬀerence between one hundred percent probability and more than ﬁfty
percent probability. If we want to be one hundred percent sure that there
will be two people in the room having the same birthday, then we would

384
A Walk Through Combinatorics
indeed need 366 people to be present. To have more than ﬁfty percent
chance is an entirely diﬀerent issue.
In what follows, we prove that if there are at least 23 people at the party,
then Adam, not Bill, has more chance of winning this game. In order to
prove this, it is clearly suﬃcient to provide a proof for the case when there
are exactly 23 people at the party as any additional person just improves
Adam’s chances.
Let us compute the probability that there are no two people at the party
who have the same birthday. For that to happen, the ﬁrst person’s birthday
can be any of the 365 possible days of the year, that of the second person
could be any of 364 days, and so on. So the number of favorable outcomes
is (365)23. On the other hand, the number of all outcomes is obviously
36523. Therefore, the probability that there are no two people in the room
whose birthdays coincide is
365 · 364 · · · · · 343
36523
= 364 · 363 · · ·343
36522
< 1
2.
Therefore, the probability that there are two people at the party who do
have the same birthday is more than one half.
Finally, we point out that the condition that nobody was born on Febru-
ary 29 was only included to make the situation simpler. Indeed, February
29 exists only in leap-years, so the chance of being born on that day is 1/4
of the chance of being born on any other given day. That would make the
outcomes in our sample space not equally likely, contradicting the deﬁnition
of sample space. We could help this by changing our sample space from the
365-element set of dates in a year to the set of 4 · 365 + 1 = 1461 days of a
4-year cycle. That would make computations a little bit more cumbersome.
Example 15.4 is sometimes called the birthday paradox.
Quick Check
(1) We roll two independent, fair dice. What is the probability that they
show two numbers that are relatively prime to each other?
(2) A class has 20 students and meets three times a week. During each of
those three meetings, the instructor calls three students to the black-
board. What is the probability that in a given week, no student will
be called to the blackboard more than once?
(3) Let Fn be the set of all functions from [n] to [n], and let f be a
randomly selected element of Fn. What is the probability that there
is no i ∈[n] satisfying i + f(i) = n + 1?

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
385
15.2
Non-constructive Proofs
If there are balls in a box, and we know that the probability that a randomly
selected ball is blue is more than 0, then we can certainly conclude that
there is at least one blue ball in the box. This thought seems utterly simple
at ﬁrst sight, but it has proved to be extremely useful in existence proofs
as the following examples show.
Recall that in Chapter 13, we deﬁned the symmetric Ramsey number
R(k, k). For easy reference, this was the smallest positive integer so that if
we 2-color the edges of the complete graph on R(k, k) vertices, we always
get a Kk subgraph whose edges are all the same color.
Now we are going to ﬁnd a lower bound for R(k, k) by proving that
R(k, k) > 2k/2. Let us take a closer look at the statement to be proved.
That statement says that if G is a complete graph on 2k/2 vertices, then
it is possible to 2-color the edges of G so that no monochromatic copy of
Kk is formed. When we proved similar statements in Chapter 13, showing
that R(3, 3) > 5, or R(4, 4) > 17, we proved them by actually providing a
coloring of K5 or K17 that indeed did not contain the required monochro-
matic copies. However, this was more than what we strictly needed to do.
To prove R(k, k) > 2k/2, it suﬃces to prove that it is possible to 2-color
the edges of G so that no monochromatic copy of Kk is formed; it is not
necessary to actually ﬁnd such a coloring. We will shortly see how big a
diﬀerence this is.
Theorem 15.5. For all positive integers k ≥3, the inequality R(k, k) >
2k/2 holds.
Proof. Let G = Kn, and let us color each edge of G red or blue as follows.
For each edge, ﬂip a coin. If we get a head, we color that edge red, otherwise
we color that edge blue. This way each edge will be red with probability
one half, and blue with probability one half. We are going to show that the
probability p that we get no monochromatic Kk-subgraphs in G this way
is more than zero. On the other hand, p = |F |
|Ω|, the number of favorable
outcomes divided by the number of all outcomes, where Ω is the set of
all possible 2-colorings of the edges of a complete graph on n vertices. So
p > 0 implies that there is at least one favorable outcome, that is, there is at
least one Kn with 2-colored edges that does not contain any monochromatic
Kk-subgraphs.
Instead of proving that p > 0, we will prove that 1 −p < 1, which is an
equivalent statement. Note that 1−p is the probability that we get at least

386
A Walk Through Combinatorics
one monochromatic subgraph in our randomly colored graph G = Kn.
The number of ways to 2-color the edges of a given Kk-subgraph of Kn
is clearly 2(
k
2) as there are two choices for the color of each edge. Out of
all these colorings, only two will be monochromatic, one with all edges red,
and one with all edges blue. Therefore, the probability that a randomly
chosen Kk-subgraph is monochromatic is
2
2(
k
2) = 21−(
k
2).
The graph Kn has
n
k

subgraphs that are isomorphic to Kk. Each of
them has the same chance to be monochromatic. On the other hand, the
probability that at least one of them is monochromatic is at most the sum
of these
n
k

individual probabilities, by Proposition 15.2. In other words,
if AS denotes the event that the Kk-subgraph S of G has monochromatic
edges, then
P

S
AS

≤

S
P(AS) =
n
k

21−(k
2),
(15.1)
where S ranges through all Kk-subgraphs of G.
Now let us assume, in
accordance with our criterion, that n ≤2k/2. Then the last term of (15.1)
can be bounded as follows.
n
k

21−(
k
2) < nk
k! · 21−(
k
2) ≤2 · 2k2/2
k!2(
k
2)
= 2 · 2k/2
k!
< 1,
for all k ≥3. The last inequality is very easy to prove, for example by
induction.
We have seen in Chapter 13 that R(k, k) ≤4k. Our latest result shows
that (
√
2)k < R(k, k). These are essentially the best known results on the
size of R(k, k), so there is a lot of progress to be made on Ramsey numbers.
Theorem 15.6. Let n and m be two positive integers larger than 1, and
let m ≥2 log2 n. Then it is possible to color each edge of Kn,n red or blue
so that no Km,m-subgraph with monochromatic edges is formed.
Proof. The number of ways to 2-color the edges of a given Km,m sub-
graph of Kn,n is 2m2, and two of these colorings result in monochromatic
subgraphs.
Therefore, the probability that at least one monochromatic
Km,m is formed is at most
 n
m
221−m2. Therefore, all we have to prove is
n
m
2
21−m2 < 1,

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
387
that is,
2
n
m
2
< 2m2.
To see this, we insert two intermediate expressions as follows.
2
n
m
2
< n2m ≤(2m/2)2m = 2m2,
where the second inequality is a simple consequence of the relation between
n and m.
Another way to formulate this same theorem is as follows.
If m ≥
2 log2 n, then there exists a matrix of size n × n whose entries are either 0
or 1 having no m × m minor that consists of zeros only, or of ones only.
What is amazing about this result is that nobody knows how to construct
that matrix, or how to color the edges of Kn,n so that the requirements are
fulﬁlled. In fact, the gap between what we can do and what we know is
possible is rather large. The best construction known to this day for an
n × n matrix with zeros and ones, and not having m × m homogeneous
minors works for m = c√n, where c is a constant. This is much more than
what we know is true, that is, m = 2 log2 n.
Quick Check
(1) Let n ≥7, and let F be a collection of 15 distinct 5-element subsets of
[n]. Prove that it is possible to color each element of [n] red or blue so
that each set belonging to F has elements of both colors.
(2) Let n ≥12, and let G be a collection of 15 distinct 10-element subsets
of [n]. Prove that it is possible to color each element of [n] red, blue, or
green so that each set belonging to G has elements of all three colors.
(3) Prove that there exists a tournament on 15 vertices that does not con-
tain a transitive tournament on eight vertices as a subgraph. (Transi-
tive tournaments were deﬁned in the proof of Theorem 9.8.)
15.3
Independent Events
15.3.1
The Notion of Independence and Bayes’ Theorem
Let us throw two dice at random. Let A be the event that the ﬁrst die
shows six, and let B be the event that the second die shows six.
It is
obvious that P(A) = P(B) = 1/6, and P(A ∩B) = 1/36. We see that

388
A Walk Through Combinatorics
P(A)·P(B) = P(A∩B), and start wondering whether this is a coincidence.
Now let us pick a positive integer from [12] at random. Let C be the event
that this number is divisible by two, let D be the event that this number
is divisible by three, and let F be the event that this number is divisible
by four. Then P(C) = 1/2, P(D) = 1/3, and P(F) = 1/4. Furthermore,
P(C∩D) = 1/6, and P(D∩F) = 1/12, so the “product rule” seems to hold.
However, P(C ∩F) = P(F) = 1/4 ̸= P(A)P(B), breaking the “product
rule”.
Why is it that sometimes we ﬁnd P(A) · P(B) = P(A ∩B), and some-
times we ﬁnd P(A) · P(B) ̸= P(A ∩B)? As you have probably guessed,
this is because sometimes the fact that A occurs makes the occurrence of
B more likely, or less likely, and sometimes it does not alter the chance
that B occurs at all. For example, if we choose an integer from 1 to 12,
then the fact that it is divisible by two certainly makes it more likely that
it is also divisible by four. Indeed, the number of all possible outcomes
decreases from 12 to six, while that of favorable outcomes does not change.
On the other hand, the fact that our number is divisible by two does not
change its chances to be divisible by three. Indeed, the number of all out-
comes decreases from 12 to six, but the number of favorable outcomes also
decreases, from four to two.
This warrants the following two deﬁnitions.
Deﬁnition 15.7. If A and B are two events from the same sample space
Ω, and P(A ∩B) = P(A) · P(B), then A and B are called independent
events. Otherwise they are called dependent.
Deﬁnition 15.8. Let A and B be events from the same sample space, and
assume P(B) > 0. Let
P(A|B) = P(A ∩B)
P(B)
.
Then P(A|B) is called a conditional probability, and is read “the probability
of A given B”.
That is, P(A|B) is the probability of A given that B occurs. The following
proposition is now immediate from the deﬁnitions.
Proposition 15.9. The events A and B are independent if and only if
P(A|B) = P(A) holds.

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
389
In other words, A and B are independent if and only if the occurrence
of B does not make the occurrence of A any more likely, or any less likely.
Example 15.10. We toss a coin four times. We are not allowed to see the
results, but we are told that there are at least two heads among the results.
What is the probability that all four tosses resulted in heads?
Solution. Let A be the event that all four tosses are heads, and let B
be the event that there are at least two heads.
Then A ∩B = A, so
P(A|B) = P(A)/P(B). As the probability of getting a head at any one
toss is 1/2, we have P(A) =
1
24 =
1
16. There is 1/16 chance to get four
heads, 4/16 chance to get three heads and one tail, and 6/16 chance to get
two heads, two tails. Therefore, P(B) = 11
24 , and P(A|B) = 1/11.
Example
15.11. Let p
=
p1p2 · · · pn
be a randomly selected n-
permutation. Let A be the event that p1 > p2, and let B be the event
that p2 > p3. Compute P(A|B), and decide if A and B are independent.
Solution. Clearly, P(A) = P(B) = 1/2 as can be seen by reversing the
relevant pair of entries. On the other hand, A ∩B is the event that p1 >
p2 > p3, which occurs in 1/6 of all permutations. Therefore,
P(A|B) = P(A ∩B)
P(B)
= 1/6
1/2 = 1
3 ̸= P(A),
so A and B are not independent.
Your reaction to the previous example was probably something along
the lines “Of course.
If p1 > p2, then p2 is smaller than normal, so it
is less likely than normal that p2 > p3.” While that argument works in
this case, one should be extremely careful when injecting intuition into
arguments involving conditional probabilities. The following example is a
striking instance of this.
Example 15.12. A University has two colleges, the College of Liberal Arts,
and the College of Engineering. Each college analyzed its own admission
record and each college found that last year, a domestic applicant to the
college had a larger chance to be admitted than an international applicant.
Can we conclude that the same is true for the entire university? (In this
example, we assume that applicants can only apply to one college.)
Solution. No, we cannot. A counterexample is shown in Figure 15.1.

390
A Walk Through Combinatorics
Domestic
International
Applied:   120
applicants
applicants
Entire
University
Liberal Arts        Engineering
Admitted: 10
Admitted:  10
Admitted: 20
Applied:   130
Applied:    10
Applied:   15
Admitted:  1
Applied:    115
Admitted:    91
Admitted:    90
: 15.9%
success rate : 79.1%
success rate:90% 
success rate:6.7%
success rate:8.3%
success rate: 100%
success rate 
Applied:    100
Fig. 15.1
Not all that glitters is gold.
How can this very counterintuitive fact called Simpson’s paradox be
explained? Some people do not believe it even after seeing examples of it.
An imprecise, but conceptually correct, explanation is this. A much larger
portion of the international applicants applied to Engineering, where the
general rate of acceptance was higher. While it is true that the domestic
students had an even higher acceptance rate in that college, it concerned
only eight percent of all domestic applicants, versus more than 85 percent
of international applicants. In other words, more than 85 percent of all
international applicants got into Engineering, whereas less than 16 percent
of all domestic applicants did. This is a huge diﬀerence, and the College of
Liberal Arts, with relatively few applicants, cannot make up for that.
In order to ﬁnd a more precise explanation, we will need Bayes’ Theo-
rem.
Theorem 15.13 (Bayes’ Theorem). Let A and B be mutually exclusive
events so that A ∪B = Ω. Let C be any event. Then
P(C) = P(C|A) · P(A) + P(C|B) · P(B).
(15.2)
In other words, the probability of C is the weighted average of its con-
ditional probabilities, where the weights are the probabilities of the condi-
tions.
Proof. (of Theorem 15.13) As A and B are mutually exclusive, A ∩C and

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
391
B∩C are disjoint, and since A∪B = Ω, their union is exactly C. Therefore,
P(C) = P(C ∩A) + P(C ∩B),
and the proof follows as the ﬁrst (resp. second) member of the right-hand
side agrees with the ﬁrst (resp. second) member of the right-hand side of
15.2.
Now we are in a position to provide a deeper explanation for Example
15.12. Let A1 (resp. B1) be the event that an international (resp. domestic)
applicant applies to the College of Liberal Arts, and deﬁne A2 and B2
similarly, for the College of Engineering. Let C1 (resp. C2) be the event that
an international (resp. domestic) applicant is admitted to the university.
Then Theorem 15.13 shows that
P(C1) = P(C1|A1) · P(A1) + P(C1|B1) · P(B1),
and
P(C2) = P(C2|A2) · P(A2) + P(C2|B2) · P(B2).
The criterion requiring that domestic students have larger chances to get
accepted by any one college ensures that P(C1|A1) < P(C2|A2), and
P(C1|B1) < P(C2|B2). It does not, however, say anything about P(A1)
and P(B1). (We know that A2 is the complement of A1, and B2 is the
complement of B1.) Therefore, we can choose A1 and B1 so that it is very
advantageous for P(C1), and very bad for P(C2). We can do this by choos-
ing P(A1) to be large if P(C1|A1) is large, and by choosing P(A1) small if
P(C1|A1) is small. Similarly, we can choose P(A2) to be large if P(C2|A2)
is small, and vice versa.
In other words, weighted averages are a lot harder to control than
unweighted averages. Indeed, if we impose the additional condition that
P(A1) = P(B1) = 1/2, or even only the condition P(A1) = P(B1), then
the domestic students would have a greater chance to be admitted to the
university.
Example 15.14. Exactly one of two people, Andrew and Brandi, has com-
mitted a crime. The only additional information that the police have is that
the perpetrator had a certain blood type T that is shared by ﬁve percent
of the general population. If the police ﬁnds out that Andrew also has that
blood type, how likely will that make that Andrew is the perpetrator?

392
A Walk Through Combinatorics
Solution. Let A (resp. B) denote the event that Andrew (resp. Brandi)
is the perpetrator. Let X denote the event that Andrew has blood type T .
We need to compute
P(A|X) = P(A ∩X)
P(X)
= P(X|A)P(A)
P(X)
.
(15.3)
As we will see, only the determination of P(X) requires work. Before
getting his blood type, the police only know that P(A) = P(B) = 1/2. If
Andrew is the perpetrator, then his blood type is surely T , so P(X|A) = 1,
whereas if Brandi is the perpetrator, then the blood type of Andrew has
ﬁve percent probability to be T , since then Andrew is just a member of the
general population. So P(X|B) = 1/20. Therefore, Bayes’ theorem implies
P(X) = P(X|A) · P(A) + P(X|B) · P(B) = 1 · 1
2 + 1
20 · 1
2 = 21
40.
So (15.3) implies
P(A|X) = 1 · 1
2
21
40
= 20
21.
So, if the only additional information is that Andrew has blood type T ,
then with probability 20/21, Andrew is the perpetrator.
The way in which we solved the above example often turns out to be
useful. We needed to compute P(A|X), which was not an obvious task.
However, the reverse conditional, that is, P(X|A), was simple to determine,
and then we used the fact that P(A ∩X) is equal to both P(A|X)P(X)
and P(X|A)P(A).
The reader is asked to solve Exercise 34 at this point. That exercise
shows a typical example when Bayes’ theorem solves a problem that does
not seem to be simple at the ﬁrst sight, and whose results are important
and counter-intuitive.
15.3.2
More Than Two Events
It is not obvious at ﬁrst sight how the independence of three or more events
should be deﬁned. We could require the equality P(A1 ∩A2 ∩· · · ∩An) =
P(A1) · P(A2) · · · ·· P(An). This, in itself, is not a very strong requirement,
however. It holds whenever P(A1) = 0, no matter how strongly the other
variables depend on each other. In order to have some more local conditions,
we can impose the requirements that P(Ai∩Aj) = P(Ai)P(Aj) for all i ̸= j.
However, consider the following situation.

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
393
We select a positive integer from [10] at random. Let A be the event
that this number is odd. Now let us select an integer from [20] at random,
and let B be the event that this number is odd. Finally, let C be the event
that the diﬀerence of the two selected integers is odd.
It is then not diﬃcult to verify that P(A) = P(B) = P(C) = 1/2, and
also the events A, B, and C are pairwise independent, that is, any two of
them are independent. However, P(A ∩B ∩C) = 0 ̸= P(A)P(B)P(C) =
1/8. Therefore, we do not want to call these events independent, either.
We resolve these possible problems by requiring a very strong property
for a set of events to be independent.
Deﬁnition 15.15. We say that the events A1, A2, · · · , An are independent
if, for any nonempty subset S = {i1, i2, · · · , ik} ⊆[n], the equality
P(Ai1 ∩Ai2 ∩· · · ∩Aik) = P(Ai1) · P(Ai2) · · · · P(Aik)
holds.
We close this section by mentioning that Theorem 15.13 is easy to gen-
eralize to more than two conditions.
Theorem 15.16 (Bayes’ Theorem, General Version). Let us assume
that A1, A2, · · · , An are events in a sample space Ω so that the equality
A1 ∪A2 ∪· · · ∪An = Ω holds, and Ai ∩Aj = ∅if i ̸= j. Let C ⊂Ω be any
event. Then
P(C) =
n

i=1
P(C|Ai)P(Ai).
Proof. Analogous to that of Theorem 15.13.
A famous application of the general version of Bayes’ theorem is the
Monty Hall problem. Consider a game show in which a contestant has to
choose one of three doors. One of the three doors hides a valuable prize,
as a new car, while each of the other two doors hides a goat. Once the
contestant makes her choice, the host, who knows where the car is, opens
one of the two doors not chosen by the contestant and shows that that door
has a goat behind it. At this moment in time, the contestant must choose
between the two remaining doors. Is she better of staying where she is, or
switching to the other door?
This problem has become famous because it is very tempting to say that
“there are two doors, one of them has the goat, the other has the car, so

394
A Walk Through Combinatorics
each of them has one-half chance to have the car, so it does not matter if
we stay or switch”.
This argument is incorrect. A quick explanation is that staying at the
original door will only reveal the car behind that door if the contestant
picked the right door at the beginning of the game, and clearly, there is
only a 1/3 probability of that. In the other 2/3 of the time, the original
choice of doors was wrong, and then switching is the good choice.
For a more detailed argument, we apply Theorem 15.16. Let A1, A2,
and A3 denote the events that the car is behind door 1, 2, and 3, respec-
tively. Let us assume that the contestant originally chooses door 1. Let
B be the event that the host shows that door 2 hides a goat. We need to
compute P(A1|B). We do this similarly to the solution of Example 15.14,
by computing
P(A1|B) = P(A1 ∩B)
P(B)
=
P(B|A1) · P(A1)
P(B|A1)P(A1) + P(B|A2)P(A2) + P(B|A3)P(A3),
(15.4)
where in the denominator of the far-right term, we applied Theorem 15.16.
The ingredients in (15.4) are not diﬃcult to compute. First, A1 = A2 =
A3 = 1/3. Second, if door 1 hides the car, then the host is equally likely
to open doors 2 and 3, so P(B|A1) = 1/2. Third, if door 2 hides the car,
then the host, who knows that the car is there, will never open that door,
so P(B|A2) = 0. Fourth, if door 3 hides the car, then the host has no
choice but opening door 2, since door 1 is taken by the contestant. So
P(B|A3) = 1. Therefore, (15.4) yields
P(A1|B) =
1
2 · 1
3
1
2 · 1
3 + 0 · 1
3 + 1 · 1
3
=
1
6
1
2
= 1
3.
So staying at the ﬁrst door results in 1/3 probability of winning the car,
therefore, the contestant should switch.
Quick Check
(1) A football team consists of 30 oﬀensive players and 20 defensive players.
For an oﬀensive player, there is a 50 percent chance of suﬀering an
injury in the course of a season; for a defensive player, that chance is
30 percent. If we select a player of the team at random, what is the
probabilty that he or she will get injured in the course of a season?
(2) Adam and Brandi each wrote a random element of [10] on a piece of
paper. An observer looked at those numbers, and told Charles that

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
395
the integer 1 appeared among them. Then Charles said that given that
information, it was more likely than not that both integers were odd.
Was he right?
(3) Let us assume that 48 percent of the population of a small town is
male. Among males, 20 percent have blond hair, while among females,
25 percent do. If we randomly select a resident of this town who has
blond hair, what is the probability that that person is a women?
15.4
Expected Values
A random variable is a function that is deﬁned on a sample space Ω, and
whose range is a set of real numbers. For example, if Ω is the set of all
graphs on n labeled vertices, we can deﬁne the random variable X by setting
X(G) to be the number of edges of G, or we can deﬁne the random variable
Y by setting Y (G) to be the number of connected components of G.
Just as for functions, we can deﬁne the sum and product of random
variables over the same sample space the usual way, that is, (X + Y )(u) =
X(u) + Y (u), and (X · Y )(u) = X(u) · Y (u).
Possibly the most important and useful parameter of a random variable
is its expected value, or, in other words, expectation, or average value, or
mean.
Deﬁnition 15.17. Let X : Ω →R be a random variable so that the set
S = {X(u)|u ∈Ω} is ﬁnite, that is, X only takes a ﬁnite number of values.
Then the number
E(X) =

i∈S
i · P(X = i)
is called the expected value, or expectation of X on Ω.
Here, and throughout this chapter, P(X = i) is the probability of the
event that X(u) = i. That is,
P(X = i) = |{u ∈Ω|X(u) = i}|
|Ω|
.
In other words, E(X) is the weighted average of all values X takes, with
the weights being equal to the probability of X taking the corresponding
value.
This implies that
E(X) = 1
|Ω|

u∈Ω
X(u).
(15.5)

396
A Walk Through Combinatorics
Remarks. Some probability variables can be deﬁned over many diﬀer-
ent sample spaces. Our above example, the number of edges of a graph,
can be deﬁned not just over the space of all graphs on n vertices, or all con-
nected graphs on n vertices, but also on all graphs on at most 3n vertices,
and so on. In each case, the set S = {X(u)|u ∈Ω} is diﬀerent, therefore
the expectation of X is also diﬀerent. Therefore, if there is a danger of con-
fusion, we write EΩ(X), to denote where the expectation is taken. If there
is no danger of confusion, however, we will only write E(X), to alleviate
notation.
Sometimes we announce both Ω and X in the same sentence as in “let
X(G) be the number of edges of a randomly selected connected graph G
on n vertices.” This means that Ω is the set of all connected graphs on n
vertices, and X(G) is the number of edges of the graph G ∈Ω.
It is possible to deﬁne the expectation of X in some cases when the set
S = {X(u)|u ∈Ω} is not ﬁnite. If S is a countably inﬁnite set, we can
deﬁne E(X) = 
i∈S i · P(X = i) as long as this inﬁnite sum exists. See
Exercise 4 for an example. If S is not countable, the summation may be
replaced by integration. Details can be found in any probability textbook.
Deﬁnition 15.18. The random variables X and Y are called independent
if for all s and t, the equality
P(X = s, Y = t) = P(X = s)P(Y = t)
holds.
15.4.1
Linearity of Expectation
For any real number c, we can deﬁne the random variable cX by setting
cX(u) = c(X(u)) for all u ∈Ω. The following innocent-looking theorem
proves to be extremely useful in enumerative combinatorics.
Theorem 15.19.
(1) Let X and Y be two random variables deﬁned over the same space Ω.
Then
E(X + Y ) = E(X) + E(Y ).
(2) Let X be a random variable, and let c be a real number. Then
E(cX) = cE(X).

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
397
So “taking expectations” is a linear operator. The best feature of this
theorem is that it does not require that X and Y be independent! No matter
how deeply X and Y are intertwined, nor how hard it is to compute, say,
the probability that X = Y , the expected value of X + Y is always given
by this simple formula. This is why linearity is the most useful property of
expectation, and is applied to a very wide array of problems.
Proof. (of Theorem 15.19)
(1) Using (15.5), we have
E(X + Y ) =
1
|Ω|

u∈Ω
(X + Y )(u)
=
1
|Ω|

u∈Ω
X(u) + 1
|Ω|

u∈Ω
Y (u)
= E(X) + E(Y ).
(2) Similarly,
E(cX) = 1
|Ω|

u∈Ω
(cX)(u) = c 1
|Ω|

u∈Ω
X(u) = cE(X).
We point out that the proofs above depended on formula (15.5), which
in turn depended on our condition throughout this chapter that each out-
come in Ω was equally likely. Theorem 15.19 can be proved without that
condition, as we show it below.
Proof. (of Theorem 15.19)
(1) Let x1, x2, · · · , xn be the values that X takes with a positive probabil-
ity, and let y1, y2, · · · , ym be the values that Y takes with a positive

398
A Walk Through Combinatorics
probability. Then
E(X + Y ) =
n

i=1
m

j=1
(xi + yj)P(X = xi, Y = yj)
=
n

i=1
m

j=1
xiP(X = xi, Y = yj)
+
n

i=1
m

j=1
yjP(X = xi, Y = yj)
=
n

i=1
xiP(X = xi) +
m

j=1
yjP(Y = yj)
= E(X) + E(Y ).
(2) Let r ∈Ω, then by deﬁnition (cX)(r) = cX(r). So if x1, x2, · · · , xn is
the range of X, then P(cX = cxi) = P(X = xi). Therefore,
E(cX) =
n

i=1
cxi · P(cX = cxi) = c
n

i=1
xiP(X = xi) = cE(X).
In order to be able to better appreciate the surprising strength of The-
orem 15.19, let p = p1p2 · · · pn be an n-permutation, and let us say that i
is a valley if pi is smaller than both of its neighbors, that is pi < pi−1, and
pi < pi+1. We require 2 ≤i ≤n −1 for i to be a valley.
Theorem 15.20. Let n ≥2 be a positive integer.
Then on average, a
randomly selected permutation of length n has (n −2)/3 valleys.
Without Theorem 15.19, this would be a painful task. We would have
to compute the number v(j) of n-permutations with j valleys for each j, (a
diﬃcult task), then we would have to compute 
j j · v(j)
n! . Theorem 15.19,
however, turns the proof into a breeze.
Proof. (of Theorem 15.20) Take n −2 diﬀerent probability variables
Y2, Y3, · · · , Yn−1, deﬁned on the set of all n-permutations as follows. For an
n-permutation p, let Yi(p) = 1 if i is a valley, and let Yi(p) = 0 otherwise.
Then for 2 ≤i ≤n −1, every pi has a 1/3 chance to be the smallest of the
set {pi−1, pi, pi+1}. Therefore,
E(Yi) = 1
3 · 1 + 2
3 · 0 = 1
3.

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
399
Deﬁne Y = Y2 + Y3 + · · · + Yn−1. Then Y (p) is the number of valleys of p.
Therefore, Theorem 15.19 implies
E(Y ) =
n−1

i=2
E(Yi) = (n −2) · E(Y1) = n −2
3
.
Variables similar to Yi, that is, variables that take value 1 if a certain
event occurs, and value 0 otherwise, are called indicator (random) variables.
Theorem 15.21. The expected value of the number of ﬁxed points in a
randomly selected n-permutation is 1.
Proof. We deﬁne n diﬀerent probability variables X1, X2, · · · , Xn on the
set of all n-permutations as follows. For an n-permutation p, let Xi(p) = 1
if pi = i, that is, when p has a ﬁxed point at position i, and let Xi(p) = 0
otherwise.
As pi is equally likely to take any value j ∈[n], it has a 1/n chance to
be equal to i. Therefore,
E(Xi) = 1
n · 1 + n −1
n
· 0 = 1
n,
for all i ∈[n]. Now deﬁne X = X1 + X2 + · · · + Xn; then X(p) is precisely
the number of ﬁxed points of p. On the other hand, applying Theorem
15.19, we get
E(X) =
n

i=1
E(Xi) = n · E(X1) = n · 1
n = 1,
(15.6)
which was to be proved.
15.4.2
Existence Proofs Using Expectation
It is common sense that the average of a set of numbers is never larger than
the largest of those numbers. This is true for weighted averages as well as
the following theorem shows.
Theorem 15.22. Let X : Ω →R be a random variable so that the set
S = {X(u)|u ∈Ω} is ﬁnite, and let j be the largest element of S. Then
j ≥E(X).

400
A Walk Through Combinatorics
Proof. Using the deﬁnition of E(X),
E(X) =

i∈S
i · P(X = i) ≤j

i∈S
P(X = i) = j.
We present two applications of this idea. The ﬁrst shows that a simple
graph will always contain a large bipartite subgraph.
Theorem 15.23. Let G be a simple graph with vertex set [n], and m edges.
Then G contains a bipartite subgraph with more than m/2 edges.
Proof. Let us split the vertices of G into two disjoint nonempty subsets
A and B. Then A and B span a bipartite subgraph H of G. (We remove
the edges within A and within B.) Let Ω be the set of 2n−1 −1 diﬀerent
bipartite subgraphs we get this way. Let X(H) be the number of edges in
H.
On the other hand, let us number the edges of G from one through m,
and let Xi = 1 if the edge i has one vertex in A, and one in B, and let
Xi = 0 otherwise.
What is P(Xi = 1)? By our deﬁnitions, we can get a subdivision of [n]
leading to Xi = 1 by ﬁrst putting the two endpoints of the edge i to diﬀerent
subsets, then splitting the remaining (n −2)-element vertex set in any of
2n−2 ways. Therefore, P(Xi = 1) =
2n−2
2n−1−1, and P(Xi = 0) = 2n−2−1
2n−1−1.
This implies
E(Xi) = 0 · P(Xi = 0) + 1 · P(Xi = 1) =
2n−2
2n−1 −1 > 1
2.
We can repeat this argument for all edges. Then we note that X = X1 +
X2 + · · · + Xm, so Theorem 15.19 implies
E(X) =
m

i=1
E(Xi) = m · E(X1) > m
2 .
As the expected value of the number of edges in these bipartite subgraphs
of G is more than m/2, it follows from Theorem 15.22 that there is at least
one bipartite subgraph of G with more than m/2 edges.
The next example is related to a well-known problem in complexity
theory, the so-called “Betweenness problem”.
Example 15.24. We are given a list L = (L1, L2, · · · , Lk) of ordered triples
Li = (ai, bi, ci), so that for any i, the numbers ai, bi, and ci are distinct

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
401
elements of [n]. It is possible, however, that symbols with diﬀerent indices
i and j denote the same number.
Let p = p1p2 · · · pn be an n-permutation. We say that p satisﬁes Li if
the entry bi is between ai and ci in p. (It does not matter whether the order
of these three entries in p is aibici or cibiai.)
Prove that there exists an n-permutation p that satisﬁes at least one
third of all Li in any given list L.
Solution. Let Yi be the indicator variable of the event that a randomly
chosen n-permutation satisﬁes Li. Then P(Yi = 1) = 1
3 as each of ai, bi
and ci has the same chance to be in the middle. Therefore, E(Yi) = 1
3.
Now if Y = k
i=1 Yi, then Y is the number of Li in L that are satisﬁed by
p. Theorem 15.19 then implies
E(Y ) =
k

i=1
E(Yi) = k
3 ,
and our claim follows from Theorem 15.22.
15.4.3
Conditional Expectation
Another way of computing the expectation of a variable is by using condi-
tional expectations. The conditional expectation E(X|A) is the expected
value of X given that event A occurs. Accordingly, E(X|A) is deﬁned by re-
placing the absolute probabilities in the deﬁnition of E(X) by probabilities
conditional on the occurrence of A. In other words,
E(X|A) =

i
i · P(X = i|A),
where i ranges through all values X takes with a positive probability, given
that A occurs.
We can then extend Theorem 15.16 to expectations as follows.
Theorem 15.25. Let X be a random variable, and let A1, A2, · · · , An be
events in a sample space Ω so that A1 ∪A2 ∪· · ·∪An = Ω, and Ai ∩Aj = ∅
if i ̸= j. Then
E(X) =
n

i=1
E(X|Ai)P(Ai).
Proof. This follows immediately from Theorem 15.16. Just let C be the
event X = j in that theorem. Multiply both sides by j, and sum over all
values of j taken by X with a positive probability.

402
A Walk Through Combinatorics
Example 15.26. We throw a die three times. Provided that the ﬁrst throw
was at least four, what is the expectation of the number of times a throw
resulted in an even number?
Solution. If the ﬁrst throw was an even number, then the expected number
of times we got an even result is two as it is one over the last two throws
and is one over the ﬁrst throw. If the ﬁrst throw was an odd number, then
this expectation is 1. Therefore, Theorem 15.25 implies
E(X) =
2

i=1
E(X|Ai)P(Ai) = 2
3 · 2 + 1
3 · 1 = 5
3.
In this problem, it was very easy to compute the probabilities P(Ai).
The following problem is a little bit less obvious in that aspect.
Example 15.27. Our football team wins each game with 3/4 probability.
What is our expected value of wins in a 12-game season if we know that we
won at least three of the ﬁrst four games?
Solution. We either won three games (event A1), or four games (event A2)
out of the ﬁrst four games. If we disregard the condition that we won at least
three games out of the ﬁrst four (event B), then P(A1) = 4· 1
4( 3
4)3 = 27
64, and
P(A2) = ( 3
4)4 =
81
256. That condition, however, leads us to the conditional
probabilities
P(A1|B) = P(A1 ∩B)
P(B)
=
27
64
27
64 + 81
256
= 4
7,
and
P(A2|B) = P(A2 ∩B)
P(B)
= 3
7.
In this problem we assume that B occurred, that is, B is our sample
space. To emphasize this, we will write PB(Ai) instead of P(Ai|B). We
denote the expectations accordingly.
In the last eight games of the season, the expected number of our wins
is certainly 8 · 3
4 = 6, by Theorem 15.19. Therefore, denoting the number
of our wins by X, Theorem 15.25 shows
EB(X) = EB(X|A1)PB(A1) + EB(X|A2)PB(A2) = 9 · 4
7 + 10 · 3
7 = 93
7.
We see that this expectation is larger than nine, the expectation without
the condition that we won at least three of the ﬁrst four games. This is
because that condition allowed us to win all four of those games, which is
better than our general performance.

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
403
Quick Check
(1) Let X be deﬁned on the set Fn of all functions from [n] to [n] as follows.
For f ∈Fn, we set X(f) to be the number of ﬁxed points of f on [n].
Compute E(X).
(2) Let X be deﬁned on the set of all permutations p of length n as follows.
We set X(p) to be the number of entries in p = p1p2 · · · pn that are
larger than all their neighbors and second neighbors. In other words,
X(p) counts the entries pi for which pi > pj if 0 < |i−j| ≤2. Compute
E(X).
(3) Let X be deﬁned on the set of all permutations p ∈Sn as follows. Let
X(p) be the number of entries i for which i and i + 1 are in the same
cycle of p. Compute E(X).
Notes
This Chapter was not as much on Probability Theory itself as on the
applications of Probability in Combinatorics.
While there are plenty of
textbooks on Probability Theory itself, there are not as many on Discrete
Probability, that is, when Ω is ﬁnite. A very accessible introductory book
in that ﬁeld is “Discrete Probability” by Hugh Gordon [27]. As far as the
Probabilistic Method in Combinatorics goes, a classic is “The Probabilistic
Method”, by Alon and Spencer [3].
Exercises
(1) Let pn be the probability that a random text of n letters has a sub-
string of consecutive letters that reads “Probability is fun”. Prove that
limn→∞pn = 1.
(2) A big corporation has four levels of command. The CEO is at the top,
(level 1) she has some direct subordinates (level 2), who in turn have
their own direct subordinates (level 3), and even those people have their
own direct subordinates (level 4). Nobody, however, has more direct
subordinates than his immediate supervisor. Is it true that the average
number of direct subordinates of an oﬃcer on level i is always higher
than the average number of direct subordinates of an oﬃcer on level
i + 1?
(3) A women’s health clinic has four doctors, and each patient is assigned

404
A Walk Through Combinatorics
to one of them. If a patient gives birth between 8am and 4pm, then her
chance of being attended by her assigned doctor is 3/4, otherwise it is
1/4. What is the probability that a patient is attended by her assigned
doctor when she gives birth?
(4) We toss a coin a ﬁnite number of times. Let S denote the sequence of
results. Set X(S) = i if a head occurs in position i ﬁrst. Find EΩ(X),
where Ω is the set of all ﬁnite outcome sequences.
(5) Show that for any n, there exist n events so that any n −1 of them are
independent, but the n events are not.
(6) At a certain university, a randomly selected student who has just en-
rolled has 66 percent chance to graduate in four years, but if he success-
fully completes all freshmen courses in his ﬁrst year, then this chance
goes up to 90 percent. Among those failing to complete at least one
freshmen course in their ﬁrst year, the 4-year-graduation rate is 50 per-
cent. What is the percentage of all students who cannot complete all
freshmen courses in their ﬁrst year?
(7) We select an element of [100] at random. Let A be the event that this
integer is divisible by three and let B be the event that this integer is
divisible by seven. Are A and B independent?
(8) Six football teams participate in a round robin tournament. Any two
teams play each other exactly once. We say that three teams beat each
other if in their games played against each other, each team got one
victory and one loss. What is the expected number of triples of teams
who beat each other? Assume that each game is a toss-up, that is, each
team has 50 percent chance to win any of its games.
(9) Solve the previous exercise if one of the teams is so good that it wins
its games by 90 percent probability.
(10) What is the expected value of the number of digits equal to 3 in a
4-digit positive integer?
(11) Let X(α) be the ﬁrst part of a randomly selected composition α of n.
Find E(X).
(12) Let Y (α) be the number of parts in a randomly selected composition
α of n. Find E(Y ).
(13) Let π be a randomly selected partition of the integer n. Let X(p) be
the ﬁrst part of π, and let Y (p) be the number of parts in π. Find
E(X) −E(Y ).
(14) Let p = p1p2 · · · pn be an n-permutation. Recall that the index i is
called an excedance of p if p(i) > i. How many excedances does the
average n-permutation have?

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
405
(15) Let k be any positive integer, and let n ≥k. Let Y be the number of
k-cycles in a randomly selected n-permutation. Find E(Y ).
(16) Recall from Chapter 14 that Sn(1234) < Sn(1324) if n ≥7. Let n
be a ﬁxed integer so that n ≥7.
Let A be the event that an n-
permutation contains a 1234-pattern, and let B be the event that an
n-permutation contains a 1324-pattern. Similarly, let X, (resp.
Y )
be the number of 1234-patterns (resp. 1324-patterns) in a randomly
selected n-permutation. What is larger, E(X|A) or E(Y |B)?
(17) Prove that there is a tournament on n vertices that contains at least
n!
2n−1 Hamiltonian paths. What can we say about the number of Hamil-
tonian cycles?
(18) Let Y be a probability variable. Then
Var(Y ) = E

(Y −E(Y ))2
is called the variance of Y .
(a) Prove that Var(Y ) = E(Y 2) −E(Y )2.
(b) Let X(p) be the number of ﬁxed points of a randomly selected n-
permutation p. Prove that Var(X) = 1.
Note that

Var(X) is called the standard deviation of X.
(19) For i ∈[n], deﬁne Xi as in the proof of Theorem 15.21. Are the Xi
independent?
(20) Let X and Y be two independent random variables deﬁned on the same
space. Prove that Var(X + Y ) = Var(X) + Var(Y ).
(21) We are given a list L = (L1, L2, · · · , Lk) of ordered 4-tuples Li =
(ai, bi, ci, di), so that for any i, the numbers ai, bi, ci, and di are distinct
elements of [n].
It is possible, however, that symbols with diﬀerent
indices i and j denote the same number.
Let p = p1p2 · · · pn be an n-permutation. We say that p satisﬁes Li if
the substring of p that stretches from ai to bi does not intersect the
substring of p that stretches from ci to di. (It could be that ai is on
the right of bi, or ci is on the right of di.)
Prove that there exists an n-permutation p that satisﬁes at least one
third of all Li in any given list L.
(22) A player pays a ﬁxed amount of n dollars to a casino for the right to
participate in the following game. A fair coin is tossed several times
until a tail is obtained. If the ﬁrst tail is obtained as the result of the
ith coin toss, then the player receives a payout of 2i dollars, and the
game ends.

406
A Walk Through Combinatorics
(a) Assuming that the casino has unlimited resources to pay its obliga-
tions and that the player has an unlimited amount of time to pay,
what is the value of n that the player should pay for the right to
play this game. (For this part of the exercise, let us say that the
player should pay any amount of n dollars as long as n is less than
the amount of his expected winnings.)
(b) What is the probability that the player will win less than 1000
dollars? Compare your answer to the answer to part (a).
(c) What is the expected value of the player’s payout if the casino has
“only’ 1014 dollars available for payouts? (This is more than the
world’s annual GDP.)
(23) Let X be deﬁned on the set of all 132-avoiding permutations of length
n so that X(p) is the number of right-to-left maxima of p. For instance,
X(43512) = 2, since in 43512, there are two entries that are larger than
everything on their right, namely 5 and 2. Compute E(X).
Supplementary Exercises
(24) What is the probability of ﬁnding two people who were born in the
same month of the year in a group of six randomly selected people?
(25) Prove that it is possible to 2-color the integers from 1 to 1000 so that
no monochromatic arithmetic progression of length 17 is formed.
(26) Is it true that if the occurrence of A makes B more likely to occur,
then the occurrence of B also makes A more likely to occur?
(27) (-) Give an example for three events A, B, and C, so that A and
B are independent, B and C are independent, but A and C are not
independent.
(28) (-) Give an example for three events A, B, and C so that A and B
are not independent, B and C are not independent, but A and C are
independent.
(29) (-) What is the probability of the event that a randomly selected
composition of n has ﬁrst part 1?
(30) What is the probability of the event that a randomly selected compo-
sition of n has a second part and that second part is 1?
(31) Let i ≥3. What is the probability that a randomly selected composi-
tion of n has an ith part and that part is 1?
(32) Let S be an n × n magic square (see Exercise 24 in Chapter 3) with
line sum r. Let A be the event that each entry of the ﬁrst row is at

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
407
least
r
2n, and let B be the event that each element of the second row
is at least
r
2n. Is the following argument correct?
“It must be that P(B|A) < P(B). Indeed, if A occurs, then the entries
of the ﬁrst row are all larger than normal, so each entry of the second
row must be smaller than normal, because the sum of each column is
ﬁxed.”
(33) Can two events be at the same time mutually exclusive and indepen-
dent?
(34) A medical device for testing whether a patient has a certain type of
illness will accurately indicate the presence of the illness for 99 percent
of patients who do have the illness, and will set oﬀa false alarm for
ﬁve percent of patients who do not have the illness.
Let us assume that only three percent of the general population has
the illness.
(a) If the test indicates that a given patient has the illness, what is
the probability that the test is correct?
(b) If the test indicates that a given patient does not have the illness,
what is the probability that the test is correct?
(c) What percentage of the test results provided by this device will
be accurate?
(35) In the National Basketball Association, home teams win about 60
percent of games. One expert tries to predict the outcome of each
game. On the long term, he correctly predicts a home team win for
85 percent of the games that are actually won by the home team, and
he incorrectly says that the home team will win for ten percent of the
games which are then won by the visiting team.
If the expert predicts that the home team will win a given game, what
is the probability that his prediction is correct?
(36) Adam and Brandi are playing the following game. They write each
integer from 1 through 100 on a piece a paper, then they randomly
select a piece of paper, and then another one.
They add the two
integers that are written on the two pieces of paper, and if the sum is
even, then Adam wins, if not, then Brandi. Is this a fair game?
(37) Replace 100 by n in the previous exercise. For which positive integers
n will the game be fair?
(38) Note: here, and in the next several exercises, when we say that we
randomly select two objects of a certain kind, we mean that we select
an ordered pair (A, B) of objects of that kind. So (A, B) and (B, A)

408
A Walk Through Combinatorics
are diﬀerent pairs, and A = B is allowed.
(a) Let us randomly select two subsets of [n]. What is the probability
that they have the same number of elements?
(b) Let f(n) be the probability you were asked to compute in part
(a). Prove that f(n) ≃
1
√nπ.
(39) Let us randomly select two compositions of the integer n, and let g(n)
be the probability that they have the same smallest part. Prove that
if n goes to inﬁnity, then g(n) →1.
(40) (+) Let us randomly select two partitions of [n], and let h(n) be the
probability that their smallest blocks have the same size. Prove that
if n goes to inﬁnity, then h(n) →1.
(41) Let us randomly select two permutations of length n, and let m(n) be
the probability that their largest cycles have the same length. Prove
that
m(n) ≥
n

i=⌈(n+1)/2⌉
1
k2 .
Note that the summation starts in the smallest value of i that is strictly
larger than n/2.
(42) A dealership has n cars. An employee with a sense of humor takes all
n keys, puts one of them in each car at random, then locks the doors
of all cars. When the owner of the dealership discovers the problem,
he calls a locksmith. He tells him to break into a car, then use the key
found in that car to open another, and so on. If and when the keys
already recovered by this procedure cannot open any new cars, the
locksmith is to break into another car. This algorithm goes on until
all cars are open.
(a) What is the probability that the locksmith will only have to break
into one car?
(b) What is the probability that the locksmith will have to break into
two cars only?
(c) What is the probability that the locksmith will have to break into
at most k cars?
(43) (+)
(a) Let us consider the situation described in the previous exercise, but
let us now assume that the manager calls two locksmiths, each of
whom chooses a car and breaks into it. What is the probability
that there will be no need to break into any other cars? (Make the

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
409
rather conservative assumption that the two locksmiths will not
break into the same car.)
(b) Same as part (a), but with k locksmiths, instead of two.
(c) Compare the result of part (a) of this exercise and part (b) of
the previous exercise. Explain why the results agree with common
sense.
(44) Let X be a random variable deﬁned on the sample space of all trees
on vertex set [n] so that X(t) equals the number of leaves of the tree
t. Find E(X). Explain what your result means for large values of n.
(That is, explain, roughly what fraction of the vertices of a tree on [n]
will be leaves on average.)
(45) Find the expectation of the number of k-cycles in a randomly selected
n-permutation. Then use the result to solve Exercise 7 of Chapter 6.
(46) We randomly select a cycle of an n-permutation. On average, what
will be the length of this cycle?
(47) There are 16 disks in a box. Five of them are painted red, ﬁve of
them are painted blue, and six are painted red on one side, and blue
on the other side. We are given a disk at random, and see that one of
its sides is red. Is the other side of this disk more likely to be red or
blue?
(48) There are ten disks in a basket, two of them are blue on both sides,
three of them are red on both sides, and the remaining ﬁve are red on
one side, and blue on the other side. One disk is drawn at random,
and we have to guess the color of its back. Does it help if we know
the color of its front?
(49) A pack of cards consists of 100 cards, two of them are black kings. We
shuﬄe the cards, then we start dealing them until we draw a black
king. Which is the step where this is most likely to occur?
(50) Let p = p1p2 · · · pn be an n-permutation. We say that p get changes
direction at position i, if either pi−1 < pi > pi+1, or pi−1 > pi < pi+1,
in other words, when pi is either a peak or a valley. We say that p has
k runs if there are k −1 indices i so that p changes direction at these
positions. For example, p = 3561247 has 3 runs as p changes direction
when i = 3 and when i = 4. What is the average number of runs in a
randomly selected n-permutation?
(51) What is the average number of cycles of length four in a randomly
selected graph on vertex set [n]? (Each pair of vertices has 1/2 chance
to be connected by an edge.)

410
A Walk Through Combinatorics
(52) Recall that a descent of a permutation p = p1p2 · · · pn is the number of
indices i ∈[n −1] so that pi > pi+1. Let X be the number of descents
of a randomly selected n-permutation. Find E(X) and Var(X).
Solutions to Exercises
(1) First, we note that the sequence {pn} is increasing. Indeed, pn+1 =
pn + qn, where qn is the probability of the event that the set of the
ﬁrst n letters does not contain the required sentence, but that of the
ﬁrst n + 1 letters does.
It is therefore suﬃcient to show that the sequence {pn} has a subse-
quence that converges to 1. Such a subsequence is rn = p16n. (Note
that the sentence “Probability is fun” contains 16 letters.)
Let a be the probability of the event that a randomly selected 16-letter
string is not our required sentence. Then a < 1. On the other hand,
rn ≥1 −an as we can split a 16n-letter string into n strings of length
16, each of which has a chance to be something else than our sentence.
So we have
1 −an ≤rn ≤1,
and our claim follows by the squeeze principle as an →0.
(2) That is not true. Figure 15.2 shows a counterexample. Indeed, the
average number of direct subordinates of level-2 oﬃcers is 6/4 = 1.5,
while that of level-3 oﬃcers is 10/6 = 1.66.
CEO (level 1)
level 2
level 3
level 4
Fig. 15.2
A counterexample for Exercise 2.
(3) There is 1/3 chance that a given patient gives birth between 8am and
4pm, and there is 2/3 chance that she gives birth between 4pm and

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
411
8am. Therefore, Bayes’ theorem shows that the answer is 1
3 · 3
4 + 2
3 · 1
4 =
5
12.
(4) The only way for the ﬁrst head to occur in position i is to have a tail
in each of the ﬁrst i −1 positions, then a head in position i. The
chance of this happening is 1/2i. Therefore, we have
E(X) =
∞

i=1
i
2i = 2.
We used the fact that 
n≥1 nxn =
x
(1−x)2 . This has been proved in
two diﬀerent ways in Exercise 26 of Chapter 4.
(5) Let us throw a die n −1 times, and for 1 ≤i ≤n −1, denote Ai the
event that throw i results in an even number. Finally, let An be the
event that the sum of all the results is even. Then for any k-element
subsets of these events, for 1 ≤k ≤n −1, we have
P(Ai1) · P(Ai2) · · · · P(Aik) = P(Ai1 ∩Ai2 ∩· · · ∩Aik) = 1
2k .
However,
P(A1 ∩A2 ∩· · · ∩An) = P(A1 ∩A2 ∩· · · ∩An−1) =
1
2n−1
̸= 1
2n = P(A1) · P(A2) · · · · P(An).
(6) Let A be the event that a randomly selected new student passes all
his courses in his ﬁrst year, and let C be the event that a randomly
selected new student graduates in four years. Then Bayes’ theorem
and our data imply
P(C) = P(C|A)P(A) + P(C| ¯A)P( ¯A),
0.66 = 0.9P(A) + 0.5(1 −P(A)),
yielding P(A) = 0.4, and P( ¯A) = 0.6. This means that sixty percent
of freshmen fail to complete at least one course in their ﬁrst year.
(7) No, they are not. There are 33 integers in [100] that are divisible by
three, and there are 14 integers in [100] that are divisible by seven.
Therefore P(A) = 33/100, and P(B) = 14/100. On the other hand,
there are just 4 integers in [100] that are divisible by 21 (so both by
three and seven), which implies that P(A ∩B) = 4/100 = 0.04. On
the other hand, P(A)P(B) =
462
1000 = 0.0462.

412
A Walk Through Combinatorics
(8) Select three teams A, B, and C. Their three games within this 3-
member group, that is A vs. B, B vs. C, and A vs. C can end in
eight diﬀerent ways. Only two of those are outcomes in which these
teams beat each other. Thus the expected number of beat-each-other
triples on {A, B, C} is 1/4. As there are
6
3

= 20 possible triples, it
follows from Theorem 15.19 that the expected number of beat-each-
other triples is 5.
(9) In this case, the ten triples not containing the strong team still have
a 1/4 chance to beat each other. In any of the other ten triples, the
chances for this are 2 · 0.9 · 0.1 · 0.5 = 0.09. Therefore, using indicator
variables and Theorem 15.19, we get that on average, there will be
10 · 0.25 + 10 · 0.09 = 3.4 beat-each-other triples.
(10) Deﬁne indicator variables the usual way, that is, Xi = 1 if the ith
digit is equal to 3, and zero otherwise. Then E(X1) = 1/9, as the ﬁrst
digit cannot be zero, and E(Xi) = 0.1 if i > 1. Therefore, we have
E(X) = E(X1 + X2 + X3 + X4) = 1
9 + 3
10 = 0.4111.
(11) Let Ai be the event that α has i parts. Then P(Ai) = (n−1
i−1)
2n−1 , and the
ﬁrst part of α is n/i on average. Therefore,
E(X) =
n

i=1
n−1
i−1

2n−1 · n
i =
1
2n−1 ·
n

i=1
n
i

= 2n −1
2n−1 = 2 −
1
2n−1 .
(12) First solution. The number of weak compositions of n into k parts
is
n−1
k−1

. Therefore, the probability that a randomly selected weak
composition of n will have k parts is
n−1
k−1

/2n−1. This implies
E(Y ) =
1
2n−1
n

k=1
k
n −1
k −1

=
1
2n−1 ((n −1)2n−2 + 2n−1) = n + 1
2
.
Second solution. Alternatively, we know that weak compositions of
n into k parts are in bijection with (k −1)-element subsets of [n −1].
There is a natural bijection between these subsets of [n −1], and
(n −k)-element subsets of [n −1], simply by taking complements.
This, however, deﬁnes a bijection between weak compositions of n
into k parts, and weak compositions of n into n + 1 −k parts, and the
claim follows.
(13) For all i, we have P(X = i) = P(Y = i). Indeed, π has ﬁrst part i
if and only if its conjugate partition has i parts. Therefore, E(X) =
E(Y ), so E(X) −E(Y ) = 0.
(14) Let Xi the indicator variable of the event that i is an excedance of
p. Then clearly, P(Xi = 1) = n−i
n , thus E(Xi) = n−i
n . Let X(p) be

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
413
the number of excedances of p, then E(X) =  E(Xi) = n
i=1
n−i
n
=
n(n−1)
2n
= n−1
2 .
(15) We know from Lemma 6.19 that the probability that a given entry
i of p is part of a k-cycle is 1/n.
Therefore, if Yi is the indicator
variable of i being part of a k-cycle, then E(Yi) = 1/n.
Now we
have Y = Y1+Y2+···+Yn
k
. Indeed, a k-cycle contains exactly k entries.
Therefore, we get by Theorem 15.19 that E(Y ) = nE(Y1)/k = 1/k.
(16) First note that E(X) = E(Y ) =
n
4

/24 as any four entries of p have a
1/24 chance of forming a q-pattern, for any 4-element pattern q. Now
Theorem 15.25 shows
E(X) = E(X|A)P(A) + E(X| ¯A)P( ¯A) = E(X|A)P(A),
E(Y ) = E(Y |B)P(B) + E(Y | ¯B)P( ¯B) = E(Y |B)P(B).
Indeed, the second summands are obviously equal to zero. As E(X) =
E(Y ), this implies E(X|A)P(A) = E(Y |B)P(B), and then P(A) >
P(B) implies E(Y |B) > E(X|A).
This makes perfect sense: a smaller number of permutations contains
the same number of patterns, so on average, they must contain more
patterns.
(17) Take Kn, and direct each of its edges at random, to get a tournament
T . If p is an undirected Hamiltonian path in Kn, then let Xp(T ) = 1
if p becomes a directed Hamiltonian path in T , and let Xp(T ) = 0
otherwise. Then we have E(Xp) =
1
2n−1 , as p has n −1 edges. Let
X = 
p Xp, where p ranges through all n! Hamiltonian paths of Kn.
Then X equals the number of Hamiltonian paths of T . Theorem 15.19
then implies
E(X) = n!E(Xp) =
n!
2n−1 ,
and our claim follows from Theorem 15.22.
For Hamiltonian cycles, the only diﬀerence is that they have one ad-
ditional edge. Therefore, there exists a tournament on n vertices with
at least n!
2n Hamiltonian cycles.
(18)(a) We get Var(Y ) = E((Y −E(Y ))2) = E(Y 2)−E(2Y E(Y ))+E(Y )2,
by simply computing the square. Note that in the second term,
E(Y ) is a number, so we get Var(Y ) = E(Y 2)−2E(Y )2 +E(Y )2 =
E(Y 2) −E(Y )2.

414
A Walk Through Combinatorics
(b) Using the result computed in part (a), and the linearity of expec-
tation, we simply have to show that E(X2) = 2. For i ∈[n], deﬁne
Xi as in the proof of Theorem 15.21. Then
E(X2) = E((
n

i=1
Xi)2) =
n

i=1
E(X2
i ) + 2

i<j
E(XiXj).
(15.7)
Now note that the Xi are 0-1 variables, so Xi = X2
i , and in partic-
ular, E(X2
i ) = E(Xi) = 1/n, by Theorem 15.21. If p is a randomly
selected n-permutation, and i < j, then there is 1/(n −1)n chance
that pi = i, and pj = j, which is the only way for XiXj to be
nonzero (one). Therefore, E(XiXj) =
1
n(n−1). This, compared to
(15.7), implies
E(X2) = n · 1
n + 2 ·
n
2

·
1
n(n −1) = 1 + 1 = 2,
and our claim follows.
(19) No, they are not. We have computed in the proof of the previous
exercise that P(XiXj = 1) =
1
n(n−1). On the other hand, we have
computed in Theorem 15.21 that P(Xi) = P(Xj) = 1
n. So P(XiXj =
1) ̸= P(Xi = 1)P(Xj = 1), and our claim is proved.
(20) It follows from part (a) of Exercise 18 that
Var(X + Y ) = E((X + Y )2) −E(X + Y )2.
(15.8)
Let us express both members of the right-hand side by simpler terms
as follows. On one hand,
E((X + Y )2) = E(X2) + E(Y 2) + 2E(XY ) = E(X2) + E(Y 2)
+2E(X)E(Y ),
as X and Y are independent. On the other hand,
E(X + Y )2 = (E(X) + E(Y ))2 = E(X)2 + E(Y )2 + 2E(X)E(Y ).
Comparing these two equations to (15.8), we get Var(X + Y ) =
E(X2) + E(Y 2) −E(X)2 −E(Y )2, and the statement is proved.
(21) Let Yi be the indicator variable of the event that a randomly chosen
n-permutation satisﬁes Li. Then clearly, P(Yi = 1) = 1
3 as ai, bi, ci
and di can occur in p in 24 diﬀerent ways, of which eight satisﬁes Li.
Indeed, we can ﬁrst choose if the (ai, bi) pair comes ﬁrst, or the (ci, di)
pair comes ﬁrst, then we can choose the order of the elements within
the pairs.

Who Knows What It Looks Like, But It Exists. The Probabilistic Method
415
Therefore, E(Yi) = 1
3. Now let Y = k
i=1 Yi, then Y is the number of
Li in L that are satisﬁed by p. Theorem 15.19 then implies
E(Y ) =
k

i=1
E(Yi) = k
3 ,
and our claim follows from Theorem 15.22.
(22)(a) The probability of the ﬁrst tail coming at the ith toss is 2−i, for
all i. So the expected payout is

i≥1
2−i · 2i =

i≥1
1 = ∞.
So, given the (unrealistic) conditions of this part of the exercise,
no ﬁnite price is too high for the player to play this game.
(b) The player will win more than 1000 dollars if and only if it takes
at least ten tosses to get the ﬁrst tail (since 210 = 1024 is the
smallest power of 2 that is larger than 1000). That happens if and
only if the ﬁrst nine tosses are all heads, and the probability of
that is 2−9 = 1/512. So very few people would pay more than
1000 dollars to play this game, since the chances of recovering their
participation fee are less than 0.002 percent.
(c) In this case, the expected value of the payout is

i≥1
2−i · min(2i, 1014) =
log2(1014)

i≥1
1 + 1014 ·

i>log2(1014)
2−i
= 46 + 1014
246
= 47.2.
So expecting a payout of more than 47.2 dollars is not realistic.
(23) Let Xi be the indicator random variable of the event that the ith entry
pi of p is a right-to-left maximum. In 132-avoiding permutations with
that property, all entries on the left of pi must be larger than all
entries on the right of pi, or a 132-pattern would be formed with pi
in its middle. As pi itself is also larger than all entries on its right, it
follows that the entries on the right of pi must be precisely the element
of [n −i]. Both the strings p1p2 · · · pi and pi+1pi+2 · · · pn must be 132
avoiding permutations. This implies that
E(Xi) = cicn−i
cn
,

416
A Walk Through Combinatorics
where ci =
2i
i

/(i+ 1) denotes the ith Catalan number. So, using the
linearity of expectation, we get that
E(X) = 1
cn
n

i=1
cicn−i = cn+1 −cn
cn
=
3n
n + 2.
We used the recurrence relation of Catalan numbers that states that
cn+1 = n
i=0 cicn−i.

Chapter 16
At Least Some Order. Partial Orders
and Lattices
16.1
The Notion of Partially Ordered Set
Let us assume that you are looking for air tickets for your upcoming trip.
There are ﬁve diﬀerent airlines oﬀering service to your destination, and
you know what each of them would charge for a ticket. However, price is
not the only important criterion for you. The duration of the ﬂights also
matters a little bit. In other words, if airline X oﬀers a lower price and a
shorter ﬂight-time than airline Y , then you say that the oﬀer of airline X
is a better oﬀer.
Let us assume that the oﬀers from the ﬁve airlines are as follows.
A 600 dollars, 9 hours 20 minutes,
B 650 dollars, 8 hours 40 minutes,
C 550 dollars, 9 hours 10 minutes,
D 575 dollars, 8 hours 20 minutes,
E 660 dollars, 9 hours 5 minutes.
For example, the oﬀer of airline D is clearly better than that of airline
E, but there is no such clear-cut diﬀerence between the oﬀers of airlines C
and D. You can represent the entire complex situation with the diagram
shown in Figure 16.1.
In this diagram, the dots correspond to the oﬀers. If an oﬀer X is better
than another oﬀer Y , then X is above Y in the diagram, and there is a path
from X to Y so that when we walk through that path, we never walk up.
This was an example of a partially ordered set, the main topic of this
chapter. The reader probably sees the explanation for this name: some,
but not necessarily all, pairs of our elements were comparable. The time
has come for a formal deﬁnition.
417

418
A Walk Through Combinatorics
C
D
B
A
E
600 dollars
9h 20min
650 dollars
8h 40min
660 dollars
9h 5min
575 dollars
8 h 20 min
550 dollars
9h 10 min
Fig. 16.1
Comparing the ﬁve oﬀers.
Deﬁnition 16.1. Let P be a set, and let ≤be a relation on P so that
(a) ≤is reﬂexive, that is, x ≤x, for all x ∈P,
(b) ≤is transitive, that is, if x ≤y and y ≤z, then x ≤z,
(c) ≤is antisymmetric, that is, if x ≤y and y ≤x, then x = y.
Then we say that P≤= (P, ≤) is a partially ordered set, or poset. We also
say that ≤is a partial ordering of P.
Just as for the traditional ordering of real numbers, we write x < y if
x ≤y, but x ̸= y. When there is no danger of confusion as to what the
partial ordering ≤of P is, we can write P for the poset P≤. If, for two
elements x and y of P, neither x ≤y nor y ≤x holds, then we say that x
and y are incomparable.
Example 16.2. Let P be the set of all subsets of [n], and let A ≤B if
A ⊆B. Then P≤is a partially ordered set. This partially ordered set is
denoted by Bn and is often called a Boolean algebra of degree n.
Example 16.3. The set of all subspaces of a vector space, ordered by
containment, is a partially ordered set.
Example 16.4. Let P be the set of all positive integers, and let x ≤y if
x is a divisor of y. Then P≤is a partially ordered set.
Example 16.5. Let P = R, the set of real numbers, and let ≤be the
traditional ordering. Then P≤is a partial order, in which there are no two
incomparable elements. Therefore, we also call R a total order, or chain.

At Least Some Order. Partial Orders and Lattices
419
Example 16.6. Let P be the set of all partitions of [n]. Let α and β be
two elements of P. Deﬁne α ≤β if each block of β can be obtained as the
union of some blocks of α. For instance, if n = 6, then {1, 4}{2, 3}{5}{6} ≤
{1, 4, 6}{2, 3, 5}.
Then P≤is a partial order, which is often called the
reﬁnement order, and is denoted by Πn.
If x ∈P is such that there is no y ∈P for which x < y, then we say
that x is a maximal element of P. If for all z ∈P, z ≤x holds, then we
say that x is the maximum element of P. Minimal and minimum elements
are deﬁned accordingly. The reader should verify that all ﬁnite posets have
minimal and maximal elements.
Not all ﬁnite posets have minimum or
maximum elements, however. The poset shown in Figure 16.1 does not
have either. The minimum element of a poset, if it exists, is often denoted
by ˆ0, while its maximum element, if it exists, is often denoted by ˆ1.
If x < y in a poset P, but there is no element z ∈P so that x < z < y,
then we say that y covers x. This notion enables us to formally deﬁne Hasse
diagrams, the kind of diagrams we informally used in our introductory
example.
The Hasse diagram of a ﬁnite poset P is a graph whose vertices represent
the elements of the poset. If x < y in P, then the vertex corresponding
to y is above that corresponding to x. If, in addition, y covers x, then
there is an edge between x and y. Alternatively, if we want to avoid the
imprecise (but intuitively obvious) notion of “above”, we can say that the
Hasse diagram of P is the directed graph whose vertices are the elements
of P, and in which there is an edge from x to y if x is covered by y.
Example 16.7. The Hasse diagram of B3 is shown in Figure 16.2.
Hasse diagrams are useful to visualize various properties of posets. In
particular, they can help us decide whether two small posets are isomorphic
or not. We can hear the complaints of the reader that we have not even
given the deﬁnition of isomorphism of posets yet. This is true, but the
deﬁnition is the obvious one.
That is, two posets P and Q are called
isomorphic if there is a bijection f : P →Q so that for any two elements x
and y of P, the relation x ≤P y holds if and only if f(x) ≤Q f(y).
It is easy to verify that up to isomorphism, there is one 1-element poset,
two 2-element posets, and ﬁve 3-element posets. The Hasse diagrams of the
latter are shown in Figure 16.3. The reader is invited to ﬁnd all sixteen
4-element posets.
We have deﬁned chains in Example 16.5. To see a ﬁnite example, in

420
A Walk Through Combinatorics
{1,2,3}
{2,3}
{1,3}
{1,2}
3
2
1
empty set 
{  }
{  }
{  }
Fig. 16.2
The Hasse diagram of B3.
Fig. 16.3
The ﬁve three-element posets.
B4, the set of subsets {{2, 3}, {3}, {1, 2, 3, 4}} is a chain as we have {3} ≤
{2, 3} ≤{1, 2, 3, 4}.
The dual notion is that of antichains. If the subset S ⊆P contains no
two comparable elements, then we say that S is an antichain. For example,
{{2, 3}, {1, 3}, {3, 4}, {2, 4}} forms an antichain in B4 as none of these four
sets contains another one.
It is straightforward that any subset of a chain is a chain, and any subset
of an antichain is an antichain. A chain cover of a poset is a collection of
disjoint chains whose union is the poset itself. The size of a chain cover

At Least Some Order. Partial Orders and Lattices
421
is just the number of chains in it. It seems plausible that if a poset has a
large antichain, then it cannot be covered with just a few chains, and vice
versa. The following classic theorem shows the precise connection between
the sizes of antichains and chain covers of a poset.
Just as for matchings, a chain, (resp. antichain) X of P is called max-
imum if P has no larger chain (resp. antichain) than X, and X is called
maximal if it cannot be extended. That is, no element can be added to X
without destroying the chain (resp. antichain) property of X.
Theorem 16.8 (Dilworth’s Theorem). In a ﬁnite partially ordered set
P, the size of any maximum antichain is equal to the number of chains in
any smallest chain cover.
Proof. Let a be the size of a maximum antichain A of P, and let b be the
size of any smallest chain cover of P. Then it is clear that a ≤b. Indeed,
no chain can contain more than one element of A, so at least a chains are
needed in any chain cover.
We still have to prove the converse, that is, if the largest antichain of
P is of size k, then P can be decomposed into the union of k chains. We
prove this by induction on n, the number of elements in P. The initial case
of n = 1 is trivial. Now let us assume that the statement is true for all
positive integers less than n. We distinguish two cases.
• First let us assume that P has a k-element antichain A that contains
at least one element that is not minimal, and at least one element
that is not maximal. Then A “cuts P into two”, that is, into the
sets U and L, where U is the set of elements that are greater than
or equal to at least one element in A, and L is the set of elements
that are smaller than or equal to at least one element in A. Note that
U ∩L = A. As A contains non-minimal and non-maximal elements, U
and L are non-empty, and they both are partially ordered sets, with
the ordering of P naturally restricted to them. Moreover, they have
less than n elements, so the induction hypothesis implies that they
are both unions of k chains. Each of the k chains in U has one of the
k elements of A at its bottom, and each of the k chains in L has one
of the k elements of A at its top. Therefore, these 2k chains can be
united to k chains covering P.
• Now let us assume that P does not have an antichain like the an-
tichain A of the previous case. That is, all maximum antichains of

422
A Walk Through Combinatorics
P consist of maximal elements only, or minimal elements only. That
necessarily implies that they contain all minimal elements, or all max-
imal elements.
Let x be a minimal element of P, and let y be a
maximal element of P such that x ≤y. (Since P is ﬁnite, such a pair
of elements exist, though in the trivial special case when P itself is
antichain, x = y will occur.) Let P ′ be the poset obtained from P by
removing x and y. Then the largest antichain of P ′ has k −1 elements
as it cannot contain all minimal elements or all maximal elements of
P. Moreover, P ′ has less than n elements, so by the induction hy-
pothesis, it can be decomposed into k −1 chains. Adding the chain
x ≤y to this chain cover of P ′, we get a chain cover of P that is of
size k.
Note that the size of the largest antichain of a poset P is often called
the width of P.
If P is an n-element poset, then a linear extension of P is just an
order-preserving bijection from P onto [n]. That is, if x ≤y in P, then
f(x) ≤f(y) in [n].
Example 16.9. The poset shown on the left in Figure 16.4 has two linear
extensions, f, and g, where f(A) = g(A) = 4, f(D) = g(D) = 1, f(B) =
g(C) = 2, and f(C) = g(B) = 3. The poset shown on the right in Figure
16.4 has four linear extensions, as {E, F} can be mapped onto {3, 4} in two
ways, and {G, H} can be mapped onto {1, 2} in two ways.
A
B
C
D
E
F
G
H
Fig. 16.4
Posets with two and four linear extensions.

At Least Some Order. Partial Orders and Lattices
423
Quick Check
(1) Show an example of a poset that has inﬁnitely many elements, a con-
nected Hasse diagram, and inﬁnitely many minimal and maximal el-
ements.
(2) Let P be a ﬁnite poset, and let GP be the simple graph whose vertex
set is the set of elements of P, and in which vertices x and y are
adjacent if and only if one of x ≤y and y ≤x holds. Note that GP is
called the comparability graph of P. Is it true that if GP is a regular
graph, then P must be a chain or an antichain?
(3) An order-preserving bijection f : P →P whose inverse is also order-
preserving is called an automorphism of the poset P.
How many
automorphisms does the Boolean algebra Bn have?
16.2
The M¨obius Function of a Poset
In what follows we will develop some powerful computation techniques for
a large class of posets. This class includes all ﬁnite posets. If the reader is
only interested in ﬁnite posets, she can skip the next two paragraphs. In
those paragraphs we discuss what other posets will belong to this class.
If x ≤y are elements of P, then the set of all elements z satisfying
x ≤z ≤y is called the closed interval between x and y, and is denoted by
[x, y]. If all intervals of P are ﬁnite, then P is called locally ﬁnite. Note
that this does not necessarily mean that P itself is ﬁnite. The set of all
positive integers with the usual ordering provides a counterexample.
A set of elements I ⊆P is called an ideal if x ∈I and y ≤x imply
y ∈I. If an ideal is generated by one element, that is, I = {y : y ≤x},
then I is called a principal ideal. For example, if P = Bn, then the ideal
of all subsets of [k] is a principal ideal, while the ideal of all subsets that
have at most four elements is not. In some of our theorems, we will have to
restrict ourselves to posets in which each principal ideal is ﬁnite. In other
words, each element is larger than a ﬁnite number of elements only. Note
that this is a stronger requirement than being locally ﬁnite. The poset of
all integers is locally ﬁnite, but has no ﬁnite principal ideals. Finally, we
note that dual ideals, and principal dual ideals are deﬁned accordingly.
Let Int(P) be the set of all intervals of P.
Deﬁnition 16.10. Let P be a locally ﬁnite poset.
Then the incidence
algebra I(P) of P is the set of all functions f : Int(P) →R.

424
A Walk Through Combinatorics
Multiplication in this algebra is deﬁned by
(f · g)(x, y) =

x≤z≤y
f(x, z)g(z, y).
This deﬁnition of multiplication may seem odd at ﬁrst sight. However,
note that this is precisely the same as matrix multiplication. Indeed, take
any linear extension x1x2 · · · xn of P, and deﬁne the n × n matrices F and
G whose (i, j) entries are f(xi, xj) and g(xi, xj). These matrices will be
upper triangular. Taking their product FG, we can see that the (i, j) entry
of this product is
n

k=1
f(xi, xk)g(xk, xj) =
j

k=i
f(xi, xk)g(xk, xj) =

xi≤xk≤xj
f(xi, xk)g(xk, xj),
as claimed. So the incidence algebra of P is isomorphic to the algebra of
n × n upper triangular matrices. We will alternatingly use the function
terminology and the matrix terminology in our discussion.
Does I(P) have a unit element, that is, an element u so that uf = fu =
f for all f ∈I(P)? The above discussion shows that it must have as the
algebra of all upper triangular matrices does have one, namely the identity
matrix.
The corresponding element of I(P) is the function δ satisfying
δ(x, y) = 1, if x = y, and δ(x, y) = 0 if x < y. It is straightforward to verify
that indeed, this function satisﬁes δf = fδ = f for all f ∈I(P), so it is
indeed the unit element of I(P).
The following element of I(P) is also a simply deﬁned zero-one function.
Nevertheless, it is surprisingly useful.
Deﬁnition 16.11. Let P be a locally ﬁnite poset. Let ζ ∈I(P) be deﬁned
by ζ(x, y) = 1 if x ≤y. Then ζ is called the zeta function of P.
A multichain in a poset is a multiset of elements a1, a2, · · · , am satisfying
a1 ≤a2 ≤· · · ≤am. Note that the inequalities are not strict, unlike in the
deﬁnition of chains.
Proposition 16.12. Let x ≤y be elements of the locally ﬁnite poset P.
Then the number of multichains x = x0 ≤x1 ≤x2 ≤· · · ≤xk = y is equal
to ζk(x, y).
Proof. By induction on k. If k = 1, then we have ζ1(x, y) = 1 if and only
if x ≤y, and the statement is true. (In fact, the statement is even true if
k = 0. Then ζ0(x, y) = δ(x, y) = 1 if and only if x = y.)

At Least Some Order. Partial Orders and Lattices
425
Now let us assume that the statement is true for all positive integers less
than k. Each multichain x = x0 ≤x1 ≤x2 ≤· · · ≤xk = y can uniquely
be decomposed to a multichain x = x0 ≤x1 ≤x2 ≤· · · ≤xk−1 = z, and
a two-element multichain z ≤y, where z ∈[x, y]. Fix such a z. Then our
induction hypothesis implies that the number of multichains x = x0 ≤x1 ≤
x2 ≤· · · ≤xk−1 = z is ζk−1(x, z), while the number of multichains z ≤y
is ζ(z, y). Summing over all z, we get that the total number of multichains
x = x0 ≤x1 ≤x2 ≤· · · ≤xk = y is

z∈[x,y]
ζk−1(x, z)ζ(z, y) = ζk(x, y).
The above proof shows that the number of elements of a multichain,
or chain for that matter, is not always the handiest description of its size.
We will sometimes use the length of the chain, or multichain instead. The
length of a chain (or multichain) is the number of its elements minus one.
For chains, this has the following intuitive justiﬁcation. If we walk up in
the Hasse diagram of the poset, from the bottom of a chain of length k to
its top, we will make k steps.
Lemma 16.13. Let P be a locally ﬁnite poset. Let [x, y] ∈Int(P). Then
the number of chains of length k that start at x and end in y is (ζ−δ)k(x, y).
Proof. Analogous to that of Proposition 16.12.
Does the zeta function of P have an inverse? That is, does there exist
a function μ ∈I(P) so that ζμ = μζ = δ? Again, resorting to our usual
help, the matrix representations of the elements of I(P), we see that the
answer to this question should be in the aﬃrmative. (The zeta matrix Z
of P is just the n × n matrix whose rows and columns are labeled by the
n elements of P, according to some linear extension of P, and Zi,j = ζi,j.)
Indeed, ζ(x, x) = 1 for all x ∈P, therefore all diagonal entries of the zeta
matrix Z of P are equal to 1, so det Z = 1 as Z is triangular. Hence Z−1
exists, and those who remember the formula for the inverse of a matrix
know that the matrix Z−1 will have integer entries only.
It turns out that the inverse of the zeta function of P is even more
important than the zeta function itself. Therefore, it has its own name.
Deﬁnition 16.14. The inverse of the zeta function of P is called the
M¨obius function of P, and is denoted by μ = μP .

426
A Walk Through Combinatorics
Computing the values of μ by computing the matrix Z−1 could be quite
time-consuming. Fortunately, the triangular property of Z makes the fol-
lowing recursive computation possible.
Theorem 16.15. Let P be a locally ﬁnite poset. Let [x, y] ∈Int(P). Then
μ(x, x) = 1, and
μ(x, y) = −

x≤z<y
μ(x, z)
(16.1)
if x < y. In other words, μ is the only function in I(P) satisfying μ(x, x) =
1, and 
z∈[x,y] μ(x, z) = 0 for all x < y.
Proof. First, we have 1 = δ(x, x) = (μζ)(x, x) = μ(x, x)ζ(x, x) = μ(x, x).
Second, we have
0 = δ(x, y) = μζ(x, y) =

z∈[x,y]
μ(x, z)ζ(z, y) =

z∈[x,y]
μ(x, z)
if x < y. So the sum of μ(x, z), taken over all z in a nontrivial interval
[x, y] is indeed 0 as we claimed.
Corollary 16.16. Let P be a locally ﬁnite poset. Let [x, y] ∈Int(P), and
let us assume that x ̸= y. Then
μ(x, y) = −

z∈(x,y]
μ(z, y).
Proof. This can be proved as Theorem 16.15, except that we have to use
the equality ZM = I instead of the equality MZ = I.
Theorem 16.15 enables us to compute the values of μ(x, y) starting at
μ(x, x) = 1, and going from the bottom up.
Example 16.17. Figure 16.5 shows the computation of the values of
μ(x, y).
In this example, x is chosen to be the bottom element of the
poset.
By deﬁnition, μ(x, x) = 1. Therefore, we must have μ(x, y) = −1 for all
y covering x. Then we compute all the other values from the bottom up,
using formula (16.1).
Let us compute the value of μ(x, y) for some of the most frequently
encountered posets.
Example 16.18. Let P be the poset of all nonnegative integers, and let
x < y be two distinct elements of P. Then μ(x, y) = −1 if x + 1 = y, and
μ(x, y) = 0 if x + 1 < y.

At Least Some Order. Partial Orders and Lattices
427
0
1
−1
−1
−1
1
1
0
−1
1
−1
−1
2
x
Fig. 16.5
The values of μ(x, y) when x is the bottom element.
Solution. This is straightforward by induction on y −x.
Example 16.19. Let P = Bn, and let S and T be two elements of P, that
is, two subsets of [n] so that S ⊆T . Then
μ(S, T ) = (−1)|T −S|.
Solution. Proof by induction on k = |T −S|. If k = 0, then S = T , so
μ(S, T ) = 1 by deﬁnition, and the statement is true. Now let us assume
that the statement is true for all nonnegative integers less than k, and let
|T −S| = k. Then for all natural numbers i satisfying 0 ≤i ≤k −1, the
interval [S, T ] contains
k
i

elements of P that are |S| + i element subsets
of [n]. If Z is such a subset, then it follows from the induction hypothesis
that μ(S, Z) = (−1)i. Therefore, Theorem 16.15 implies
μ(S, T ) = −

Z∈[S,T )
μ(S, Z) = −
k−1

i=0
k
i

(−1)i = (−1)k.
The last equality is a direct consequence of Theorem 4.2. It can also be
seen directly, from (1 −1)k = 0.
The induction step is complete, and so our statement is proved.
Example 16.20. Let P be the set of positive integers with the partial
order in which x ≤y if x is a divisor of y. Then
• μ(x, y) = (−1)k if y
x = p1p2 · · · pk, where p1, p2, · · · , pk are diﬀerent
primes, and
• μ(x, y) = 0 if y
x is divisible by the square of a prime number.
Solution. First note that the interval [1, y
x] and the interval [x, y] are iso-
morphic as posets. Therefore, it suﬃces to prove our statements in the

428
A Walk Through Combinatorics
special case when x = 1. To simplify notation, we will write μ(y) instead
of μ(1, y).
If y = p1p2 · · · pk, where the pi are diﬀerent primes, then a little thought
shows that the interval [1, y] is isomorphic to the poset Bk.
Indeed, a
divisor of y = p1p2 · · · pk is just the product of the elements of a subset of
{p1, p2, · · · , pk}. Therefore, μ(y) = (−1)k as claimed.
We prove the second statement by strong induction on y. If y = 4,
then the statement is true. Now assume that the statement is true for all
positive integers smaller than y. Let p1, p2, · · · , pk be the distinct prime
divisors of y; it then follows that at least one of them occurs in the prime
factorization of y more than once. Let us call a divisor of y good if it is not
divisible by the square of a prime, and let us call a divisor of y bad if it is
divisible by the square of a prime.
Then Theorem 16.15 implies
μ(y) = −

z<y
μ(z) = −

z good
μ(z) −

z bad
μ(z) = −(0 + 0) = 0.
Indeed, the set of the good elements z is precisely the interval
[1, p1p2 · · · pk], and we know from Theorem 16.15 that 
z∈I μ(z) = 0 for
any interval I. On the other hand, μ(z) = 0 for all bad integers z by the
induction hypothesis, so it goes without saying that 
z bad μ(z) = 0 as
well.
You could say “Fine, but who cares? What is the M¨obius function good
for?” In the following paragraphs, we will try to put our answer to this
question into context.
Let a0, a1, a2, · · · be a sequence of real numbers, and deﬁne the sequence
b0, b1, b2, · · · by
bn =
n

i=0
ai.
Then given the numbers ai, one can certainly compute the numbers bi.
Conversely, given the numbers bi, one can certainly compute the numbers
ai by the formula
an = bn −bn−1.
Now let f : Bn →R be a function deﬁned on the subsets of [n], and let
g : Bn →R be another function deﬁned on the subsets of [n] by
g(T ) =

S⊆T
f(S).

At Least Some Order. Partial Orders and Lattices
429
Again, given the values of f, the values of g are easy to compute. Given
the values of g, however, the values of f are a little bit harder to compute.
We have done this in Theorem 7.6, showing that
f(T ) =

S⊆T
g(S)(−1)|T −S|.
What was common in these two examples? In both cases, we worked
in a poset. In the ﬁrst case, it was the poset of all nonnegative integers (a
sequence is just a function that is deﬁned on nonnegative integers), in the
second case it was Bn. We deﬁned a function by setting its value in y to
be the sum of the values of another function for all elements of the poset
that were smaller than y. Then we showed that the values of the original
function can be computed from the values of the new function.
The major application of the M¨obius function, the M¨obius Inversion
Formula, will generalize this idea for any locally ﬁnite poset P.
Theorem 16.21 (M¨obius Inversion Formula). Let P be a poset in
which each principal ideal is ﬁnite, and let f : P →R be a function.
Let the function g : P →R be deﬁned by
g(y) =

x≤y
f(x).
Then
f(y) =

x≤y
g(x)μ(x, y).
Proof. Let x1, x2, · · · be a linear extension of P. Let f be the row vector
deﬁned by fi = f(xi), and let g be the row vector deﬁned by gi = g(xi).
Let Z be the zeta matrix of P, and let M be the M¨obius matrix of P. Then
the equality g(y) = 
x≤y f(x) just means
g = fZ.
Multiplying both sides by M from the right, and using the fact that ZM =
I, we get
gM = f,
which is equivalent to our claim.

430
A Walk Through Combinatorics
Just as Theorem 16.15, this theorem also has a dual version.
Corollary 16.22. Let P be a poset in which each principal dual ideal is
ﬁnite, and let f : P →R be a function. Let g : P →R be deﬁned by
g(y) =

x≥y
f(x).
Then
f(y) =

x≥y
g(x)μ(y, x).
Proof. This can be proved as Theorem 16.21, replacing the row vectors by
column vectors, and right multiplication by left multiplication.
Deﬁnition 16.23. Let P and Q be two posets. Then the direct product
P × Q of these two posets is the poset whose elements are all the ordered
pairs (p, q), where p ∈P, and q ∈Q, and in which (p, q) ≤(p′, q′) if p ≤p′
and q ≤q′.
The values of the M¨obius function in a direct product poset can be
computed by the following Theorem.
Theorem 16.24. Let us keep the notation of Deﬁnition 16.23. Then
μP ×Q ((p, q), (p′, q′)) = μP (p, p′)μQ(q, q′).
Proof. We know that 0 = 
z∈[p,p′] μ(p, z), when p ̸= p′, and also 0 =

s∈[q,q′] μ(q, s), when q ̸= q′. Multiplying these formulae together, we get
0 =
⎛
⎝
z∈[p,p′]
μ(p, z)
⎞
⎠·
⎛
⎝
s∈[q,q′]
μ(q, s)
⎞
⎠.
Note that we also know that μP (p, p′)μQ(q, q′) = 1 if and only if p =
p′ and q = q′.
Therefore, the function μP (p, p′)μQ(q, q′) is the unique
function deﬁned on Int(P ×Q) that sums to zero on all nontrivial intervals
of P ×Q, and takes value 1 on all trivial intervals. That unique function is,
by deﬁnition, the M¨obius function of the poset P × Q, and our statement
is proved.
Applications of this theorem will be provided in the next section, and
also in the Exercises.

At Least Some Order. Partial Orders and Lattices
431
Quick Check
(1) Let P2,n be the ﬁnite poset that has a minimum and a maximum ele-
ment, and n antichains A1, A2, . . . , An so that each Ai consists of two
elements, and each element of Ai is smaller than each element of Aj
if i < j. Let x and y be two elements of P2,n so that x ≤y holds.
Compute μP2,n(x, y).
(2) Deﬁne Pk,n in a way that is analogous to the preceding question, except
that each antichain Ai consists of k elements.
Let x and y be two
elements of Pk,n so that x ≤y holds. Compute μPk,n(x, y).
(3) Let Pj be the poset of all positive divisors of the integer 3 · 2j in which
x ≤y if x divides y. Find a simple formula for μPj(x, y).
16.3
Lattices
There is a natural class of partial ordered sets called lattices for which
additional techniques to compute the values of the M¨obius functions are
available. Let P be a poset, and let x ∈P. If x ≤P a, then we say that
a is an upper bound for x. If b ≤P x, then we say that b is a lower bound
for x. If a is an upper bound for both x and y, then a is called a common
upper bound for x and y. A common lower bound is deﬁned analogously.
Now we are in a position to deﬁne lattices. Recall that the minimum
(resp. maximum) element of a set, if it exists, is the element that is smaller
(resp. larger) than any other element of the set.
Deﬁnition 16.25. A poset L is called a lattice if any two elements x and
y of L have a minimum common upper bound a, and a maximum common
lower bound b.
In this case, a is called the join of x and y, and b is called the meet of
x and y. We denote these relations by x ∨y = a, and x ∧y = b.
Example 16.26. The poset Bn is a lattice. Indeed, for any two subsets
S ⊆[n], and T ⊆[n], the minimum subset of [n] containing both S and T
is S ∪T , and the maximum subset of [n] that is contained in both S and
T is S ∩T . Therefore, S ∪T = S ∨T , and S ∩T = S ∧T .
Example 16.27. The poset of all subspaces of a vector space V is a lattice.
If A and B are two subspaces of V , then A ∧B = A ∩B, and A ∨B is the
subspace generated by A and B.

432
A Walk Through Combinatorics
Example 16.28. The poset shown in Figure 16.6 is not a lattice. Indeed,
elements A and B fail to have a minimum common upper bound since both
C and D are minimal upper bounds for them. Similarly, C and D fail to
have a maximum common lower bound since both A and B are maximal
common lower bounds for them.
A
B
C
D
Fig. 16.6
This poset is not a lattice.
A ﬁnite lattice always has a minimum and a maximum element, as we
show in Exercise 7. This is not necessarily true in inﬁnite lattices. For
example, the lattice of all ﬁnite subsets of N does not have a maximum
element, or even a maximal element, for that matter.
The operations ∨and ∧can easily be extended to more than two vari-
ables. It is straightforward to check that in a lattice, (a∨b)∨c = a∨(b∨c),
so we can talk about a ∨b ∨c, or, in more generality, a1 ∨a2 ∨· · · ∨an.
The same applies for the operation ∧. The following simple proposition will
be useful shortly. More importantly, it shows a typical lattice-theoretical
argument.
Proposition 16.29. If x, y, and t are elements of a lattice L, and x ≤t,
and y ≤t, then x ∨y ≤t also holds. Similarly, if r ∈L, and x ≥r, and
y ≥r, then x ∧y ≥r.
Proof. As both x and y are less than or equal to t, we know that t is a
common upper bound for x and y, therefore it must be at least as large as
their minimum common upper bound x∨y. Similarly, r is a common lower

At Least Some Order. Partial Orders and Lattices
433
bound for x and y, therefore it must be at most as large as their maximum
common lower bound.
We have seen that if we want to prove that a poset is a lattice, we have
to show two things: the existence of the meet, and the existence of the join,
for any two elements of the poset. Sometimes, one of these two claims is
much easier to prove than the other. In these cases, the following lemma
can help. Let us say that L is a meet-semilattice if, for any two elements x
and y of L, the maximum common lower bound x ∧y exists.
Lemma 16.30. Let L be a ﬁnite meet-semilattice with a maximum element.
Then L is a lattice.
In other words, if our poset is ﬁnite, and has a maximum element, then
we only have to prove the existence of the meet.
That of the join will
automatically follow.
Proof. Let x ∈L and y ∈L. Let B be the set of all common upper bounds
of x and y. Then B is not empty as ˆ1 ∈B, where ˆ1 is the maximum element
of L. We must show that B has a minimum element.
We know that B is a ﬁnite set as L itself is ﬁnite.
Let B
=
{b1, b2, · · · , bk}. Then b = b1 ∧b2 ∧· · · ∧bk exists, and is an element of
B by Proposition 16.29. Therefore, b ≤bi for all i ∈[k], so b is the mini-
mum element of B.
Example 16.31. The poset Πn is a lattice.
Indeed, we will show that
it is a ﬁnite meet semilattice with a maximum element. As Πn has B(n)
elements, it is ﬁnite. The maximum element of Πn is obviously the partition
consisting of one block. If α and β are two partitions of [n], then α ∧β is
the partition in which the elements i and j are in the same block if and
only if they are in the same block in both of α and β. Therefore, Lemma
16.30 shows that Πn is a lattice.
Recall from Chapter 14 that a partition π of [n] is called non-crossing if
there are no four elements a < b < c < d so that a and c belong to a block
B1 of π, and b and d belong to a block B2 of π. As non-crossing partitions
are partitions, the reﬁnement order Πn deﬁnes a partial order on them.
Example 16.32. The poset NCn of non-crossing partitions of [n], ordered
by reﬁnement, is a lattice.

434
A Walk Through Combinatorics
Solution. Again, we show that NCn is a ﬁnite meet-semilattice with a
maximum element. Again, the one-block partition is the maximum element
of NCn, and our poset is ﬁnite. To see that NCn is a meet-semilattice,
note that if α and β are both non-crossing, then α ∧Πn β, as deﬁned in the
previous example, is also non-crossing. Therefore, α ∧Πn β = α ∧NCn β.
Our claim then follows from Lemma 16.30.
We point out that it is not true that the join of two elements of NCn is
also the same in NCn as in Πn. Indeed, let n = 4, and let α = {1}{2, 4}{3},
and let β = {1, 3}{2}{4}. Then α∨Π4β = {1, 3}{2, 4}, however, {1, 3}{2, 4}
is not even an element of NC4. On the other hand, α ∨NC4 β = {1, 2, 3, 4}.
To compute the M¨obius functions of these lattices, we will need the
following Theorem.
Theorem 16.33 (Weisner’s theorem). Let L be a lattice with minimum
element ˆ0 and with maximum element ˆ1. Then for any element a ∈L−{ˆ1},
μ(ˆ0, ˆ1) = −

x:x∧a=ˆ0
x̸=ˆ0
μ(x, ˆ1).
In other words, for lattices, the M¨obius function can be obtained by
computing a signiﬁcantly shorter sum than in the case of general posets.
For posets, when computing μ(ˆ0, ˆ1), in general we have to compute a sum
of n −1 members, where n is number of elements of the poset. However,
for lattices, Theorem 16.33 shows that it is enough to sum over all elements
whose meet with a is ˆ0. If we choose a to be a large element, then the
number of these elements will probably be small.
The remarkably simple proof we present is due to Vincent Vatter.
Proof. (of Theorem 16.33) After rearranging, our statement is equivalent
to
0 =

x:x∧a=ˆ0
μ(x, ˆ1)
(16.2)
as ˆ0 ∧a = ˆ0.
Now note that (16.2) is equivalent to
0 =

x∈L
μ(x, ˆ1)f(x),
(16.3)
where f(x) = 1 if x ∧a = ˆ0, and f(x) = 0 otherwise.

At Least Some Order. Partial Orders and Lattices
435
Observe that
f(x) =

y∈[ˆ0,x∧a]
μ(ˆ0, y).
(16.4)
Indeed, the right hand side of this equation sums the values of μ(ˆ0, y) for
all y in an interval [0, x ∧a]. As we know, such a sum is 0 or 1, depending
on whether the interval is non-trivial or trivial, and that is exactly how f
is deﬁned as well. Comparing (16.3) and (16.4) shows that the claim to be
proved is equivalent to
0 =

x∈L
μ(x, ˆ1)

y∈[ˆ0,x∧a]
μ(ˆ0, y).
Note that y ≤x ∧a if and only if y ≤x and y ≤a. Therefore, reversing
the order of summation in the last displayed equation, we conclude that
the claim (16.2) is equivalent to
0 =

y≤a
μ(ˆ0, y)

x∈[y,ˆ1]
μ(x, ˆ1).
(16.5)
Finally, (16.5) clearly holds, since y ≤a < 1, so the interval [y, ˆ1] is non-
trivial, and hence the inner sum on the right-hand side is always 0.
Now we are in a position to compute the values of μΠn(ˆ0, ˆ1), and
μNCn(ˆ0, ˆ1).
Example 16.34. For all positive integers n,
μΠn(ˆ0, ˆ1) = (−1)n−1(n −1)!.
Solution. We want to use Theorem 16.33. That theorem works for any
nonzero element a ∈Πn, but we want to choose an a so that the sum

x:x∧a=ˆ0
x̸=ˆ0
μ(x, ˆ1) is easy to evaluate. We propose a = {1, 2, · · · , n −1}{n}.
Then there are relatively few partitions x so that x ∧a = 0. Indeed, in
such partitions x, no two elements i and j of [n −1] can be in the same
block. Therefore, x can only be one of the n −1 partitions which have one
doubleton block {i, n}, and n −2 singleton blocks. Let x be any of these
partitions. We then claim that
[x, ˆ1] ∼Πn−1.
Indeed, if {i, n} is the only doubleton block of x, then the elements i and
n are in the same block in any partition from [x, 1]. Therefore, Theorem
16.33 implies,
μΠn(ˆ0, ˆ1) = −

x:x∧a=ˆ0
x̸=ˆ0
μ(x, ˆ1) = −(n −1)μΠn−1(ˆ0, ˆ1),
and our claim follows by induction on n.

436
A Walk Through Combinatorics
The observation that [x, ˆ1] ∼Πn−1 when x is a partition of [n] with one
doubleton block and n −2 singletons can be generalized into the following
statement.
Proposition 16.35. Let y be a partition of [n] that has k blocks. Then
[y, ¯1] ∼Πk.
Proof. If two entries are in the same block in y, they are in the same block
in all elements of [y, ¯1]. Therefore, in the poset [y, ¯1], the blocks of y play
the role of elements, and the statement follows.
The formula obtained for the M¨obius function of the partition lattice is
surprisingly simple. The M¨obius function of NCn is even more surprising.
Recall that the number of elements of that lattice is the Catalan number
cn.
Example 16.36. For any positive integer n,
μNCn(ˆ0, ˆ1) = (−1)n−1cn−1.
Solution. We prove the statement by strong induction on n, the initial
case being trivial. Let us assume that the statement is true for all positive
integers less than n.
Let us proceed as in the previous example, with the same choice for a.
What are the elements x so that a ∧x = ˆ0? As we know that a ∧Πn x =
a ∧NCn x, it follows that these are again the partitions with n −2 singleton
blocks, and one doubleton block, that is of the form {i, n}. What can we
say about μ(x, ˆ1) if x is the mentioned partition? Since we are working in
NCn, all partitions in [x, ˆ1] are non-crossing. Since {i, n} is a block in x,
all partitions in [x, ˆ1] can naturally be decomposed as a partition of the set
[i −1], and a partition of the set {i + 1, i + 2, · · · , n −1}.
Based on this, we claim that [x, ˆ1] ∼NCi × NCn−i. Indeed, consider
ﬁrst the sublattice L1 of [x, ˆ1] in which in all partitions, each of the elements
of {i + 1, i + 2, · · · , n −1} forms a singleton block (so all the “action” takes
place on the partitions of [i]). Then L1 is isomorphic to NCi, because of the
lattice isomorphism f : NCi →L1 deﬁned by f({j}) = {j} if j ∈[i −1],
and f({i, n} = {i}. Similarly, the sublattice L2 of [x, ˆ1] in which in all
partitions, each of the elements of [i] forms a singleton block is isomorphic
to NCn−i.

At Least Some Order. Partial Orders and Lattices
437
As i ranges from 1 to n−1, using our induction hypothesis and Theorem
16.33, we get
μNCn(ˆ0, ˆ1) = −

x:x∧a=ˆ0
x̸=ˆ0
μ(x, ¯1) = −
n−1

i=1
(−1)n−2ci−1cn−i−1 = (−1)n−1cn−1.
How many connected simple graphs are there on the vertex set [n]? The
diﬃculty here lies in enumerating connected graphs. It is certainly clear that
there are 2(
n
2) graphs on these vertices as each of the
n
2

pairs of vertices
can be connected or not connected by an edge.
At any rate, the connected components of any simple graph on [n] parti-
tion n in a natural way, that is, vertices that belong to the same component
will belong to the same block. This partition will be called the underlying
partition of the graph.
Now let H be any partition of [n], and let us say that the blocks of H
are of size c1, c2, · · · , ch. We cannot directly tell how many graphs on [n]
will have underlying partition V . However, we can easily tell how many
graphs will have an underlying partition D so that D ≤Πn H. Indeed,
these graphs cannot have edges between vertices that belong to diﬀerent
blocks of H. They can have edges within each block of H. Therefore, their
number is 2
h
i=1 (
ci
2 ).
Let f(H) be the number of all graphs on [n] with underlying partition
H, and let g(H) be the number of all graphs on [n] with underlying partition
D so that D ≤Πn H.
Then g(H) = 2
h
i=1 (
ci
2 ), and
g(H) =

D≤ΠnH
f(D),
so the M¨obius Inversion Formula implies
f(H) =

D≤ΠnH
g(D)μΠn(D, H).
We wanted to compute the number of connected graphs on [n], that is,
graphs whose underlying partition is the one-block partition N. Substitut-
ing N in the last equation, and using Proposition 16.35, we get
f(N) =

D∈Πn
2
d
i=1 (
di
2 )(−1)d−1(d −1)!,
where d is the number of blocks of D, and d1, d2, · · · , dd, are the sizes of
the blocks in D.

438
A Walk Through Combinatorics
Quick Check
(1) Let P be the partially ordered set of all subsets of [n] that contain an
even number of elements, ordered by inclusion. Is P a lattice?
(2) Let P be the partially ordered set of all partitions of [n] that con-
tain more than n/2 blocks, ordered by reﬁnement, with the one-block
partition added as the maximum element of P. Is P a lattice?
(3) Prove that the direct product of two lattices is a lattice. See Deﬁnition
16.23 for the deﬁnition of the direct product of two posets.
Notes
We recommend [51] for further information on M¨obius functions. For a
diﬀerent approach (dimension theory) on posets, see “Combinatorics and
Partially Ordered Sets. Dimension Theory” by William T. Trotter [54]. Fi-
nally, we mention that Dilworth’s theorem has a far-reaching generalization,
the Greene–Fomin–Kleitman theorem. See [29] for details.
Exercises
(1) Let p be a permutation, and let d be the smallest integer so that p can
be written as the union of d increasing subsequences. Prove that the
longest decreasing subsequence of p consists of d elements.
(2) The dimension of a partial ordered set P is the minimum number of
linear orders of the vertex set of P so that the intersection of these
linear orders is precisely the partial order of P. Find a natural way
to associate a poset of dimension two to each permutation. Will this
mapping be injective?
(3) Let P be the set of all ﬁnite permutations, and let p ≤P p′ if p is con-
tained in p′ as a pattern. Does this poset contain an inﬁnite antichain?
(4) Let P be any locally ﬁnite poset and let x1, x2, · · · , xn be a linear
extension of P. Find a formula for the number of all chains from xi to
xj, using the zeta function, or zeta matrix of P.
(5) We deﬁne the covering matrix C of a poset P as follows. The rows and
columns are indexed by the vertices, listed according to some linear
extension. Ci,j = 1 if xj covers xi, and Ci,j = 0 otherwise. Prove that
the (i, j)-th entry of the matrix (I −C)−1 is equal to the number of
maximal chains of the interval [x, y].

At Least Some Order. Partial Orders and Lattices
439
(6) Let P be any locally ﬁnite poset, let xi, xj ∈P, and assume xi < xj.
Prove that μ(xi, xj) = c0 −c1 + c2 −c3 + · · · , where ci is the number
of chains of length i from xi to xj. (So c0 = 0 and c1 = 1.)
(7) Prove that a ﬁnite lattice always has a minimum element and a maxi-
mum element.
(8) Find an example for a lattice that does not have a minimum element.
(9) Find a proof for the formula of the M¨obius function of Bn using The-
orem 16.24.
(10) Prove that in any lattice, we have (x ∧y) ∨y = y.
(11) Prove that it is not true in every lattice that if x ≤z, then
x ∨(y ∧z) = (x ∨y) ∧z,
for all y ∈L. A lattice in which this is true is called modular.
(12) Prove that it is not true in every lattice, not even in every modular
lattice, that
x ∧(y ∨z) = (x ∧y) ∨(x ∧z)
for all x, y, z ∈L. A lattice in which this is true is called distributive.
(13) Prove that the condition of the previous exercise, that is, x ∧(y ∨z) =
(x ∧y) ∨(x ∧z), for all x, y, z ∈L, is equivalent to the condition
x ∨(y ∧z) = (x ∨y) ∧(x ∨z),
for all x, y, z ∈L so the latter can also be used to deﬁne distributive
lattices.
(14) Prove that all distributive lattices are modular.
(15) In a lattice, we say that a is a complement of b if and only if a ∧b = ˆ0,
and a ∨b = ˆ1. Prove that if L is a distributive lattice, and b ∈L has a
complement, then b has a unique complement a ∈L.
(16) Show an example for a distributive lattice L in which each element has
a complement, but L ̸= Bn for any n.
(17) Decide whether Bn, Πn, and NCn are distributive lattices.
(18) Let x and y be two given elements of Πn so that x ≤y. Compute
μΠn(x, y).
(19) Is NCn a modular lattice?
(20) A poset P is called self-dual if there exists a bijection f : P →P so that
f(x) ≥f(y) if and only if x ≤y. In other words, the Hasse diagram of
P is invariant to the “turn upside down” operation. The bijection f is
called an anti-automorphism of P.
Decide if the posets Bn, Dn, and Πn are self-dual.

440
A Walk Through Combinatorics
(21) Prove that NCn is self-dual.
(22) Let Qn be the poset of non-crossing partitions of [n] in which π ≤π′
if the set of minimal elements of π is a proper subset of the set of
minimal elements of π′. (By minimal element, we mean an element
that is minimal in its block.) Prove that Qn is self-dual.
(23) Keep the notation of the previous two exercises. Prove that if x ≤NCn
y, then y ≤Qn x.
Supplementary Exercises
(24) (-) Find all sixteen 4-element posets.
(25) (-) Prove that Bn is a distributive lattice.
(26) (-) Is it true that every ﬁnite poset has as many antichains as ideals?
(27) (-) Show an example of a poset that is locally ﬁnite and has an inﬁnite
principal ideal.
(28) (-) Let P be a ﬁnite poset, and let J(P) be the poset whose elements
are the ideals of P, ordered by inclusion. Prove that P is a lattice.
(29) Let P be a ﬁnite poset, and let J(P) be deﬁned as in the previous
exercise. Prove that J(P) is a distributive lattice.
(30) (-) What is P if J(P) = Bn?
(31) (-) Let p = p1p2 · · · pn be a permutation. Let Pp be the poset whose
elements are the elements of [n], and in which i < j if i < j in the
usual ordering of natural numbers and i is on the left of j in P.
(a) What is p if Pp is the n-element chain?
(b) What is p if Pp is the n-element antichain?
(c) What are the minimal and maximal elements of Pp?
(32) Find the number of all 2-element antichains in Bn.
(33) Find the number of all 2-element chains in Bn.
(34) Let P be the product of a k-element chain and an n-element chain.
What is the size of the largest chain and the largest antichain of P?
(35) Let m and n be two distinct positive integers, and let Dm and Dn be
the (respective) lattices of their divisors. Under what conditions is it
true that the product of Dm and Dn equals Dmn?
(36) Let M(n, k) be the multiset consisting of k copies of each element of
[n]. Deﬁne a partial ordering P(n, k) on the set of all sub-multisets of
M(n, k) as follows. Let x ≤y if for all i ∈[n], the multiset x contains
at most as many copies of i as y.

At Least Some Order. Partial Orders and Lattices
441
Find a general formula for μP (n,k)(x, y). Explain the connection be-
tween this exercise and Example 16.20.
(37) Prove that the poset Nk does not have inﬁnite antichains for any
k. (Recall that this is the poset of vectors with nonnegative integer
coordinates, x ≤y if and only if xi ≤yi for all i.)
(38) Let P be a poset that has a minimum element ˆ0, and let x be an
element of P that covers one single element y. Let us assume that
y ̸= ˆ0. Prove that μ(0, x) = 0.
(39) Let m be any positive integer, and let P be a ﬁxed poset.
Let
ΩP (m) be the number of order-preserving maps f from P to the set
{1, 2, · · · , m}. In other words, if x ≤P y, then f(x) ≤f(y). Prove
that ΩP (m) is always a polynomial in m. This polynomial is called
the order polynomial of P.
(40) What is ΩP (m) if P is a k-element chain?
(41) What is ΩP (m) if P is a k-element antichain?
(42) What is ΩP (m) if P is the three-element poset consisting of one max-
imum element and two minimal elements?
(43) A chain in a poset is called maximal (or saturated) if it cannot be
extended. Let Bn be the poset of all subsets of {1, 2, · · · , n}. How
many maximal chains does Bn have?
(44) How many linear extensions does the following poset have?
Fig. 16.7
How many linear extensions does this poset have?
(45) Find the number of linear extensions of the direct product of a 2-
element chain and an n-element chain.
(46) Prove that for any ﬁnite poset P, the number of elements in any max-
imum chain equals the number of antichains in the smallest antichain
cover.
(47) Let P be a poset having n elements. Prove that P contains either a
chain of at least √n elements, or an antichain of at least √n elements.

442
A Walk Through Combinatorics
(48) Let us deﬁne a partial order on the set of all partitions of the integer
n as follows. If a = (a1, a2, · · · , ak) and b = (b1, b2, · · · , bt), then we
say that a ≥b if for all i ∈[k] the inequality
i

j=1
ai ≥
i

j=1
bi
holds. Note that if k ≤t, then we set ak+1 = ak+2 = · · · = at = 0.
This order Dn is called the dominance order.
(a) Is Dn a lattice?
(b) Is Dn self-dual?
(49) Let Y be the poset of all partitions of all nonnegative integers ordered
lexicographically. That is, a ≤Y b if ai ≤bi for all i. Note that this
automatically implies that if a has more (positive) parts than b, then
a cannot be smaller than b in Y .
(a) Explain what this ordering means in terms of Ferrers shapes.
(b) Is Y a lattice?
(c) Prove that if an element x ∈Y covers k elements, then x is covered
by k + 1 elements.
(50) Is it true that every interval of NCn is self-dual?
(51) An interval order is a poset P that is isomorphic to a poset Q whose
elements are closed intervals of real numbers, with the precedence or-
dering. That is, [a, b] < [c, d] if b < c.
Prove that an interval order cannot contain two chains c1 < c2 and
d1 < d2 so that for any i, j ∈[2], the elements ci and dj are in-
comparable. (This condition is often expressed by saying that P is
2+2-avoiding.)
We point out that the converse is also known: if P does not contain
four elements like that, then P is an interval order.
(52) A unit interval order is a poset P that is isomorphic to an interval
order Q whose elements are closed intervals of unit length.
Prove that a unit interval order cannot contain a chain c1 < c2 < c3
and an element d so that d is incomparable with ci, for all i ∈[3].
(These conditions are often expressed by saying that P is both 2+2-
avoiding and 3+1-avoiding.)
We point out that the converse is also known: if P does not contain
four elements like that, then P is a unit interval order.

At Least Some Order. Partial Orders and Lattices
443
Solutions to Exercises
(1) We show that this is a special case of Dilworth’s Theorem. Indeed, let
us introduce a partial ordering P on the elements of our permutation
p = p1p2 · · · pn as follows. Let pi <P pj if pi < pj as integers and
i < j. Then chains in P are the increasing subsequences of p, and
antichains of P are the decreasing subsequences of p.
(2) See the partial ordering deﬁned in the previous exercise. This map
is not one-to-one. For instance, p and p−1 are mapped into the same
poset.
(3) Yes, it does. There are several ways to ﬁnd an inﬁnite antichain in
this poset, and one of them is this.
Let a1 = 13, 12, 10, 14, 8, 11, 6, 9, 4, 7, 3, 2, 1, 5. We view a1 as having
three parts: a decreasing sequence of length three at its beginning,
a long alternating permutation starting with the maximal element of
the permutation and ending with the entry 7 at the ﬁfth position from
the right (in this alternating part odd entries only have even neighbors
and vice versa. Moreover, the odd entries and the even entries form
two decreasing subsequences so that 2i is between 2i + 5 and 2i + 3),
and a terminating subsequence 3 2 1 5.
To get ai+1 from ai, simply insert two consecutive elements right after
the maximum element m of ai, and give them the values (m −4)
and (m −1).
Then make the necessary corrections to the rest of
the elements, that is, increment all old entries on the left of m (m
included) by two and leave the rest unchanged (see Figure 16.8). Thus
the structure of any ai+1 is very similar to that of ai—only the middle
part becomes two entries longer.
We claim that the ai form an inﬁnite antichain.
Assume by way
of contradiction that there are indices i, j so that ai < aj.
How
could that possibly happen? First, note that the rightmost element
of aj must map to the rightmost element of ai, since this is the only
element in aj preceded by four elements less than itself. Similarly, the
maximal element of aj must map to the maximal element of ai, since,
excluding the rightmost element, this is the only element preceded by
three smaller elements. This implies that the ﬁrst four and the last six
elements of aj must be mapped to the ﬁrst four and last six elements
of ai, thus none of them can be deleted.
Therefore, when deleting elements of aj in order to get ai, we can
only delete elements from the middle part, Mj.
We have already

444
A Walk Through Combinatorics
13
12
10
14
11
9
7
3
2
5
6
8
1
4
5
1
2
3
7
4
6
9
11
8
13
10
12
16
14
15
Fig. 16.8
Elements of our antichain.
seen that the maximum element cannot be deleted. Suppose we can
delete a set D of entries from Mj so that the remaining pattern is ai.
First note that D cannot contain three consecutive elements, otherwise
every element before those three elements would be larger than every
element after them, and ai cannot be divided into two parts with this
property.
Similarly, D cannot contain two consecutive elements in
which the ﬁrst is even. Thus D can only consist of separate single
elements (elements whose neighbors are not in D) and consecutive
pairs in which the ﬁrst element is odd. Clearly, D cannot contain
a separate single element as in that case the middle part of resulting
permutation would contain a decreasing 3-subsequence, but the middle
part, Mi, of ai does not.
On the other hand, if D contained two
consecutive elements x and y so that x is odd, then let z be the
element that immediately precedes x. Then all elements preceding z
in the remaining permutation are larger than all elements on the right
of z, including z. This is again a contradiction, as our permutations
ai cannot be divided into two parts with this property.
This shows that D is necessarily empty, thus we cannot delete any
elements from aj to obtain some ai where i < j.
We have shown
that no two elements in {ai} are comparable, so {ai} is an inﬁnite
antichain.
Note that all elements of our antichain avoid the pattern 123.
(4) Let Z be the zeta matrix of P. We claim that the number of all chains
from xi to xj is equal to the (i, j)-th entry of the matrix (2I −Z)−1.
Note that 2I −Z = I −(Z −I). Therefore,
(2I −Z)−1 = (I −(Z −I))−1 = I +(Z −I)+(Z −I)2 +(Z −I)3 +· · · .

At Least Some Order. Partial Orders and Lattices
445
As discussed in Lemma 16.13, the element of (Z −I)k in position
(i, j) is the number of all k-element chains from xi to xj, and the
proof follows.
(5) Note that (I −C)−1 = I +C +C2 +· · · . It follows from the deﬁnition
of C that the (i, j)-th element of Ck is the number of all k-element
maximal chains from xi to xj, and the proof follows.
(6) We know from Lemma 16.13 that ck = (ζ −δ)k(xi, xj).
In other
words, ck is the (i, j)-entry of the matrix (Z −I)k. Therefore c0 −
c1 + c2 −c3 + · · · is the (i, j)-entry of the matrix 
k(−1)k(Z −I)k =
(I + Z −I)−1 = Z−1 = M. Therefore,
c0 −c1 + c2 −c3 + · · · = μ(xi, xj)
as claimed.
(7) Let L be a ﬁnite lattice, and assume it does not have a minimum
element. Then it has at least two diﬀerent minimal elements x and y.
Take x ∧y; it has to be smaller than or equal to both x and y. As
both x and y are minimal, this forces x = x ∧y and y = x ∧y. This
contradicts to x ̸= y. The existence of a maximum element can be
proved analogously.
(8) Take all subsets of N that have a ﬁnite complement. These subsets are
partially ordered by containment, and form a lattice where the meet
is the intersection, and the join is the union. There is no minimum
element, however. Indeed, if there were such an element K, with com-
plement size k, then we could take any subset of N whose complement
is of size k + 1 to reach a contradiction. This lattice does not even
have a minimal element.
(9) Note that Bn = In
2 , where I2 is the chain of two elements.
(10) The left-hand side is an upper bound of y, so it is at least y. On the
other hand, y is a common upper bound for y and x∧y, so it is indeed
their lowest common lower bound.
(11) The lattice shown in Figure 16.9 is a counterexample. Indeed, in that
lattice, x ∨(y ∧z) = x ∨ˆ0 = x, and (x ∨y) ∧z = ˆ1 ∧z = z.
(12) The lattice shown in Figure 16.10 is a counterexample. Indeed, in that
lattice, x ∧(y ∨z) = x ∧ˆ1 = x, and (x ∧y) ∨(x ∧z) = ˆ0 ∧ˆ0 = ˆ0.
(13) Let us assume that the condition of Exercise 12 holds. Apply this
to the right-hand side of our new condition, considering x ∨y, the
expression in the ﬁrst set of parentheses, as one element. We get
(x ∨y) ∧(x ∨z) = [(x ∨y) ∧x] ∨[(x ∨y) ∧z] = x ∨[(x ∨y) ∧z]
= x ∨[(x ∧z) ∨(y ∧z)] = [x ∨(x ∧z)] ∨(y ∧z) = x ∨(y ∧z),

446
A Walk Through Combinatorics
z
x
y
1
0
Fig. 16.9
A lattice that is not modular.
as claimed. The other implication can be proved in an analogue way.
(14) Let L be distributive, and let x ≤z. Then
(x ∨y) ∧z = (x ∧z) ∨(y ∧z) = x ∨(y ∧z),
which was to be proved.
(15) Let us assume that the opposite is true, that is, that there is another
element c ∈L so that c is the complement of b. In that case, we have
(a ∨b) ∧(c ∨b) = ˆ1 ∧ˆ1 = ˆ1, and also, (a ∨c) ∧b ≤b. So this lattice
could only be distributive if b = ˆ1 held, but then b would only have ˆ0
for its complement.
(16) Let L be the set of all subset of N that are either ﬁnite, or co-ﬁnite
(have a ﬁnite complement).
Then the complement of x is its set-
theoretical complement. As our lattice is inﬁnite, it is not isomorphic
to Bn for any n. (It can be shown that there is no ﬁnite example for
L.)
(17) If n ≥3, then Πn and NCn are not distributive. Indeed, let a, (resp.
b, and c) be three partitions with n −2 singleton blocks, and the only
doubleton block {1, 2} (resp. {1, 3}, {2, 3}). Then the distributivity
axioms do not hold for these three elements.

At Least Some Order. Partial Orders and Lattices
447
x
y
z
1
0
Fig. 16.10
A lattice that is not distributive.
On the other hand, Bn is always distributive. Indeed, for all three
subsets A, B, C ⊆[n], we have
A ∩(B ∪C) = (A ∩B) ∪(A ∩C).
This is because both sides consist of the elements of [n] that are ele-
ments of A, and at least one of B and C.
(18) As x ≤y, the blocks of y are unions of the blocks of x. Say that y has
k blocks, and they are unions of u1, u2, · · · , uk blocks of x. Then it is
straightforward to see that
[x, y] ∼Πu1 × Πu2 × · · · × Πuk.
Therefore, Theorem 16.24 and Example 16.34 imply
μ(x, y) = Πk
i=1(−1)uk−1(uk −1)!.
(19) No, NCn is not modular if n ≥3. Let n = 4, and let x = {1, 3}{2}{4},
y = {1}{3}{2, 4}, and z = {1, 2, 3}{4}. Then x ≤z, but x ∨(y ∧z) =
x∨ˆ0 = x, and (x∨y)∧z = ˆ1∧z = z. If n ≥4, then the same example
will work, by adding all the other elements as singleton blocks.
(20) The poset Bn is self-dual as the map deﬁned by f(S) = Sc is an anti-
automorphism. The poset Dn is self-dual as the map g(k) = n/k is an
anti-automorphism. However, Πn is not self-dual if n ≥3. If it was, it
would have as many elements covering ˆ0 (atoms) as elements covered

448
A Walk Through Combinatorics
by ˆ1 (coatoms). That is not the case, as Πn has
n
2

atoms, namely
the partitions that have one doubleton block, and n −2 singletons,
and 2n−1 −1 coatoms, namely the 2-block partitions.
(21) This result was ﬁrst proved in [46].
Write the elements 1, 2, · · · , n
clockwise around a circle, and write elements 1′, 2′, · · · , n′ interlaced
in counterclockwise order, so that 1′ is between 1 and n, 2′ is between
n and n −1, and so on, i′ is between n + 2 −i and n + 1 −i. For
π ∈NCn, join by chords cyclically successive unprimed elements be-
longing to the same block of π. Then deﬁne g(π) to be the coarsest
non-crossing partition on the elements 1′, 2′, · · · , n′ so that the chords
joining primed elements of the same block do not intersect the chords
of π. See Figure 16.11 for an example.
1
2
3
4
5
6
7
8
1’
2’
3’
4’
5’
6’
7’
8’
Fig. 16.11
The partition π = ({1}, {2, 3, 8}, {4, 5, 7}, {6}) and its image g(π).
The map g is certainly a bijection, and it is order-reversing in NCn
since merging two blocks of π subdivides a block of g(π).
(22) In Exercise 16 of Chapter 14, we have seen that there is a bijection
between non-crossing partitions of [n] with a given set of minimal
elements, and 132-avoiding n-permutations with a given descent set.
Then Exercise 18 of Chapter 14 shows that the latter form a self-dual
poset when ordered by the strict containment of their descent set.
(23) If x ≤NCn y, then each block of y is the union of some blocks of x.
This means however, that the minimal element of each block of y is

At Least Some Order. Partial Orders and Lattices
449
also a minimal element of x. So the set of minimal elements of y is
strictly contained in that of x, and the statement follows.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 17
As Evenly As Possible. Block Designs
and Error Correcting Codes
17.1
Introduction
17.1.1
Moto-cross Races
The following is a real-life example from moto-cross competitions. There
are sixteen drivers competing for a main prize and various other prizes.
The racetrack can safely accommodate four drivers in any single course,
called a heat. So there will be numerous heats, and at the end of each
heat, participants get points based on their rank in that heat. At the end
of the day, the driver with the highest number of total points is declared
the winner, the driver with the second highest number of points is declared
the runner-up, and so on.
The question is how to schedule the various heats. If there were only a
ﬁrst prize to be awarded, then we could simply split the set of 16 contestants
into four heats of four contestants each, and then have the four heat-winners
compete in a ﬁnal. That would be a short and fair race in that the best
driver would win.
It would not be fair if a second prize, a third prize,
or additional prizes were awarded.
Indeed, if the second-best driver is
unlucky, she could be put in the same heat as the best driver, and so would
not qualify for the ﬁnal.
The other extreme solution is a race that is very fair, but unreasonably
long. Schedule each of the
16
4

possible four-driver heats to run once, and
rank the drivers at the end based on their total number of points earned.
The problem is that such a race would consist of
16
4

= 1820 heats. Even
if one heat took only ten minutes, and there were no down-time between
consecutive heats, this would take more than 12 days. The attention span
of most fans is shorter than that.
Therefore, the challenge is to design the heats so that the race is both fair
451

452
A Walk Through Combinatorics
and reasonably short (it can be completed in an afternoon). The length of
the race is very easy to measure. The fairness of the race is a little bit more
complex, but participants can agree on a few simple principles. As drivers
earn points in each heat they participate, each driver should compete in
the same number of heats. Each heat should use the available space, that
is, it should contain four drivers. Finally, to avoid situations in which some
drivers had stronger opponents than others, we can require that for any
two drivers, there is at least one heat in which they both competed. If this
“at least one” can be replaced by “exactly one”, that is even better. This
has the additional beneﬁt of being a way to break two-way ties: if, at the
end of the race, two drivers have the same aggregate score, let the one who
beat the other in their only shared heat be ranked ahead of the other.
If such a race can be designed, then each driver needs to participate in
at least ﬁve heats. Indeed, each driver needs to compete against 15 others
in at least one heat, but can compete only against three in any one heat.
At least ﬁve heats for each of sixteen drivers means at least 80 ordered pairs
(d, H), where d is a driver competing in heat H. Since each heat consists
of four drivers, this means that there would have to be at least 20 heats.
So the question now is whether these minimal values can actually be
attained. That is, can we plan 20 heats of four drivers each so that each
driver participates in exactly ﬁve heats, and for any two drivers d1 and d2,
there is a heat in which they both competed? (It follows from the preceding
paragraph that if such a set of 20 heats exists, then for any two drivers d1
and d2, there is a unique heat H in which they both competed.)
It is very far from obvious, but it is possible to design such a race.
An example is shown below. If each heat takes ten minutes to complete,
and there is a two-minute down-time in the 19 breaks between heats, then
it takes only 238 minutes, or slightly less than four hours, for the entire
contest to take place.
Example 17.1. The following collection of heats satisﬁes all the require-
ments. Every driver is in ﬁve heats, every heat consists of four drivers, and
for any two drivers, there is exactly one heat containing both of them.
(1) 1, 2, 3, 4
(2) 5, 6, 7, 8
(3) 9, 10, 11, 12
(4) 13, 14, 15, 16

As Evenly As Possible. Block Designs and Error Correcting Codes
453
(5) 1, 5, 9, 13
(6) 2, 6, 10, 14
(7) 3, 7, 11, 15
(8) 4, 8, 12, 16
(9) 1, 6, 11, 16
(10) 2, 5, 12, 15
(11) 3, 8, 9, 14
(12) 4, 7, 10, 13
(13) 1, 7, 12, 14
(14) 2, 8, 11, 13
(15) 3, 5, 10, 16
(16) 4, 6, 9, 15
(17) 1, 8, 10, 15
(18) 2, 7, 9, 16
(19) 3, 6, 12, 13
(20) 4, 5, 11, 14
At this point, the reader hopefully wants to know how this collection
of heats was built, and for what set of requirements will such a collection
exist. By the end of this chapter, we will ﬁnd some interesting answers to
these questions.
17.1.2
Incompatible Computer Programs
Let us assume that we have downloaded seven new programs to our com-
puter.
We have enough memory to run any three of them at the same
time, but not more. We want to test that the seven programs are pairwise
compatible with each other. That is, we want to make sure that there are
no programs A and B among our seven programs so that running A and
B at the same time always results in a system error (for reasons unrelated
to space or memory availability). Let us assume that all incompatibilities
are caused by a pair of programs, that is, if a subset S of programs cannot
run together, then there is a 2-element subset T ⊂S so that even the ele-
ments of T cannot run together. What is the most eﬃcient way to do this
if testing the simultaneous operation of any k programs (k ≤3) takes one
minute?
Before we start looking for the most eﬃcient way to test all pairs of

454
A Walk Through Combinatorics
programs, let us discuss some obvious upper bounds for the needed time.
First, it is clear that
7
3

= 35 minutes will suﬃce, since we can simply test
all three-element subsets of the seven-element set {A, B, C, D, E, F, G} of
programs. There is a tremendous waste in this method, since every pair of
programs will run together ﬁve times (since there are ﬁve choices for the
third element of the triple that is being tested). A somewhat better upper
bound is 21 minutes. Indeed, we can just test each of the
7
2

= 21 pairs of
programs. However, it is easy to see the waste in this method as well. In
each test run, we are only testing a pair, and not a triple, of programs, and
hence we gain information about the compatibility of just one pair, and not
three pairs.
What is the best testing time that we can achieve? First, let us note
that we may assume that in an optimal testing scheme, each run consists
of testing a triple of programs, and not a pair. Indeed, we were told that
testing a triple takes one minute, the same amount of time that it takes to
test a pair, so we do not lose any time by completing all pairs of our testing
scheme to triples.
Let b be the number of all triples used in our testing scheme. In each of
these triples, three pairs are tested, so our scheme tests at most 3b pairs,
exactly that many if all these 3b pairs are diﬀerent. On the other hand, we
need to test
7
2

= 21 pairs. Therefore, for any testing scheme, 3b ≥21,
and so b ≥7. So we need at least seven minutes to test all 21 pairs.
There remains the question whether we can actually construct a testing
system that consists of only seven triples and still tests for every pair. The
following example shows that the answer is in the aﬃrmative.
Example 17.2. The following family F of subsets of the set S
=
{A, B, C, D, E, F, G} has the property that for any two elements x and
y of S there is a (necessarily unique) element of F that contains both x
and y.
• {A, B, D},
• {B, C, E},
• {A, F, C},
• {A, E, G},
• {B, F, G},
• {C, D, G},
• {D, E, F}.
One way to verify that the preceding example is correct is by checking

As Evenly As Possible. Block Designs and Error Correcting Codes
455
that if x ∈S, then x occurs in exactly three subsets belonging to F, and
that no element other than x occurs in more than one of those three subsets.
So we can test all pairs using the above scheme in just seven minutes.
Note that the above scheme is free of any waste; each pair is tested once, but
no pair is tested more than once. Usually, it is not possible to completely
eliminate waste like that. For instance, if we had to test all pairs of an eight-
element set of programs using a scheme of triples, then we would have had
to test
8
2

= 28 pairs.
As 28 is not divisible by three, we would have
needed 10 triples, meaning that there would have been pairs tested more
than once. If we had to test all pairs of a six-element set of programs using
a scheme of triples, that would have meant testing
6
2

= 15 pairs. While 15
is divisible by three, complete elimination of waste is still not possible for
the following reason. Each program has to be part of at least three triples,
since each triple contains two other programs. So placing program A in
just two triples will test it in only four pairs. However, placing A in three
pairs tests A in six pairs. There are only ﬁve programs other than A, so at
least one of the pairs containing A gets tested twice.
As we see, there are several reasons for which a completely waste-free
testing scheme may not exist. From a more high-brow point of view, just
because in some cases we may not be able to prove that such a scheme
does not exist, it does not follow that it exists; it could be that it does not
exist for some reason that is unknown to us. This raises a whole family
of questions, such as what the suﬃcient and necessary conditions of the
existence of a waste-free testing scheme are, and what the most interesting
generalizations of this problem are.
Quick Check
(1) Consider the collection of heats given in Example 17.1. Choose two
drivers at random. How many heats will there be in which neither of
the two chosen drivers participate?
(2) Consider the family F of subsets in Example 17.2. Choose two ele-
ments of the set {A, B, C, D, E, F, G}. How many sets are there in F
that do not contain either of the two selected elements?
(3) Consider the family F of subsets in Example 17.2. Choose any three
elements of the set {A, B, C, D, E, F, G}. Is it true that the number
of sets in F that do not contain any of the three chosen elements is
independent of the choice of those three elements?

456
A Walk Through Combinatorics
17.2
Balanced Incomplete Block Designs
Let S be a ﬁnite set of v elements called vertices. Let B be a collection
of b non-empty subsets of S called blocks. Then the pair (S, B) is called a
block design or just a design. Note that this deﬁnition does not exclude the
possibility of some blocks appearing in B more than once, so the repetition
of blocks is allowed.
That said, most of our examples will not contain
repeated blocks. Vertices of designs sometimes are called varieties.
If a design (S, B) contains at least one block that does not contain all
vertices of S, then the design is called incomplete, otherwise it is called
complete. It goes without saying that complete designs are not very inter-
esting, unless some additional structure is placed on them. Our examples
will all be incomplete designs.
If in a design, each block consists of k vertices, then the design is called
uniform or k-uniform. Note that simple graphs are 2-uniform designs, with
the edges of the graph being the blocks. If each vertex of a design occurs
in exactly r blocks, then the design is called regular or r-regular.
Finally, if in a k-uniform, r-regular incomplete design (S, B), each pair
of vertices occurs together in exactly λ blocks, then we say that (S, B)
is a balanced incomplete block design or BIBD, of parameters (b, v, r, k, λ).
Alternatively, we may simply call such a design a (b, v, r, k, λ)-design, since
the mere existence of the parameters r, k, and λ shows that (S, B) is regular,
uniform, and balanced, and if k < v, then (S, B) is incomplete.
Example 17.3. The design of Example 17.1 is a balanced incomplete block
design of parameters (20, 16, 5, 4, 1). That is, it has 20 blocks, 16 vertices,
each vertex occurs in ﬁve blocks, each block consists of four vertices and
each pair of vertices occurs together in exactly one block.
Example 17.4. The design of Example 17.2 is a balanced incomplete block
design of parameters (7, 7, 3, 3, 1). That is, it has seven blocks, seven ver-
tices, each vertex occurs in three blocks, each block consists of three vertices,
and each pair of vertices occurs together in exactly one block.
The following is an even smaller example of a BIBD.
Example 17.5. Let S = {a, b, c}, and let B= {{a, b}, {b, c}, {a, c}}. Then
(S, B) is a balanced incomplete block design with parameters (3, 3, 2, 2, 1).
The preceding example can be easily generalized as follows.

As Evenly As Possible. Block Designs and Error Correcting Codes
457
Example 17.6. Let 1 < k < n. Then the family of all k-element subsets
of [n] is a BIBD. The reader is invited to verify that the parameters of this
block design are
	n
k

, n,
n−1
k−1

, k,
n−2
k−2

.
We point out that while all BIBDs have a lot of symmetries built in
them, some have more than others. The BIBDs of Examples 17.2 and 17.5
both satisfy the equalities b = v, and, following from the latter, r = k. If
a BIBD satisﬁes either (or as we will see very soon, equivalently, both) of
these equalities, then it is called symmetric. So the BIBDs of Examples
17.2 and 17.5 are symmetric, those of the other examples are not.
At this point, you may say, “OK, so there exist a lot of BIBDs. However,
can we have idea about how diﬃcult it is to create one? What are the
necessary conditions on the parameters for the existence of a BIBD?” The
following two propositions give a partial answer to those questions.
Proposition 17.7. If a (b, v, r, k, λ)-design exists, then bk = vr.
Proof. Let (S, B) be such a design. Then both sides count all ordered
pairs (w, B), where w ∈S, B ∈B, and w ∈B. In other words, these
are ordered pairs consisting of a vertex and a block containing that vertex.
The left-hand side counts these pairs according to the blocks (there are k
such pairs for each of b blocks), and the right-hand side counts these pairs
according to the vertices (there are r such pairs for each of v vertices).
Note that in the proof of Proposition 17.7, the parameter λ did not
play any role, and even the fact that λ existed, that is, that the design
was balanced, was irrelevant. So the equality bk = vr holds for all regular,
uniform designs.
Proposition 17.8. If a (b, v, r, k, λ)-design exists, then r(k−1) = λ(v−1).
Proof. Let (S, B) be such a design. Let x ∈V be a ﬁxed vertex. Then
both sides count all ordered pairs (w, B), so that x and w are both vertices
in the block B, with x ̸= w.
The left-hand side counts these pairs by
ﬁrst choosing one of the r blocks that contain x, then choosing any of the
remaining k −1 vertices of B for the role of w. The right-hand side counts
these pairs by ﬁrst choosing w in one of v −1 ways, then choosing one of
the λ blocks that contain both x and w for the role of B.
Note that Propositions 17.7 and 17.8 show that the three parameters
v, k, and λ determine the other two in any BIBD. Therefore, it is correct

458
A Walk Through Combinatorics
to refer to BIBDs as (v, k, λ)-designs. In this terminology, the BIBD of
Example 17.1 is a (16, 4, 1)-design, and the BIBD of Example 17.2 is a
(7, 3, 1)-design.
Quick Check
(1) Does there exist a polygon whose vertices are the vertices of a BIBD,
and whose edges are the blocks of the same BIBD?
(2) Does there exist a convex polyhedron whose vertices are the vertices of
a BIBD, and whose edges are the blocks of the same BIBD?
(3) Does there exist a convex polyhedron whose vertices are the vertices of
a BIBD, and whose faces are the blocks of the same BIBD?
17.3
New Designs From Old
There are several ways to create new designs from ones that we already
have at hand. Perhaps the simplest of these is the complementary design.
For two sets X and Y , let X \ Y denote the set of elements that are in X
but not in Y .
Deﬁnition 17.9. Let D = (S, B) be a design. The complementary design
of (S, B) is the design Dc whose set of vertices is S, and whose blocks are
the complements of the blocks in B in S. That is, B is a block of Dc if and
only if S \ B is a block of D.
Example 17.10. If D is the design of Example 17.2, then Dc is the design
on vertex set {A, B, C, D, E, F, G} that has blocks
• {C, E, F, G},
• {A, D, F, G}
• {B, D, E, G},
• {B, C, D, F},
• {A, C, D, E},
• {A, B, E, F},
• {A, B, C, G}.
The reader should spend a moment on verifying that the complementary
design of a regular, uniform design is also regular and uniform. It is a little
bit less obvious, but still straightforward to see that the complementary
design of a BIBD is also balanced, and so it is also a BIBD. You are asked
to prove this in Exercise 5.

As Evenly As Possible. Block Designs and Error Correcting Codes
459
We present the next construction to deﬁne a new design from an old
one because it allows us to talk about the incidence matrix of a design, a
concept which will be useful in the near future.
Deﬁnition 17.11. Let D be a design with blocks B1, B2, · · · , Bb and ver-
tices v1, v2, · · · , vv. The incidence matrix of D is the v ×b matrix A deﬁned
by
Ai,j =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1 if vi ∈Bj,
0 if vi /∈Bj.
Example 17.12. Let D be the design whose blocks are the two-element
subsets of [4]. Then the incidence matrix of D is
A =
⎛
⎜
⎜
⎝
{1, 2}
{1, 3}
{1, 4}
{2, 3}
{2, 4}
{3, 4}
1
1
1
1
0
0
0
2
1
0
0
1
1
0
3
0
1
0
1
0
1
4
0
0
1
0
1
1
⎞
⎟
⎟
⎠.
Now we are in a position to present the next example of constructing
new designs from old.
Deﬁnition 17.13. Let D be a design with incidence matrix A. Then the
dual of D is the design Dd whose incidence matrix is AT , that is, the
transpose of A.
Example 17.14. The dual Dd of the design of Example 17.12 is the design
whose incidence matrix is
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
{a, b, c}
{a, d, e}
{b, d, f}
{c, e, f}
a
1
1
0
0
b
1
0
1
0
c
1
0
0
1
d
0
1
1
0
e
0
1
0
1
f
0
0
1
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.

460
A Walk Through Combinatorics
That is, if we relabel the rows of AT by the letters a, b, c, d, e, f, then
the blocks of Dd are {a, b, c}, {a, d, e}, {b, d, f}, and {c, e, f}.
Note that Dd of Example 17.14 is not a BIBD since it is not balanced.
This is because some pairs of blocks of D intersect, while some others do
not. Hence some pairs of vertices of Dd do appear together in a block, while
some others do not.
The incidence matrix is a seminal tool in using techniques of linear
algebra to prove facts about designs. Let us start with a simple observation.
Proposition 17.15. Let A be the incidence matrix of a design D with
parameters (b, v, r, k, λ). Then
AAT = (r −λ)Iv + λJv,
(17.1)
where Iv is the identity matrix of size v × v and Jv is the matrix of size
v × v whose entries are all equal to 1.
Proof. If i ̸= j, then the (i, j)-entry of AAT is the dot product of the ith
and jth rows of A. This dot (scalar) product is the sum of 0s and 1s, with
a 1 for every block that contains both the ith and the jth vertex. There are
λ such blocks. If i = j, then the (i, i)th entry of AAT is the dot product of
the ith row of A by itself. This dot product is a sum of 0s and 1s, a 1 for
each time the ith vertex appears in a block. That happens r times.
Recall from linear algebra that the number m is called an eigenvalue of
the square matrix M if there exists a nonzero vector x so that Mx = mx.
In that case, x is called an eigenvector. A subspace spanned by eigenvectors
of M is called an eigenspace of M.
Corollary 17.16. If A is the incidence matrix of a BIBD with parameters
(b, v, r, k, λ), then the eigenvalues of AAT are r −λ with multiplicity v −1,
and r + λ(v −1) = rk with multiplicity one. In particular, since none of
these eigenvalues is 0, we have det AAT ̸= 0.
Proof. We have seen in Proposition 17.15 that AAT = (r −λ)I + λJ.
On the one hand, all nonzero vectors are eigenvectors of (r −λ)I, with
eigenvalue r−λ. On the other hand, it is easy to verify that any vector with
coordinate sum 0 is an eigenvector of λJ with eigenvalue 0. Furthermore,
vectors of the form (x, x, · · · , x) also form an eigenspace (a one-dimensional
eigenspace) of J, with eigenvalue λv.
Therefore, the eigenvectors of AAT = (r −λ)I +λJ are the eigenvectors
of λJ, and their associated eigenvalues are the sums of their associated

As Evenly As Possible. Block Designs and Error Correcting Codes
461
eigenvalues for the matrix (r −λ)I and the matrix λJ. This proves our
claim.
We have pointed out immediately after Example 17.14 that the dual of
a BIBD is not necessarily a BIBD because it is not necessarily balanced.
Indeed, it follows from the deﬁnition of dual designs that for Dd to be
balanced, the following would have to hold. For any two distinct blocks Bi
and Bj of D, the size of the intersection Bi ∩Bj should be a ﬁxed integer
ℓ, that is, it should not depend on the choice of Bi and Bj. In that case,
we say that D is a linked BIBD. If D is linked, and only then, Dd will be
balanced, since any two of its vertices will occur together in ℓblocks.
Proposition 17.15 makes it easy to prove that all symmetric designs are
linked.
Proposition 17.17. All symmetric BIBDs are linked.
Proof. Let D be symmetric with parameters (v, k, λ). Then the adjacency
matrix A of D is a square matrix, so the product AT A exists. Note that
AT is the adjacency matrix of Dd. So if we can prove that AT A = AAT ,
then we will be done, since all non-diagonal entries of AAT are equal to
λ, which then implies that any two blocks of A intersect in exactly ℓ= λ
vertices.
Given that AAT = (r−λ)I +λJ, the proof of the equation AAT = AT A
is purely algebraic. Note that JA = AJ, where J is the v × v matrix whose
entries are all equal to 1. We know from Corollary 17.16 that A−1 exists,
otherwise det AAT would be 0. Multiply both sides of (17.1) by A−1 from
the left, then by A from the right, to get
AT A = A−1((r −λ)I)A + λA−1JA
= (r −λ)I + λJ.
So AAT = AT A as claimed, implying that D is linked.
In particular, since a symmetric BIBD is linked, its dual is also a BIBD.
The following theorem shows that the converse of that statement is true as
well. That is, if the dual of a BIBD is a BIBD, then that BIBD must be
symmetric. This is because, as we will see, all BIBDs have at least as many
blocks as vertices.
Theorem 17.18 (Fisher’s inequality). If D is a BIBD on v vertices
and b blocks, then v ≤b.

462
A Walk Through Combinatorics
Proof. Let us consider the incidence matrix A of D. We know from Propo-
sition 17.15 that det AAT ̸= 0, so in particular, this v × v matrix has rank
v. On the other hand, the rank of the product of two matrices is never
more than the rank of either matrix, so
v = rank(AAT ) ≤rank(A).
Finally, the rank of any matrix is the number of its linearly independent
columns, so at most the number of its columns. Hence
rank(A) ≤b.
The last two displayed inequalities imply our claim by transitivity.
See Exercise 10 for a very interesting variation of this Theorem.
The following result provides another necessary condition for the exis-
tence of symmetric BIBDs.
Theorem 17.19. If D is a symmetric BIBD with parameters (v, r, λ), and
v is even, then (r −λ) is a perfect square.
Proof. In the proof of Corollary 17.16, we have determined the eigenvalues
of the matrix AAT . It is therefore easy to compute det AAT as the product
of these eigenvalues, namely
det AAT = (r + (v −1)λ) · (r −λ)v−1.
Clearly, the left-hand side is a perfect square since it is equal to (det A)2.
On the right-hand side, using Proposition 17.8 and the fact that our design
is symmetric, we have (r + (v −1)λ) = r + r(k −1) = rk = r2. Therefore,
(r −λ)v−1 has to be a perfect square as well. For that to happen, r −λ has
to be a perfect square since v −1 is odd.
Note that Theorem 17.19 has a counterpart for the case of odd v which
is much more diﬃcult to prove. We present that theorem without a proof.
In the Notes section, we give some pointers to more specialized books that
contain the proof of this and other theorems that go beyond the scope of
this book.
Theorem 17.20. If there exists a symmetric BIBD with parameters
(v, r, λ), and v is odd, then there exist integers x, y, and z that are not
all equal to zero so that
x2 = (k −λ)y2 + (−1)(v−1)/2 · λz2.

As Evenly As Possible. Block Designs and Error Correcting Codes
463
Theorems 17.19 and 17.20 are called the Bruck-Ryser-Chowla theorem.
We mention two more ways of creating new BIBDs from existing ones.
For these methods to work, the existing BIBD has to be symmetric.
Deﬁnition 17.21. Let D be a symmetric BIBD, and let B be a block of D.
The residual design of D with respect to D is obtained from D by removing
B from D, and removing all vertices of B from all remaining blocks of D.
So, if V is the set of vertices of D, then its residual design DB,res with
respect to its block B has vertex set V −B.
In Exercise 8, you are asked to verify that this is a correct deﬁnition,
that is, that the block design deﬁned by Deﬁnition 17.21 is indeed a BIBD.
Deﬁnition 17.22. Let D be a symmetric BIBD, and let B be a block of D.
The derived design of D with respect to B is obtained from D by removing
B from D, and replacing every other block Bi by Bi ∩B.
So, if V is the set of vertices of D, then its derived design DB,der with
respect to its block B has the same vertex set as B.
You will be asked to justify this deﬁnition in Exercise 9.
Quick Check
(1) Is the dual of a linked design linked?
(2) Is the complement of a linked design linked?
(3) Is the dual of a balanced and linked design also balanced and linked?
17.4
Existence of Certain BIBDs
In Section 17.2, we have seen examples of necessary conditions for the ex-
istence of balanced incomplete block designs. Propositions 17.7 and 17.8
provided such conditions in terms of the parameters b, v, r, k, and λ. Later,
these were supplemented by Theorems 17.18, 17.19, and 17.20. In Section
17.3, we saw examples showing how to obtain new BIBDs from old ones.
However, we have not seen many examples of constructing BIBDs, espe-
cially inﬁnite families of them, from “scratch”, as opposed to constructing
them from other designs. An exception was the rather easy Example 17.6.
The reason for this is that suﬃcient conditions on the existence of certain
designs are typically more diﬃcult to prove than necessary conditions. We
will mention some of them here without complete proofs.

464
A Walk Through Combinatorics
Theorem 17.23. Let n = pk be a power of a prime number p, where k is a
positive integer. Then a symmetric BIBD with parameters (n2 + n + 1, n +
1, 1) exists.
Reading this, the reader should wonder why the fact that n is a power
of a prime matters. The answer is that if n is a power of a prime, then a
ﬁnite ﬁeld Fn with n elements exists. We can then take the n3 −1 ordered
triples of the form (x, y, z) in which at least one of the three coordinates
is non-zero, and identify two such triples if they are constant multiples
of each other. As there are (n −1) non-zero constants in Fn, this creates
(n3−1)/(n−1) = n2+n+1 non-identical triples. These will be the vertices
of the BIBD that we are constructing.
Interestingly, the blocks will also be deﬁned as ordered triples (a, b, c)
of the same kind. So (1, 2, 3) labels both a block and a vertex. (One should
think of the block (1, 2, 3) and the vertex (1, 2, 3) as diﬀerent objects with
the same label– say one is red and the other is blue.) Then we say that
block (a, b, c) contains vertex (x, y, z) if
xa + yb + zc = 0.
It can then be shown that these rules deﬁne a BIBD with the aforemen-
tioned parameters.
A symmetric BIBD with parameters (n2+n+1, n+1, 1) is called a ﬁnite
projective plane of order n. So Theorem 17.23 shows that if n is a prime
power, then a ﬁnite projective plane of order n exists. This, of course, does
not imply that no ﬁnite projective plane can exist if n is not a prime power.
However, no such plane is known, and it is conjectured that no such ﬁnite
projective planes exist. It is known that no ﬁnite projective planes of order
6, 10, or 14 exist.
Also note that if n = pk, then there may be more than one ﬁnite pro-
jective plane of order n. The smallest example for this is n = 9, in which
case there are four ﬁnite projective planes of order 9. It is also known that
there are at least 22 ﬁnite projective planes of order 16.
Note that if we apply Theorem 17.23 with n = 2, then we conclude that
a symmetric BIBD with parameters (7, 3, 1) exists. We have seen one such
design, that of Example 17.2. We say that designs D and H are isomorphic
if there is a bijection f from the vertex set of D to the vertex set of H
so that {v1, v2, · · · , vk} is a block that appears in D exactly m times if
and only if {f(v1), f(v2), · · · , f(vk)} is a block in H exactly m times. In
Exercise 16, you are asked to prove that all BIBDs with parameters (7, 3, 1)
are isomorphic. So the design of Example 17.2 is the projective plane of

As Evenly As Possible. Block Designs and Error Correcting Codes
465
order two. It is called the Fano plane, in honor of the Italian mathematician
Gino Fano. The Fano plane is often represented by the diagram shown in
Figure 17.1.
E
D
G
F
C
B
A
Fig. 17.1
The Fano plane.
In this representation, the blocks are the six straight lines, and the
circle. The fact that a circle is used is not by accident. See Exercise 30 for
an explanation.
17.4.1
A Residual Design of a Projective Plane
As an application, consider a residual design of a projective plane with
parameters (n2 + n + 1, n + 1, 1). In Exercise 8, you are asked to compute
the parameters of such a design. For now, we just state that if n = 4, then
a residual design of a (21, 5, 1)-projective plane is a BIBD with parameters
(20, 16, 5, 4, 1). If that 5-tuple seems familiar, then that is because we have
seen such a design, namely in the very ﬁrst example of this chapter, Example
17.1, that discussed moto-cross races. The design presented there was a
residual design of a ﬁnite projective plane of order four. It can be shown
that such a residual design can be constructed directly, without constructing
the projective plane, as follows. Consider the 4-element ﬁnite ﬁeld F4, with
elements {0, 1, a, a2}. Let the vertices of our design be the 16 ordered pairs
(x, y), where x and y are elements of F4. Let the blocks be the solutions of
the 16 equations of the form y = mx + c, where m and c are also elements
of F4, and the solutions of the four equations of the form x = c.
It is
straightforward to show that each of these equations has four solutions of

466
A Walk Through Combinatorics
the form (x, y), so we get 20 blocks of size four. It can be shown that the
other conditions of being a BIBD are also satisﬁed by the design we have
just deﬁned. You will be asked to ﬁll in the gaps (in a more general form) in
Exercises 31 and 32. A residual design of a ﬁnite projective plane is called
a ﬁnite aﬃne plane.
Quick Check
(1) Compute a residual design of the Fano plane.
(2) Compute a derived design of the Fano plane.
(3) Find all symmetric designs D that have a residual design and a derived
design that are isomorphic to each other.
17.5
Codes and Designs
17.5.1
Coding Theory
The quest for ways to encode a message reliably, securely, and economically
goes back to at least the Roman empire. Here security means that inter-
cepted messages are only readable by the intended recipients. This excludes
commonly used ways of communication, such as natural languages. Econ-
omy means that a message should not take unreasonably long to encode or
decode, that is, both the number of symbols used to encode a message and
the number of diﬀerent kinds of symbols used to encode the message should
be kept as low as possible without hurting the other goals of the encoding
process. Third, the coding process should be reliable. In other words, the
recipient should not misinterpret our message. This means that our coding
system should be injective, that is, diﬀerent messages should be encoded
diﬀerently. We may impose the stronger requirement that the recipient be
able to decode our message even if there are a few mistakes in the coded
message that he receives, as long as the number of those mistakes is not
too large.
Coding theory is the huge discipline that studies the above problems
from various aspects. It is the subject of independent graduate and un-
dergraduate courses. We will not even attempt to give an overview of the
topic here; we will just show a few connections between coding theory and
the theory of designs.

As Evenly As Possible. Block Designs and Error Correcting Codes
467
17.5.2
Error Correcting Codes
Let us assume that in a crucial moment of a football game, the coach wants
to send a message to one of his players, who is standing far away from him.
Before the game, the coach and a player agreed on signals as follows. If
the coach lifts his left hand, that means that the player should try to run a
previously discussed very risky play next time he gets the ball; if the coach
lifts his right hand, then the player should not try to run that play.
Given the importance of this decision, but also the short time that is left
to relay the message, the coach will send the same signal three times, with
short pauses in among those times. In the heat of the moment, the player
may misinterpret one of the signals, or may mistake someone else’s hand
for the coach’s hand. Both of these are rather unlikely, but not impossible,
sources of error. It is extremely unlikely that any of these errors would
occur more than once out of the three signals. Assuming that the coach
will not change his mind between his ﬁrst and last signal, there are only two
possible series of signals he can send, namely LLL or RRR (L for raising
his left hand, and, yes, R for raising his right hand). If the player sees one
of these sequences, he will immediately know what to do. However, if he
mistakes a signal for its opposite, and he gets a sequence like LRL or RRL,
then he can simply take a majority vote. For instance, if the player reads
the sequence LLR, he can argue as follows. It is extremely unlikely that I
misread the signal more than once. Therefore, the two times I saw the left
hand of the coach raised, could not both be in error. So the correct signal
is L, and I will run the risky play.
The previous example was simple since there were only two possible
correct outcomes. Now let us assume that we want to send a message in
the form of a 0-1 string that will encode which of the four friends Anna,
Benjamin, Catherine and David plans to attend a party. This message can
be described by a 0-1 string of length four, in which the ﬁrst, second, third,
and fourth digit is 1 if, respectively, Anna, Benjamin, Catherine and David
plans to attend the party. So the number of possible correct messages is
24 = 16. If the receiver gets the message 1001 and knows that there is at
most one erroneous digit, then she does not know which digit is erroneous
and needs to be corrected. However, if we send the intended message three
times, and the receiver still knows that at most one digit is erroneous, then
she can easily ﬁgure out which digit that is. Indeed, for each of k = 1, 2, 3, 4,
consider the 3-tuple of the kth, k + 4th and k + 8th digits. If they are all
identical, then they are correct, if they are not all identical, then the digit

468
A Walk Through Combinatorics
that occurs only once has to be changed to the opposite digit.
The preceding examples show the important expectations that we have
towards error correcting codes. They should be compact, that is, the words
encoding the messages should be as short as possible, errors should be rec-
ognizable if we know that there are not too many of them, and errors should
be correctable in an unambiguous way. This last expectation suggests that
in some sense, our legal codewords (the possible correct messages) should
be quite dissimilar, that is, changing a digit in a legal codeword should
not lead to another legal codeword, since then we would be unable to tell
when that digit is correct. These concepts will be formalized in the next
subsection.
17.5.3
Formal Deﬁnitions About Codes
Let S and T be two ﬁnite alphabets. Let T ∗be the set of all ﬁnite sequences
whose elements are in T . A code c is an injective function c : S →T ∗. If
t ∈T ∗is in the range of c : S →T ∗, then t is called a codeword for the code
C. The set C of all codewords for c is also called the code c. If T = {0, 1},
then the code is called binary. The injection c : S →T ∗can easily be
extended to the set S∗of all ﬁnite sequences (or words) over S by setting
c(s1s2 · · · sn) = c(s1)c(s2) · · · c(sn).
The fact that c : S →T ∗is an injective function does not in itself guarantee
that the extended function c : S∗→T ∗is injective.
Example 17.24. Let S = {x, y, z}, let T = {0, 1}, and let c(x) = 0, c(y) =
1, and c(z) = 01. Then c : S∗→T ∗is not injective since c(xy) = c(z) = 01.
That is, a recipient receiving the string 01 could not know whether the
original message was xy or z. If this problem does not occur, that is, if the
extended function c : S∗→T ∗is injective, then we say that c is uniquely
decodable.
A good way to make sure that c is uniquely decodable is by making sure
our code c : S →T ∗is preﬁx-free.
Deﬁnition 17.25. We say that a code c : S →T is preﬁx-free if there are
no two codewords c(x) and c(y) so that c(x) = c(y)q for some string q ∈T ∗.
Example 17.26. Let S = {x, y, z}, let T = {0, 1}, and let c(x) = 0,
c(y) = 11, and c(z) = 10. Then c is preﬁx-free.

As Evenly As Possible. Block Designs and Error Correcting Codes
469
The following theorem shows the main advantage of preﬁx-free codes.
Theorem 17.27. If c is preﬁx-free, then it is uniquely decodable.
Proof. Let c : S →T ∗be a preﬁx-free code, and let us say that
c(x1x2 · · · xk) = c(y1y2 · · · ym) = t1t2 · · · tn,
where the xi and the yj are elements of S, and tr ∈T .
We prove that then k = m, and x1x2 · · · xk = y1y2 · · · yk, so xi = yi. We
prove this by strong induction on n. For n = 1, the statement is obvious
since c : S →T is an injective function by deﬁnition. Now let us assume
that the statement is true for all positive integers less than n. Observe that
c(x1) = c(y1) must hold, otherwise one of c(x1) and c(y1) would be a preﬁx
of the other. As c is injective on S, this implies that x1 = y1. Hence
c(x2 · · · xk) = c(y2 · · · ym) = th · · · tn
for some h > 1. In particular, th · · · tn has less than n letters, and as such,
is uniquely decodable by the induction hypothesis. So xi = yi for all i as
claimed.
The converse of Theorem is not true as you are asked to show in Exercise
33.
One way to make absolutely sure that a code is preﬁx-free is to choose
all codewords to be of the same length. These codes have many additional
advantages in addition to being uniquely decodable. Therefore, for the rest
of this chapter, all codes will consist of codewords of the same length.
Deﬁnition 17.28. Let v and w be two n-letter words over the same ﬁnite
alphabet. The Hamming distance of v and w, denoted by d(v, w), is the
number of positions in which v and w diﬀer.
Example 17.29. Let v = (0, 1, 1, 0, 1, 0), and let w = (1, 0, 1, 0, 1, 1). Then
d(v, w) = 3, since v and w diﬀer in their ﬁrst, second, and sixth entries.
The Hamming distance satisﬁes the triangle inequality. This is the con-
tent of the next theorem.
Theorem 17.30. Let u, v, and w be three n-letter words over the same
alphabet. Then
d(u, w) ≤d(u, v) + d(v, w).

470
A Walk Through Combinatorics
Proof. We can turn u to v by changing at most d(u, v) letters, then we
can turn v to w by changing at most d(v, w) letters. So we can turn u to
w by changing no more than d(u, v) + d(v, w) letters.
If we are to create a code that can correct e errors, or, in what follows,
e-error correcting codes, then it suﬃces to choose the codewords in such a
way that the distance between any two of them is at least 2e + 1. That
makes sure that if a codeword is transmitted by no more than e errors, then
it will be closer to one codeword w than all others. The receiver can then
conclude that w was the intended message.
A geometric way to describe the above idea is as follows. Let us say
that the ball B(w, e) whose center is the codeword w and whose radius is e
is the set of all words v so that d(v, w) ≤e. A code c is e-error correcting if
the balls of radius e around any two of its codewords w and w′ are disjoint.
In other words, a code is e-error correcting if and only if the distance of
any two codewords is at least 2e + 1.
Deﬁnition 17.31. An (n, m, d)-code is a code that consists of m codewords
of length n so that the Hamming distance of any two codewords is at least
d.
Intuitively, the key of creating eﬃcient e-error correcting codes is to
“pack” the codewords as closely as possible while making sure that the
balls of radius e centered at each codeword remain disjoint. It is plausible
to think that highly symmetric structures will be useful in the creation of
such codes. For instance, one can try to build an error correcting code using
the incidence matrix A of the BIBD of Example 17.2, that is, the matrix
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
{ABD}
{BCE}
{ACF}
{AEG}
{BFG}
{CDG}
{DEF}
A
1
0
1
1
0
0
0
B
1
1
0
0
1
0
0
C
0
1
1
0
0
1
0
D
1
0
0
0
0
1
1
E
0
1
0
1
0
0
1
F
0
0
1
0
1
0
1
G
0
0
0
1
1
1
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
First, we note that the Hamming distance of any two distinct rows is four,
since any two vertices of the (7, 3, 1)-design at hand occur together in ex-
actly one block. So for any two rows, there are exactly one position in

As Evenly As Possible. Block Designs and Error Correcting Codes
471
which both rows contain a 1, and two positions in which both rows contain
a 0. Therefore, the two rows diﬀer in four positions. Hence, the seven rows
of the above matrix form a (7, 7, 4)-code. In particular, this code is 1-error
correcting.
At this point, the reader should feel some discomfort since the code we
have just created is wasteful. Indeed, having the codewords four apart is
not any better than having them three apart for error correction purposes.
Both constructions lead to 1-error correcting codes. So it is natural to ask
whether the (7,7,4) code above can be extended in some natural way.
The answer is yes. This is the content of the next theorem. If v is
a vector of length n whose entries are all 0 or 1, then the complement of
v is the 0-1 vector of the same length whose coordinates disagree with
the corresponding coordinates of v in every position. In other words, the
complement of v is equal to 1 −v in the binary arithmetic, where 1 is the
vector of length n whose entries are all equal to 1.
Theorem 17.32. Let T be the incidence matrix of a (7, 3, 1)-design D.
The following 16 codewords form a (7, 16, 3)-code over the binary alphabet.
(1) The seven rows of the matrix T ,
(2) the complements of the seven rows of T ,
(3) the word 0000000, and
(4) the word 1111111.
Proof. All we need to show is that the distance between any two codewords
is at least three. Let v and w be two codewords. If they both correspond
to the same row of T , then they both correspond to a vertex in D. As D is
linked with link number 1, this implies that there is exactly one position in
which v and w both have a 1. Hence there are two positions in which they
both have a 0, so d(u, v) = 4. If u and v are both complements of rows of
T , then the same argument, applied to the complement of u and v, proves
that again, d(u, v) = 4.
If u is a row of T , and v is the complement of another row of T , then u
and v together contain seven 1s. Note that d(u, v) is the number of columns
with exactly one 1, therefore d(u, v) is an odd number. So it suﬃces to show
that d(u, v) ̸= 1. As u contains three 1s and v contains four 1s, d(u, v) = 1
is only possible if v contains a 1 in each position where u does. That implies
that the vertices corresponding to u and the complement of v do not appear
together in any block of D, which is a contradiction.
In all other cases, that is, when at least one of u and v is the all-0 or

472
A Walk Through Combinatorics
all-1 word, the statement d(u, v) ≥3 is obviously true.
17.5.4
Perfect Codes
The reader is probably wondering why we stopped at 16 codewords instead
of trying to extend our code even further. The answer is that the addition
of further codewords is not possible without losing the 1-error correction
property.
Indeed, if c is a binary code whose codewords are of length seven, then
the ball B(w, 1) centered at the codeword w and of radius 1 consists of eight
words, namely w itself, and the seven words obtained from w by changing
exactly one letter of w. If c is 1-error correcting, then the m balls B(w, 1)
are all disjoint, showing that their total volume is at most the total number
of 7-letter binary words, that is, 27 = 128. As the volume of each such ball
is eight, there can be no more than 128/8 = 16 balls, and so, there can be
at most 16 words in such a code.
The following example was a special case of some general phenomena.
The ﬁrst is a simple upper bound for the number of codewords in an e-error
correcting code.
Proposition 17.33. Let c be an r-error correcting code over the binary
alphabet in which all codewords are of length n. Then the number |C| of
codewords in c is at most
2n
r
i=0
n
i
.
You are asked to provide the proof in Exercise 11.
Second, the (7,16,3)-code we created from the (7,3,1)-BIBD was as good
as it could be in that the balls of radius 1 centered at the codewords ﬁlled
the entire vector space B7 (the seven-dimensional vector space over the
binary ﬁeld) with no gaps. This is an important concept that has its own
name.
In what follows, when we mention a code over Bn, we mean a code over
B whose words are of length n.
Deﬁnition 17.34. Let c be an r-error correcting code over Bn. We say
that c is perfect if each word v ∈Bn belongs to a ball B(w, r) for some
codeword w.
So the code of Theorem 17.32 is perfect. For perfect codes, the state-
ment of Proposition 17.33 can be strengthened as follows.

As Evenly As Possible. Block Designs and Error Correcting Codes
473
Lemma 17.35. Let c be a perfect code over Bn that is r-error correcting.
Then
|c| =
2n
r
i=0
n
i
.
You are asked to provide the proof in Exercise 12.
In particular, a perfect r-error correcting code over Bn does not exist
unless 2n is divisible by r
i=0
n
i

. In other words, for such a code to exist,
it is necessary for r
i=0
n
i

to be a power of 2.
So a perfect 1-error correcting code over Bn can exist only if
n
0

+
n
1

=
n + 1 is a power of 2, that is, when n = 2k −1 for some positive integer
k. The code we created in Theorem 17.32 was the special case k = 3. The
special case k = 2 also yields a perfect 1-error correcting code, namely the
somewhat unexciting code consisting of the two words 000 and 111.
The last paragraph raises two interesting questions.
First, we have
seen that a perfect 1-error correcting code over Bn can only exist in very
limited circumstances, namely when n = 2k −1. Is this necessary condition
suﬃcient?
Question 17.36. Is it true that for all integers k ≥2, there exists a 1-error
correcting code over Bn = B2k−1 that consists of
2n
n + 1 = 22k−1
2k
= 22k−k−1
codewords?
Second, are there other r-error correcting binary codes that are perfect?
Note that this question can be broken down into the following two parts.
Question 17.37. Are there any pairs of positive integers (n, r) so that
n > r > 1 and r
i=0
n
r

is a power of 2?
If yes, are there any r-error correcting codes over Bn that are perfect?
The answer to Question 17.36 is in the aﬃrmative. In order to be able
to prove that, we need a few simple deﬁnitions. A code c over Bn is called
linear if the set of codewords forms a subspace of the vector space Bn. In
other words, c is a linear binary code if the binary sum of any two codewords
is also a codeword. Note that the sum of two codewords is computed letter
by letter, in the binary arithmetic, without carries. So the sum of 101 and
011 is 110. The weight of a codeword is simply the sum of its letters. If the
code is binary, then this means the number of letters equal to 1 in a given
codeword.
We are now ready to state the next theorem.

474
A Walk Through Combinatorics
Theorem 17.38. For all positive integers k ≥2, there exists a perfect
binary (2k −1, 22k−k−1, 3) code.
The codes described in Theorem 17.38 are called Hamming codes, to
honor their inventor, Richard Hamming. It follows from the parameters of
these codes that they are 1-error correcting codes.
Proof. (of Theorem 17.38) Let A be any (2k −k −1) × k matrix whose
rows are the 2k −k −1 binary strings of length k that contain at least two
digits equal to 1. Note that in particular, the rows of A are all diﬀerent.
Now consider the matrix H = I|A, where I is the identity matrix of size
(2k −k −1) × (2k −k −1), and I|A simply means that A is placed on the
right of I. So H is a (2k −k −1)×(2k −1) matrix over the binary alphabet,
and each row of H contains at least three digits equal to 1.
Now let c be the binary code whose codewords are the 22k−k−1 possible
linear combinations of the rows of H with coeﬃcients 0 or 1. Note that all
these linear combinations are diﬀerent, since even their (2k −k−1)-preﬁxes
are diﬀerent. Indeed, for i ≤2k −k −1, a linear combination will have a 1
in the ith position if and only if the coeﬃcient of the ith row in that linear
combination is 1.
The rows of H are obviously of length 2k −1 as claimed, hence so are
all their linear combinations, so all the codewords of c. There remains to
show that the distance of any two codewords is at least three.
We claim that every nonzero codeword of c has weight at least three.
Indeed, every codeword obtained by adding at least three rows of H contains
at least three 1s among its ﬁrst 2k −k −1 entries, every codeword obtained
by adding two rows of H contains two 1s among its ﬁrst 2k −k −1 entries
and at least one 1 after that, while the rows of H contain, by deﬁnition,
one 1 among their ﬁrst 2k −k −1 entries and at least two 1s after that.
Now let us assume that v and w are two distinct codewords so that
d(v, w) < 3. Then w −v = w + v is also a codeword, and the weight of
w −v is less than 3, since w −v can have a 1 only in the positions where v
and w diﬀer. That contradicts the fact proved in the previous paragraph,
namely that all codewords in c have weight at least three.
Therefore, c is indeed a (2k −1, 22k−k−1, 3) binary code as claimed.
The answer to Question 17.37 is not as positive as that to the previous
question. It is easy to notice that if n is odd, and r = (n −1)/2, then
r

i=0
n
i

= 2n−1.

As Evenly As Possible. Block Designs and Error Correcting Codes
475
However, this is not too exciting, since this equality simply means that there
is a perfect binary (n, 2, n) code, in other words, a perfect binary code that
is (n −1)/2-error correcting, but which consists of only two codewords of
length n. This is obvious, since any word and its opposite will do, such as
11 · · · 1, and 00 · · ·0.
Interestingly, there are not many other pairs (n, r) so that 1 < r < n
and r
i=0
n
i

is a power of two.
It turns out that the only such pairs
are (23, 3) and (90, 2). As far as these pairs of parameters are concerned,
there does exist a perfect binary code, called the Golay code with n = 23
and r = 3, but there does not exist a perfect binary code with parameters
n = 90 and r = 2.
Quick Check
(1) Let A be the incidence matrix of a symmetric BIBD. Is it true that the
Hamming distance of any two distinct columns of A is the same?
(2) Does there exist a perfect 2-error correcting code over the binary al-
phabet in which all words are of length ﬁve?
(3) Prove that there is no perfect 2-error correcting code over the ternary
alphabet {0, 1, 2} in which all words are of length ten. Does your ar-
gument work for words of length 11?
Notes
The topic of design theory is huge, and is the subject of many books at
diﬀerent levels. At the introductory level, a recent and readable volume is
Introduction to Combinatorial Designs [56] by W. D. Wallis. For a com-
prehensive reference, we recommend the Handbook of Combinatorial De-
signs [18].
The theory of designs is closely connected to other areas in combina-
torics. The reader got a glimpse of one of those areas, coding theory, in
this chapter. For further reading in that subject, a very reader-friendly
possibility is Codes by Norman Biggs [7].
Another related topic is that of Latin squares. These interesting struc-
tures have not been discussed in our text, but they are the subject of
Exercises 18-22, and of Exercise 43 of this chapter.

476
A Walk Through Combinatorics
Exercises
(1) (-) Does there exist a BIBD with parameters (120, 10, 36, 3, 9)?
(2) (-) Does there exist a BIBD with parameters (120, 10, 36, 3, 8)?
(3) (-) Does there exist a BIBD with b = 35, k = 3, and r = 4?
(4) (-) Recall from Chapter 9 that a regular graph is a simple graph in
which each vertex has the same degree. So, regular graphs are regular,
2-uniform designs, with the edges of the graphs playing the role of
blocks. Which regular graphs are BIBDs?
(5) (-) Prove that the complementary design of a BIBD is also a BIBD.
What are the parameters of this BIBD?
(6) What is the largest possible number of blocks in a uniform design on v
vertices if no block is repeated?
(7) Describe all symmetric BIBDs with 3 ≤v ≤12 and λ = 1.
(8) Prove that the residual design of a symmetric design is a BIBD. What
are the parameters of a residual design of a symmetric BIBD of pa-
rameters (v, k, λ)? (See Deﬁnition 17.21 for the deﬁnition of residual
designs.)
(9) Prove that the derived design of a symmetric design is a BIBD. What
are the parameters of a derived design of a symmetric BIBD of pa-
rameters (v, k, λ)? (See Deﬁnition 17.22 for the deﬁnition of derived
designs.)
(10) Let D be a block design without repeated blocks with b blocks and v
vertices. Let us assume that each vertex is in more than one block,
and that every pair of distinct vertices appears together in exactly one
block. Prove that v ≤b.
Note that unlike in Theorem 17.18, D is not assumed to be regular or
uniform. On the other hand, the number of times each pair of vertices
appears together in a block is not just equal to some ﬁxed λ, but to 1.
(11) Prove Proposition 17.33.
(12) Prove Lemma 17.35.
(13) Let c : S →{0, 1}∗be a preﬁx-free code in which bi codewords have
length i. Prove that 
i
bi
2i ≤1.
(14) Let c be a Hamming code with parameters (2k −1, 22k−k−1,3, 3) as
constructed in the proof of Theorem 17.38. Let us assume that k ≥3.
Let A be the matrix whose columns are the weight-3 codewords of c.
Consider the design D whose incidence matrix is A.
(a) Prove that D is uniform and incomplete.
(b) Prove that D is balanced.

As Evenly As Possible. Block Designs and Error Correcting Codes
477
(c) Conclude that D is a BIBD, and determine the parameters of D.
(15) A t-design is a design in which every t-element set of vertices appears
together in exactly λ blocks. So BIBDs are 2-designs. Prove that if D
is a t-design with parameters (b, v, r, k, λ), then
b
k
t

= λ
v
t

.
(16) Prove that all (7, 7, 3, 3, 1)-designs are isomorphic.
(17) If D is a design, then an automorphism of D is a bijection f from the
vertex set of D into the vertex set of D so that if {v1, v2, · · · , vk} is a
block with multiplicity m, then {f(v1), f(v2), · · · , f(vk)} is also a block
with multiplicity m, and vice versa.
How many automorphisms does the Fano plane have?
(18) A Latin square is an n×n matrix in which each row and column contain
exactly one copy of each element of [n]. Let L(n) be the number of Latin
squares of side length n (or order n). Find L(n) for all positive integers
n ≤4.
(19) Magic cubes were deﬁned in Exercise 10 of Chapter 11. Prove that the
number of magic cubes of side length n having line sum 1 is equal to
L(n).
(20) Two Latin squares A and B are called orthogonal if for each ordered
pair (x, y) ∈[n]×[n], there is exactly one position (i, j) so that Ai,j = x
and Bi,j = y. A set S of several n × n Latin Squares is called mutually
orthogonal if every pair (A, B) of Latin squares with A ∈S, and B ∈S,
is orthogonal. Let N(n) be the highest number so that there exist N(n)
mutually orthogonal Latin squares of side length n. Find N(n) for all
positive integers n ≤4.
(21) (+) Prove that if a k-element set of mutually orthogonal Latin squares
of order n exists, then k < n.
(22) The aﬃne plane of order four was deﬁned in Subsection 17.4.1. The
general deﬁnition is analogous. If q is a power of a prime, then the
aﬃne plane Aq of order q is the BIBD whose vertices are the ordered
pairs (x, y), where x and y are elements of the q-element ﬁeld Fq, and
whose blocks are the solutions (x, y) of the q2 equations of the form
y = mx+ c, where m and c are elements of Fq, and the solutions of the
q equations of the form x = c.
(a) Prove that the q2 + q blocks Aq can be classiﬁed into q + 1 classes
so that each class has q blocks in it, blocks in the same class are

478
A Walk Through Combinatorics
pairwise disjoint, and if two blocks are in two distinct classes, then
they have exactly one vertex in common.
(b) (+) Prove that if q > 1 is a power of a prime, then q −1 mutually
orthogonal Latin squares of side length q do exist.
Supplementary Exercises
(23) (-) Prove that every 3-element subset S of the 5-element set
{b, v, r, k, λ} of parameters of a BIBD determines the value of the
two parameters that are not in S.
(24) (-) Let D be a BIBD with parameters (b, v, r, 3, 1). Prove that either
v = 6i + 1 or v = 6i + 3 for some non-negative integer i.
(25) (-) Prove that a balanced, uniform design is regular.
(A balanced
design is a design in which every pair of vertices belongs to the same
number of blocks.)
(26) (-) Construct a BIBD with parameters (12, 9, 4, 3, 1).
(27) (-) Give an example of a BIBD with no repeated blocks in which λ > k.
(28) How many diﬀerent (7,7,3,3,1)-BIBDs are there on vertex set [7]? Note
that two such designs are diﬀerent if their sets of blocks are diﬀerent.
That is, we do not require that the BIBDs be non-isomorphic; we
simply require that they be non-identical.
(29) We are given ﬁve distinct positive integers, and we are told that they
are the ﬁve parameters of a BIBD. We are not told which number
corresponds to which parameter. Can we ﬁnd it out?
(30) (+) Let S be a ﬁnite set of points in the plane so that not all points
of S are on the same straight line. Prove that there exists a straight
line that contains exactly two points of S.
(31) In Exercise 22, we deﬁne a design on q2 vertices and q2 + q blocks,
where q is a power of prime. Why is that design D uniform? Why is
it regular?
(32) Why is the design D discussed in the previous exercise balanced?
(33) Show an example of a code that is not preﬁx-free but still uniquely
decodable.
(34) State and prove the version of Proposition 17.33 for an alphabet of
size k instead of the binary alphabet.
(35) Prove that in a linear binary code, either all codewords have even
weight, or at most half of the words have even weight.

As Evenly As Possible. Block Designs and Error Correcting Codes
479
(36) Let c be a linear code. Prove that the minimum distance between
any two codewords of c is equal to the minimum weight of nonzero
codewords in c.
(37) Let c be a code over the binary alphabet in which every codeword has
the same length. Let ¯c be a code obtained by the rule
¯c(s) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
c(s)0 if c(s) has even weight,
c(s)1 if c(s) has odd weight.
Let us assume that the minimum distance between any two codewords
in c is d. What is the minimum distance between any two codewords
of ¯c?
(38) Recall that t-designs are deﬁned in Exercise 15. Prove that if D is a
t-design with parameters (b, v, r, k, λ), then
r
k −1
t −1

= λ
v −1
t −1

.
(39) (+) Prove that if D is a t-design, then it is also a u-design for all
integers u ∈[2, t].
(40) (+) Let D be a design with no repeated blocks. A subdesign of D is
a design F so that the set of vertices of F is a subset of the set of
vertices of D, and the set of blocks of F is a subset of the set of blocks
of D.
Let D be a (v, k, λ)-design, and let F be a (w, k, λ)-subdesign of D,
with w < v. Prove that then w ≤v−1
k−1.
(41) Show two non-isomorphic BIBDs with parameters (14, 7, 6, 3, 2).
(42) (+) Show four non-isomorphic BIBDs with parameters (14, 7, 6, 3, 2).
(43) (+) Prove that if n −1 mutually orthogonal Latin squares exist, then
there exists an (n2 + n, n2, n + 1, n, 1)-design.
Solutions to Exercises
(1) No. The ﬁrst four parameters force the equality λ = 8 by Proposition
17.8.
(2) Yes. The design of all 3-element subsets of [10] is a BIBD with these
parameters.

480
A Walk Through Combinatorics
(3) No. By Proposition 17.7, if bk is odd, then so is vr.
(4) If a simple graph is a BIBD, then any pair of its vertices must occur
together in the same number of edges (0 or 1). Only the complete
graph and the empty graph have this property.
(5) Let D be a BIBD with parameters (b, v, r, k, λ). Then the blocks of Dc
are all of size v −k since they are complements of k-element blocks.
Each vertex x of Dc is part of b −r blocks (the complements of those
that did not contain x in D). Finally, if x and y are two vertices, then
in D, they each belonged to r blocks, and there were λ blocks that
contained both. So, by the Priciple of Inclusion-Exclusion, there were
2r −λ blocks that contained at least one of them, hence there were
b −2r + λ blocks that contained neither. The complements of these
blocks will contain both of them, so any two vertices appear together
in exactly b −2r + λ blocks in Dc. So Dc is a BIBD with parameters
(b, v, b −r, v −k, b −2r + λ).
(6) If the design is k-uniform, and has no repeated blocks, then it cannot
have more than
v
k

blocks, and we have seen in Chapter 4 that for a
given v, the binomial coeﬃcient
v
k

is maximal when k = ⌊v/2⌋. So
we have b ≤

v
⌊v/2⌋

.
(7) For symmetric BIBDs, the claim of Proposition 17.8 reduces to the
equality λ(v −1) = k(k −1). We know that v ≤12, so v −1 ≤11.
That means that if λ = 1, then k(k −1) = v −1 has to be 2 or 6, since
these are the only allowed numbers that are of the form k(k −1). In
the ﬁrst case, v = 3, and k = 2, and we recognize the design of all
2-element subsets of [3]. In the second case, k = 3 and v = 7, and we
recognize the design of Example 17.2.
(8) Let D be a symmetric BIBD with parameters (v, k, λ). The residual
design R of D will have one less block than D. The size of these blocks
will be k −λ, since any two blocks of D intersect in λ vertices, so in
particular, B intersects any other block in λ vertices. (See the proof of
Proposition 17.17 for this fact.) The number of vertices decreases by
k, to v−k, since the vertices of B are removed. The remaining vertices
still occur in all r blocks they occurred before, and any pair of them
still occurs together λ times. So we conclude that R has parameters
(b −1, v −k, r, k −λ, λ).
(9) As D is linked with link number λ, any given block intersects B in D in
λ vertices. So the blocks of the derived design D′ will be of size λ. The
number of vertices will be k since vertices outside B will disappear.
The number of blocks will be b−1 = v−1 since B disappears, all other

As Evenly As Possible. Block Designs and Error Correcting Codes
481
blocks intersected B, so their intersection with B will be in D′. Any
two vertices will appear together in λ−1 blocks, (all those blocks that
contain both them in D, except for the block B). Finally, all vertices
will appear in r −1 = k −1 blocks (all blocks in which they appeared
before, except B). So D′ has parameters (b −1, k, k −1, λ, λ −1).
(10) Proceed as in the proof of Theorem 17.18. We get that AAT = D +J,
where D is a v × v matrix whose non-diagonal entries are all 0, (since
any pair (v1, v2) of vertices appears together in exactly one block),
and whose ith diagonal entry is rvi −1, where rvi is the number of
blocks in which vertex vi appears.
Now we show that det(AAT ) ̸= 0 by showing that it has linearly
independent rows. Indeed, let us assume that the rows of AAT have
a non-trivial linear combination with coeﬃcients c1, c2, · · · , cv that is
equal to 0. It then follows from routine algebra that
c1(v1 −1) = c2(v2 −1) = · · · = cv(vv −1).
As the numbers vi are larger than 1, the numbers vi −1 are larger
than 0. No ci can be 0 since that would imply that all ci are equal to
0, and the linear combination at hand is non-trivial. Therefore, either
all ci are positive, or all ci are negative, both of which contradicts the
assumption that the ci are coeﬃcients of a linear combination of the
all-positive rows that equals 0. So det(AAT ) ̸= 0, and therefore, AAT
has rank v. As rank(AAt) ≤rank(A), this implies that rank(A) = v.
The rank of a matrix cannot be more than the number of its columns.
Applying this fact for the matrix A, we get v ≤b.
(11) As c is r-error correcting, the balls centered at the codewords and
having radius r must all be disjoint. Therefore, their total volume
is the sum of their individual volumes, which is |C| · r
i=0
n
i

. This
cannot be more than the total number of strings of length n over the
binary alphabet.
(12) Continuing the line of thought of the previous exercise, if c is perfect,
then the union of the balls centered at the codewords and having
radius r must be the Bn.
(13) Let t be a randomly selected binary string of length n, where n is at
least as long as all the codewords of c. Let w be a given codeword of
c of length i. Then the probability of the event Aw that w is a preﬁx
of t is 2−i. The probability of the event that any codeword of c is a

482
A Walk Through Combinatorics
preﬁx of t is
P

w
Aw

=

w
P(Aw) =

i
bi
2i .
This number cannot be more than 1 since it is a probability. The
fact that the code is preﬁx-free is crucial, since that fact assures that

w Aw is a disjoint union of events, hence its probability is equal to
the sum of the probabilities of the Aw.
(14)(a) As the columns of A are the weight-3 codewords, each column con-
tains three 1s, and so each block contains three vertices, hence D
is uniform. As k ≥3, the number of v of vertices of D is at least
2k −1 ≥7, so D is incomplete.
(b) We show that any two vertices of D appear together in exactly one
block. In other words, we show that for any i ̸= j, there is exactly
one position in which both the ith and jth row of A contain a 1.
There cannot be more than one such position, since if the ath and
bth position were both like that, then the ath and bth columns
would diﬀer in at most two positions, contradicting the fact that
any two columns (codewords) diﬀer in at least three positions. Now
we show that there is indeed column that contains a 1 in positions
i and j. Let wij be the word of weight two in B2k−1 that has a 1 in
positions i and j and 0 everywhere else. As c is a perfect code, wij
belongs to the ball of radius 1 of exactly one codeword x of c. By
the deﬁnition of Hamming codes, x has weight at least 2. However,
as x is at distance 1 from wi,j, the weight of x cannot be exactly
two, so it is at least three. As x has weight three, it must contain
a 1 in positions i and j, otherwise it would be at distance at least
two from wi,j. This proves that D is balanced, and λ = 1.
(c) We know that D is a balanced, uniform design, hence by Supple-
mentary Exercise 25 it is regular. As the codewords are of length
2k −1, we have v = 2k−1. Then Proposition 17.8 implies
r = λ(v −1)
k −1
= 2k −2
2
= 2k−1 −1,
and then 17.7 implies
b = vr
k = (2k −1)(2k−1 −1)
3
.
(15) Both sides count the same objects, namely pairs (S, B), where S is
a t-element subset of vertices that are all part of the block B. The
left-hand side ﬁrst chooses B in b ways, then S ⊂B. The right-hand
side ﬁrst chooses S in
v
t

ways.

As Evenly As Possible. Block Designs and Error Correcting Codes
483
(16) We show that every design with those parameters has to be built up
the same way. This will imply a stronger statement. Let D be a design
with those parameters, and let A, B, and C be three vertices in D that
do not form a block. Then any pair of these three vertices appears
together in a block, and each of those three blocks has a separate third
vertex. Let us say that {A, B, D} is a block, {B, C, E} is a block, and
{A, C, F} is a block. Finally, D has a seventh vertex, which we will
call G. As λ = 1, G has to appear together with each of the other
six vertices in exactly one block. What can be the third vertex of
the block that contains A and G? It cannot be anything that already
shares a block with A, so it can only be E. So {A, E, G} is a block.
Similarly, the third vertex of the block containing B and G must be
F, so {B, G, F} is a block. Finally, the third vertex containing C and
G must be D, so {C, D, G} is a block.
We have found six of the seven blocks of D. The seventh block must
be formed by the vertices that have not been used in three blocks yet,
so {D, E, F} is a block.
Note that we have not used anything other than the parameters of D
in this argument. So any (7, 7, 3, 3, 1)-design can be built up this way,
from starting by any three vertices A, B, and C that do not form a
block. So we have in fact proved that if D and H are two (7, 7, 3, 3, 1)-
designs, then they are isomorphic, and an isomorphism can be found
by choosing three vertices A, B, and C that do not form a block, and
mapping them to any three vertices A′, B′, and C′ of H that are not in
the same block. These three images will determine the isomorphism.
(17) By the previous argument, f is determined by the images of any three
vertices A, B, and C that do not form a block.
There are seven
possible choices for f(A), six possible choices for f(B), then four pos-
sible choices for f(C) since we cannot choose the vertex that forms a
block with f(A) and f(B). Hence the Fano-plane has 7 · 6 · 4 = 168
automorphisms.
(18) It is obvious that L(1) = 1 and L(2) = 2. In order to construct a
Latin square of side length 3, ﬁrst we need to place the three 1s on
the board in one of 3! = 6 ways, then the three 2s in one of two
ways, and ﬁll the remaining boxes by 3s. So L(3) = 12. In order to
determine L(4), note that in any Latin square of side length 4, we
can permute the columns so that the top row becomes 1234, then we
can permute the top three rows so that the leftmost column becomes
1234. There remains to ﬁll out the remaining 3 × 3 grid, and it is easy

484
A Walk Through Combinatorics
to verify that there are four ways to do that. Recalling the operations
that made sure that the ﬁrst row and column were in increasing order,
this implies that L(4) = 4! · 3! · 4 = 576.
Note that a Latic square in which both the ﬁrst row and ﬁrst column
is increasing is called a reduced Latin square.
(19) If L is a Latin square of side length n, then let its entries 1 correspond
to the 1s at the bottom ﬂoor of the magic cube M, let the entries 2
of L correspond to the 1s on the second ﬂoor of M, let the entries 3
of L correspond to the 1s on the third ﬂoor of M, and so on.
(20) Clearly, N(1) = 1 and N(2) = 1. We claim that N(3) = 2. On the one
hand, there exist two orthogonal Latin squares of side length three,
as can be seen from the examples of
A =
⎛
⎜
⎜
⎜
⎝
1 2 3
2 3 1
3 1 2
⎞
⎟
⎟
⎟
⎠
and
B =
⎛
⎜
⎜
⎜
⎝
1 2 3
3 1 2
2 3 1
⎞
⎟
⎟
⎟
⎠.
Now we prove that N(3) < 3. Let us assume that P, Q, and R are
mutually orthogonal Latin squares of side length three. As P and Q
are orthogonal, there is a position in which they both contain a 1. Let
us assume without loss of generality that this is the position (1, 1).
Then, again without loss of generality, P has a 1 in (2, 2) and (3, 3),
while Q has a 1 in (2, 3) and (3, 2). The set of positions in which R has
a 1 must intersect the set of positions in which P has a 1 in exactly
one position, and the set of positions in which Q has a 1 in exactly
one position. This is impossible.
(21) Permute the symbols of each of the mutually orthogonal Latin squares
S1, S2, · · · , Sk so that each of these squares has an increasing top row.
This does not change orthogonality. Now consider the ﬁrst entry of the
second row of each of these squares. This is a collection T of k entries,
none of which is equal to 1, since the entry just above them is 1. No
two entries of T can be equal, say b, since if Si and Sj both contained b
in the (2, 1)-position, then Si and Sj would not be orthogonal. Indeed,
the pair (b, b) would occur in both the (2, 1)-position of both of these
squares, and in their (1, b)-positions.
(22) The reader may want to use Example 17.1 to illustrate the concepts
explained here. Note that in that example, q = 4.
(a) Let all blocks that were deﬁned by keeping m ﬁxed and by letting
c vary over all elements of Fq belong to the class Cm. For instance,

As Evenly As Possible. Block Designs and Error Correcting Codes
485
C0 is the class of all blocks deﬁned by the equations c = y. This
deﬁnes q classes indexed by the q elements of Fq; ﬁnally let C∞be
the class of blocks deﬁned by the equations x = c, where c varies
over all elements of Fq. First, it is straightforward to see that two
blocks of the same class are always disjoint. Indeed, if two blocks
of Cm (for m ̸= ∞) had a non-empty intersection containing the
vertex (x, y), that would mean that c1 = mx + y = c2 for two
diﬀerent values of c1 and c2, which is absurd.
Similarly, if two
blocks of C∞had a non-empty intersection containing the vertex
(x, y), then c1 = x = c2 would have to hold for two distinct values
c1 and c2.
Now let B and B′ be blocks from two diﬀerent classes. First, con-
sider the case when they are respectively deﬁned by the equations
m1x + c1 = y and m2x + c2 = y, with m1 ̸= m2.
Then it is
straightforward to check that the system of those two equations
has a unique solution (x, y), so |B ∩B′| = 1. If B′ is from the class
Fq+1, then the second equation has to be replaced by x = c2, and
then y = m1c2 + c1 from the ﬁrst equation. So again there is one
(x, y) that is in B ∩B′.
(b) If q is a power of a prime, then the ﬁnite ﬁeld Fq does exist, and
the aﬃne plane over Fq can be created as explained in part (a) of
this exercise. This aﬃne plane is a (q2 + q, q2, q + 1, q, 1)-design,
and its set of blocks can be partitioned into classes as explained in
part (a).
Now we create q −1 mutually orthogonal Latin squares from q −1
of these classes. The classes that will not correspond to a Latin
square will be C0 and C∞. In each class Ca, number the blocks in
some arbitrary way Ca1, Ca2, · · · , Caq. Let (i, j) ∈[q] × [q]. Find
the unique vertex v in the intersection of blocks C0i and C∞j. This
v lies in exactly one block of each of the remaining q −1 classes.
If, in the class Ca, the vertex v lies in the block Cak, then we put
the number k in the (i, j)-position of the Latin square Sa that we
are creating.
This procedure deﬁnes q −1 square matrices of side length q. Each
of these squares S1, S2, · · · , Sq−1 is a Latin square. Indeed, the jth
column of Sa will contain all the numbers k of blocks Cak in the
class Ck that contain a vertex of C∞j. Given that each vertex of
C∞j is part of one block of Ca, each element of [q] will occur once
in this column. A dual argument shows that the ith row of Sa also

486
A Walk Through Combinatorics
contains each element of [q] once.
Finally, we must show that Sa and Sb are orthogonal if a ̸= b.
Consider the q squares where Sa has an entry x. These squares were
ﬁlled in instances when the vertex v of the above algorithm was part
of the block Cax. The block Cax has a one-element intersection with
the block Cb1, and one-element intersection with the block Cb2, and
so on, a one-element intersection with each block Cbk, for k ∈[q].
Therefore, in the q positions where Sa has an entry x, the Latin
square Sb contains the q diﬀerent elements of [q]. So Sa and Sb are
indeed orthogonal.

Chapter 18
Are They Really Diﬀerent? Counting
Unlabeled Structures
18.1
Enumeration Under Group Action
18.1.1
Introduction
Let us assume that we have a garbage can whose base has the shape of a
regular hexagon. We see this garbage can every day, and one day, we start
thinking about the following problem. How many diﬀerent ways are there
to paint the six sides of the can using only the colors red, blue, white, and
green?
This question is easy if the faces are distinguishable. Indeed, in that
case, we have four choices for each of the six sides, resulting in a total of
46 = 4096 paint jobs. However, what can we say if the sides are indis-
tinguishable as is often the case in practice? That is, what if two paint
jobs are considered identical if one can be obtained from another by simply
rotating the can around a vertical axis going through its center?
This is a much more diﬃcult problem than the problem of counting
the ways of coloring six distinguishable objects using a ﬁnite set of colors.
Clearly, some general theory would be helpful, since a naive way of counting
would probably consist of considering too many cases. In this section, we
will learn such a technique. First, we need to learn about a structure from
Abstract Algebra that will enable us to precisely describe how one paint
job can be turned into another.
18.1.2
Groups
18.1.2.1
Groups in General
Deﬁnition 18.1. A group G is a set endowed with an operation called
multiplication deﬁned on ordered pairs of elements of G so that all of the
487

488
A Walk Through Combinatorics
following conditions hold.
(1) The set G is closed under multiplication. That is, for all elements a
and b of G, the product a · b and the product b · a are elements of G.
(2) There exists an identity element id ∈G so that for all g ∈G, the
equalities
id · g = g · id = g
hold.
(3) Multiplication is associative, that is, (a·b)·c = a·(b·c), for all elements
a, b, and c of G.
(4) Each element g ∈G has an inverse, that is, there exists a unique
element g−1 so that g · g−1 = g−1 · g = id.
Example 18.2. The set Z of all integers is a group if the usual addition of
integers is deﬁned as the operation on Z.
It is easy to see why Z is not a group with the usual multiplication of
integers as the operation. No elements other than 1 and −1 would have an
inverse if we used that deﬁnition, so the last criterion in the deﬁnition of
groups would not be satisﬁed.
Example 18.3. The set R −{0} of non-zero real numbers forms a group
with the usual multiplication of the real numbers as the operation.
Note that it is important that we exclude 0 from our set. Indeed, 0 does
not have an inverse under usual multiplication (there is no real number x
so that x · 0 = 1), so the last criterion would not be fulﬁlled.
We point out that the deﬁnition of groups does not require that in a
group, multiplication be commutative. That is, it is possible in a group
that ab ̸= ba. In fact, it turns out that most groups are non-commutative.
Example 18.4. Let SL2(R) be the set of 2 × 2 matrices with real entries
that have determinant 1. Then SL2(R) is a non-commutative group.
Solution. It is easy to verify that all the group axioms are satisﬁed by
SL2(R), so SL2(R) is indeed a group. Indeed, the fact that the elements
of SL2(R) have determinant 1 assures that their set is closed under mul-
tiplication.
The fact that their determinant is nonzero assures that all
elements have an inverse. Matrix multiplication is known to be associative
and the identity matrix serves as the identity element of the group.

Are They Really Diﬀerent? Counting Unlabeled Structures
489
On the other hand, let A =
⎛
⎝1 0
a 1
⎞
⎠, and let B =
⎛
⎝1 b
0 1
⎞
⎠. Then we
have
AB =
⎛
⎝1
b
a 1 + ab
⎞
⎠
and
BA =
⎛
⎝1 + ab b
a
1
⎞
⎠,
and so AB ̸= BA if ab ̸= 0.
Two groups G and M are called isomorphic if there exists a bijection
f : G →M that preserves the group operation. That is, if g and g′ are
elements of G, then f(g · g′) = f(g) · f(g′).
18.1.2.2
Subgroups and Cosets
If a subset H of the elements of a group G forms a group with the same
operation of G restricted to H as the operation, then H is called a subgroup
of G. This is denoted by the symbols H ≤G.
Equivalently, H is a subgroup of G if it contains the identity element of
G, and is closed under the operation of G and under taking the inverse of
each element of H in G.
Example 18.5. Let GL2(R) be the set of all 2 × 2 matrices with real
entries and non-zero determinants. Then SL2(R) ≤GL2(R).
If H is a subgroup of G, and a ∈G, then we deﬁne
aH = {ah|h ∈H}.
In other words, aH is the set of elements of G that can be obtained by left-
multiplying the elements of H by a. The set aH is then called a coset of H in
G. We point out that HH denotes the set of all two-term products formed
by elements of H, and that clearly, HH = H. The following property of
cosets is what makes them interesting.
Proposition 18.6. Let H ≤G.
Let a ∈G and b ∈G.
Then either
aH = bH, or aH ∩bH = ∅.
Proof. Let us assume that c ∈aH ∩bH. Then there exist elements h1 ∈
H and h2 ∈H so that ah1 = c = bh2.
In other words, ah1h−1
2
= b,
so, since h1h−1
2
in H, we have that b ∈aH. However, that implies that
bH ⊆aHH = aH. In an analogous way, aH ⊆bH, proving our claim.

490
A Walk Through Combinatorics
Corollary 18.7. If G is a ﬁnite group and H is a subgroup of G, then |G|
is divisible by |H|.
Proof. We claim that the diﬀerent cosets of H partition the set of elements
of G. Indeed, each element g of G belongs to a coset of H, namely to the
coset gH.
It follows from Proposition 18.6 that the diﬀerent cosets of
H do not overlap. As each of these cosets has size |H|, the Corollary is
proved.
Note that the ratio |G|/|H| is called the index of H in G, and is denoted
by G : H.
18.1.3
Permutation Groups
In Chapter 6, when we ﬁrst deﬁned permutations as bijections on a ﬁnite
set, we mentioned how to multiply two permutations together. For easy
reference, if f : [n] →[n] and g : [n] →[n] are permutations, then the
permutation fg is simply the permutation that is obtained by ﬁrst applying
the bijection f to [n], then the bijection g to [n]. In other words, fg is the
composition of f and g, that is, (fg)(x) = g(f(x)).
The following proposition shows that permutations of length n form a
group. This will be the most important group for us in this chapter.
Proposition 18.8. The set of n! permutations of [n] forms a group with
the multiplication of permutations as its operation.
Proof. The identity map id of [n] (the permutation 12 · · · n) has the prop-
erty that id · p = p · id = p for all permutations p of length n.
Each
permutation is a bijection from [n] to [n], and so has an inverse permuta-
tion p−1 that satisﬁes p·p−1 = p−1 ·p = id. Multiplication of permutations
is associative, since if p, q, and r are permutations, p(i) = j, q(j) = k, and
r(k) = m, then
((p · q) · r)(i) = r((p · q)(i)) = r(q(p(i))) = r(q(j)) = r(k) = m,
while
(p · (q · r))(i) = (q · r)(p(i)) = r(q(p(i))) = r(q(j)) = r(k) = m.
The group of n! permutations of length n is called the symmetric group
of degree n and is denoted by Sn.

Are They Really Diﬀerent? Counting Unlabeled Structures
491
Deﬁnition 18.9. Let H be a subgroup of Sn for some n. Then H is called
a permutation group.
Recall that we deﬁned automorphisms of graphs in Chapter 9. For easy
reference, an automorphism of a simple graph G is a bijection f from the
set of vertices of G onto that same set so that uv is an edge in G if and
only if f(u)f(v) is an edge in G.
Example 18.10. The set of all automorphisms of a graph G, with com-
position of functions as the operation, forms a permutation group, denoted
by Aut(G), and called the automorphism group of G.
Solution. By deﬁnition, the elements of Aut(G) are permutations of the
set of vertices of G. As the elements of Aut(G) are multiplied as permu-
tations, multiplication in Aut(G) is associative. The identity map of the
vertex set of G is always an automorphism.
Let f −1 be the inverse of
f ∈Aut(G) as a permutation. If uv is an edge of G, then f −1(u)f −1(v)
must be an edge as well, otherwise f would map the non-edge f −1(u)f −1(v)
into the edge uv. So f −1 ∈Aut(G), proving our claim.
Permutation groups are of seminal importance for theory we present in
this chapter. Therefore, we spend a paragraph to put them in context. In
some sense, permutation groups are not diﬀerent objects from groups in
general (which are sometimes called abstract groups). Indeed, each permu-
tation group is a group, and it can be shown that each group of n-elements
is isomorphic to a subgroup of Sn, that is, each ﬁnite group is isomorphic to
a permutation group. However, what is diﬀerent between abstract groups
and permutation groups is the way in which we view them. An abstract
group, such as the set of all real numbers with addition as the operation,
stands on its own. There is no need to consider any other objects to under-
stand and describe this group. On the other hand, a permutation group,
such as Sn or one of its subgroups, consists of bijections (permutations) on
the set [n]. So the elements of the set [n], that is, the numbers 1, 2, · · · , n
are present. The elements of Sn act on [n]; they permute these elements
among each other. They move them around. So a permutation group al-
ways acts on some set of objects. For instance, the automorphism group of
a graph acts on the set of vertices of that graph (and, for that matter, also
on the set of edges of that graph).
At this point, the reader may well start seeing where we are going with
this.
Recalling the introductory example of this chapter, we point out

492
A Walk Through Combinatorics
that the rotations of the hexagon-based garbage can that turn a paint
job into another one will be part of a permutation group.
We do need
some additional machinery before we can make this observation useful in
counting.
Deﬁnition 18.11. Let G be a permutation group acting on a set S, and
let i ∈S. Then the set
Gi = {g ∈G|g(i) = i}
is called the stabilizer of i.
Example 18.12. Let G = S6, acting on the set S = [6]. Let i = 1. Then
Gi is the set of all permutations in S6 that keep 1 ﬁxed. In other words, this
is the group of all permutations on the set {2, 3, 4, 5, 6}, which is isomorphic
to S5.
Example 18.13. Let G = Aut(Cn) be the automorphism group of a cycle
on n ≥3 vertices. Let i be any vertex of Cn. Then Gi = S2 is the two-
element group.
Solution. Indeed, let j and k be the neighbors of i. Then any automor-
phism f of Cn that ﬁxes i must either ﬁx both of j and k, or interchange
them. In either case, the rest of f is determined by f(j) and f(k). So Gi
is isomorphic to the 2-element group S2 acting on j and k.
Proposition 18.14. For any group G acting on the set S, and any i ∈S,
we have Gi ≤G. That is, the stabilizer of i in G is a subgroup of G.
Proof. We verify that all conditions listed in the deﬁnition of groups hold
for Gi. As Gi ⊆G, the associtiavity of the operation automatically holds.
Furthermore, Gi has an identity element, namely the identity element of
G, which ﬁxes all elements of S, including i. If both f and g ﬁx i, then
g(f(i)) = g(i) = i, so Gi is closed under multiplication. Finally, if f(i) = i,
then applying f −1 ∈G to both sides of the preceding equation, we get
i = f −1(i), so f −1 ∈G as well.
A notion that is somewhat complementary to the notion of stabilizers
is that of orbits.
Deﬁnition 18.15. Let G be acting on a set S and let i ∈S. Then the
orbit of i by G, denoted by iG, is the set of all elements of S to which i can
be moved by an element of G. That is
iG = {g(i)|g ∈G}.

Are They Really Diﬀerent? Counting Unlabeled Structures
493
The following lemma connects the notions of the orbit and the stabilizer
of G. Roughly speaking, if the orbit of i is big, then the stabilizer of i is
small, and vice versa.
Lemma 18.16. Let G be a ﬁnite permutation group acting on a set S, and
let i ∈S. Then
|G|
|Gi| =
iG .
Example 18.17. If G and i are as in Example 18.12, then |G| = 6! = 720,
G1 = 5! = 120, and iG = [6] and so
iG = 6.
Example 18.18. If G and i are as in Example 18.13, then |G| = 2n,
|Gi| = 2, and
iG = n since iG is the entire vertex set of the cycle C.
Proof. We have seen in the proof of Corollary 18.7 that the left-hand side
is the number of diﬀerent cosets of Gi in G. We show that these cosets are
in bijection with the elements of iG.
Indeed, let C be a coset of Gi in G. Then C = gGi for some g ∈G. We
then set f(C) = g(i) ∈iG.
Before we prove that f is a bijection, we need to prove that f is well-
deﬁned. That is, we need to prove that for each C, it deﬁnes one and only
one object f(C). This is not obvious since there could be several candidates
for g that satisfy C = gGi. However, Exercise 3 shows that any two such
candidates will only diﬀer by an element of Gi, so they will have the same
eﬀect on i. That is, if gGi = g′Gi = C, then g′−1g ∈Gi, so g′−1g(i) = i,
which implies that g(i) = g′(i). So indeed, f is well-deﬁned, that is, it is a
function on the cosets of Gi in G, and it does not depend on the choice of
the element g of a given coset.
It is straightforward to prove that f is a bijection. Indeed, if j ∈iG,
then there exists an element g ∈G so that g(i) = j. Then it is a direct
consequence of the deﬁnition of f that j = f(gC). Again, there are several
candidates for g, but if g(i) = g′(i), then g′−1g(i) = i, so g′−1g ∈Gi, and
by Exercise 3 the cosets gGi and g′Gi are identical.
The following notion is complementary to the notion of stabilizers in
a diﬀerent sense. It collects the objects that are ﬁxed by a given element
of the permutation group as opposed to the stabilizer, which collects the
elements of the permutation group that ﬁx a given object.

494
A Walk Through Combinatorics
Deﬁnition 18.19. Let G be a permutation group acting on a set S, and
let g ∈G. Let
Fg = {i ∈S|g(i) = i}.
The following theorem will be our fundamental tool in counting objects
that cannot be moved into one another by a given permutation group. It
is sometimes called Burnside’s lemma, or Burnside’s theorem.
Theorem 18.20. Let G be a permutation group acting on a set S. Then
the number of orbits of S under the action of G is equal to
1
|G|

g∈G
|Fg|.
Proof. As we have deﬁned two distinct notions, Gi and Fg, that related to
pairs (g, i) so that g ∈G, i ∈S, and g(i) = i, it is perhaps not surprising
that the proof of this important result consists of counting these pairs in
two diﬀerent ways, and equating the resulting formulae.
Let n be the number of orbits of S under the action of G. It then suﬃces
to show that
|G| · |n| =

g∈G
|Fg|.
(18.1)
Here the right-hand side is clearly the number of ordered pairs (g, i) so that
g ∈G, i ∈S, and g(i) = i, summed ﬁrst over each ﬁxed g, then summed
as g ranges over G.
Summing the number of these same pairs ﬁrst over each ﬁxed i, then
summing as i ranges over S, we get

g∈G
|Fg| =

i∈S
|Gi|
=

i∈S
|G|
|iG|
= |G|

i∈S
1
|iG|
= |G| · n.
Here we applied Lemma 18.14 in the second step. In the last step, we noted
that each orbit of size k contributes k fractions equal to 1/k each to the
sum, for a total contribution of 1 from that orbit. So the sum evaluates to
the number of orbits.

Are They Really Diﬀerent? Counting Unlabeled Structures
495
Corollary 18.21. Let the ﬁnite permutation group G act on the ﬁnite set
S. Then the average number of ﬁxed points of this action is equal to the
number of orbits of this action.
Proof. The displayed chain of equations in the proof of Theorem 18.20
shows that |Gi| = n|G|, where n is the number of orbits of the action of G
on S. Dividing both sides by |G|, we get our claim.
The following example illustrates Theorem 18.20 in a very simple case.
Example 18.22. Let us color the edges of K3 red or blue. Let us con-
sider two colorings equivalent if they can be moved into each other by an
automorphism. How many inequivalent colorings are there?
Solution. The key is to put the problem into a context where Burnside’s
lemma can be applied, that is, where the number we are looking for is
precisely the number of orbits of a set under an appropriate group action.
In this case, this is easy. Let S be the set of all colorings of the edges of
K3 with colors red or blue, and let G be the automorphism group of K3.
Then G acts as a permutation group on the set S (it moves colorings into
other colorings). Under this group action, two colorings belong to the same
orbit precisely when they are equivalent, so the number of inequivalent
colorings is precisely the number of orbits.
Note that G = Aut(K3) consists of the identity permutation, two 3-
cycles, and three permutations that have a ﬁxed point and a 2-cycle.
All we need to do now is to ﬁnd the numbers |Fg| for all six elements
of G. Clearly, the identity permutation ﬁxes all eight colorings, the two
3-cycles ﬁx only the two colorings in which all edges have the same color,
and the remaining three permutations ﬁx four colorings each. Indeed, the
permutation (AB)(C) ﬁxes all four colorings in which the color of AB and
the color of BC agrees.
Therefore, the number of orbits, and so the number of inequivalent
colorings is
1
|G|

g∈G
|Fg| = 8 + 2 + 2 + 4 + 4 + 4
6
= 4.
This result is very easy to verify since the four inequivalent colorings
are precisely those with 0, 1, 2, or 3 blue edges. Once the number of blue
sides is determined, the coloring is determined. This, of course, would not
be true for regular polygons with more than three sides.

496
A Walk Through Combinatorics
We can now see that in order to answer the question asked in the intro-
duction of this chapter, we have to compute Fg for each of the 6 elements
of the group of rotations of the regular hexagon, viewed as a permutation
group acting on the set of the 46 colorings of the six sides of the hexagon
using the four available colors.
The identity permutation (rotation by zero degrees) will keep all 46 col-
orings ﬁxed. Rotations by 60 or 300 degrees will only ﬁx the four colorings
that use one color each. Indeed, such a rotation moves a side of the hexag-
onal can into a neighboring side, so if a coloring is ﬁxed by such a rotation,
then in that coloring, each side must have the same color as its neighbors.
By a similar argument, if a coloring is ﬁxed by a rotation by 120 or 240
degrees, then in that coloring second neighbors must have the same color.
There are 42 = 16 colorings like that, since there are four possible choices
for the color of the ﬁrst, third, and ﬁfth sides, and four possible choices for
the color of the second, fourth, and sixth sides.
An analogous argument shows that rotation by 180 degrees ﬁxes 43 = 64
colorings. Therefore, Theorem 18.20 shows that the number of inequivalent
colorings is
1
|G|

g∈G
|Fg| = 46 + 2 · 4 + 2 · 42 + 43
6
= 700.
Example 18.23. Let H be the graph shown in Figure 18.1.
Find the
number of ways to color the edges of H using only the color red, blue, and
green if two colorings are considered identical if H has an automorphism
that takes the ﬁrst coloring into the second one.
H
Fig. 18.1
Count the ways to color the edges of this graph with three colors.

Are They Really Diﬀerent? Counting Unlabeled Structures
497
Solution. It is easy to see that H has six automorphisms, and that all
these automorphisms keep all vertices that have degree more than one ﬁxed.
Therefore, the automorphisms keep a coloring ﬁxed if and only if it keeps
the coloring of the ﬁve edges leading to the degree-one vertices ﬁxed. The
other three edges will never be moved by an automorphism, so all their 27
colorings will always be ﬁxed.
As far as the ﬁve edges leading to the degree-one vertices go, the identity
will keep all their 35 = 243 colorings ﬁxed, and the two automorphisms of
degree six keep nine of their colorings ﬁxed (one color for the three edges on
the left, one color for the three edges on the right). The two automorphisms
of degree three keep 27 colorings of these ﬁve edges ﬁxed (one color for the
three edges on the left, one color for each of the two edges on the right).
Finally, the only automorphism of degree two keeps 81 coloring of these ﬁve
edges ﬁxed, since the two edges on the right must have the same color.
Therefore, by Theorem 18.20, the edges of the graph H have
27(243 + 2 · 9 + 2 · 27 + 81)
6
= 27 · 396
6
= 1782
non-identical colorings.
Classic applications of Theorem 18.20 include the enumeration of col-
orings of the ﬁve regular polyhedra that were discussed in Chapter 12. We
will encounter some of those problems in the Exercises section.
Quick Check
In these three exercises, we consider two colorings equivalent if there is a
reﬂection, rotation, or combination thereof, that takes one coloring to the
other.
(1) Let T be an isosceles triangle that is not regular. Find the number of
non-equivalent colorings of the sides of T using k colors.
(2) Let R be a rectangle that is not a square. Find the number of non-
equivalent colorings of the sides of R using k colors.
(3) Let P be a regular pentagon. Find the number of non-equivalent col-
orings of the sides of P using two colors.

498
A Walk Through Combinatorics
18.2
Counting Unlabeled Trees
18.2.1
Counting Rooted Non-plane 1-2 Trees
In Chapter 8, we learned various techniques to use generating functions in
order to solve enumeration problems. These techniques were applicable in
many situations. However, there was something common in all the circum-
stances in which our methods were useful. The structures to be enumerated
were always labeled structures. That is, there was an n-element set of dis-
tinct objects, and the task was to compute the number of ways to carry out
a task on that set. Using diﬀerent objects for a given role resulted in new
structures. Examples of these structures were permutations, set partitions,
and graphs with labeled vertices.
In this section, we will learn a technique to enumerate certain unlabeled
structures. The tools we present will not always lead to exact enumeration
formulae, but they will provide a way to obtain the number of our structures
recursively. Techniques of Analytic Combinatorics, which are beyond the
scope of this book, can be used to obtain the approximate number of the
studied structured from the formulae that we deduce.
Unless otherwise
stated, in the rest of this section all graphs are unlabeled graphs.
As our ﬁrst example, we consider the problem of enumerating rooted
trees on n vertices in which each non-leaf vertex has at most two children.
Let us call these trees non-plane 1-2 trees. The word “non-plane” empha-
sizes the fact that our trees are not embedded in the plane, that is, there
is no notion of the “left child” and the “right child” of a vertex.
Let bn be the number of non-plane 1-2 trees on n vertices. Set b0 = 1.
The reader is invited to verify that b1 = b2 = 1, b3 = 2, and b4 = 3. The
six non-plane 1-2 trees on ﬁve vertices are shown in Figure 18.2, and we
conclude that b5 = 6.
Cutting oﬀthe root of an n-vertex non-plane 1-2 tree, we get a multiset
of two non-plane 1-2 trees (one of which may be a 0-vertex tree) that
together have n −1 vertices. The word multiset is of double importance in
the preceding sentence. First, as our trees are non-plane, the order of the
obtained two trees is insigniﬁcant. This is why we do not get an ordered
pair of two trees. Second, we cannot even say that we get a set of two trees,
since it is possible that the two obtained trees are identical. This is why
we get a multiset of two trees.
Note that the advantage of setting b0 = 1 was that now we do not have
to treat the case when the root has only one child separately. When the

Are They Really Diﬀerent? Counting Unlabeled Structures
499
Fig. 18.2
The six non-plane 1-2 trees on ﬁve vertices.
root has one child, we can still say that the root has two subtrees, one of
which is empty.
Let B(x) = 
n≥0 bnxn be the ordinary generating function of the se-
quence bn.
If the order of the two subtrees of the root mattered, then we could use
the Product Formula (Theorem 8.5) to get the generating function xB2(x).
However, in our setup the two subtrees of the root are unordered. It would
be tempting to say that since the two subtrees of the root form an unordered
pair, the number of possible such pairs is half of what it would be if they
formed an ordered pair, and so the generating function for non-plane 1-2
trees is 1
2xB2(x). The problem with this argument is that sometimes the
two subtrees of the root are identical. See Figure 18.3 for an illustration.
Trees with this property are counted by xB2(x) only once and not twice,
hence 1
2xB2(x) slightly undercounts our trees.
How many non-plane 1-2 trees are there on n vertices that fall in this
exceptional class, that is, how many non-plane 1-2 trees are there on n
vertices in which the two subtrees of the root are identical? If n is even,
then there are no such trees (since there are n −1 non-root vertices), and
if n = 2k + 1, then there are bk such trees, since there are bk choices for
one subtree of the root, and the other subtree must be identical to the
ﬁrst.
Hence the generating function of trees in this exceptional class is

k≥0 x · bkx2k = xB(x2).
So we have proved the following theorem.

500
A Walk Through Combinatorics
Fig. 18.3
A non-plane 1-2 tree in which the root has two identical subtrees.
Theorem 18.24. Let B(x) be deﬁned as above. Then we have
B(x) = 1 + x
2

B2(x) + B(x2)

.
(18.2)
You could ask what the use of this theorem is, given that we cannot
obtain an explicit formula for the numbers bn from (18.2). A recurrence re-
lation can certainly be deduced from (18.2), but that could be done without
introducing generating functions. You are asked to prove such a relation in
Exercise 28.
The real advantage of Theorem 18.24 is that it makes it possible to
evaluate, in the asymptotic sense, how large the numbers bn are.
The
methods needed to do this are beyond the scope of this book. The result
is that there exists a constant c so that
bn ∼c · an
n3/2 ,
where a = 2.4832535.... The constant c is close to 0.791. The interested
reader may consult Section 5.6 of the book Mathematical Constants [24] for
details.
Compare this to the case of unlabeled binary plane trees on n vertices.
Their number is the Catalan number
cn =
2n
n

n + 1 ∼π−1/2 · 4n
n3/2 .
So the binary plane trees are about 1.6n times as numerous as the non-plane
1-2 trees. This agrees with our intuition. Indeed, in a binary plane tree,
if a vertex is the only child of its parent, it can be its left or right child;
in a non-plane tree, there is no such issue. For vertices with a sibling, this
issue comes up only if the two siblings have non-identical subtrees, which

Are They Really Diﬀerent? Counting Unlabeled Structures
501
happens often if the subtrees are large, but not so often if the subtrees are
small, and never if they are empty. So we expect the set of binary plane
trees be more numerous than the set of non-plane 1-2 trees, by a number
between 1 and 2n, and that is indeed the case.
18.2.2
Counting Rooted Non-plane Trees
What if we drop the condition that each vertex has at most two children?
In that case, our method needs some signiﬁcant modiﬁcation. Indeed, as
long as a vertex has two children, there are only two cases, in that the
subtrees rooted at those children are either identical or not. However, if a
vertex can have 17 children, then it could happen that out of the 17 subtrees
rooted at those children, there is a set of ﬁve subtrees that are identical to
each other, there are another two subsets of three subtrees each that are
identical to each other, and the rest of the subtrees are all diﬀerent. We
need a method that can keep track of all these cases.
The method we present will be somewhat similar to the method we used
in Chapter 8 when we proved that the generating function of the sequence
p(n) counting partitions of the integer n is

n≥0
p(n)xn =

i≥1
1
1 −xi = (1+x+x2 +· · · )·(1+x2 +x4 +· · · ) · · · . (18.3)
Indeed, if a partition of n has mi parts equal to i, then it is accounted
for on the right-hand side by the summand

ximi of the ith inﬁnite sum.
The task of ﬁnding the ordinary generating function of the sequence
Tn, where Tn is the number of rooted non-plane trees is somewhat similar
to ﬁnding the above generating function for the sequence p(n). Indeed,
cutting of the root of such a tree that has n vertices, we get a multiset of
trees whose numbers of vertices add up to n −1. However, the diﬀerence
is that among these smaller trees, there could be some that have the same
size but are diﬀerent. This did not happen for integer partitions; indeed all
parts of size i were identical.
For instance, there are two rooted non-plane trees on three vertices. (In
one, the root has one child, in the other one, the root has two children.)
Therefore, a formula for T (x) = 
n≥1 Tnxn similar to (18.3) will contain
not one but two factors of the form (1 + x3 + x6 + · · · ) =
1
1−x3 . One of
these factors will account for the number of 3-vertex subtrees of the ﬁrst
kind, and the other one will account for the number 3-vertex subtrees of
the second kind.

502
A Walk Through Combinatorics
Extending this argument, we see that
T (x) = x

i≥1

1
1 −xi
Ti
.
(18.4)
Again, the factor x on the right-hand side accounts for the root. Equation
(18.4) seems to be interesting, but somehow needing more work. In par-
ticular, the right-hand side contains all Ti, but in a way which does not
make it clear how T (x) can appear on the right-hand side. Fortunately,
some purely algebraic manipulations will resolve this issue. First, using the
fact that y(x) = exp(ln y(x)), and the rule stating that the logarithm of
a product equals the sum of the logarithms of the factors, (18.4) can be
written in the form
T (x) = x exp
⎛
⎝
n≥1
Tn ln

1
1 −xn
⎞
⎠.
(18.5)
The reader is invited to verify that the ﬁrst few numbers Tn, starting
with n = 1, are 1, 1, 2, 4, 9, and 20.
At this point, the reader might point out that (18.5) is even worse than
(18.4), especially if we note that ln
	
1
1−xn

is an inﬁnite sum, so the right-
hand side involves an inﬁnite sum of inﬁnite sums. This is true, but further
simpliﬁcation is possible. Indeed, we know that ln(1/(1 −x)) = 
k≥1
xk
k ,
so
ln

1
1 −xn

=

k≥1
xnk
k ,
and therefore,

n≥1
Tn ln

1
1 −xn

=

n≥1
Tn

k≥1
xnk
k
=

k≥1

n≥1
Tn
xnk
k
=

k≥1
T (xk)
k
.
Comparing the last displayed chain of equations to (18.5), we see that we
have proved the following theorem.
Theorem 18.25. Let T0 = 0, and let Tn be the number of all rooted non-
plane trees on n vertices. Let T (x) = 
n≥1 Tnxn be the ordinary generating

Are They Really Diﬀerent? Counting Unlabeled Structures
503
function of the sequence {Tn}n≥1. Then
T (x) = x exp
⎛
⎝
k≥1
T (xk)
k
⎞
⎠.
(18.6)
Again, using methods of analytic combinatorics, it is possible to show
from (18.6) that
Tn ∼c · an
n3/2 ,
(18.7)
where c = 0.439924 · · · and a = 2.95576 · · ·. The interested reader can ﬁnd
the details in the papers referenced in Section 5.6 of [24].
Compare (18.7) with Cayley’s formula, proved in Chapter 10.
That
formula implies that the number of rooted labeled trees on n vertices is
nn−1.
If every rooted unlabeled non-plane tree on n vertices could be
labeled in n! diﬀerent ways, then the number of labeled trees would be n!
times larger than Tn. However, there are a few trees that can be labeled
in less than n! ways (think of a star rooted at its center). So we expect
this ratio to be a little bit less than n!. This intuition proves to be correct.
Indeed, by Stirling’s formula (see formula (3.1)),
nn−1
n!
∼
en
√
2πn3/2 ,
which is a little bit less than Tn since e = 2.718 < a = 2.95576. We also
point out that the number of rooted unlabeled plane trees on n vertices
is the Catalan number cn−1, as you were asked to prove in Exercise 45
of Chapter 14. Catalan numbers grow roughly as fast as powers of 4, so
somewhat faster than the numbers Tn that grow roughly as fast as powers
of 2.95. The diﬀerence in growth rates is the eﬀect of the diﬀerence between
plane trees and non-plane trees.
18.2.3
Counting Unrooted Trees
What can we say about the number of all unlabeled trees, that is, unlabeled
trees that are not rooted? This seems to be a diﬃcult question since some
trees can be rooted in many non-equivalent ways (the path is an example
for this), while some others can only be rooted in a few ways (the star can
only be rooted in two ways).
The following famous result of Richard Otter establishes a surprisingly
close connection between the number of rooted and unrooted trees on n
unlabeled vertices.

504
A Walk Through Combinatorics
Theorem 18.26. Let t0 = 0, let tn be the number of unrooted trees on n
unlabeled vertices for n ≥1, and let t(x) = 
n≥1 tnxn. Then we have
t(x) = T (x) −1
2

T (x)2 −T (x2)

.
(18.8)
Theorem 18.26 is surprising for more than just its simple form. The
right-hand side of (18.8) contains the number 2 three times, in ways that
are similar to what we have seen in formula (18.2) for rooted non-plane 1-2
trees. This is unexpected, since the trees counted by Theorem 18.26 do
not have limits on their vertex degrees. The special role that the number
2 plays in (18.8) is surprising.
The reader can get familiar with the problem at hand by verifying that
the ﬁrst few values of the sequence of the numbers tn, starting with n = 1,
are 1, 1, 1, 2, 3, and 6.
Proof. (of Theorem 18.26) In order to prove Theorem 18.26, we need a
few deﬁnitions. If v and w are two vertices of the tree T , and T has an
automorphism f so that f(v) = w, then we call v and w similar vertices.
In other words, v and w are similar if they are in the same orbit of the
action of Aut(T ) on T . The number of orbits of this action will be called
the number of non-similar vertices of T . In an analogous way, Aut(T ) acts
on the set of all edges of T . Edges of T that are in the same orbit of this
action are called similar edges, and the number of non-similar edges is the
number of orbits of the action of Aut(T ) on the set of edges of T .
A symmetry edge of T is an edge that connects two similar vertices of
T . Let v and w be the two endpoints of a symmetry edge L of the tree
T . In Exercise 30, the reader is asked to prove that each f ∈Aut(T ) that
satisﬁes f(v) = w must also satisfy f(w) = v. It then follows easily (see
Exercise 31) that no tree can have more than one symmetry edge.
The following, somewhat technical lemma is (almost) the only graph-
theoretical part of the proof of Theorem 18.26.
Lemma 18.27. Let T be a tree, and let T0 be a subtree of T so that no two
vertices of T0 are similar in T . Let P be a vertex of T that is not in T0,
and let P be adjacent to a vertex Q in T0.
Let f ∈Aut(T ) so that P ′ = f(P) ∈T0. Set Q′ = f(Q). Denote by e
the edge between P and Q, and denote by e′ the edge between P ′ and Q′.
Then either Q = Q′ or e = e′.
See Figure 18.4 for an illustration. It is easy to see that in that particular

Are They Really Diﬀerent? Counting Unlabeled Structures
505
example, the function f interchanging P and P ′ and keeping all other
vertices ﬁxed is an automorphism of T .
T
T0
P
Q
P’
e
e’
Fig. 18.4
An instance of the situation in Lemma 18.27.
Proof. (of Lemma 18.27) We show that if e ̸= e′, then Q = Q′. If we
remove the edge e = PQ from T , we get the trees TP and TQ, where TP is
the tree containing P. In a similar manner, if we remove e′ from T , we get
the trees TP ′ and TQ′.
We will now prove that the edge e′ is in T0. That, in turn, implies that
Q′ ∈T0 since Q′ is an endpoint of e′. As f(Q) = Q′, this forces Q = Q′,
since T0 does not contain two distinct vertices that are similar in T .
Let us assume by way of contradiction that e′ /∈T0. That means that
the removal of e′ leaves T0 intact, so T0 is part of TP ′ or TQ′. However,
by deﬁnition, P ′ ∈T0, so T0 ⊆TP ′ since P ′ is an endpoint of e′. Since by
deﬁnition, Q ∈T0, this implies that Q ∈TP ′. As Q is adjacent to P (by
way of e), this implies that e ∈TP ′, since we know that e is not identical
to the removed edge e′. The fact that e ∈TP ′ implies that e /∈TQ′ since
TP ′ and TQ′ are disjoint.
In a similar manner, e = PQ is by deﬁnition not part of T0 (since P is
not part of T0), so its removal leaves T0 intact. This means T0 is a subtree
of TP or TQ, but since Q ∈T0, therefore T0 ∈TQ. In particular, P ′ ∈TQ
since P ′ ∈T0. As the removed edge e is not identical to the edge e′ = P ′Q′,
this implies that Q′ ∈TQ, and also e′ ∈TQ.

506
A Walk Through Combinatorics
Finally, because Q′ ∈TQ, and the removed edge e = PQ is not in TQ′,
it follows that TQ′ ⊆TQ. This containment is strict, since TQ contains
the edge e′, while TQ′ by deﬁnition does not.
This is a contradiction,
since f(TQ) = f(TQ′), so TQ and TQ′ have the same number of edges. So
e′ ∈T0, and, as we explained in the second paragraph of this proof, that
forces Q = Q′.
Note that if e = e′, that means that the edge PQ and the edge P ′Q′ are
identical. As P ̸= P ′, this means that P = Q′ and P ′ = Q. In particular,
P and Q are similar, and the edge PQ is a symmetry edge. Also note that
f(P) = P ′ = Q, and f(Q) = Q′ = P, so f reverses the edge e.
The following, perhaps surprising, lemma shows that the number of
non-similar vertices and the number of non-similar edges of a tree are very
closely connected, almost in the same way as the number of all vertices and
the number of all edges.
Lemma 18.28. In any tree T , the number of non-similar vertices is one
larger than the number of non-similar edges (symmetry edge excluded).
The reader should verify this claim for the tree T shown in Figure 18.4
before reading further.
Proof. (of Lemma 18.28) Let T0 be a maximal (that is, non-extendible)
subtree of T that contains no two vertices that are similar in T . Let T0
consist of m vertices. See Figure 18.5 for an illustration.
We will prove two claims, which will together imply the statement of
Lemma 18.28.
(1) We claim that T has exactly m non-similar points. We claim that this
is true since each vertex v of T is similar to a vertex of T0.
We prove this claim by induction on k, the distance of a vertex v ∈T
from T0. For k = 1, the claim is obvious. Indeed, in that case, v is a
neighbor of a vertex of T0, so if v were not similar to a vertex of T0,
then v could be added to T0, contradicting the maximality of T0.
Now let us assume that we know that our claim holds for k and prove it
for k + 1. Let v be at distance k + 1 from T0, and let u be the neighbor
of v on the unique path from v to T0. Then u is at distance k from
T0, so by the induction hypothesis, u is similar to a vertex u0 ∈T0.
So the neighbors of u (including v) are similar to the neighbors of u0,
which are vertices at distance at most one from T0. By transitivity,

Are They Really Diﬀerent? Counting Unlabeled Structures
507
0
T
T
Fig. 18.5
The tree T0 has no two vertices that are similar in T, but no other vertices
of T can be added to T0 without destroying that property of T0.
(and because the claim holds for k = 1), this implies that all neighbors
of u, including v, are similar to a vertex in T0. This completes the
induction step and the proof of our claim.
(2) We claim that T has m −1 non-similar edges that are not symmetry
edges. We claim that this is true since each non-symmetry edge of T
is similar to an edge of T0.
Let pq be an edge of T . By the previous claim, q is similar to a vertex
in T0, so we may assume that q ∈T0 (since there is an automorphism
of T that maps q into a vertex of T0).
If p ∈T0 as well, then our
claim is obviously true. If p /∈T0, then p is similar to a vertex p′ ∈T0,
otherwise p could be added to T0, contradicting the maximality of T0.
Now apply Lemma 18.27, with the vertices p, p′, and q playing the roles
of the vertices P, P ′ and Q, and f ∈Aut(T ) being an automorphism
such that f(p) = p′. Then Lemma 18.27, and the remark after it imply
that either f(q) = q, or pq is a symmetry edge.
So if pq is not a
symmetry edge, then f(pq) = p′q, which is an edge of T0 since both p′
and q are in T0, and the automorphism f of T preserves edges. So pq
is similar to the edge p′q of T0.
The statement of the Lemma is now obvious since m−(m−1) = 1.
Now let vn be the total number of non-similar vertices of all n-vertex
unlabeled trees, and let en be the total number of all non-similar edges
(that are not symmetry edges) of all n-vertex unlabeled trees. In other

508
A Walk Through Combinatorics
words, vn is the sum of the number of non-similar vertices taken over all
n-vertex unlabeled trees, and en is the sum of the number of all non-similar
edges (excluding symmetry edges) of all n-vertex unlabeled trees.
The following proposition expresses the number of our unrooted trees
in a way that will be useful in our enumeration eﬀorts.
Proposition 18.29. For all positive integers n ≥2, we have
tn = vn −en.
Proof. (of Proposition 18.29) Let v(t) (resp. e(t)) denote the number of
non-similar vertices (resp. edges) of the unrooted tree t. Then by Lemma
18.28, we have
vn −en =

t
(v(t) −e(t))
=

t
1
= tn.
Here t ranges all unrooted trees on n unlabeled vertices.
In order to use Proposition 18.29 to compute tn, we need to determine
both vn and en. First, we have
vn = Tn,
(18.9)
since rooting the unlabeled tree t at its vertex x will result in a rooted tree
diﬀerent from the rooted tree obtained from rooting t at its vertex y if and
only if x and y are non-similar vertices.
Second, en is equal to the number of rooted trees t on n unlabeled
vertices in which one edge that is not a symmetry edge is colored blue. We
claim that the number of the latter is
en =
Tn/2
2

+ 1
2

i̸=j
i+j=n
TiTj,
where Tn/2 = 0 if n is odd.
Indeed, removing the colored edge (but not its vertices) from t will
result in two smaller rooted trees, the endpoints of the removed edges being
the roots. If these trees have a diﬀerent number of vertices, then they are
counted by the ﬁrst summand of the right-hand side, and if they have the
same number of vertices, then they are counted by the second term of the
right hand side. (Since the removed edge was not a symmetry edge, the
obtained two smaller trees are always diﬀerent.)

Are They Really Diﬀerent? Counting Unlabeled Structures
509
A routine rearrangement of the last displayed equation yields
en =

i+j=n TiTj
2
−Tn/2
2
.
(18.10)
Substituting the expressions that we obtained for vn and en in formulae
(18.9) and (18.10) into the formula of Proposition 18.29, we get
tn = Tn −1
2
⎛
⎝
⎛
⎝
i+j=n
TiTj
⎞
⎠−Tn/2
⎞
⎠,
which is equivalent to the claim of Theorem 18.26.
The asymptotics of tn are not surprising, given that each unrooted tree
on n vertices can be rooted in at least one and at most n diﬀerent ways.
So tn ≤Tn ≤ntn clearly holds. This implies that tn must be of the same
exponential order as Tn. A more precise analysis, whose scope is beyond
this book, leads to the result
tn ∼an
n5/2 b,
(18.11)
where a = 2.95576 just as in formula (18.7), and b = 0.534949. Comparing
formulas (18.7) and (18.11), we get the asymptotic formula
Tn
tn
∼0.822366 · n.
So on average, for large n, an unrooted tree t on n vertices can be rooted in
0.822366n ways, that is, the expected number of non-identical rooted trees
we will obtain if we root t in all n possible ways.
Quick Check
All trees in the following three exercises are unrooted and unlabeled.
(1) Let T be a tree, let f ∈Aut(T ), and let u and v be two vertices of T
that are ﬁxed by f. Prove that each vertex of the unique path uv is
ﬁxed by f.
(2) Prove that there is no tree T that has exactly three automorphisms.
(3) For which odd integers d does there exist a tree T that has exactly d
automorphisms?

510
A Walk Through Combinatorics
Notes
For an introducton to Analytic Methods in Combinatorics, the reader can
start by Chapter 7 of the book Introduction to Enumerative and Analytic
Combinatorics [11]. A somewhat more advanced treatment is Chapter 5
of Generatingfunctionology by Herb Wilf [59]. The comprehensive book on
the subject is Analytic Combinatorics [25] by Philippe Flajolet and Robert
Sedgewick.
A recent, extensive survey is Chapter 2 of the Handbook of
Enumerative Combinatorics, by Helmut Prodinger [12].
A central part of these methods is a theorem that claims that (with
suitable conditions), the exponential order of the coeﬃcients of the power
series A(x) equals 1/a, where a is the singularity of A(x) that is closest to
0. Singularity is an important concept in complex analysis, and the reader
is encouraged to read about it in the aforementioned books. For instance,
if a = 1/4, then the coeﬃcients of A(x) grow roughly as fast as 4n.
Exercises
(1) (-) Prove that the group of all real numbers with addition as the oper-
ation is isomorphic to the group of all positive real numbers as multi-
plication as the operation.
(2) (-) Prove Proposition 18.14.
(3) (-) Let H be a subgroup of G, and let a and b be two elements of G.
Prove that aH = bH if and only if b−1a ∈H.
(4) We say that the action of the group G on the set S is transitive if for
any two elements s, t ∈S, there is a g ∈G so that g(s) = t. Give an
example of a regular graph R such that the action of Aut(R) on the
vertex set of R is not transitive.
(5) Show an example of a graph G such that the action Aut(G) on the set
of vertices of G is transitive, but the action of Aut(G) on the set of
edges of G is not transitive.
(6) Let H be a regular hexagon. Let us color the six sides of H using
only the colors red, white, blue, and green, and consider two colorings
equivalent if one can be moved into the other by rotating H around its
center, or reﬂecting H through one of its six symmetry lines (three of
which are diagonals, and the other three of which connect midpoints of
opposing sides). How many non-equivalent colorings are there?
Note that in the next three exercises, we consider two colorings equiv-
alent if there is an automorphism of the graph at hand that moves one

Are They Really Diﬀerent? Counting Unlabeled Structures
511
coloring into the other.
(7) Find the number of non-equivalent ways to color the vertices of a tetra-
hedron using only red, blue or green.
(8) Find the number of non-equivalent ways to color the vertices of an
octahedron using only red or blue.
(9) Find the number of non-equivalent ways to color the vertices of a cube
using only red or blue.
(10) Let us say that two n-permutations q and r are c-equivalent if there
exists a natural number j ≤n−1 and a bijection between the cycles of
q and the cycles of r so that each cycle of r can be obtained from the
corresponding cycle of q by adding j (modulo n) to each entry of the
corresponding cycle of q. For instance, q = (413)(52) and r = (241)(35)
are c-equivalent, as can be seen by selecting j = 3.
(a) Describe, in the language of group theory, what it means for q and
r to be c-equivalent. Your description should be in terms of multi-
plying permutations within the symmetric group.
(b) (+) Analyze the sizes of the equivalence classes created by the c-
equivalence relation to prove that if n is a prime, then (n −1)! + 1
is divisible by n. (This statement is called Wilson’s theorem.)
(11) Let P be any of the ﬁve regular polyhedra. For f ∈Aut(P), let X(f)
be the number of vertices ﬁxed by f. Find E(X).
(12) A non-plane 2-tree is a rooted tree in which each non-leaf vertex has
exactly two children.
(a) (-) Prove that all non-plane 2-trees have an odd number of vertices.
(b) Let dn be the number of non-plane 2-trees on 2n + 1 vertices. Prove
that dn = b2n+1, where bm is the number of non-plane 1-2 trees on
m vertices.
(13) Recall from Chapter 6 that a permutation p is called an even per-
mutation if it has an even number of inversions, or, equivalently, if
det Ap = 1. See Exercise 11 of Chapter 6 for a deﬁnition of Ap.
What is the average number of ﬁxed points in all even permutations of
length n?
(14) We have seen in Chapter 14 that the number of decreasing binary trees
on vertex set [n] is n!. Recall that those trees were plane trees. Now
let Nn be the number of decreasing binary non-plane trees on vertex
set [n]. In such a tree, the root has label n, and each non-leaf vertex v
has at most two children, and the labels of these children are less than

512
A Walk Through Combinatorics
the label of v. The order of the children of v is insigniﬁcant, so there
is no “left child” and “right child”.
Let N0 = 1, and let N(x) = 
n≥0 Nn xn
n! . Prove that N 2(x) + 1 =
2N ′(x).
(15) Deduce from the result of the previous exercise that N(x) = tan x +
sec x.
(16) Let En be the number of permutations of length n whose descent set
is {2, 4, · · ·}.
(a) Characterize the decreasing binary trees (the plane version) of such
permutations.
(b) Prove that En = Nn, where Nn is deﬁned in the previous exercise.
(17) (+) Find a bijective proof of the result of part (b) of the previous
exercise.
(18) Let d0 = 0, let dn be the number of all decreasing non-plane trees
on vertex set [n] if n ≥1. In these trees, each non-leaf vertex v can
have any number of children, as long as the labels of these children are
smaller than the label of v. The children of v are unordered.
Let D(x) = 
n≥1 dn xn
n! .
(a) Let Dk(x) be the exponential generating function for the sequence
counting decreasing non-plane trees in which the root has exactly k
children. Prove that
D′
k(x) = Dk(x)
k!
.
(b) Use the result of part (a) to ﬁnd a closed form for D(x), and then
for dn.
(19) Find a combinatorial proof of the result of part (b) of the previous
exercise.
(20) Let gn be the number of plane 1-2 trees on n unlabeled vertices. In
such trees, each non-leaf vertex v has either one or two children. If v
has two children, then the order of those children matters, that is, v
has a left child and a right child. However, if v has only one child, that
child is not a left child or right child (unlike in decreasing binary trees).
Set g0 = 0, and verify that g1 = 1, g2 = 1, g3 = 2, g4 = 4, and g5 = 9.
Find a closed form for the generating function G(x) = 
n≥0 gnxn.

Are They Really Diﬀerent? Counting Unlabeled Structures
513
Supplementary Exercises
(21) A permutation group G acting on the set S is called transitive if for
any two elements s, t ∈S, there exists g ∈G so that g(s) = t.
Let R be a regular simple graph (meaning that all vertices of R have
the same degree. Is Aut(R) a transitive permutation group as it acts
on the vertex set of R?
(22) A permutation group G acting on the set S is called primitive if there
is no non-trivial partition of S that is preserved under the action of G.
That is, there is no partition π of S other than the 1-block partition
and the |S|-block partition with the property that for all g ∈G and
all blocks B of π, the set g(B) is a block of π.
Now let S be the set of vertices of a cube, and let G be the automor-
phism group of the cube. Is G primitive over S?
(23) Let H be a simple graph on n vertices.
Let l(H) be the number
of diﬀerent ways to label the vertices of l using each element of [n]
exactly once.
Two labelings are considered identical if the labeled
graphs deﬁned by them have identical sets of edges. That is, for all
i, j ∈[n], the edge ij is either part of both labeled graphs, or of neither
labeled graphs.
Find a formula for l(H) in terms of Aut(H).
(24) Euler’s theorem states that if p is a prime and x is a positive integer,
then xp −x is divisible by p. Use Theorem 18.20 to prove Euler’s
theorem.
Note that in the next three exercises, we consider two colorings equiv-
alent if there is an orientation-preserving automorphism of the graph
at hand that moves one coloring into the other.
An automorphism f of a graph G is called orientation preserving if
the orientation (positive or negative, clock-wise or counter-clockwise)
of each cycle A1A2 · · · Ak of G agrees with the orientation of the cycle
f(A1)f(A2) · · · f(Ak). Note that the orientation-preserving automor-
phisms of regular polyhedra are precisely those automorphisms that
correspond to three-dimensional movements. This group is sometimes
called the rotation group of the polyhedron.
(25) Find the number of non-equivalent ways to color the vertices of a cube
using only red or blue.
(26) Find the number of non-equivalent ways to color the vertices of an
octahedron using only red or blue.
(27) Find the number of non-equivalent ways to color the vertices of a

514
A Walk Through Combinatorics
tetrahedron using only red, blue or green.
(28) Let bn be the number of unlabeled non-plane 1-2 trees on n vertices.
Prove that
(a) bn = i−1
k=0 bkbn−1−k if n = 2i, and
(b) bn = 1
2bi(bi + 1) + i
k=0 bkbn−1−k if n = 2i + 1.
(29) (-) Show an example of a tree on six vertices with a symmetry edge,
and of a tree on six vertices without a symmetry edge.
(30) Let v and w be the endpoints of a symmetry edge L of the tree T . Let
f ∈Aut(T ). Prove that if f(v) = w, then f(w) = v.
(31) Prove that a tree can have at most one symmetry edge.
(32) Let p = p1p2 · · · pn be a permutation. Let us deﬁne two families of
operations on p.
(a) For 1 ≤i ≤n, let Hi(p) = pipi+1 · · · pnp1 · · · pi−1, and,
(b) for 0 ≤i ≤n −1, let Vi(p) = (p1 + i)(p2 + i) · · · (pn + i), where
integers larger than n are taken modulo n.
In other words, Hi(p) shifts p “horizontally” and Vi(p) shifts p “ver-
tically”, by i units.
Let us call two permutations equivalent if one can be obtained from
the other by a series of operations Hi and Vj, where i and j are allowed
to change. Find the number of equivalence classes of n-permutations
under this equivalence relation.
(33) (-) Let P be any of the ﬁve regular polyhedra. Let f ∈Aut(P). Let
Y (f) be the number of edges of P ﬁxed by Y . Find E(Y ). (We say
that f ∈Aut(P) ﬁxes the edge e if f either leaves both endpoints of
e ﬁxed, or interchanges them.)
(34) (+) Recall that in Chapter 16, we proved that if Πn is the lattice of
partitions of [n] ordered by reﬁnement, then
μΠn(ˆ0, ˆ1) = (−1)n−1(n −1)!.
Use this fact to give an alternate proof of Wilson’s theorem, which is
stated in Exercise 10, part (c).
(35) (-) Recall that tn is the number of unlabeled trees on n vertices. An un-
labeled forest is a forest whose components are unlabeled trees. Let fn
be the number of such forests on n vertices, and let f(x) = 
n≥0 fnxn,
with f0 = 1. Express f(x) in terms of the numbers tn.
(36) (-) A rooted unlabeled non-plane forest is a forest on unlabeled vertices
whose components are rooted non-plane trees. Let Fn be the number
of such forests on n vertices, and set F0 = 0. Find a simple expression

Are They Really Diﬀerent? Counting Unlabeled Structures
515
for F(x) = 
n≥0 Fnxn in terms of one of the generating functions
discussed in this chapter.
(37) Let h0 = 0, and let hn be the number of rooted non-plane trees on n
unlabeled vertices in which each vertex has at most three children if
n ≥0. Find a functional equation satisﬁed by the generating function
H(x) = 
n≥0 hnxn.
(38) Let n ≥3, and let un be the number of graphs on n unlabeled vertices
that contain exactly one cycle and that cycle is a triangle. Express the
generating function U(x) = 
n≥3 unxn in terms of some generating
functions introduced in this chapter.
(39) Let an be the number of rooted plane 1-2 trees on vertex set [n] in
which every non-leaf vertex v has a label that is larger than the label
of its children. If v has two children, then one of them is the left child
of v and the other one is the right child of v, but if v has only one
child, that child is not a left child or right child (unlike in decreasing
binary trees). Let a0 = 1, and let A(x) = 
n≥0 an xn
n! . Prove that
A′(x) = A2(x) −A(x) + 1.
(40) Let an be the number deﬁned in the previous exercise. Find a (simply
deﬁned) class of permutations of length n that has an elements.
Solutions to Exercises
(1) The map f(x) = ex is an isomorphism between these two groups.
(2) If g and g′ both ﬁx i, then so does gg′ since (gg′)(i) = g′(g(i)) = g′(i) =
i. The inverse of g reverses the action of g, so if g takes i to i, then
g−1 takes i to i as well. The identity permutation ﬁxes every element
of S, including i. Finally, multiplication is automatically associative,
since it is associative in the group G.
(3) If aH = bH, then multiplying both sides by b−1 from the left, we get
b−1aH = H. If b−1a /∈H, then this cannot hold, since H contains
the identity element of G. So aH = bH implies that b−1a ∈H.
Now let us assume that b−1a ∈H. Let x ∈bH. Then x = bh for some
h ∈H. Note that
x = b(b−1a)(a−1b)h = a(a−1b)h ∈aH.
Indeed, if b−1a ∈H, so is its inverse, a−1b. So bH ⊆aH. Applying
the same argument for the a−1b, which is in H if and only if its inverse,
b−1a is, we get the inclusion aH ⊆bH.

516
A Walk Through Combinatorics
(4) Let R be an octogon, with its vertices labeled 1 through 8 in circular
succession, and with the diagonals 15, 28, 37, and 46. Then R is a
regular graph since each of its vertices has degree three. However,
the action of Aut(R) on the vertex set of R is not transitive, since
some vertices of R are not part of any triangles (3 and 7), while other
vertices are.
(5) Let G have vertices ABCA′B′C′, where ABC and A′B′C′ are tri-
angles, and AA′, BB′ and CC′ are edges. One can think of G as a
triangular prism. It is clear that Aut(G) acts transitively on the set
of vertices. However, Aut(G) does not act transitively on the edges,
since edges AA′, BB′ and CC′ are not part of any triangles, while the
other edges are.
(6) Let G be the automorphism group of a regular hexagon. It follows
from Exercise 8 (c) of Chapter 9 that G has 12 elements, which can be
identiﬁed as six rotations around the center of the hexagon (by angles
iπ/3, for i = 0, 1, · · · , 5) and six reﬂections (through three maximal
diagonals and three lines connecting the midpoints of opposite faces).
Let us start with the easy cases. If g is the identity element of G, then
it of course ﬁxes all colorings, so Fg = 46 = 4096. If g is a rotation
by π/3 or 5π/3, then it only ﬁxes colorings in which all sides have
the same color (four colorings each). If g is a rotation by π, then g
ﬁxes the colorings in which opposite faces have the same color (there
are 43 = 64 such colorings). If g is a rotation by 2π/3 or 4π/3, then
g ﬁxes the colorings in which second neighbors have the same color.
There are 42 = 16 such colorings.
If g is a reﬂection, then we distinguish two cases. If g is a reﬂection
through a maximal diagonal, then it ﬁxes 43 = 64 colorings, and if g
is a reﬂection through a line connecting the midpoints of two opposite
sides, then g ﬁxes 44 = 256 colorings.
So
1
|G|

g∈G
|Fg| = 46 + 2 · 4 + 43 + 2 · 42 + 3 · 43 + 3 · 44
12
= 430.
(7) The automorphism group of the tetrahedron is S4, the group of all
permutations of length 4. The elements of this group can be of ﬁve
diﬀerent cycle types.
(a) Four 1-cycles. This permutation ﬁxes all 81 colorings.
(b) Two 1-cycles and one 2-cycle. Such permutations ﬁx 27 colorings,
since the two colors in the 2-cycle have to be identical.

Are They Really Diﬀerent? Counting Unlabeled Structures
517
(c) Two 2-cycles. By the same argument as in the preceding case,
such permutations ﬁx nine colorings.
(d) One 1-cycle and one 3-cycle. Such permutations ﬁx nine colorings.
(e) One 4-cycle. Such permutations ﬁx three colorings.
The number of permutations of each type is, 1, 6, 3, 8, and 6 as
we learned in Chapter 6. Therefore, Theorem 18.20 yields that the
number of inequivalent colorings is
81 + 6 · 27 + 3 · 9 + 8 · 9 + 6 · 3
24
= 15.
(8) Burnside’s theorem is not the simplest way to solve this problem. Let
us consider the possible distributions of colors. There is one coloring
in which all vertices are red, one coloring in which all vertices are
blue, one coloring in which ﬁve vertex is red and one is blue, and one
coloring in which ﬁve vertices are blue and one is red.
If four vertices are red and two are blue, then those two blue ver-
tices may be at distance one or two from each other, leading to two
inequivalent colorings. The same holds for four blue and two red ver-
tices. Finally, if there are three red and three blue vertices, then the
three red vertices may or may not contain an opposite pair, leading to
two more colorings. So there are altogether ten inequivalent colorings.
(9) There is one such coloring with zero, one, seven, or eight red vertices.
There are three inequivalent colorings with two red vertices, since the
two red vertices may be at distance 1,
√
2, or
√
3. The same goes for
colorings with two blue vertices.
Now consider colorings with three red vertices. One possibility is that
all three red vertices are on the same face. Another one is when two
red vertices are endpoints of the same edge, and the third is the unique
vertex at distance
√
3 from one of them. The only remaining case is the
one in which no edge has two red endpoints, that is, the red vertices
are the three neighbors of a given vertex. This means there are three
inequivalent colorings with three red vertices, and three inequivalent
colorings with three blue vertices.
Finally, there is the case of four red vertices and four blue vertices.
There is one coloring in which all red vertices are on one face. There
are three colorings in which three red vertices and a blue vertex are
on one face. The only remaining case is when each face has two red
and two blue vertices. That can happen in two ways, namely either
there will be an edge with monochromatic vertices, or not. So there
are a total of six colorings with four vertices of each color.

518
A Walk Through Combinatorics
So altogether, there are 1+1+1+1+3+3+3+3+6 = 22 inequivalent
colorings.
(10) (a) Let q and r be c-equivalent by way of the integer j, and let q(a) =
b. Then r(a + j) = b + j. Now let gj(i) = i + j modulo n (that is,
n + t is identiﬁed with t for positive t). Then gj is a permutation
(a “cyclic translation”) on [n]. Furthermore, r(a + j) = b + j just
means that r(gj(a)) = gj(q(a)). So we have that gj · r = q · gj as
permutations, or r = g−1
j
· q · gj. This fact is referred to by saying
that r and q are conjugates by way of a cyclic translate gj.
(b) The n cyclic translates gj form a group G that acts on the set of
all n-permutations by the conjugate relation. That is, the action
of gj on q sends q to r = g−1
j
· q · gj. The size of this group is n,
and so, by Lemma 18.16, the sizes of the orbits of its action, that
is, the sizes of c-equivalence classes, are divisors of n. If n is a
prime, that means that the orbit sizes are 1 or n.
It is easy to characterize the c-equivalence classes of size 1. The
reader is invited to verify that these correspond to powers of the
n-cycle (12 · · · n).
In particular, if a permutation p is not the
identity, and not an n-cycle, then the size of its equivalence class
is n. The number of such permutations is n! −[(n −1)! + 1], so
this number is divisible by n, but then so is (n −1)! + 1.
(11) By Corollary 18.21, the average number of ﬁxed points of the action
of a ﬁnite group G on the ﬁnite set S is the number of orbits of that
action.
The automorphism group of each regular polyhedron acts
transitively on the vertex set of that polyhedron, which means that it
has only one orbit. So E(X) = 1.
(12)(a) This is true for the one-vertex tree, then it follows by induction,
since each non-plane 2-tree consists of a left subtree, a right subtree,
and a root.
(b) Let T be a tree counted by dn. Remove all n + 1 leaves of T . This
leaves us with a tree f(T ) counted by bn. We are going to show
that f is a bijection by showing that it has an inverse. Let U be
a tree counted by bn. Let us add two leaves to be the children of
each leaf of U, and one extra child to each vertex of U that has one
child. Let g(U) be the obtained non-plane 2-tree with n non-leaf
vertices. Then g and f are inverses of each other.
(13) Even permutations of length n form a group (called the alternating
group and denoted by An). It is straightforward to see that An is
transitive over the set [n] if n ≥3. So by Corollary 18.21, the average

Are They Really Diﬀerent? Counting Unlabeled Structures
519
number of ﬁxed points is 1 if n ≥3. By trivial considerations, it is 1
if n = 1, and 2 if n = 2.
(14) By Theorem 8.21, N 2(x) is the generating function counting two-
element sequences binary non-plane trees (on a combined vertex set
[n −1]) obtained by cutting of the root of such a tree on vertex set
[n]. If, instead of sequences, we count 2-element sets of such trees,
this generating function turns into (N 2(x)+ 1)/2. (The reader should
explain why the addition of 1 is needed.)
On the other hand, the
number of such 2-element sets of trees on [n−1] is equal to the number
of such trees on [n], that is, Nn, so their generating function is also
equal to 
n≥1 Nn xn−1
(n−1)! = N ′(x).
(15) For a quick answer, note that N(x) = tan x + sec x does solve the
initial value problem 2N ′(x) = N 2(x) + 1, with N(0) = 1. It is well-
known in the theory of diﬀerential equations that the solution of a
(correctly stated) initial value problem is unique, so N(x) must equal
tan x + sec x.
The answer that we have just given did not deduce the solution of the
diﬀerential equation at hand; it only veriﬁed it. If we were not told
the solution in advance, we could have deduced it as follows. Taking
reciprocals, our equation leads to the separable diﬀerential equation
1
N(x)2 + 1 = 1
2 · dx
dN .
Solving this separable equation as such, with the initial condition
N(0) = 1, we get the solution
N(x) = tan
	x
2 + π
4

= 1 + tan(x/2)
1 −tan(x/2).
Multiplying both the numerator and the denominator by 1+tan(x/2),
and then regrouping in the numerator, we get
N(x) =
2 tan(x/2)
1 −tan2(x/2) + 1 + tan2(x/2)
1 −tan2(x/2) = tan x + sec x.
(16)(a) If n is odd, then these are precisely the permutations whose de-
creasing binary tree has the property that every non-leaf vertex
has exactly two children.
If n is even, then the right-most ver-
tex has one (left) child, other non-leaf vertices have two children.
These claims are easy to prove by induction on n.
(b) We show that the sequences En and Nn satisfy the same recurrence
relation, namely 2Nn+1 = n
i=0
n
i

EiEn−i for n ≥0, with N(0) =

520
A Walk Through Combinatorics
1. For the sequence Nn, this is equivalent to the result of Exercise
14. For the sequence En, we proceed as follows. It is clear that
En is also the number of permutations of length n with descent set
{1, 3, · · ·}. So the number of permutations of length n + 1 with
descent set {1, 3, · · ·} plus the number of permutations of length
n + 1 with descent set {2, 4, · · ·} is 2En+1. On the other hand,
we get such a permutation by placing the entry n + 1 into the
(i + 1)st position, selecting the i entries that will be on the left of
that position, then placing one of the En−i permutations of length
n −i with descent set {2, 4, · · ·} on the right of n + 1, and placing
the reverse of one of the Ei permutations of length i with descent
set {2, 4, · · ·} on the left of n + 1.
(17) The ﬁrst such proof was found by R. Donaghey [21].
(18)(a) By the Product Formula of Exponential Generating Functions
(Theorem 8.21), we know that Dk(x) is the generating function
of the sequence counting ordered lists of k such trees so that the
vertex set of their union is [n]. Therefore, Dk(x)/k! is the gen-
erating function for the sequence counting k-element sets of such
trees.
On the other hand, by cutting oﬀthe root n of a decreasing non-
plane tree in which the root has k children, we get a set of k de-
creasing binary trees so that the union of their vertex sets is [n−1].
This shows that the coeﬃcient of xn/n! in Dk(x)/k! agrees with
the coeﬃcient of xn+1/(n + 1)! in Dk(x), proving our claim.
(b) Summing the result of part (a) over all k, we get D′(x) = eD(x), or,
equivalently, D′(x)e−D(x) = 1. Integrating both sides, we obtain
−e−D(x) = x −1, since the constant of integration must be chosen
to −1 to conform with the fact D(x) = 0. So e−D(x) = 1−x, hence
D(x) = ln

1
1 −x

=

n≥1
xn
n! .
So dn = (n −1)!.
(19) Let p = p1p2 · · · pn−1 be a permutation. Deﬁne the decreasing non-
plane tree Dp by making pi the parent of pj if, when walking from
pj to the right, pi is the ﬁrst entry we meet that satisﬁes pi > pj. If
there is no such pi, then let n be the root of pj. It is straightforward
to verify that the map p →Dp is a bijection.
(20) As the root has either one or two children, the Product formula (The-

Are They Really Diﬀerent? Counting Unlabeled Structures
521
orem 8.5) implies that G(x) = 1 + xG(x) + xG2(x). This leads to
G(x) = 1 −x −
√
1 −2x −3x2
2x
.
Note that these numbers are the Motzkin numbers that we have seen in
Exercise 17 of Chapter 8. The indexing is shifted by 1, so gn = Mn−1.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 19
The Sooner The Better.
Combinatorial Algorithms
19.1
In Lieu of Deﬁnitions
In all preceding parts of this book, when we considered a problem, we were
interested in enumerating certain structures, ﬁnding the number of ways in
which a certain task could be carried out, or deciding whether a structure
with a certain set of properties can exist.
In this chapter, we will consider combinatorial problems from a new
aspect. Instead of ﬁnding the number of ways in which we can carry out a
task, we will be asking how fast we can carry out that task.
For our purposes, an algorithm is a ﬁnite sequence of unambiguously
deﬁned steps that carries out a task. We will not attempt to deﬁne an
algorithm better than that sentence as that would be a topic for a logic
course. Let us nevertheless point out that one could question what “unam-
biguously deﬁned” means. Consider for instance the following deﬁnition.
“Let N be the smallest positive integer that cannot be deﬁned using the
English language and writing less than one thousand letters.”
Now is N deﬁned or not? The above sentence took less than one thou-
sand letters to write, so it would seem that after all, it does deﬁne N within
the allowed limits. However, N, by deﬁnition, cannot be deﬁned with those
limits.
The above paradox, which is sometimes called the typewriter paradox,
is caused by the fact that the meaning of the word “deﬁned” is not precise.
As we said, we will not attempt to resolve that problem in this class, we
will simply work with algorithms in which each step will be deﬁned with
no room left for ambiguity.
The above “pseudo-deﬁnition” of an algorithm nevertheless made it
523

524
A Walk Through Combinatorics
clear that an algorithm must consist of a ﬁnite number of steps.
So if
a procedure ever gets into an inﬁnite loop, then that procedure is not an
algorithm.
Example 19.1. The following procedure is not an algorithm as it contains
an inﬁnite loop.
# start with a_1=1
# for i larger than 0 do
# a_{n+1} = -a_n
The data that the algorithm is given at the beginning is called the input
of the algorithm, and the data that the algorithm returns is called the
output.
19.1.1
The Halting Problem
In order to further illustrate the diﬃculties of properly deﬁning an algo-
rithm, consider the following. Let us assume that we formally deﬁned what
an algorithm is. Then if somebody gives us a text T , we can surely decide
whether T is an algorithm or not, can we not? Even more strongly, we can
surely ﬁnd a generic way, that is, an algorithm that decides whether T is
an algorithm or not, can we not? In particular, we can surely decide that
if we give a speciﬁc input t to T , then T will eventually halt (meaning that
T behaves as an algorithm) or go into an inﬁnite loop, can we not?
It turns out that no, we cannot. Let us assume that we can, that is,
that there exists an algorithm Halt(T, t) so that
Halt(T, t) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
“Yes” if T halts when given t as input,
“No” if T goes into an inﬁnite loop when given t as input.
What we do next will sound familiar to readers who took a course on Set
Theory. We will present a proof by the so-called diagonalization method.
Write a program Diagonal so that
Diagonal(s) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
returns “Yes” and halts if Halt(s, s) is “No”,
goes into an inﬁnite loop if Halt(s, s) is “Yes”.

The Sooner The Better. Combinatorial Algorithms
525
Now we are making one more step of this strange, self-referring kind.
We feed Diagonal to itself as input. Will Diagonal(Diagonal) stop or not?
Let us consider both possible answers.
(1) Let us assume ﬁrst that Diagonal(Diagonal) halts. By the deﬁni-
tion of Diagonal, that means that Halt(Diagonal, Diagonal) is “No”.
However, by the deﬁnition of Halt, that means that Diagonal does
not halt on itself. This is a contradiction.
(2) Let us now assume that Diagonal(Diagonal) goes into an in-
ﬁnite loop.
By the deﬁnition of Diagonal, that means that
Halt(Diagonal, Diagonal) is “Yes”.
However, by the deﬁnition of
Halt, that means that Diagonal does halt on itself. This, again, is a
contradiction.
So our original assumption that Halt exists led to a contradiction, there-
fore Halt does not exist.
It is important to point out that all we proved is that there is no algo-
rithm that would decide whether any given text T is an algorithm, that is,
whether T will halt on an arbitrary input t. For a speciﬁc text T , we can
very often decide whether T halts on t or not.
Quick Check
The goal of the following three questions is to provide an opportunity for
the reader to practice the diagonalization method that we used to show
that Halt does not exist.
(1) Let us call a set T honest if it does not contain itself as an element.
Let S be the set of all honest sets. Is S an honest set? What causes
the paradox encountered when answering this question?
(2) Let S be the set of all positive integers that can be deﬁned in English
using at most three hundred letters and no symbols other than letters.
Let n be the smallest positive integer that is not in S. Is n well-deﬁned?
What causes the paradox encountered when answering this question?
(3) Let S be any inﬁnite set, and let P(S) be the set of all subsets of S.
Prove that no bijection f : S →P(S) exists.

526
A Walk Through Combinatorics
19.2
Sorting Algorithms
One of the classes of algorithms used most often in real life are sorting
algorithms. These arrange certain objects in a line according to a speciﬁed
property of the objects. In our examples, we will most often sort sets of
real numbers. In order to simplify the discussion, we will assume that all
the real numbers to be sorted are all distinct, but if we allowed multisets of
real numbers, the algorithms would still work, with minor modiﬁcations.
19.2.1
BubbleSort
There are n children standing in a line, and they are of all diﬀerent heights.
We would like to rearrange the line so that the children are in increasing
order of their height. What is the best way to achieve that goal?
The question at the end of the last paragraph is very imprecise. What
makes it imprecise is the word best, that is, we have not said what we mean
by the best way. We will revisit this problem in the next chapter, when we
will formalize our ways of describing the eﬃciency of various algorithms.
However, for now, let us say that we measure eﬃciency by the number
of pairwise comparisons an algorithm makes.
That is, the less pairwise
comparisons an algorithm makes, the better it is. So the best algorithm is
the one that makes the smallest number of comparisons.
One idea that naturally comes to mind is the following.
Let
a1, a2, · · · , an denote the heights of the n children, with ai being the height
of the child who is currently in the ith place of the line. Let us compare a1
and a2. If a1 < a2, then the relative order of the ﬁrst two children is the
desired one, and we do nothing. If a1 > a2, then the relative order of the
ﬁrst two children is not the desired one, and we ask them to change places.
Note that in either case, we have made one comparison so far.
After making sure that the relative order of the ﬁrst two children in
the original line was the desired one, we compare the heights of the two
children who are currently in the second and the third position of the line.
If it is the desired one, that is, the second child is shorter than the third,
then we do nothing, otherwise we ask them to change places.
We then continue the same way, that is, we compare the third and the
fourth children of the current line, and if they are in the wrong order, we ask
them to change places, then we compare the fourth and the ﬁfth children,
and if they are in the wrong order, we ask them to change places, and so
on. The ﬁrst part of the algorithm will end after we compared the two

The Sooner The Better. Combinatorial Algorithms
527
last children of the then-current line, and made sure they were in the right
order. After that is done, we can be sure that the tallest child is indeed in
the last place of the line. Indeed, no matter where he was in the line, once
our swapping procedure reached him, he moved back on place in each step,
until he reached the end of the line.
Example 19.2. If n = 5, and originally, the children’s line corresponded to
4, 1, 5, 2, 3, then this ﬁrst round of comparisons will take place as follows.
(1) Start with 4, 1, 5, 2, 3.
(2) As 4 > 1, interchange these two children, to get 1, 4, 5, 2, 3.
(3) As 4 < 5, do nothing.
(4) As 5 > 2, interchange these two children, to get 1, 4, 2, 5, 3.
(5) As 5 > 3, interchange these two children, to get 1, 4, 2, 3, 5.
(6) End of ﬁrst round.
Unfortunately, the tallest child is the only one who is surely in his right
place after this part of our algorithm. Indeed, it could even happen that
the second-tallest child is in the ﬁrst place! The reader is invited to check
that this could happen if a1 is the largest of all ai, and a2 is the second
largest, or if a2 is the largest and a1 is the second largest. The reader is
also invited to check that for any positions i and i + 1, with i ≤n −2, we
cannot know for sure that the child in position i is shorter than the child
in position i + 1.
Therefore, we will now repeat almost all the steps of the ﬁrst part of
the algorithm. That is, we compare the ﬁrst two children of the current
line, and if they are in the wrong order, we ask them to change places, then
we compare the second and the third children of the then-current line, and
proceed in an analogous way, and so on. The last pairwise comparison we
will make in this round is comparing the (n −2)nd and (n −1)st children
of the then-current line. Indeed, there is no need to compare the n −1st
and nth children of the line, since we already know that the latter is the
tallest of all n children.
After this second round of comparisons, we can be sure that the second-
tallest child is at her right place (since she was taller than anybody who
got compared to anyone in this round). Again, nothing more is assured.
Therefore, we need to run another round of comparisons on the ﬁrst n −2
children of the current line again.
That will make sure that the third-
tallest child gets in his right place, and so on. When we run the ith round
of comparisons, the ith-tallest child will get in his right place. Therefore,

528
A Walk Through Combinatorics
when we run the n −1st run, of comparisons, the (n −1)st-tallest (or
second-shortest) child gets in his right place. At that point, our task is
done since the remaining child is automatically in his right place, namely
the ﬁrst place.
Example 19.3. Continuing the process started in Example 19.2, we would
proceed as follows.
(1) Our starting point for the second round would be the line 1, 4, 2, 3, 5.
(2) As 1 < 4, we would do nothing.
(3) As 4 > 2, we would interchange these two children, to get 1, 2, 4, 3, 5.
(4) As 4 > 3, we would interchange these two children, to get 1, 2, 3, 4, 5.
(5) This would end the second round of comparisons. In this particular
case, no further comparisons would result in any changes, since we
have reached the increasing order.
How many comparisons will we have to make while rearranging the line
of n children? The ﬁrst round will take n−1 comparisons, the second round
will take n −2, comparisons, and so on, with the ith round taking n −i
comparisons. Therefore, the total number of comparisons that we will have
to make is n−1
i=1 (n −i) = n−1
i=1 i =
n
2

. Another way of seeing this is by
considering that every pair of elements gets compared exactly once.
As we mentioned before, the procedure of arranging n objects in a line
in a previously speciﬁed order is called sorting. The sorting algorithm we
presented above that used subsequent comparisons of adjacent elements is
called Bubble Sort. (If we imagine that the objects are arranged vertically,
then the largest, second-largest, third-largest elements, will rise to their
correct positions as bubbles in water.)
In a generic programming language often called pseudo-code, the Bubble
Sort algorithm can be described as follows.
#
for i := 1 to n - 1
#
do for j := 1 to n - i
#
do if a_j > a_{j+1}
#
then t :=
a_j
#
a_j := a_{j+1}
#
a_{j + 1} := t
Here the variable i tells in which round of comparisons we are, and the
variable j tells which comparison of that round we are currently carrying
out. The temporary variable t is needed so that while we declare the new

The Sooner The Better. Combinatorial Algorithms
529
aj to be equal to the old aj+1, we do not lose the value of the old aj before
we assign it as the new value of aj+1.
A “generic programming language”, or pseudo-code is a loosely deﬁned
concept. It describes algorithms in a way programming languages do, but
without the formal constraints. It helps to get a quick overview of what
the algorithm does.
19.2.2
MergeSort
We have seen in the previous section that BubbleSort can sort an array of
n real numbers in
n
2

steps, even in the worst case. It is natural to ask
whether we can ﬁnd a better algorithm, that is, an algorithm that uses
less pairwise comparisons, even in the worst case. Every element needs
to get compared to another element at least once throughout any sorting
procedure, otherwise we will have no information about the size of that
element.
So we cannot expect to ﬁnd an algorithm that uses less than
n/2 comparisons. This leaves a rather big gap between the two bounds we
currently have, that is, the (trivial) lower bound n/2 and the proved upper
bound
n
2

.
It turns out that the truth is much closer to the lower end.
There
exist several sorting algorithms that can sort n elements in no more than
cn log2 n steps, for some positive constant c.
One of these algorithms is called MergeSort. This is because this algo-
rithm will ﬁrst split the list of n objects in two parts which are as equal in
size as possible, then sort both parts, and then merge the two sorted lists
together. OK, you could say, but how will this algorithm sort those two
partial lists? The answer to this is the most self-contained answer possible.
MergeSort will sort those two lists by Mergesort again, that is, by splitting
each of them into two sublists, sorting each of them by MergeSort, and
then merging each pair of ordered lists into an ordered list. In other words,
MergeSort is a recursive algorithm that calls unto itself in each step.
There is one more detail that we must discuss. How do we merge two
sorted lists, say a1 < a2 < · · · < am and b1 < b2 < · · · < bk? We can
do this eﬃciently as follows. Compare a1 to b1. If a1 < b1, then a1 is the
smallest of all m + k elements at hand, and we can put it to the front of
the merged list. Then we can continue with the lists a2 < a3 < · · · < am
and b1 < b2 < · · · < bk and repeatedly use the merging procedure we are
describing. If a1 > b1, then b1 is is the smallest of all m + k elements
at hand, and we can put it to the front of the merged list. Then we can

530
A Walk Through Combinatorics
continue with the lists a1 < a2 < · · · < am and < b2 < · · · < bk, and use
the same procedure again.
Example 19.4. The following shows MergeSort at work on the list 3, 1, 4,
2.
(1) Start with the list 3, 1, 4, 2.
(2) Split the list into the partial lists 3, 1 and 4, 2.
(3) Sort the partial lists, to get the sorted partial lists 1, 3 and 2, 4.
(4) Merge the partial lists 1,3 and 2, 4 to get 1, 2, 3, 4.
(5) End.
In the above example, the procedure worked in a very “symmetric” way
since the number of elements to sort, four, was a power of two. This does
not have to be the case for MergeSort to work.
Example 19.5. The following shows MergeSort at work on the list 4, 2, 1,
5, 6, 3.
(1) Start with the list 4, 2, 1, 5, 6, 3.
(2) Split the list into the partial lists 4, 2, 1 and 5, 6, 3.
(3) Sort the partial lists as follows.
(a) Split them into the partial lists 4, 2, and 1; and 5, 6, and 3.
(b) Sort the partial lists, to get the sorted lists, 2, 4, and 1; and 5, 6,
and 3.
(c) Merge the partial lists 2, 4, and 1; and 5, 6, and 3, to get the sorted
lists 1, 2, 4 and 3, 6, 5.
(4) Merge the sorted partial lists 1, 2, 4 and 3, 6, 5 to get the sorted list 1,
2, 3, 4, 5, 6.
(5) End.
In pseudo-code, MergeSort can be implemented as follows.
# MergeSort(i=1..n)
# if 1<n do
# m=[(1+n)/2];
# Mergesort(1,m);
# Mergesort(m+1,n);
# merge(1,m,n)
# end

The Sooner The Better. Combinatorial Algorithms
531
Here merge(1, m, n) is the subalgorithm that merges two sorted partial
lists. It can be implemented for instance by copying the two ordered partial
lists into a temporary list (so that the original lists are not overwritten),
and then by moving the smallest elements still in the two lists into the new,
sorted list. In pseudo-code, this can be done as follows.
# merge(1,
m,
n)
# for i=1..n do
#
b_i=a_i;
#
i=1; j=m+1; k=lo;
#
while (i<=m && j<=n)
#
if (b_i<b_j)
#
a_{k+1}=b_{i+1};
#
else
#
a_{k+1}=b_{j+1};
# end
How many comparisons will MergeSort make when it sorts an n-element
list? Let M(n) denote this number. Then M(1) = 0 and M(2) = 1. For
the general case, we claim that if n = 2k, then
M(2k) = 2M(k) + 2k −1,
(19.1)
and when n = 2k + 1, then
M(2k + 1) = M(k) + M(k + 1) + 2k.
(19.2)
Both of these formulae are easy to explain. Indeed, the ﬁrst two terms
of the right-hand side are the number of comparisons needed to sort the
two partial lists, and the last term is the number of comparisons needed
to merge the two sorted partial lists. Indeed, after each comparison, we
are able to place one element to its right place in the merged list, so n −1
comparisons will place the ﬁrst n −1 elements in their right place, which
then will force the last element into its right place.
Note that (19.1) and (19.2) can be comprised in the formula
M(n) = M(⌊n/2⌋) + M(⌈n/2⌉) + n −1.
(19.3)
These cumbersome divisibility issues suggest that we ﬁrst try to ﬁnd an
exact formula for M(n) in the special case when n = 2t. In that case, set
mt = M(2t). Then (19.3) translates to
mt = 2mt−1 + 2t −1
(19.4)

532
A Walk Through Combinatorics
for t ≥1, and m0 = 0. Let m(x) = 
t≥0 mtxt be the ordinary generating
function of the sequence mt. Multiplying both sides of (19.4) by xt and
summing over t ≥1, we get
m(x) = 2xm(x) +
2x
1 −2x −
x
1 −x.
This implies
m(x) =
2x
(1 −2x)2 −
x
(1 −x)(1 −2x) =
x
(1 −x)(1 −2x)2
=
1
(1 −2x)2 +
1
1 −x −
2
1 −2x.
Therefore, mt = (t −1)2t + 1. This means that if n = 2t, then
M(n) = M(2t) = n(log2 n −1) + 1.
If n is not a power of 2, then we can add new objects to the list which
are larger than all existing objects until n does become the closest power
of 2 that is not smaller than n, that is, n1 = 2⌈log2⌉. We can then sort
the new list in n1(log2 n1 −1) + 1 steps as above. The obtained sorted list
will contain the original n elements in the right order, at the beginning of
the list. Finally, note that n1 < 2n, and log2 n1 < log2 n + 1, therefore, in
terms of n, the sorting algorithm will never take more than 1 + 2n log2 n
comparisons.
At this point, we would like to stress that MergeSort is a very signiﬁcant
improvement compared to BubbleSort. Indeed, the ratio of the numbers of
steps in the two algorithms is not more than
gn = 1 + 2n log2 n
n
2

=
1
n
2
 + 4log2 n
n −1 .
Therefore limn→∞gn = 0, so for large n, the number of comparisons Merge-
Sort needs is negligible when compared to the number of comparisons that
BubbleSort needs.
19.2.3
Comparing the Growth of Functions
In the rest of this chapter, we will deﬁne ways to describe good estimates
of the number of steps an algorithm makes. As the example of MergeSort
shows, these estimates can often be obtained much faster than a precise
formula, and will still provide a good measurement of the eﬃciency of the
algorithm. In order to facilitate discussion of these estimates, we make the
following three deﬁnitions, which are all very widely used in approximation
theory.

The Sooner The Better. Combinatorial Algorithms
533
Deﬁnition 19.6. Let f : Z+ →R be a function, and let g : Z+ →R be
another function. We say that f(n) = O(g(n)) (read “f is big O of g”) if
there exists a positive constant c so that
f(n) ≤cg(n)
for all n ∈Z+.
In other words, f(n) = O(g(n)) means that f(n) is at most a constant
factor larger than g(n), for all n. In other words, g(n) approximates f(n)
up to a constant factor.
Example 19.7. Let M(n) be deﬁned as above. Then M(n) = O(n log2 n).
Solution. We have seen that M(n) ≤1 + 2n log2 n for all n. Furthermore,
M(1) = 0, and 1 ≤n log2 n if n ≥2. Therefore, M(n) ≤3n log2 n.
Example 19.8. Let f(n) = 100
n
2

+
n
3

. Then f(n) = O(n3).
Solution. Use c = 51.
Example 19.9. Let f(n) =
n
2

and let g(n) = 1000n.
Then f(n) ̸=
O(g(n)).
Solution. No matter what c we choose, f(n) > cg(n) will hold when n >
2000c + 1.
Let us return for a minute to the function M(n) that counted the number
of comparisons MergeSort needed to make in order to sort an n-element
list. Then the statement that M(n) = O(n2) is certainly correct since n2
grows much faster than 2n log2 n + 1. However, this statement is not very
informative since it is not very sharp. It simply says that M(n) is smaller
than another function, but it does not say how much smaller. There are
other notions that can make this statement more precise.
Deﬁnition 19.10. Let f : Z+ →R and g : Z+ →R be two functions. We
say that f(n) = Ω(g(n)) (read “f is omega of g”) if there exists a positive
constant c so that
f(n) ≥cg(n)
for all n ∈Z+.
Example 19.11. Let f(n) = 0.001n and let g(n) = 100 log2 n.
Then
f(n) = Ω(g(n)).

534
A Walk Through Combinatorics
Solution. Choose c = 10−5.
Finally, our last notation brings the previous two together.
Deﬁnition 19.12. Let f : Z+ →R and g : Z+ →R be two functions.
We say that f(n) = Θ(g(n)) (read “f is theta of g”) if f(n) = O(g(n)) and
f(n) = Ω(g(n)).
Example 19.13. Let f(n) = n2 + n log3(n). Let g(n) = n2. Then f(n) =
Θ(g(n)).
Solution. On the one hand, f(n) = O(g(n)) as can be seen by choosing
c = 2. On the other hand, f(n) = Ω(g(n)) as can be seen by choosing
c = 1.
Quick Check
(1) Is it true that if f(n) = O(g(n)), then g(n) = Ω(f(n))?
(2) Prove that the stack sorting algorithm (repeated a suﬃcient number of
times) will sort every permutation of length n in O

n2
steps, where
one step is the movement of an entry in or out the stack. The stack
sorting algorithm was discussed in Section 14.2.
(3) Prove that if q is permutation pattern of length k, then O

nk
compar-
isons are suﬃcient to decide whether a given permutation p of length
n contains q as a pattern or not.
19.3
Algorithms on Graphs
19.3.1
Minimum-cost Spanning Trees, Revisited
We saw an algorithm on graphs in Chapter 10.
That algorithm, called
Kruskal’s algorithm, took a connected simple graph whose edges were as-
signed a cost (or weight) as the input and returned a minimum-cost span-
ning tree of G as an output. In Chapter 10, we were concerned about the
greedy property of the algorithm, that is, the fact that in each step, the
algorithm took the edge that increased the short-term costs the least. In
each step, the algorithm chose an edge that did not create a cycle and had
the minimum cost of all edges with that property.
Now we will consider that algorithm from a diﬀerent aspect. Our goal
is to decide how many steps the algorithm takes. Foretelling the need for

The Sooner The Better. Combinatorial Algorithms
535
a uniﬁed approach that we will introduce in the next section, we point out
that what a step is needs a little bit of explanation. In the sorting algo-
rithms of the previous section, we simply counted comparisons. However,
in Kruskal’s algorithm, it is not so clear what we should count. Indeed,
choosing an edge from a graph is easy, but choosing an edge that does not
create a cycle is more diﬃcult (in a very large graph), because we need to
make sure that indeed, no cycle is created, and that in itself can take a long
time if we do not have an eﬃcient method to do it.
Let us discuss an eﬃcient way of running the Kruskal algorithm. As
we said, each round of that algorithm will look for the lowest-cost edge
that can be added to the set S of edges already selected without creating
a cycle.
This means that if there are several edges that can be added
without creating a cycle, then we have to look for the one with minimum
cost.
Finding a minimum-cost edge in each round, and then forgetting
the results of all comparisons made in the process seems wasteful. It is
therefore sensible to sort all edges of G at the beginning of the algorithm.
As we have seen in the previous section, this can be done in O(E log2 E)
steps, where E is the number of edges of G. Let edges = {e1, e2, · · · , eE}
be the obtained list of all edges of G in non-decreasing order of their costs.
Now in the ﬁrst round of Kruskal’s algorithm, we choose the edge e1,
and in the second round, we choose e2. As G is simple, e1 and e2 never form
a cycle. The third round is more complicated as e1, e2, and e3 could form
a cycle. If that happens, e3 is rejected, and e4 is selected. However, as we
proceed further, we need an eﬃcient approach to decide whether the next
edge of edges is eligible to be chosen or not, that is, whether its addition
would create a cycle or not.
It would take very long to consider every
possible subset of edges containing the newly chosen edge and verify that
they do not contain a cycle. Instead, we propose the following. From the
beginning of the algorithm, let us keep track of the connected components
of the graph T of selected edges.
That is, when we choose e1, let us put the two endpoints of e1 into a
new set C1, indicating that they are in the same component of T . After
selecting e2, put its endpoints in C1 if the two-edge graph with edges e1
and e2 is connected, and put them into a new set C2 if that graph is not
connected.
Continue this way. That is, in round i, scan the still unused edges of
edges until you ﬁnd the ﬁrst edge whose endpoints are not in the same
component Ci. (It could be that they are in diﬀerent components, or it
could be that one or both of them are not in any components yet.) Add

536
A Walk Through Combinatorics
that edge eh to T . Discard the edges preceding eh from edges. If they could
not be added to T before without forming a cycle, they cannot be added
to T now without forming a cycle.
Then update the list of components. That is, if neither endpoint of eh
was included in any Ci before, create a new component with the endpoints
of ei. If one of them was in Cj, and the other one was in no component,
add that other one to Cj. Finally, if one endpoint of eh was in Ci and
the other one in Cj, then unite Ci and Cj, and add both ei and ej to the
obtained component. Rename that component so that it inherits the label
of the larger of its predecessors, that is, the component which had more
vertices in it.
This assures that the graph T remains cycle-free since we never join two
of its vertices in the same component by an edge.
Before counting the steps in this second part of the procedure, let us
consider an example.
Example 19.14. The above implementation of Kruskal’s algorithm ap-
plied to the graph of Figure 19.1 runs as follows.
1
2
2
5
1
4
2
8
6
3
3
G
F
C
E
D
H
B
e
2
4
A
5
e12
9
e
e
e
e
e
e
e
e
e
e
1
3
6
 7
 8
9
10
11
Fig. 19.1
The graph G with its cost function and sorted edges.
(1) Start with the graph shown in Figure 19.1 (with the costs assigned to
the edges, but not yet the labels ei).
(2) Sort the edges according to their cost.
Obtain the list edges =
{e1, e2, · · · , e11}.
(3) Select e1. Create the component C1 = {A, B}.
(4) Select e2. Create the component C2 = {G, H}.
(5) Select e3. Add E to C1, to get C1 = {A, B, E}.

The Sooner The Better. Combinatorial Algorithms
537
(6) Select e4. Unite C1 and C2 to get C1 = {A, B, E, G, H}.
(7) Select e6. (Note that e5 is ineligible since its endpoints both belong to
C1.) Add F to C1 to get C1 = {A, B, E, F, G, H}.
(8) Select e8. Note that e7 is ineligible since its endpoints both belong to
C1. Add D to C1 to get C1 = {A, B, D, E, F, G, H}. Select e12, since
e9, e10, and e11 are ineligible as their endpoints both belong to C1.
(9) End with the tree whose edges are e1, e2, e3, e4, e6, e8 and e12.
Returning to the question of how many steps the Kruskal algorithm
takes, let us say that for this algorithm, a step is whenever we do some-
thing, that is, put a vertex in a component, unite two components, or check
whether two vertices are in the same component. Note that in each round,
we have to scan at most E edges before ﬁnding the minimal-cost edge that
is eligible. After ﬁnding this edge e, there are two possibilities. If e will not
unite two existing components, but create a new component of two vertices,
or add one vertex to an existing component, then we can record that in a
constant number of steps. Indeed, we spend at most two steps adding a
vertex to one or two components. If e unites two components, say Ci and
Cj, then we change the label of the vertices in the smaller component to
the label of the other component. This may take as many as n/2 steps.
However, if x is a vertex whose label changed this way, then the component
containing x at least doubled in size. This cannot happen more than log2 n
times for any x. So each x will change labels no more than log2 n times,
therefore the number of all changes of labels is not more than n log2 n.
To summarize, it takes O(E log2 E) steps to sort the edges according to
their costs, then it takes O(E + n log2 n) steps to ﬁnd the minimum-cost
tree. Therefore, the total number of steps needed is O(E log2 E) since our
graph is connected, so E ≥n −1.
19.3.2
Finding the Shortest Path
The next problem we consider is one that everyone with a driver’s license
has faced before. Given a starting point s, an endpoint t, and a network of
one-way streets, ﬁnd the shortest path from s to t.
We will present an algorithm that will ﬁnd not simply the shortest path
to t, but the shortest path to any point on the map. The algorithm is called
the Dijkstra algorithm, after its inventor, the Dutch mathematician Edsger
W. Dijkstra.
Our input is a directed simple graph G.
The edges of G all have a

538
A Walk Through Combinatorics
positive cost; the cost of ei will be denoted by d(ei). One can think of d(ei)
as the “length” of ei.
While looking for the shortest path from s to any given vertex t, we will
associate a number δ(vi) to each vertex vi. This number can be thought of
as the “length of the shortest discovered path” from s to vi. Originally, we
set δ(s) = 0 and δ(t) = ∞for all t ̸= s, since we have not yet discovered
any paths from s to t.
In what follows, we split the vertex set V (G) of G into two parts, the
set S vertices to which we already have a path from s, and the set T of
vertices to which we do not yet have a path. So at the beginning, S = {s}
and T = V (G) −s.
For all edges sv, set δ(v) = d(s, v) replacing the original δ(t) = ∞. This
makes perfect sense, since it expresses the fact that if there is an edge from
s to v, then the minimum distance from s to v is the length of that edge.
Now we describe a generic step of the algorithm.
This step will be
applied several times, following the initial step described in the previous
paragraph.
Find a vertex v ∈T for which δ(v) is minimal.
Put v into S, and
proceed with all the edges leaving v and going to a vertex outside S as you
proceeded with the edges leaving s. More precisely, if vr is an edge with
r ∈T , and δ(v)+d(v, r) ≥δ(r), then do nothing. Otherwise replace δ(r) by
δ(v) + d(v, r), corresponding to the fact that we have just found a shorter
path to r, namely the path that consists of a shortest path to v, and the
edge vr. This step is often described by saying that we relax the edge vr.
When this is done, iterate this procedure. That is, ﬁnd the vertex v′ ∈T
for which δ(v′) is minimal, and start over. Stop when all vertices are in S,
and therefore, all edges are relaxed, or when there are no edges going from
S to T (the latter can happen when G is not strongly connected).
Throughout the algorithm, ties can be broken in any way. An example
is shown below.
Example 19.15. For the graph shown in Figure 19.2, Dijkstra’s algorithm
works as follows.
(1) Start with the graph shown, and set S = {s}.
(2) Relax the edges leaving s. Set δ(A) = 4 and δ(B) = 5. Put A in S.
(3) Relax the edges leaving A. Set δ(C) = 8 and δ(F) = 9. Put B in S.
(4) Relax the edges leaving B. Set δ(D) = 10, and δ(F) = 7 (so δ(F) is
being reset). Put F in S.

The Sooner The Better. Combinatorial Algorithms
539
s
t
4
4
4
5
5
5
5
3
9
5
2
6
A
B
C
E
F
G
H
I
2
7
D
Fig. 19.2
We will use the Dijkstra algorithm on this graph.
(5) Relax the edges leaving F. Set δ(G) = 12 and δ(I) = 16. Put C in S.
(6) Relax the only edge leaving C. Set δ(E) = 12. Put D in S.
(7) Relax the only edge leaving D. This happens to have no eﬀect, since
δ(G) = 12. Put G in S.
(8) Relax the only edge leaving G. Set δ(H) = 17. Put H in S.
(9) Relax the only edge leaving H. This has no eﬀect. Put I in S.
(10) End.
Figure 19.3 shows the graph of Figure 19.2 with the values of δ written
next to the vertices in italics, and the weights of the edges written on the
edges in Roman font.
E
C
B
A
6
2
5
9
3
5
5
5
5
4
4
F
0
17
12
12
G
16
10
8
7
5
4
D
7
2
I
H
4
s
Fig. 19.3
The Output of the Dijkstra algorithm.
Several questions are in order. First, how do we read oﬀa shortest path
from s to some t from the output of this algorithm? (We say a shortest
path, not the shortest path, since there could be times when there are
several paths of minimum length.) Second, why is it that the ﬁnal value of

540
A Walk Through Combinatorics
δ(t) is indeed the length of a shortest path from s to t. Third, how many
steps does it take to run this algorithm?
We are going to answer the ﬁrst two questions at once, by one theorem.
Before we can announce the theorem, we need one more notion. Let us say
that for a given vertex t, every time an edge vt is relaxed and the value
of δ(t) decreases, we set prev(t) = v. This expresses the fact that at that
point, there is a shortest path from s to t that ends in the edge vt. Note
that prev(t) is always a vertex that got placed into S before t, and that
when the Dijkstra algorithm is ﬁnished, prev(t) is deﬁned for all t ̸= s.
Therefore, as G is ﬁnite, for all vertices t ̸= s, there exists a positive integer
k so that prevk(t) = s. Here prevk simply means k successive applications
of prev.
Theorem 19.16. For any simple graph G, and for any pair of distinct
vertices s and t, the Dijkstra algorithm will either produce a shortest path
from s to t and compute its length, or show that there is no path from s to
t, as follows.
(a) Once the algorithm is ﬁnished, the path whose edges listed from the
end are (prev(t), t), (prev(prev(t)), prev(t)), and so on, (s, prevk(t))
is a shortest path from s to t. If prev(t) is not deﬁned, then there is
no path from s to t.
(b) Furthermore, the length of any shortest path from s to t is equal to the
value of δ(t) when the algorithm is ﬁnished. If there is no path from
s to t, then this value will be ∞.
Proof. We ﬁrst prove part (b).
In fact, we prove the following, even
stronger statement. We claim that at each stage of the Dijkstra algorithm,
(i) if t ∈S, then δ(t) is the length of a shortest path from s to t, and
(ii) if t /∈S, then δ(t) is the length of a shortest path from s to t whose
last edge is an edge from S to t.
We prove these claims by induction on the size of S. If |S| = 1, that is
S = {s}, then (i) holds since δ(s) = 0. Claim (ii) holds since if (s, t) is an
edge, then δ(t) = d(s, t) is the length of a shortest path from (s, t) with the
desired property, and if (s, t) is not an edge, then δ(t) = ∞.
Now let us assume that the claims hold for the case of |S| = k, and
prove them for the case of |S′| = k + 1. Let S′ = S ∪x, that is, x is the
new vertex added to S in this step of the Dijkstra algorithm. We ﬁrst show

The Sooner The Better. Combinatorial Algorithms
541
that (i) holds for x. Before this step, x was outside S, so by the induction
hypothesis, δ(x) was the length of a shortest (s, x) path q whose last edge
was from S to x. Note that every path p from s to x has to ﬁrst leave S
and then arrive at x. If the ﬁrst vertex of p outside S is some y ̸= x, then
p is not a shortest (s, x) path. See Figure 19.4 for an illustration.
s
S
y
x
q
p
Fig. 19.4
The path p is longer than the path q.
Indeed, the part of p that is between s and y cannot be shorter than
q since if it were, then y, not x, would be selected to be added to S in
this step. (Recall that by the induction hypothesis, we know that δ(x) is
minimal for x /∈S, and that δ(x) is the length of a shortest (s, x) path
ending in an edge from S to x.) We would then have to get from y to x,
which would make p longer than q.
Also note that adding x to S will not change the label of the vertices
that are already in S since, by the deﬁnition of the Dijkstra algorithm,
edges within S are not being relaxed. Therefore, (i) is proved.
In order to prove (ii), let h ∈V (G) −S′. Note that if there is a shortest
(s, h) path ending in an (S′, h) edge that does not end in an (x, h) edge,
then the placement of x into S′ did not change anything, so our claim
holds by the induction hypothesis. If all the shortest (s, h) paths ending in
an (S′, h) edge do end in an (x, h) edge, then the Dijkstra algorithm sets
δ(h) = δ(x) + d(x, h), and our claim is proved since in all such paths, the
path from s to x must be a shortest path from s to x, and so have length
δ(x).
This proves part (b) of the theorem. Part (a) is now not diﬃcult to see.
Indeed, now that we know that the Dijkstra algorithm correctly computes

542
A Walk Through Combinatorics
the minimum distances to all vertices, we see that part (a) simply describes
how we can keep track of the way those minimum distances are actually
achieved. A minimum distance is achieved by a shortest path, and the path
described in part (a) is a path achieving the minimum distance from s to
t, therefore it is a shortest path.
Note that the Dijkstra algorithm takes O

n2
steps. Indeed, in each
stage, we add one vertex to S, so there are at most n stages, and in each of
those stages, we must ﬁnd the vertex v /∈S for which δ(v) is minimal. This
can be done in O(n) steps, (as you are asked to prove in Supplementary
Exercise 15) proving our claim.
The Dijkstra algorithm has several reﬁnements and enhanced versions.
Perhaps the most widely used special case is breadth ﬁrst search. This is
the special case when all edges have weight one, and the task is reduced to
ﬁnding the path from s to t that contains the minimum number of edges.
The name “breadth ﬁrst search” refers to the fact that the algorithm will
ﬁrst reach all the neighbors of s, before going deeper into the graph. This
is in contrast to another approach, depth ﬁrst search, which we deﬁne in
Exercise 8.
Quick Check
In this section, the Quick Check questions all relate to the following algo-
rithm.
A mailman lands his helicopter in a remote village that cannot be ac-
cessed by ground transportation. He does not have a map of the village, and
does not speak the language of the residents. His task is to walk through
each street of the village exactly twice, and end where he started.
Tha mailman adopts the following strategy. He will carry a red chalk
and a blue chalk. He will used these pieces of colored chalk to mark the
beginning and the end of each street he walks through. Markings will never
be changed or erased. The crossings of streets will be called vertices. The
vertex where the mailman currently is will be denoted by v.
Let S denote the starting vertex of the mailman, and at the start of his
walk, set v = S. Then, in any vertex v, the mailman proceeds as follows.
(A) If all streets adjacent to v are marked, then go to step (C).
(B) Choose a street s adjacent to v that is not marked with any color. Mark
the beginning of s red. Walk through s to its other end w.

The Sooner The Better. Combinatorial Algorithms
543
– If w has any streets that were marked at w (that is, if w has been
visited before), then mark the end of s at w red, and walk back on
s to v. Go to Step (A).
– If no streets are marked at w, that is, if this is the ﬁrst visit to w,
then mark the end of s at w blue, set w = v, and go to Step (A).
(C) If all streets adjancent to v are marked red at v, STOP.
(D) If street t is marked blue at v, walk through t to its other endpoint x,
set x = v, and go to Step (A).
(1) In the above description of the mailman’s algorithm, in Step (D), why
did we not specify how to mark the end of t when we arrive at vertex
x through t?
(2) Prove that the mailman will never walk through the same street twice
in the same direction.
(3) Prove that the algorithm always terminates, and when it terminates,
the mailman is back at S.
Note the mailman’s algorithm discussed above is also the subject of
Supplementary Exercise 27.
Notes
A very readable introduction to the topics of this chapter and the next one is
Herb Wilf’s book Algorithms and Complexity [60]. A classic comprehensive
textbook on algorithms is Introduction to Algorithms, by Cormen et al.
[20]. In this book, the reader will ﬁnd several sorting algorithms which are
roughly as eﬀective as MergeSort, as well as a detailed analysis of the two
graph traversal algorithms that we mentioned here, breadth ﬁrst search,
and depth ﬁrst search.
Exercises
(1) Consider the following sorting algorithm.
First, sort n −1 objects
recursively with the algorithm we are deﬁning. Then insert the nth
object an to its correct place as follows.
First, compare an to the
middle element of the sorted list L of n −1 elements. Depending on
the result of that comparison, an needs to be inserted into the ﬁrst or
second half of L. Whichever half it is, insert an into it by the same

544
A Walk Through Combinatorics
procedure. That is, compare an to the element in the middle of that
half of L, and conclude in which quarter of L the correct place of an is.
Let b(n) be the number of steps this sorting algorithm will take in the
worst case. Prove that b(n) = O (n log2 n).
(2) Prove that if A is any sorting algorithm that uses only pairwise com-
parisons, and f(n) is the number of comparisons that A makes in the
worst case when sorting n elements, then f(n) = Ω (n log2 n). Conclude
that the best sorting algorithms based on comparison make Θ(n log2 n)
comparisons.
(3) Let us assume that we have a machine that can do k-wise comparisons
in one step, for a ﬁxed positive integer k. That is, if we give k distinct
real numbers to the machine as input, it will output the sorted list of
those numbers in one step.
Let g(n) be the number of times we have to run this machine in order
to sort n distinct real numbers. Is it true that g(n) = Ω (n log2 n)?
(4) Construct an algorithm that ﬁnds the largest and the second largest
elements of an n-element set of real numbers using at most
3
2n + 2
pairwise comparisons.
(5) Let k be a positive integer.
Construct an algorithm that ﬁnds the
kth largest of an n-element set of real numbers using O(n) pairwise
comparisons.
(6) Construct an algorithm that will list all n! permutations of length n.
Each element of the list should be obtained from the previous one by
at most 2n −1 steps, where reversing a subsequence of entries counts
as one step.
(7) Let G be a directed graph which contains no directed cycles. Prove
that then the vertices of G can be listed in some order v1, v2, · · · , vn so
that if i > j, then there is no directed path from vi to vj.
(8) Let G be a directed graph. The following algorithm, called depth ﬁrst
search obtains all vertices t that are reachable from vertex s of G by a
directed path. First, go from s to a vertex s1 using an edge (s, s1), then
go from s1 to vertex s2 diﬀerent from s and s1 using an edge (s1, s2),
and so on, as long as this is possible. Let us assume that we are forced
to stop after k vertices s, s1, · · · , sk−1, that is, there is no edge leaving
sk−1 that ends in a vertex that we have not reached before. Then we
go back to the predecessor of sk−1, the vertex sk−2, and continue the
algorithm from there the same way. (This is called backtracking.) Each
time we get stuck at some vertex, we backtrack to the predecessor of
that vertex.

The Sooner The Better. Combinatorial Algorithms
545
Now let G be a directed graph with no loops so that each vertex of
G is reachable from vertex s by a directed path. Find a suﬃcient and
necessary condition for G not containing any directed cycles, in terms
of the depth ﬁrst search algorithm, starting at s.
(9) Decide if the following statements are true or false.
(a) If a > 0, then n log n = O

n1+a
.
(b) 2n2 = O(n!).
(c) n! = Θ
 nn
en

.
(10) Consider the following algorithm. Let G be a connected simple graph
whose edges have non-negative costs assigned to them. Start with the
one-vertex subgraph v, for any v ∈G. Build a graph from v as follows.
In each step, if T is the vertex set of the graph that has already been
built, ﬁnd the lowest-cost edge between T and V (G)−T whose addition
will not form a cycle in the graph that is being built. Add that edge
to the graph being built. Stop when T = V (G).
Prove that this algorithm constructs a minimum-cost spanning tree for
G.
(11) Let S be a ﬁnite set of n elements.
Consider the following sorting
algorithm. Pick an element s ∈S at random. Compare the remaining
n −1 elements of S to s, and based on the results, break up S −s into
the sets A and B, where A = {i ∈S|i < s}, and B = {i ∈S|i > s}.
Now S is “partially sorted”, as AsB. Next, use the same procedure
recursively, ﬁrst on A and B, and then on the obtained smaller blocks,
until a completely ordered list is obtained.
(a) Prove that sorting by this algorithm will take no more than
n
2

comparisons.
(b) When will this sorting procedure take exactly
n
2

comparisons?
(12) (+) Keep the deﬁnitions of the preceding exercise. Let X(p) denote the
number of comparisons it takes to sort S using a given set p of picks.
Prove that E(X) = O(n log n).
(13) Let p = p1p2 · · · pn be a permutation. Construct an algorithm that
involves O

n2
comparisons that decides if p avoids the pattern 132 or
not.

546
A Walk Through Combinatorics
Supplementary Exercises
(14) Give a simple proof using graph theory for the fact that there is no
algorithm that sorts n objects with less than n −1 steps.
(15) Find two diﬀerent algorithms to ﬁnd the largest element of an n-
element list of real numbers. Both algorithms should use n −1 com-
parisons.
(16) A group of 64 ping-pong players want to ﬁnd the best and second best
players among themselves. Show that they can achieve this by playing
a total of 68 games, in the following sense. After 68 games, there will
be two players A and B so that all other 62 players lost a game to A
or B, and neither A nor B lost a game to any of the other 62 players.
(17) Let X be a random variable deﬁned on the set of all n-permutations by
setting X(p) to be the number of times that BubbleSort interchanges
two elements while sorting the entries of p. Compute E(X).
(18) The depth ﬁrst search algorithm, deﬁned in Exercise 8 can be applied
to undirected graphs as well. Note that if G is a connected undirected
graph, then the algorithm will in fact ﬁnd a spanning tree T of G that
will be rooted at the vertex s in which the algorithm started.
Let us say that vertex b is a descendent of vertex a in T if the only
path in T connecting b to the root s goes through a.
Prove that if e is an edge of G, then one endpoint of e is a descendent
of the other.
(19) Prove that if a connected graph on n vertices does not contain a path
of length k, then it has at most (k −1)n edges.
(20) Explain how the Dijkstra algorithm can be used to decide whether an
undirected graph G is connected.
(21) Decide whether the following statements are true or false.
(a) sin n = O(1),
(b) sin n = Θ(1),
(c)
	
n
log2 n

n
= O(n!).
(22) The diameter of a graph was deﬁned in Exercise 33 of Chapter 10.
Find an algorithm that computes the diameter of a graph G on n
vertices in O(n3) steps.
(23) Write a pseudo-code for Kruskal’s algorithm.
(24) Write a pseudo-code for the Dijkstra algorithm.
(25) Let M be a list of n positive integers which are not necessarily distinct,
such that no element of M is larger than k. Give an algorithm that

The Sooner The Better. Combinatorial Algorithms
547
lists the n elements of M in non-decreasing order that uses O(n + k)
steps.
(26) Set n = k in the preceding exercise. Then the result of that exercise
is an algorithm that sorts an input of size n in O(n) steps. Explain
why this does not contradict the result of Exercise 2.
(27) Prove that the mailman of the Quick Check questions of Section 19.3
will traverse each street exactly once in each direction.
(28) Construct an algorithm that lists all k-element subsets of [n].
(29) Let p = p1p2 · · · pn be a permutation. Construct an algorithm that
uses O

n2
comparisons and ﬁnds the length of the longest increasing
subsequence of p ending in each pi.
(30) Decreasing binary trees were deﬁned in Example 14.25. Let p be a
permutation, given by its decreasing binary tree T (p). Construct an
algorithm that uses O(n) comparisons to decide whether p is 231-
avoiding.
(31) The Gale-Shapley algorithm was deﬁned in Section 11.3.2 to ﬁnd sta-
ble matchings in bipartite graphs. Estimate the number of steps that
algorithm takes if there are n candidates and n job openings.
Solutions to Exercises
(1) Let us ﬁrst assume that n = 2t. Let us compute how many compar-
isons it takes to ﬁnd the correct place of the nth element a of the list
once the (n −1) other elements are sorted. The reader is invited to
verify that in the ﬁrst step, we compare a to the middle element of
a list of length 2t −1, in the second step, we compare a to the mid-
dle element of a list of length 2t−1 −1, and so on, and in step i, we
compare a to the middle element of a list of length 2t+1−i. Therefore,
in the tth step, we compare a to the “middle” element of a “list” of
length one, after which we know the correct place of a. So the correct
place of a could be found in t = log2 n steps.
If n ̸= 2t, then there exists a positive integer u so that 2u + 1 ≤n ≤
2u+1. In this case, we complete our list by adding extra elements to
its end so that it has 2u+1 elements. We can then ﬁnd the correct
place of a in the new list in u + 1 ≤2 log2 n steps. So it never takes
more than 2 log2 n comparisons to ﬁnd the correct place of the nth
element a. Then, by the same argument, it takes at most 2 log2(n−1)

548
A Walk Through Combinatorics
comparisons to ﬁnd the correct place of the (n−1)st element, at most
2 log2(n −2) comparisons to ﬁnd the correct place of the (n −2)nd
element, and so on. Therefore, the total number of comparisons is at
most

i≤n
2 log2 i ≤2n log2 n.
(2) There are n! possible orders of n distinct elements, and in the worst
case, each pairwise comparison will eliminate at most half of the orders
that were possible before that comparison. So in the worst case, after
one comparison, there will be n!/2 possible orders, after two compar-
isons, at least n!/4 possible orders, after 3 comparisons, at least n!/8
possible orders, and so on. Therefore, if after m comparisons, there
is only one possible order left, then n! ≤2m, or log2 n! ≤m. From
Stirling’s formula,
m ≥log2 n! = n log2(n/e) + log2(
√
2π · n) = Ω (n log2 n)
proving our claim.
On the other hand, we have seen that it is possible to sort n elements
by only O(n log2 n) pairwise comparisons, so indeed, the best sorting
algorithms will take Θ(n log2 n) steps.
(3) Analogous to the solution of the previous exercise. The only diﬀerence
is that now each step has k! possible outcomes, so if there are a possible
orders before a step, then if we are unlucky, then there could be at
least a!/k! possible orders after that step. As k! is just a constant, like
2 in the previous exercise, the rest of the solution unchanged, except
that k! plays the role of 2.
(4) Let us split our set of elements into two blocks of equal size, or as
equal as possible size. In each set, ﬁnd the maximal element, then
compare the two maximal elements. This takes n −1 comparisons.
Say that we ﬁnd that the maximal element a of block A is larger than
the maximal element b of block B. Then a is the maximal element of
our set, and the second maximal element is either B, or the maximal
element of A −a. Find the maximal element of A −a in at most
(n + 1)/2 steps, then compare it to b in one steps. This will provide
the desired output with at most n + n+3
2
comparisons.
(5) Let a1, a2, · · · , an be our elements. First, order the ﬁrst k elements
of the list using MergeSort in O(k log2 k) = O(1) steps. Then ﬁnd
the place of ak+1 in this list in at most k steps, and discard the last
element.
Continue this way.
In each stage, ﬁnd the place of the

The Sooner The Better. Combinatorial Algorithms
549
new element in the k-element list that we keep, and discard the last
(k + 1)st element of that list. Each stage takes at most k steps, so the
whole procedure takes no more than k log2 k+nk = O(n) steps. (Note
that we could ﬁnd the place of the new element in O(log k) steps as
opposed to k steps, but that would not be a signiﬁcant improvement,
since k is a constant.)
(6) We will list the permutations of length n in lexicographic order. That
is, p = p1p2 · · · pn will precede q = q1q2 · · · qn in the order if, for the
smallest index i for which pi ̸= qi, the inequality pi < qi holds.
In order to get the permutation immediately following p = p1p2 · · · pn
in this order, ﬁrst ﬁnd the largest ascent of p, that is, the largest i so
that pi < pi+1. If there is no such i, then p is the decreasing permuta-
tion, which is the last permutation of our the list, and we stop. Oth-
erwise, let p be followed by q, deﬁned by q = p1p2 · · · pi−1qiqi+1 · · · qn,
where qi is the smallest element in {pi+1, pi+2, · · · pn} that is larger
than pi, and the string qi+1 · · · qn contains the remaining entries of
pipi+1 · · · pn in increasing order. The reader is invited to prove that
each permutation occurs exactly once in this list since each permuta-
tion (other than the increasing one) has a unique predecessor.
Note that as i is the largest ascent in p, the subsequence pi+1 · · · pn is
decreasing, and it will remain decreasing after we remove qi from it.
So it can be turned into an increasing sequence by a simple reversal.
Finding pi takes at most n −1 steps, then ﬁnding qi takes at most
n −1 steps, completing the proof.
(7) We use induction on n. For n = 2, the statement is true. Now let us
assume that the statement is true for n, and prove it for n + 1. Let G
have n + 1 vertices, and let G′ = G −vn+1. As G′ contains no cycles,
its vertices can be listed the right way by the induction hypothesis.
Let L be this list. Let A be the set of vertices a ∈G′ so that there is
a directed path from a to vn+1. Let B be the set of vertices b ∈G′
so that there is a directed path from vn+1 to b. As G has no directed
cycles, this implies that there can be no directed path from B to A.
So all vertices of A precede all vertices of B in the list. Then vn+1 can
be inserted anywhere between the end of A and the start of B in L.
(8) The depth ﬁrst search algorithm creates a directed spanning tree of
G. In this tree, the parent of each vertex v is its unique predecessor,
that is, the vertex from which v was ﬁrst reached. We claim that G is
acyclic if and only if there is no edge from G that goes from a vertex
v to one of the ancestors of v. If there is such an edge (v, u), then G

550
A Walk Through Combinatorics
contains a cycle since u is an ancestor of v, so there is a path from u
to v.
If there is a cycle C with vertices c1, c2, · · · , ck in G, then let ci be the
ﬁrst vertex of C reached by depth ﬁrst search. Then all the other cj,
including ci−1, are descendents of ci in the depth ﬁrst search tree (since
the algorithm will not backtrack from ci before reaching all vertices
reachable from ci, which includes all of C). Therefore, (ci−1, ci) is an
edge of the desired kind.
(9) Let us assume that our algorithm (called Prim’s algorithm) creates
the tree T with edges e1 ≤e2 ≤· · · ≤en−1, while there is another,
cheaper tree F. If there are several candidates for F, choose one so
that the number of edges that are part of both T and F is maximal.
Then there is a smallest index i so that ei /∈F. Let A be the vertex set
of edges e1, e2, · · · , ei−1. Then e is an edge between A and V (G) −A.
Let x and y be the endpoints of ei. Then there is a unique path from
x to y in F. Let f be the edge of F along that path that connects a
vertex in A to a vertex in V (G) −A. As in step i, we added e and not
f to our tree T , the inequality w(f) ≥w(ei) must hold.
Now remove f from F and add ei to F instead. This creates another
spanning tree of G with at most as large a cost as F. Indeed, the new
graph F ′ has n−1 edges and is connected (why?). As F had minimal
cost, it follows that w(F) = w(F ′), but F ′ and E have one more edge
in common than F and E, which is a contradiction.
(10)(a) True. After simplifying by n, the statement is reduced to log n =
O(na), and that is true since limn→∞
log n
na
= 0 by the l’Hospital
rule.
(b) False. In fact lim∞n!/2n2 = 0 as can be seen by taking logarithms.
Using Stirling’s formula, log n! = n(log n −1) + (log n + log π)/2,
while log 2n2 = n2 log2. Now use part (a).
(c) False. By Stirling’s formula, n! ∼
 nn
en
 √
2πn, and that extra
√
2πn
factor will outgrow any constant.
(11)(a) No pair will get compared more than once.
(b) Each pair will get compared once if we never pick an element that
properly partitions the set of remaining elements, that is, if each
time we make a pick, we choose the largest or the smallest available
element.
This sorting procedure is called QuickSort.
(12) Let Xi(p) be the number of times the element ai gets compared during
the sorting sequence deﬁned by p. It suﬃces to show that E(Xi) =

The Sooner The Better. Combinatorial Algorithms
551
O(log n), and the claim will follow by linearity of expectation.
In order to see that E(Xi) = O(log n), note that the size of the block
containing ai decreases, on average by at least half by each pick in-
volving that block (the reader should prove this fact), so on average,
this block will shrink into a singleton after O(log n) splits.
(13) We will move from left to right in p. For each entry pi, if pi < pi−1,
we move on to the next entry pi+1. If, on the other hand, pi−1 < pi,
then we compare pi with each pj so that i < j. If there is such a pj
satisfying pj < pi, then pi−1pipj is a 132-pattern, and we stop. If no
such pj exists, then we move on to the next entry pi+1. If we reach
the end of p without stopping, then p is 132-avoiding. As deciding
whether a suitable pj exists takes O(n) steps, our claim is proved.

This page intentionally left blank
This page intentionally left blank
This page intentionally left blank
This page intentionally left blank

Chapter 20
Does Many Mean More Than One?
Computational Complexity
The wide variety of problems in which algorithms are used suggests that we
look for a uniﬁed approach that measures how eﬃcient various algorithms
are. In the previous chapter, we did that by counting the number of steps
the algorithms used, but that meant that for each problem, we had to
specify what counted as a step. Our goal now is to have standards that can
be applied to every algorithm.
20.1
Turing Machines
A Turing machine is an idealized computer named after the English math-
ematician Alan Turing. It is meant to simulate how a human being would
carry out an algorithm step by step, moving from one stage to the next, ac-
cording to some well-deﬁned rules. Formally, a Turing machine T consists
of the following four parts.
(1) A tape. This is a one-dimensional array of cells, which is inﬁnite at
both ends, so that we never run out of tape. Each cell contains a
symbol from a ﬁnite alphabet A. Two of these symbols have to be
blank and start. If we have not written anything to a cell yet, then
we assume it contains the blank symbol. The start symbol is the one
that the machine will read ﬁrst. It will tell the machine to start. The
tape is often called the input of the machine.
(2) A head. Fair enough, if the tape contains a lot of information, the
machine should be able to read it. The head can move both ways
along the tape, and can read the symbol in the cells, and can replace
a symbol in the cells. This is often expressed by saying that the head
is read-write.
(3) A set S of states, containing the start state s. As the head moves
553

554
A Walk Through Combinatorics
along the tape, the machine changes from one state to another. How
T reacts to a certain symbol it is reading depends on the state it is
in. That is, it can happen that when the machine reads symbol a and
is in state t, it will react diﬀerently from when it reads symbol a is in
state u.
(4) A transition function (or program)
f : S × A →(S ∪“Y es” ∪“No”) × A × {←, →, stay}.
This function describes how T works. The deﬁnition is not nearly
as diﬃcult as it may look. The domain of f is S × A, which makes
perfect sense since the action of the machine must depend on the state
in which it is, and the symbol it is currently reading. The range of f is
a direct product of three factors, and we will survey them separately.
The ﬁrst factor, S ∪“Y es”∪“No” means that when T reads the input
of the given cell in its current state, it may go to a “Yes” state (often
called the accepting state), or to a “No” state, (the rejecting state).
Note that it follows from the above deﬁnition that the machine will
always halt immediately after reaching the “Yes” state or the “No”
state. Also note that the “Yes” state and the “No” state are so special
that they are not part of S.
Some enhanced versions of Turing machines can simply halt without
saying “Yes” or “No”, and these machines have a “Halt” state for
stopping like that, but we will not use that model. We will concentrate
on Turing machines that are used to test “yes or no” questions, hence
the accepting and rejecting states.
The second factor A of the right-hand side is needed since T can write
another symbol into the cell it is reading. Finally, the third factor
{←, →, stay} is needed since after writing into the current cell, the
head may move one notch to the left, one notch to the right, or it may
stay where it was.
While this deﬁnition may seem too cumbersome, or too broad, it com-
prises almost everything an algorithm can possibly do. Therefore, most
algorithms we encounter can be executed by Turing machines.
There are several versions of enhanced Turing machines, and a few sim-
pliﬁed versions as well.
The machines described above are often called
deterministic Turing machines since knowing the state in which the ma-
chine is, the position of the head, and the content of the cell the machine is
currently reading means knowing what the machine will do next. The ad-

Does Many Mean More Than One? Computational Complexity
555
jective deterministic will be further explained when we put these machines
into contrast with diﬀerent machines.
Example 20.1. We can use a Turing machine to decide whether a certain
positive integer a is divisible by 3 or not. This Turing machine will have
the following parameters.
(1) The set of states
S = {start, 0, 1, 2, Y es, No}.
(2) The set of symbols of the alphabet
A = {start, blank, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, end}.
(3) The tape containing, from left to right, start, the digits of a in order,
and end.
(4) The program f deﬁned as follows.
(5)(a) When the head reads start, it moves to the ﬁrst digit of a in the
next cell on the right. It stays in state start.
(b) When the machine reads the ith digit of a, it reacts as follows. If
that digit is 0, 3, 6, or 9, it stays in its current state. If that digit
is 1, 4, or 7, it moves one state up, (that is, if it was in state 0, it
goes into state 1, if it was in state 1, it goes into state 2, and if it
was in state 2, it goes in state 0). Finally, if that digit is 2, 5, or 8,
the machine moves two states up.
The head then moves to the next cell on the right of the current cell.
(c) If the machine is in state 0 when the head reaches the cell containing
the symbol end, the machine goes to “Yes” state and halts. If the
machine is in state 1 or 2 when the head reaches the cell containing
the symbol end, the machine goes to “No” state and halts.
The above program used the fact that a is divisible by three if and only
if the sum of its digits is divisible by three.
The reader should not be horriﬁed. In the rest of the chapter, we will not
analyze every single algorithm so painfully. The goal of the above example
was to show how to translate an algorithm into the terminology of Turing
machines. The main advantage of this model is that now it is absolutely
clear what a step is (a step of the head, either →, or ←, or stay), and it is
also clear what the running time of an algorithm is (the number of steps of
the head). This is why Turing machines are so appropriate for analyzing
the eﬃciency of a very wide array of algorithms.

556
A Walk Through Combinatorics
Quick Check
(1) Construct a Turing machine that takes an ordered pair (a, b) of positive
integers as its input, and stops in the “Yes” state if a is divisible by b,
and in the “No” state otherwise.
(2) Construct a Turing machine that takes a positive integer a as its input,
and stops in the “Yes” state if a is prime, and stops in the “No” state
if a is not prime.
(3) Construct a Turing machine that takes a graph G as its input (given by
its adjacency matrix) and stops in the “Yes” state if every pair (x, y)
of distinct vertices in G is connected by a path of length at most four,
and stops in the “No” state otherwise.
20.2
Complexity Classes
In this section, we will encounter some of the most intriguing problems of
modern mathematics. They are related to attempts of describing which
questions can be decided by Turing machines in an eﬃcient way.
20.2.1
The Class P
A decision problem is a “yes-or-no” question asked about a combinatorial
object, such as “Is this graph bipartite?” or “Is this graph connected?” or
“Is this integer prime?” or “Does this permutation contain an even number
of cycles of length seven?”. A language L is the set of all objects for which
the answer of a given decision problem is “Yes”. So, following up on the
above examples, the class of all bipartite graphs, the class of all connected
graphs, the set of all prime numbers, and the set of all permutations with
an even number cycles of length seven each form a language.
We will say that a Turing machine T accepts the language L if given
input x, T stops in the accepting state if x ∈L, and T stops in the rejecting
state if x /∈L.
We are now ready for the ﬁrst major deﬁnition of this section.
Deﬁnition 20.2. We say that a language L is in P if there exists a Turing
machine T and a positive integer k so that T accepts L in O

nk
time,
where n is the size of the input.
That is, if an input x of length n is given to T , then O

nk
moves of
the head are enough for T to decide whether x ∈L or x /∈L. So our unit
of measuring time is the number of movements that the head of our Turing

Does Many Mean More Than One? Computational Complexity
557
machine makes. This is the universal unit of measurement that we will
apply for every problem. This unit will replace all previous units that we
used before to discuss the complexity of algorithms, such as the number of
comparisons for BubbleSort or MergeSort.
If a language L is in P, we often say that membership in L can be tested
in polynomial time. With a slight abuse of language, we sometimes say that
the decision problem of deciding whether x ∈L is in P if L ∈P.
The reader might think that we are too imprecise here since P does not
discriminate between languages that can be accepted in O(n) time or in
O

n20
time. We have two answers to that, the ﬁrst one of which will be
clearer after the next example.
Example 20.3. Let L be the language consisting of all simple graphs that
contain a triangle. Then L ∈P.
Solution. A Turing machine can simply go through all
n
3

triples of the
n-element vertex set of the input graph and check whether all three pairs of
vertices in any given pair are adjacent. There are only
n
3

= O(n3) triples
to check, and in each of them, there are only three edges to check. Finally,
the head of the Turing machine never needs to travel more than n2 cells
between checking two edges, so the statement follows.
Note that it paid oﬀthat in the deﬁnition of P, we did not specify what
k had to be. This, for instance, obviates the question of what the size of the
input should really be, the number of vertices of the graph, n, or number
of entries of the adjacency matrix of the graph, n2. (The adjacency matrix
is needed to describe which vertices are connected by an edge.)
There is also no need to ﬁgure out clever ways to send the head from
one cell of the tape to another, since even sending it from one end to the
other will not hurt.
Example 20.4. Let L be the language consisting of permutations p (given
in the one-line notation) for which p2 is the identity permutation. Then
L ∈P.
In this example, the size of the input is clearly the length n of p.
Solution. Let p = p1p2 · · · pn. For each i ∈[n], if pi = j, check whether
pj = i. If this always holds, accept, otherwise reject. There are n equalities
to check, and between checking two entries, the head never needs to travel
more than n cells, so there will be no more than O

n2
steps.

558
A Walk Through Combinatorics
The class P of problems is an example of a complexity class, that is,
a class of problems that are roughly equally diﬃcult to solve. While the
reader might object by saying that there is quite some diﬀerence between a
problem that takes n steps to solve and a problem that takes n100 steps to
solve, this diﬀerence is still much smaller than the diﬀerence between the
latter and a problem that takes 2n steps to compute. Indeed, if we have a
computer that can solve a problem with input size m in log m time, then
the ﬁrst two problems will take log n and 100 log n time for this computer
to solve, respectively. These times will only diﬀer by a constant factor. The
last problem will take n log 2 time, which is an order of magnitude higher.
More precisely, as n goes to inﬁnity, the ﬁrst two problems will take a
negligible amount of time to compute when compared to the last problem.
This is our second answer to the question as to why it makes sense to put
problems solvable in O(n) time and in O

n20
time into the same class.
Loosely speaking, P is the set of languages that can be decided by an
eﬀective algorithm. Indeed, polynomial time is in some sense the best that
we can expect, since it takes n steps just to read the input.
20.2.2
The Class NP
There is a wide array of decision problems for which no polynomial-time
algorithm is known. To be more precise, there are languages L for which
there is no polynomial-time algorithm known to test whether x ∈L, for an
arbitrary input x. Quite often, there is a weaker algorithm which will not
decide whether x is in L or not, but if someone claims that x ∈L for a
speciﬁc reason, the algorithm will verify that reasoning in polynomial time,
and decide whether that reasoning is correct. If it is, then x ∈L. If not,
then it does not follow that x /∈L since it could still be that x ∈L for some
other reason.
For instance, let L be the set of all pairs (S, m) so that S is a set of
positive integers that have a subset T so that the sum of the elements of T
is m. Now let x = (A, t) be a pair so that A is a set of positive integers, t
is a positive integer, and let us see what we can say about the membership
of x in L. We could certainly take all 2|A| subsets of A and check if any of
those have sum t, but that would take more than a polynomial amount of
time. Indeed, 2|A| is an exponential function of the size of the input. On
the other hand, if someone claims that a certain subset B ⊆A has sum t,
then we can verify that claim in O(n) steps, by simply taking the sum of all
elements of B. Of course, if the claim turns out to be false, we are out of

Does Many Mean More Than One? Computational Complexity
559
luck, since it could well be that x ∈L thanks to some other subset B′ ⊆A.
This set of decision problems, that is, the problems for which we can
verify (but not necessarily test) membership in polynomial time, turns out
to be extremely important. This warrants the following formal deﬁnition.
Deﬁnition 20.5. We say that a language L is in NP if there exists a
positive integer k and a Turing machine T so that the following hold.
• For each x ∈L, there exists a witness W(x) so that when T is given
input (x, W(x)), it will recognize that x ∈L in O

nk
time.
• For each x /∈L, no such witness exists. That is, no matter what input
(x, W ′(x)) we give to T , we cannot “trick” T into falsely saying that
x ∈L.
In other words, L ∈NP if witnesses for the claim that x ∈L can be
veriﬁed in polynomial time (but not necessarily found in polynomial time).
We point out that the witness is often called a certiﬁcate.
So the introductory example of this subsection says that the language of
pairs (S, m), where S is a set of positive integers that has a subset summing
to m is in NP. This is actually a version of a well-known decision problem,
called the subset sum problem. We will take a second look at other versions
of this problem shortly.
Let us consider a few other classic examples.
Example 20.6. Let L be the language of all undirected graphs that have
a Hamiltonian cycle. Then L is in NP.
Solution. An ordered list v1, v2, · · · , vn of vertices of G can play the role
of the witness W(G). Then all we need is to check whether v1v2 is an edge,
v2v3 is an edge, and so on, up to vn−1vn, and, at the end, vnv1. This means
that a Turing machine T only needs to check the existence of n edges. As
the head of T never needs to move more than n2 cells between two checks, T
can verify in O

n3
time whether v1, v2, · · · , vn, v1 is a Hamiltonian cycle.
Example 20.7. Let L be the language of all pairs of simple graphs (G, H)
so that G is isomorphic to H. Then L is in NP.
Solution. A bijection f : V (G) →V (H) can play the role of the witness
W(G, H). Then all that a Turing machine T needs to do is to check whether
it holds for all u, v ∈V (G) that if uv is an edge, then f(u)f(v) is an edge.

560
A Walk Through Combinatorics
As this means checking at
n
2

= O

n2
edges, and the head of T never
travels more than O

n2
cells between two checks, our statement is proved.
The following proposition compares the two complexity classes we de-
ﬁned so far.
Proposition 20.8. We have P ⊆NP.
Proof. If L ∈P, then there exists a Turing machine T that can test
membership in L in polynomial time. So if we give input (x, W(x)) to T ,
then T can simply ignore W(x) and can still verify x ∈L in polynomial
time.
At this point, it seems very natural to ask whether the containment in
Proposition 20.8 is strict.
Question 20.9. Does the equality P = NP hold?
This turns out to be one of the most intriguing open problems in math-
ematics today, and probably the single most intriguing open problem of
theoretical computer science. It is one of the seven Millennium Prize Prob-
lems. These are seven particularly diﬃcult open problems designated by
the Clay Mathematics Institute in Cambridge MA in 2000. There is a one
million dollar prize oﬀered for the solution of each of them. The interested
reader can learn more about these problems in the Notes section of this
chapter.
It may sound very surprising that Question 20.9 is still open. After
all, verifying a witness seems to be a much simpler task than ﬁnding one.
However, there are several other points to consider.
First, for P to be
equal to be NP, we would not need a Turing machine T that can test
membership as fast as another machine T ′ can verify membership. It would
be enough to have T test membership in O

n10000
time while T ′ could
verify membership in O(n) time. Second, in order to prove that P ̸= NP,
one would need to ﬁnd a language L ∈NP so that L /∈P. And how do
you prove that a certain language is not in P?
There are other methods that could possibly be used to ﬁnd the answer
to Question 20.9. We will mention a few of them in the rest of this section.
20.2.2.1
The Class coNP
There is a subtle way of taking the complement of a complexity class. It is
given by the following deﬁnition.

Does Many Mean More Than One? Computational Complexity
561
Deﬁnition 20.10. We say that the language L is in coNP if there exists
a Turing machine T and a positive integer k so that the following hold.
• For each x /∈L, there exists a witness W(x) so that when T is given
input (x, W(x)), it will recognize that x /∈L in O

nk
time.
• For each x ∈L, no such witness exists. That is, no matter what input
(x, W ′(x)) we give to T , we cannot “trick” T into falsely saying that
x /∈L.
In other words, coNP is the class of languages for which we can verify
non-membership in polynomial time.
The following is a classic example of a naturally deﬁned problem which
is easily seen to be in coNP, but requires more work to be seen in NP.
Example 20.11. Let PRIMES be the set of all prime numbers.
Then
L ∈coNP.
Solution. Let x be the positive integer for which we want to show that
x /∈PRIMES. A proper divisor d = W(x) of x can play the role of witness
for x /∈L. Indeed, then T can simply divide x by d and verify that there is
no remainder. If x has n digits, then this can be done in O

n2
time.
Note that as we said before, n must be the size of the input, that is, the
number of digits of x. Therefore, the following argument would be wrong.
“The language PRIMES is in P since we could simply check for each integer
i satisfying 2 ≤i ≤√x whether i divides x. This takes √x steps, which is
less than a polynomial function of x.” The problem with this argument is
that we need an algorithm that is polynomial in terms of n ≈lg x, not in
terms of x.
The reader may ask why we deﬁned coNP before deﬁning coP as the
set of languages for which we can test non-membership in polynomial time
by a Turing machine.
We encourage the reader to spend a moment trying to ﬁgure that out
before reading further. The answer is that coP = P since if T can test
for non-membership in L in polynomial time, then the same T can test
for membership in the complement of L in polynomial time, or even, for
membership in L in polynomial time, by simply interchanging the accepting
and rejecting states at the end. This line of thinking leads to the following
proposition.

562
A Walk Through Combinatorics
Proposition 20.12. The weak containment relation P ⊆NP ∩coNP
holds.
Proof. On the one hand, Proposition 20.8 shows that P ⊆NP. On the
other hand, by the same argument, coP ⊆coNP. As coP = P, our claim
is proved.
We would like to point out that it is somewhat more diﬃcult to prove
that the language L consisting of all prime numbers is in NP. That result
is called Pratt’s theorem, and can be proved using very enjoyable facts from
number theory. In fact, the following characterization of primes can be
used. An integer p > 1 is prime if and only if there exists an integer r so
that 1 < r < p and
(i) rp−1 −1 is divisible by p, and
(ii) If q is a prime so that qd = p −1 for some integer d, then rd −1 is not
divisible by p.
Given p, a witness W(p) can be an integer r and all the prime divisors q
of p −1. A Turing machine could then verify in polynomial time that r
satisﬁes the requirements with each d = (p−1)/q. Note that the number of
distinct prime divisors q of p−1 is less than log2 p, so W(p) is of polynomial
size in terms of the size of the input, which is log p.
It is even more diﬃcult to prove that PRIMES is in P. That was perhaps
the most celebrated result in complexity theory in the early years of this
century. The proof, by Agrawal, Kayal, and Saxena [1] was published in
2004, and takes only 12 pages! It is also worth pointing out that two of
the three authors were undergraduate students at the time the proof was
found.
The known containment relations between the three complexity classes
that we have deﬁned so far are shown in Figure 20.1.
At this point, you are asked to test your understanding of the concepts
of this section by proving the following proposition.
Proposition 20.13. The following two statements are equivalent.
(1) P = NP.
(2) P = coNP.
We end the section by noting that it is not even known whether NP =
coNP. It is widely believed that these two classes are diﬀerent, just as it
is widely believed that P and NP are diﬀerent.

Does Many Mean More Than One? Computational Complexity
563
P
NP
NP
co
(this section possibly
      empty)
(this section possibly
      empty)
This section possibly empty
Fig. 20.1
The known inclusions between the three complexity classes deﬁned so far.
20.2.2.2
Nondeterministic Turing Machines
You may have wondered where the “N” comes in the name of the complex-
ity class NP. After all, the deﬁnition of the class says that certain things
have to be done in polynomial time, not in “non-polynomial” time.
The answer to that question comes from the following version of Turing
machines, called nondeterministic Turing machines. For nondeterministic
Turing machines, the ﬁrst three parameters, that is, the tape, the head,
and the set of states, are deﬁned exactly as they were for the classic (de-
terministic) Turing machines. The diﬀerence lies in f, which we called the
transition function or program in the case of deterministic Turing machines.
This
f : S × A →(S ∪“Y es” ∪“No”) × A × {←, →, stay}
was a function, that is, given a certain input consisting of a state and a
symbol at the cell currently read, it sent the machine into a uniquely deter-
mined state. This is why those Turing machines were called deterministic.
In an undeterministic Turing machine, the function f is replaced by the
relation
g : S × A ⊂[S × A] × [(S ∪“Y es” ∪“No”) × A × {←, →, stay}].
In other words, a nondeterministic Turing machine has several legal
courses of action in a generic step. Given a symbol in a cell and a state of
the machine when reading that symbol, there are several ways in which the
machine can continue.

564
A Walk Through Combinatorics
Fine, you will say, but when will we say that such a nondeterministic
Turing machine T accepts the input string x? What if a certain sequence
of legal choices will result in T halting in the “Yes” state and some other
sequence of legal choices will result in T halting in the “No” state? Will
we take a majority vote?
It turns out that we will have a very weak notion of acceptance. We
will say that T accepts x if there is at least one sequence of legal choices of
action for T that results in T halting in the “Yes” state. If there is no such
sequence, we will say that T rejects x.
With the acceptance of an input string now deﬁned, we can deﬁne ac-
ceptance of a language L by a nondeterministic machine T . This deﬁnition
is not surprising. We simply say that T accepts L if T accepts x if and only
if x ∈L.
How do we measure the running time of a nondeterministic Turing ma-
chine? We will not add up the running times it takes to carry out each
computation that arises from a legal sequence of choices. Instead, we will
deﬁne the running time of the nondeterministic Turing machine as the max-
imum running time among the running times of the possible computations.
See Figure 20.2 for an illustration. We could interpret this deﬁnition by
saying that in a nondeterministic Turing machine, all possible choices are
followed up concurrently, so the total running time will indeed be the max-
imum individual running time.
TIME
Fig. 20.2
Measuring the running time of a nondeterministic machine.
Finally, we are in a position to explain the name of NP. The class NP
is the class of languages that can be accepted by a nondeterministic Tur-
ing machine in O

nk
time, for some positive integer k, where n denotes

Does Many Mean More Than One? Computational Complexity
565
the size of the input. That is, NP stands for nondeterministically polyno-
mial. Indeed, if a language L is in NP, then for x ∈L, a witness W(x)
can be veriﬁed in polynomial time by a deterministic Turing machine. A
nondeterministic Turing machine could then just go through all possible
witnesses for x, and decide whether any of them are valid. As verifying
a witness takes polynomial time, this nondeterministic machine would ﬁn-
ish in polynomial time. If, on the other hand, no nondeterministic Turing
machine could ﬁnish the task of checking all witnesses in polynomial time,
then at least one possible witness could not be checked in polynomial time,
implying that L is not in NP.
Note that even this alternative deﬁnition of NP makes it clear that
P ⊆NP since a deterministic Turing machine T is just a special case of
a nondeterministic one. That is, it is a nondeterministic Turing machine
whose deﬁning relation g happens to be a function. In other words, in each
step, T happens to have only one legal choice. The fact that we cannot
decide whether P = NP can be expressed by saying that in some sense, we
cannot decide whether nondeterministic machines are really stronger than
deterministic ones.
Example 20.14. Let HAMCYC be the language of all undirected graphs
G that have a Hamiltonian cycle. Then HAMCYC can be decided by a
nondeterministic Turing machine T in polynomial time as follows.
Let
n be the number of vertices of G.
Then there are (n −1)!/2 ways to
arrange the vertices in a cycle. These will be the legal choices of T . No
matter what choice T makes, T can then check whether that arrangement
of vertices is a Hamiltonian cycle or not. In this stage, T can act as a
deterministic machine, and will still only need O(n) steps. So we ﬁnd again
that HAMCYC ∈NP.
20.2.3
NP-complete Problems
With a slight abuse of language, in this subsection we identify the language
L with the problem of deciding whether x ∈L.
Let us assume that we have a computer program that computes the
prime factorization of any positive integer less than one billion.
Let us
further assume that for some purpose, we need to compute not the prime
factorization of n, but the number of its positive divisors. If this is the case,
we cannot simply ask the program to do all the work for us, but we will
see that the program will in fact do almost all the work. Indeed, note that

566
A Walk Through Combinatorics
if n = pk1
1 pk2
2 · · · pkt
t
where the pi are diﬀerent primes, then the number of
positive divisors of n is precisely t
i=1(ki + 1) since m divides n if and only
if m = pa1
1 pa2
2 · · · pat
t , with 0 ≤ai ≤ki for all i. Therefore, all we need to
do is to run the program, take its output, and do something very simple
with it, namely compute the product of certain numbers determined by the
output.
The above example is a special case of a very general phenomenon in
the theory of computation (or, in mathematics in general), namely the
reduction of a problem to another one. Indeed, the above argument shows
that if we can ﬁnd the prime factorization of an integer, then we can also
ﬁnd the number of its positive divisors. In other words, the latter problem
can be reduced to the former. Furthermore, the reduction did not take long
when compared to the original algorithm, (think about this!), so it was
“worth it”. Of course, if the reduction had taken too long, we might try to
solve the new problem directly, instead of reducing it to the old one.
Another example of reduction, one in which a decision problem is re-
duced to another one, will be presented shortly, in the proof of Theorem
20.22.
If decision problem A can be reduced to decision problem B in a short
time, then it is natural to think that “B is at least as hard as A” in some
sense. If every problem of a complexity class C can be reduced to a problem
B ∈C, then it is natural to think that B has some kind of a special role in
C. The following deﬁnition is the most important example for this.
Deﬁnition 20.15. We say that the problem L is NP-complete if
(1) L ∈NP, and
(2) each L′ ∈NP can be reduced to L by a deterministic Turing machine
in polynomial time.
You may be thinking now that the above requirement is rather strong,
and therefore, it is usually rather hard to prove that a problem is NP-
complete. Then you might be thinking that therefore, the number of NP-
complete problems must be small, and so their class might be a rather
restricted one. The ﬁrst of these concerns is partly true, namely, it was
diﬃcult to ﬁnd the ﬁrst NP-complete problem. However, once an NP-
complete problem is found, others are much easier to ﬁnd, because of the
following simple fact.
Proposition 20.16. If L is an NP-complete language and L′ is a language
so that L is reducible to L′, then L′ is NP-complete.

Does Many Mean More Than One? Computational Complexity
567
Proof. If A ∈NP, then A is reducible to L in polynomial time, and
then L is reducible to L′ in polynomial time. Therefore, A is reducible
to L′ in polynomial time.
(Just run the two reducing Turing machines
consecutively.)
So once one NP-complete problem is found, others can be found by
showing that the ﬁrst one is reducible to them in polynomial time. The
more NP-complete problems we have, the easier it is to ﬁnd new ones, since
there are more problems to play the role of L in Proposition 20.16.
The notion of NP-completeness provides a strategy for those who want
to prove that P = NP. This is the content of the following corollary.
Corollary 20.17. If there exists an NP-complete language L ∈P, then
P = NP.
Proof. If the NP-complete language L is in P, then any language L′ ∈
NP is also in P. Indeed, ﬁrst reduce L′ to L in polynomial time by a
deterministic Turing machine, and then decide L in polynomial time by
another deterministic Turing machine.
As we said, it was not easy to ﬁnd the ﬁrst NP-complete language. We
will now describe this language, without proving that it is NP-complete.
Let x1, x2, · · · , xn be Boolean variables, which means that they can take
two values, true and false.
These variables will be called literals.
We
introduce the operations ∧, ∨, and¯on the set of literals as follows.
(1) xi ∨xj = true if at least one of xi and xj is true. Otherwise, xi ∨xj =
false. This can be thought of as the “or” operation.
(2) xi ∧xj = true if both xi and xj are true. Otherwise, xi ∧xj = false.
This can be thought of as the “and” operation.
(3) ¯xi = true if xi = false and ¯xi = false if xi = true. This can be
thought of as the negation operation.
A Boolean expression is just a sequence of operations on literals, such as
(x1 ∧x2)∨¯x3, or (x1 ∧x2)∨¯x1. A Boolean expression is called satisﬁable if
we can assign the values true and false to its literals so that the expression
evaluates to true.
Example 20.18. The Boolean expression
(x1 ∧x2) ∨¯x3
is satisﬁable. Indeed, setting x1 = true, x2 = true, and x3 = false, the
expression evaluates to true.

568
A Walk Through Combinatorics
Example 20.19. The Boolean expression
(x1 ∧¯x2) ∧(¯x1 ∨x2)
is not satisﬁable. Indeed, the ﬁrst parentheses will only evaluate to true if
x1 = true and x2 = false, while in that case, the second parentheses will
evaluate to false.
A Boolean expression in conjunctive normal form is a Boolean expres-
sion in which there are only ∧operations among the parentheses (the latter
are called the clauses), and there are only ∨operations within the paren-
theses.
Example 20.20. The Boolean expression
(x1 ∨x2) ∧(x1 ∨¯x3 ∨x4) ∧x2 ∧(x1 ∨¯x4)
is in conjunctive normal form.
It can be proved that each Boolean expression is equivalent to one in
conjunctive normal form. So restricting our attention to Boolean expres-
sions in this form will not result in loss of generality, but it will simplify
the handling of the expressions.
We are now in a position to announce Cook’s theorem, the ﬁrst result
showing that a certain language is NP-complete.
Theorem 20.21 (Cook’s theorem).
[19] Let SAT be the language of
satisﬁable Boolean expressions in conjunctive normal form. Then SAT is
NP-complete.
It is easy to see that SAT is in NP. Indeed, the witness W(x) for a
given Boolean expression x of length n is just an assignment of values to
the literals of x. It then takes O(n) time to verify that each clause indeed
contains at least one literal with value 1. It is also easy to see that the
total number of possible assignments is 2m if we have m literals, and the
number 2m is constant; it does not depend on n. So checking all possible
assignments would take more than a polynomial amount of time.
The proof of Cook’s theorem can be found in any textbook on Com-
plexity Theory. For a reader-friendly presentation, we recommend [60]. We
point out that even if we only consider Boolean expressions in conjunctive
normal form so that each clause contains only three literals, the correspond-
ing language 3SAT is still NP-complete. This is because SAT is reducible
to 3SAT in polynomial time as we will see in the proof of the next theorem.

Does Many Mean More Than One? Computational Complexity
569
Theorem 20.22. Let 3SAT be the language of Boolean expressions in con-
junctive normal form so that each clause contains exactly three literals.
Then 3SAT is NP-complete.
Proof. It goes without saying that 3SAT ∈NP since an assignment of
variables can play the role of the witness. We will now show how to reduce
SAT to 3SAT in polynomial time. That is, for each Boolean expression X
in conjunctive normal form, we will construct a Boolean expression f(X)
in which each clause contains exactly three literals so that X is satisﬁable
if and only if f(X) is satisﬁable.
We will construct f(X) clause by clause. Say one of the clauses of X
is (x1 ∨x2 ∨· · · ∨xm). We will break this clause up into m −2 smaller
clauses, which will also contain some new variables. In fact, let us replace
Xc = (x1 ∨x2 ∨· · · ∨xm) by the clause
f(Xc) = (x1∨x2∨y1)∧(x3∨¯y1∨y2)∧(x4∨¯y2∨y3)∧· · ·∧(xm−1∨xm∨¯ym−3).
That is, the ﬁrst and last clauses are diﬀerent from the rest. Other than
that, the ith clause is (xi+1 ∨¯yi−1 ∨yi) if 2 ≤i ≤m −3.
Let us replace each clause Xd of X by the clause f(Xd) deﬁned this
way. Let us now assume that X is satisﬁable; that happens exactly when
each clause of X is satisﬁable. As Xc is satisﬁable by a certain true-false
assignment, there is at least one index i ∈[m] so that xi = true in that
assignment. Choose the smallest such i. Now assign yj = true if j < i −1
and yj = false if j ≥i −1. This assignment will satisfy f(Xc), since the
ﬁrst i−2 clauses will evaluate to true since the unbarred yj variable in them
will be true, the (i −1)st clause will evaluate to true since it will contain
xi, and the remaining clauses will evaluate to true since the variable ¯yj in
them will be true.
This argument works for each clause of X, so we have proved that f(X)
is satisﬁable if X is satisﬁable. We still have to prove the converse.
Let us assume that f(X) = ∨(f(Xc)) is satisﬁable, but X is not satis-
ﬁable. That means that there is an assignment of values to all variables xi
and yj that satisﬁes each clause of f(X), but not each clause of X. Let c
be such that this assignment does not satisfy Xc, but satisﬁes f(Xc). As
Xc = (x1 ∨x2 ∨· · · ∨xm), this means that in the assignment satisfying
f(X), the equality xi = false holds for all i ∈[m]. Then, crucially, we
can remove all the xi from f(Xc) and the obtained clause f(XC) will still
evaluate to true (since no xi is barred in f(XC)). This implies that
y1 ∧(¯y1 ∨y2) ∧(¯y2 ∨y3) ∧· · · ∧(¯ym−4 ∨ym−3) ∧(¯ym−3)

570
A Walk Through Combinatorics
is satisﬁed by the assignment satisfying f(X). However, the last displayed
expression is unsatisﬁable. Indeed, to satisfy its ﬁrst clause, we would have
to set y1 = true, then to satisfy its second clause, we would have to set
y2 = true, and so on. The next-to-last clause would force ym−3 = true,
and then the last clause would not be satisﬁable.
So we have seen that X is satisﬁable if and only if f(X) is. As the
creation of f(X) takes only polynomial (in fact, linear) time, this shows
that SAT is reducible to 3SAT in polynomial time, proving our claim.
The result of Theorem 20.22 is probably optimal in the following sense.
If we restrict our attention to Boolean expressions which consist of clauses
of exactly two literals, and deﬁne 2SAT to be the language of those that
are satisﬁable, then 2SAT is very unlikely to be NP-complete.
This is
because, as it is proved in Exercise 4, the language 2SAT is in P! So if
2SAT is NP-complete, then P = NP. The reader should wait until the
end of this chapter before attempting to solve Exercise 4 as some additional
deﬁnitions will be needed.
Many NP-complete problems involve graphs, and the proofs of their
NP-completeness often involve the reduction of 3SAT to these problems.
The reader is strongly encouraged to attempt the solution of Exercise 6 for
an elegant example.
The following are three examples of NP-complete problems. We point
out that [26] is an entire book exclusively devoted to this complexity class!
Example 20.23. Let HAMPATH be the language of graphs that have a
Hamiltonian path. Then HAMPATH is NP-complete.
Example 20.24. Let SUBSETSUM be the set of ﬁnite multisets of real
numbers that have a non-empty submultiset whose sum of elements is equal
to 0. Then SUBSETSUM is NP-complete.
See Exercise 5 for a variation of this problem.
Example 20.25. Let L be the set of pairs (p, q) so that p is a permutation
that contains q as a pattern. Then L is NP-complete.
Note that it is very important in the above example that q is part of
the input, that is, that the length of q is not given in advance. If the length
of q were a given constant, then the corresponding language would be in
P, as you will be asked to prove in Supplementary Exercise 14. This is an

Does Many Mean More Than One? Computational Complexity
571
example of an important distinction which often decides whether a problem
can be proved to be in P or to be NP-complete.
The famous traveling salesman problem is a variation of Example 20.23.
See Supplementary Exercise 17.
Corollary 20.17 implies that if someone could ﬁnd an eﬃcient (read
“contained in P”) algorithm for the Hamiltonian path problem, or the
subset sum problem, or the pattern avoidance problem, then we would
know that there also exists an eﬃcient algorithm for the several hundred
other known NP-complete problems.
20.2.4
Other Complexity Classes
Instead of deﬁning complexity classes based on how much time it takes for
a Turing machine to solve the corresponding decision problems, one could
look at the space, that is, the number of cells, the Turing machine will need.
Deﬁnition 20.26. We say that the language L belongs to the complexity
class PSPACE if there exists a Turing machine T and a positive integer k
and a constant c so that T accepts x if and only if x ∈L and the number
of cells T will use when given input x is at most cnk.
In other words, T needs only O

nk
cells to decide if x ∈L, where n is
the size of the input x.
As a Turing machine takes a unit of time to access each cell, the following
proposition is immediate.
Proposition 20.27. We have P ⊆PSPACE.
It is not known whether this inclusion is strict or not. The following con-
tainment relation is a little bit less obvious.
Lemma 20.28. We have NP ⊆PSPACE.
Proof. Let L ∈NP. Note that as far as membership in PSPACE is con-
cerned, the running time of the machines is not important. Therefore, if T
is the nondeterministic Turing machine that accepts L in polynomial time,
we could modify T to get the machine T ′ as follows. Let T ′ be the deter-
ministic Turing machine that carries out each computation resulting from
a legal sequence of choices by T , but it does so consecutively in some spec-
iﬁed order, instead of concurrently, and so that each sequence overwrites
the previous one. Note that this T ′ is indeed a deterministic machine. This
is because in each stage, T ′ takes a uniquely deﬁned step since it takes the

572
A Walk Through Combinatorics
next step of the currently selected sequence, and the order in which the
sequences are processed is determined. Furthermore, T ′ uses polynomial
space only, since each sequence, including the longest one, uses polynomial
space only. Indeed, if a sequence s would take more than polynomial space
to process, then T could not process that sequence in polynomial time.
As it is not even known whether PSPACE is actually larger than P, it
is not surprising that it is not known whether PSPACE is actually larger
than NP.
So far, every complexity class we considered contained P. How about
classes contained in P? In order to be able to introduce two interesting
classes of that kind, we need the notion of logarithmic space. That is, we
want to consider languages that can be accepted using O(log n) space only.
“Nonsense”, you could say at this point, since n is the size of the input
given to the Turing machine, so just taking the input needs n > O(log n)
steps. Therefore, when considering these complexity classes, we will not
count the part of the tape that contains the input as part of the needed
space. We will only count the space needed for the actual computation.
Now we are ready for the deﬁnition of two new complexity classes.
Deﬁnition 20.29. We say that the language H is in L if there exists a
positive integer k and a deterministic Turing machine T so that for any
input x of length |x|, the machine T can decide whether x ∈H using at
most k log |x| cells.
A spectacular and relatively recent result in this regard is the following.
Theorem 20.30. Let UST be the language of triples (G, s, t) so that G is
an undirected graph, and s and t are two of its vertices so that there is a
path from s to t in G. Then UST ∈L.
Theorem 20.30 was proved by Omer Reingold in 2004 [44].
Deﬁnition 20.31. We say that the language H is in NL if there exists a
positive integer k and a nondeterministic Turing machine T so that for any
input x of length |x|, the machine T can decide whether x ∈H using at
most k log |x| cells.
A famous example of a decision problem that is in NL is REACHABIL-
ITY. That is, given input (G, x, k), where G is a directed graph, x is a vertex
of G, and k is a positive integer, a Turing machine must decide whether G
has at least k vertices that are reachable from x by a directed path. The

Does Many Mean More Than One? Computational Complexity
573
fact that this problem is in NL is the celebrated Immerman-Szelepcs´enyi
theorem.
It is not known whether REACHABILITY is in L or not, but it is known
that there exists a deterministic Turing machine that can solve REACHA-
BILITY using O

log2 n

cells. Note that unlike P or NP, the complexity
class L does not allow for taking squares that way.
It is clear from the deﬁnitions that L ⊆NL. Whether that inclusion is
strict is not known. The following inclusion is a little bit more diﬃcult to
prove.
Lemma 20.32. We have L ⊆P.
The reader is asked to make an eﬀort to prove this lemma on his own.
A proof is provided in the solution of Exercise 3. An enhanced version of
the argument given in that solution (see [39]) proves the inclusion NL ⊆P.
Again, it is not known if this inclusion is strict.
For a change, we mention one inclusion that is known to be strict. It is
known that L ̸= PSPACE (see [39]).
The following chain of inequalities summarizes the weak containment
relations we mentioned in this chapter.
L ⊆NL ⊆P ⊆NP ⊆PSPACE.
(20.1)
What is amazing about this chain of inclusions is that none of the in-
clusions in (20.1) is known to be strict. On the other hand, as we said,
L ̸= PSPACE. Therefore, at least one of the inclusions in (20.1) is strict.
So there is at least one strict inclusion between consecutive expressions to
be proved in this chain. Is there just one? If not, which one will be proved
ﬁrst?
We end this chapter by mentioning that the complexity classes deﬁned
with respect to space are sometimes easier to handle than those with respect
to time. For instance, the equalities
• PSPACE = NPSPACE,
• NL = coNL, and
• NPSPACE = coNPSPACE
are all known to be true, where NPSPACE is the class of languages that
can be accepted using a nondeterministic Turing machine using O

nk
cells
for some ﬁxed k, where n is the size of the input. The classes coNPSPACE
and coNL are deﬁned similarly to the class coNP.

574
A Walk Through Combinatorics
Quick Check
(1) Let F be a given simple graph. Let L be the language of simple graphs
that contain F as an induced subgraph. Prove that L ∈P.
(2) Let L be the language of all trees. Does L ∈P hold?
(3) Let L be the language of all simple graphs that have a nontrivial auto-
morphism. Prove that L ∈NP.
Notes
A list of the seven Millennium Prize Problems can be found at the website of
the Clay Institute, at http://www.claymath.org/millennium/. When this
book goes to press, in 2013, thirteen years after the announcement of the
million-dollar oﬀers for these problems, only one of these problems has been
solved.
A reader-friendly introduction to the topic of this chapter, just as to the
topic of the previous chapter, is Herb Wilf’s book Algorithms and Com-
plexity [60]. Two very enjoyable and fairly comprehensive graduate-level
textbooks are Computational Complexity by Christos Papadimitriou [39]
and Introduction to the Theory of Computation by Michael Sipser [47].
In Chapter 9, we mentioned the problem of deciding whether two graphs
are isomorphic or not. Now we have the terminology to discuss that prob-
lem more precisely. If L is the language of pairs (G, H) of isomorphic simple
graphs with ﬁnite vertex set, then it is clear that L ∈NP, as any isomor-
phism f : G →H can be the witness. It is not known whether L ∈P holds.
However, a recent result of L´aszl´o Babai [5] shows that membership in L
can be solved in exp

(log n)k
time by a deterministic Turing machine, for
some ﬁxed positive real number k. Here n denotes the number of vertices
of G and H.
Exercises
Note: in solving some of the Exercises of this chapter, the reader may use
certain theorems or examples that were mentioned in the text without proof.
(1) Let L be the language of all connected graphs. Prove or disprove that
L ∈P.
(2) Let L be the language of all bipartite graphs.

Does Many Mean More Than One? Computational Complexity
575
(a) Prove that L ∈NP.
(b) Prove that L ∈P.
(3) Prove Lemma 20.32.
(4) (+) Let 2SAT be the language of Boolean expressions in conjunctive
normal form so that each clause contains only two literals. Prove that
2SAT ∈NL. Note that this implies that 2SAT ∈P.
(5) Let BIGSUBSETSUM be the language of all ﬁnite multisets S of real
numbers that have a submultiset T so that
(a) the sum of all elements of T is 0, and
(b) |T | > 0.9 · |S|.
Prove that BIGSUBSETSUM is NP-complete.
(6) Let INDEPENDENT-SET be the language of pairs (G, k) so that G
is a simple graph and k is a positive integer so that G has an induced
subgraph on k vertices that has no edges. Prove that INDEPENDENT-
SET is NP-complete.
(7) A decision problem is called NP-hard if all problems in NP are re-
ducible to it in polynomial time, by a deterministic Turing machine.
Prove that the halting problem, discussed in Chapter 17, is NP-hard.
(8) It follows from the deﬁnition given in the previous exercise that the set
of NP-hard problems contains the set of NP-complete problems. Is
this containment strict?
(9) A problem is called coNP −complete if every problem in coNP is
reducible to it in polynomial time by a deterministic Turing machine.
A tautology is a ﬁnite Boolean expression that is satisﬁed by every
assignment of its variables. For instance, x1 ∨¯x1 is a tautology. Let
TAUT be the language of all tautologies. Prove that T AUT is coNP-
complete.
(10) Let HAMCYC be the language of graphs that contain a Hamiltonian
cycle. Prove that HAMCYC is NP-complete.
(11) A dominating set in a graph G is a subset D of vertices so that any ver-
tex that is not in D has a neighbor in D. Let DOMINATING-SET be
the language of pairs (G, k), where G is a graph that has a dominating
set consisting of k or less vertices. Prove that DOMINATING-SET is
NP-complete.
(12) Let SPANNING-TREE be the language of ordered pairs (G, k) where
G is a simple graph that has a spanning tree in which each vertex has
degree at most k. Prove that SPANNING-TREE is NP-complete.

576
A Walk Through Combinatorics
Supplementary Exercises
(13) Explain, using the formal deﬁnition of (deterministic) Turing ma-
chines, that once a Turing machine entered the accepting state or
rejecting state, it will stop.
(14) Let q be a given permutation pattern. Let L be the set of all permu-
tations that contain q. Prove that L ∈P.
(15) Let L be the language of graphs containing a matching that consists
of at least 10 edges. Prove or disprove that L ∈P.
(16) Prove Proposition 20.13.
(17) A salesman has to travel to each of n cities, visiting each of them
exactly once, and ending in the same city where he started. The cost
of travel between any two cities is given in advance. Prove that the
problem of deciding whether this can be done at a cost less than a
given C is NP-complete.
(18) Prove that if an NP-complete problem is in coNP, then NP = coNP.
(19) Let L be the language of ﬁnite multisets of real numbers such that
L can be partitioned into two blocks A and B so that the elements
of A and the elements of B have the same sum.
Prove that L is
NP-complete.
(20) Prove that if NP ⊆coNP, then NP = coNP.
(21) Let CLIQUE be the language of pairs (G, k) where G is a graph and
k is a positive integer so that G contains a subgraph isomorphic to
Kk. Prove that CLIQUE is NP-complete.
(22) Recall that a vertex cover of a graph G is a subset C of the vertex
set of G so that each edge of G has at least one endpoint in C. Let
VERTEX-COVER be the language of pairs (G, k) where G is a graph
and k is a positive integer so that G has a vertex cover of k elements
or less. Prove that VERTEX-COVER is NP-complete.
(23) Let SHORT EST PAT H be the language of 4-tuples (G, k, a, b) where
G is an undirected graph, and a and b are vertices of G so that there
is a path between a and b that consists of at most k edges. Prove that
SHORTESTPATH ∈P.
(24) Let SUBGRAPH be the language of pairs (G, H) where G and H
are graphs such that G has a subgraph isomorphic to H. Prove that
SUBGRAPH is NP-complete.
(25) Let HITSET be the language of pairs (F, k), where F is a ﬁnite family
of ﬁnite sets so that there is a k-element set that has a non-empty
intersection with each set in F. Prove that HITSET is NP-complete.

Does Many Mean More Than One? Computational Complexity
577
(26) Let PATH be the languages of ordered triples (G, s, t), where G is a
directed graph, and s and t are vertices in G so that there is a directed
path from s to t in G. Prove that PATH is in NL.
(27) Find the error in the following argument claiming to prove that HAM-
PATH is in NL ⊆P. “Let the input graph G have n vertices. When
our machine is at a vertex v, it will guess the next vertex w of a pur-
ported Hamiltonian path. The machine will not store the entire list
of n vertices belonging to that purported path (as that would take
too much space); it will simply check if w is reachable from v by an
edge. For any given branch of computation, if the answer is ever No,
then the machine will end that branch in a rejecting state, and if the
answer is never No, and the list of n vertices is over, then the machine
ends that branch in the accepting state and returns Yes as the ﬁnal
answer.”
Solutions to Exercises
(1) Yes, L ∈P.
Just run breadth ﬁrst search starting at any vertex
s. When the algorithm stops, check whether all vertices have been
reached.
(2) (a) A witness W(G) for a graph G could simply be a partition of the
vertex set of G into two blocks. It can then be veriﬁed in O(n2)
steps that there are no edges within the same block.
(b) Do breadth ﬁrst search on the vertex set of G starting from some
vertex s. Vertices at an even distance from s get colored red, and
vertices at an odd distance from s get colored blue. If this algo-
rithm never reassigns the color of a vertex, then G ∈L, otherwise
it is not.
(3) If at a given point of time, we are told the content of each cell of
the tape of the deterministic Turing machine T , the position of its
head, and state in which the machine is in, then using the transition
function of T , we can compute all future moves of T . If T uses at
most k log n cells, then there are at most |A|k log n possibilities for the
content of the tape, k log n possibilities for the position of the head,
and at most |S| states in which T can be. Therefore, the total number

578
A Walk Through Combinatorics
of conﬁgurations described by the parameters above is at most
|A|k log n · k log n · |S| = ek log n
A
e
k log n
k log n · |S|
= nkclog n · C · log n
= nk · nlog cC · log n
= ≤Cnk+log c+1.
Here C = |S| · k and c = (A/e)k. Now T processes each conﬁguration
in unit time, so in Cnc1 time, it will process all conﬁgurations. A con-
ﬁguration cannot occur twice, since that would put T into an inﬁnite
loop. This proves our claim.
(4) Let B be a Boolean expression in conjunctive normal form in which
each clause contains exactly two literals. We are going to construct
a directed graph GB from B. The vertices of GB are the literals of
B and their negations, each occurring once. There is an edge from
vertex x to vertex y if one of the clauses of B is ¯x ∨y. See Figure 20.3
for an example. Note that this clause is equivalent to the implication
“if x = true, then y = true”. That is, if an assignment satisﬁes B,
and the value of a vertex v in that assignment is true, then the value
of all vertices reachable from v by a directed path must also be true.
x
x
x1
1
2
3
x3
−
x2
−
−
x
Fig. 20.3
The graph GB deﬁned by B = (x1 ∨x2) ∧(¯x1 ∨x3).
We now claim that B ∈2SAT if and only if there is no literal x ∈B
so that there is a path from x to ¯x in GB, and also, a path from

Does Many Mean More Than One? Computational Complexity
579
¯x to x in GB. As the latter problem is in NL (it is an instance of
REACHABILIT Y ), our statement will then follow.
In order to prove that claim, let us assume that such a literal x exists,
and assume without loss of generality that in an assignment satisfying
B, the value of x is true. As there is a path in GB from x to ¯x, and
¯x is false, this contradicts to the property of GB we just proved, that
is, that all literals reachable from a true literal must also be true.
Conversely, if no such literal x exists, then we will deﬁne an assignment
satisfying B. (Intuitively, “no literal will cause any trouble”.) Note
that by the deﬁnition of GB, if there is an edge from x to y, then there
is also an edge from ¯y to ¯x. Start at a vertex u for which there is no
path from u to ¯u. Assign true to all vertices reachable from u by a
directed path, including u itself, and assign false to their negations.
If this does not exhaust all vertices, then pick another vertex v whose
value is not yet assigned, then repeat the procedure. We claim that
this procedure will never cause a conﬂict at the assignment of any
vertex. Indeed, if both z and ¯z were reachable from u, then, by the
symmetric property of GB mentioned earlier in this paragraph, there
would be paths from both ¯z and z to ¯u. That would, by concatenation,
yield a path from u to ¯u, contradicting our hypothesis.
Finally, the assignment deﬁned in the previous paragraph will satisfy
B.
Indeed, in each step of the above procedure, we ensure that if
x = true, then in all clauses in which ¯x occurs, the other literal is
set to be true. Therefore, each clause will contain at least one literal
that is true in the assignment.
(5) We are going to prove the statement by reducing SUBSETSUM to
BIGSUBSETSUM. On any input multiset S, just add 9 · |S| copies of
0 to S to get the new multiset S′. Then S′ ∈BIGSUBSETSUM if
and only if S ∈SUBSETSUM, and the statement follows since |S′|
is only ten times larger than S, so the Turing machine deciding if
S′ ∈BIGSUBSETSUM runs in polynomial time in the size of S as
well.
(6) We show that SAT is reducible to INDEPENDENT-SET. Let B be
a Boolean expression in conjunctive normal form that has k clauses.
We will deﬁne a graph GB that has an empty induced subgraph with
k vertices if and only if B is satisﬁable. The vertices of the graph
are labeled by the literals of B. If a literal xi occurs m times in B,
then there are m vertices in G labeled by xi, one for each occurrence.
Now connect each vertex labeled xi to each vertex labeled by ¯xi. In

580
A Walk Through Combinatorics
addition, connect vertices if the corresponding literals appear in the
same clause. (This does not mean that if x6 and x7 appear together
in one clause C, then we connect all vertices labeled x6 to all vertices
labeled xy; just the vertices corresponding to literals in C.)
See Figure 20.4 for an example.
3
3
2
2
1
1
x
x
−
x−
x
x
x
Fig. 20.4
The graph GB of B = (x1 ∨x2 ∨¯x3) ∧(¯x1 ∨x2 ∨x3) .
If GB contains an empty subgraph H on k vertices, then each vertex of
H must correspond to a literal from a diﬀerent clause, since each clause
contributes a complete subgraph to GB. Furthermore, none of these
k vertices could correspond to a literal that is a negation of another
literal corresponding to a vertex of H, since xi and ¯xi are always
adjacent. Therefore, assigning true to all literals represented in H by
a vertex will satisfy each of the k clauses of B, and consequently, B.
Conversely, if B is satisﬁable by an assignment, then that assignment
assigns true to at least one literal in each clause. Choosing such a
literal from each clause will result in an empty subgraph with k ver-
tices, since it will never happen that two adjacent vertices in separate
clauses are assigned true, since such vertices correspond to pairs of
literals that are negation of each other.
As the creation of GB takes only polynomial time, the proof is com-
plete.
(7) We claim that SAT is reducible to the halting problem. Indeed, if we

Does Many Mean More Than One? Computational Complexity
581
could solve the halting problem by a Turing machine T , then we could
input the pair (G, (B, x)) to T , where B is a Boolean expression in
conjunctive normal form, x is an assignment of true and false values
to the variables of B, and G is a Turing machine that halts if x satisﬁes
B and stops otherwise. The assumption that T decides the halting
problem would then imply that T decides SAT.
(8) Yes, this containment is strict. We have seen in the solution of the
previous exercise that the halting problem is NP-hard. On the other
hand, the halting problem is not in NP, and so it is not NP-complete.
Indeed, if it were, then it would also be in PSPACE, and that would
mean that it is decidable by a deterministic algorithm, and we saw in
Chapter 17 that it is not the case.
(9) It is easy to see that TAUT ∈coNP since for a Boolean expression
B, the role of the witness W(B) can be played by an assignment that
does not satisfy B, and that can be checked in polynomial (in fact,
linear) time.
In order to prove that TAUT is coNP-complete, note that the com-
plement SATc of SAT (that is the language of Boolean expressions
that are not satisﬁable) is coNP-complete, and is reducible to T AUT .
Indeed, B ∈SATc if and only if ¯B ∈TAUT.
(10) We show that HAMPATH is reducible to HAMCYC. Let G be a graph,
add a new vertex v to G, and let v be adjacent to all other vertices of
G. Then the new graph has a Hamiltonian cycle if and only if G had
a Hamiltonian path.
(11) We prove that the language VERTEX-COVER is reducible to
DOMINATING-SET in polynomial time. This suﬃces, since Exer-
cise 22 shows that VERTEX-COVER is NP-complete. Let G be a
graph. Construct the graph G′ by ﬁrst doubling each edge xy of G,
and then splitting each new xy edge by a new vertex vxy. We claim
that G′ has a dominating set of size k if and only if G′ has a vertex
cover of size k. First, it is obvious that if S is a vertex cover of G, then
S is also a dominating set of G′, since the vertices of G′ are along the
edges of G (old or new).
If G′ has a dominating set D of size k, then we can replace the vertices
of D that are of the form vxy by one of x or y without losing the
dominating property (why?). This leads to a dominating set D′ of G
that has k vertices. This set D′ is a vertex cover of G (since it still
dominates all vertices vxy, and hence it covers all edges of G). This
reduction algorithm clearly takes polynomial time only.

582
A Walk Through Combinatorics
(12) We show that HAMPATH is reducible to SPANNING-TREE. Indeed,
to decide if G has a Hamiltonian path, it suﬃces to decide if G has a
spanning tree in which every vertex has degree at most two.

Bibliography
[1] Agrawal, M., Kayal, N., Saxena, N. (2004) “PRIMES is in P”, Ann. Math.
160, 781–793.
[2] Albert, M., Elder, M., Rechnitzer, A., Westcott, P., Zabrocki, M. (2006) “A
lower bound on the growth rate of the class of 4231 avoiding permutations”,
Adv. Appl. Math. 36, 96–105.
[3] Alon, N., Spencer, J. H. (2008) “The Probabilistic Method”, third edi-
tion, Wiley-Interscience Series in Discrete Mathematics and Optimization.
A Wiley-Interscience Publication. John Wiley and Sons, Inc.
[4] Andrews, G. E. (1998) “The Theory of Partitions”, Encyclopedia of Mathe-
matics and Its Applications, vol. 2, Cambridge University Press, Cambridge,
UK.
[5] Babai, L. (2016) “Graph Isomorphism in Quasipolynomial Time”, preprint,
available at http://arxiv.org/pdf/1512.03547v2.pdf.
[6] Bevan, D. (2015) “Permutations avoiding 1324 and patterns in Lukasiewicz
paths”, J. Lond. Math. Soc. (2) 92 (2015), no. 1, 105–122.
[7] Biggs, N. L. (2008) “Codes. An Introduction to Information Communication
and Cryptography.” Springer Verlag, London.
[8] Bollob´as, B. (1978) “Extremal Graph Theory”. London Mathematical Soci-
ety Monographs, 11. Academic Press, Inc.
[9] B´ona, M. (2014) “A new upper bound for 1324-avoiding permutations”,
Combin. Probab. Comput. 23 no. 5, 717–724.
[10] B´ona, M. (2015) “A new record for 1324-avoiding permutations”, Eur. J.
Math. 1, no. 1, 198–206.
[11] B´ona, M. (2015) “Introduction to Enumerative and Analytic Combina-
torics”, CRC Press – Chapman Hall, Boca Raton, FL.
[12] B´ona, M. editor (2015) “Handbook of Enumerative Combinatorics”. CRC
Press – Chapman Hall, Boca Raton, FL.
[13] B´ona, M. (2012) “Combinatorics of Permutations”, second edition. CRC
Press – Chapman Hall, Boca Raton, FL.
[14] B´ona, M. (1998) “The permutation classes equinumerous to the smooth
class”. Electron. J. Combin. 5 (1998), Research Paper R31.
583

584
A Walk Through Combinatorics
[15] B´ona, M., Simion, R. (2000) “A self-dual poset on objects counted by the
Catalan numbers and a type-B analogue”, Discrete Math. 220, no. 1-3, 35–
49.
[16] B´ona M., MacLennan, A., White, D., (2000) “Permutations with roots”,
Random Structures and Algorithms, 17, no. 2, 157–167.
[17] B´ona, M (1997) “A new proof of the formula for the number of the 3 × 3
magic squares”, Math. Magazine 70, 201–203.
[18] Colburn, C. J., Dinitz, J. H. (2007) “Handbook of Combinatorial Designs,”
Chapman Hall - CRC Press, Boca Raton, FL.
[19] Cook, S. (1971) “The complexity of theorem proving procedures”, Proceed-
ings of the third ACM Symposium, ACM, 151–158.
[20] Cormen, T, Leiserson, C., Rivest, R., Stein, C. (2002) “Introduction to
Algorithms”, McGraw-Hill, second edition.
[21] R. Donaghey (1975) “Alternating permutations and binary increasing trees”,
J. Combinatorial Theory Ser. A 18, 141–148.
[22] M. Drmota (2009) “Random Trees: An Interplay between Combinatorics
and Probability”, Springer, Wien, New York.
[23] P. Erd˝os, G. Szekeres (1935) “On some extremum problems in elementary
geometry”, Ann. Univ. Sci. Budapest, E¨otv¨os Sect. Math. 3-4 (1960-1961),
53–62.
[24] S. R. Finch (2003) “Mathematical Constants”, in Encyclopedia of Mathemat-
ics and Its Applications, Vol. 94. Cambridge University Press, Cambridge,
UK.
[25] P. Flajolet, R. Sedgewick (2009) “Analytic Combinatorics”, Cambridge Uni-
versity Press.
[26] Garey, M. D., Johnson, S. (1979) “Computers and Intractability; A guide to
the theory of NP-completeness”, W. H. Freeman and Co.
[27] Gordon, H. (1997) “Discrete Probability”, Springer.
[28] Graham, L., Rothschild, B., Spencer, J. (2015) “Ramsey Theory”, Wiley
Interscience, second edition.
[29] Greene, C., Bogarth, K. P., Kung, J. (1990) “The impact of the chain de-
composition theorem on classical combinatorics. The Dilworth theorems”,
19–29, Contemp. Mathematics, Birkh¨auser.
[30] Harary, F., Palmer, E. M. (1973) “Graphical Enumeration”, Academic Press,
1973.
[31] Kaiser, T., Klazar, M. (2003) On growth rates of hereditary permutation
classes, Electr. J. Combinatorics 9 vol. 2, R10.
[32] Landman, B., Robertson, A. (2014) “Ramsey Theory on the Integers”, sec-
ond edition, American Mathematical Society.
[33] Lov´asz,
L. (1994) “Combinatorial Problems and Exercises”,
Elsevier;
Akad´emiai Kiad´o (Publishing House of the Hungarian Academy of Sciences),
second edition.
[34] Lov´asz, L., Plummer, M. D. (1986) “Matching Theory”, Akad´emiai Kiad´o
(Publishing House of the Hungarian Academy of Sciences).
[35] MacMahon, P. A. (1916) “Combinatorial Analysis”, vols. 1-2, Cambridge,
1916 (reprinted by Chelsea, New York, 1960).

Bibliography
585
[36] Marcus, A., Tardos, G. (2004) “Excluded permutation matrices and the
Stanley-Wilf conjecture”, J. Combin. Theory Ser. A 107 no. 1, 153–160.
[37] Nechustan, O. (2002) “On the space chromatic number”, Discrete Math.
256 (2002), no. 1–2, 499–507.
[38] Pach, J., Agarwal, P., (1995) “Combinatorial geometry”, Wiley Interscience.
[39] Papadimitriou, C. H. (1994) “Computational Complexity”, Addison-Wesley.
[40] Petkovˇsek, M., Wilf H., Zeilberger D. (1996) “A = B”, A. K. Peters.
[41] Pittel, B. (1999) “Conﬁrming two conjectures about the integer partitions”,
J. Combin. Theory Ser. A 88 no. 1, 123–135.
[42] Radoicic, R., T´oth, G. (2003) “Note on the chromatic number of the space”,
Disc. Comp. Geometry, 695–698, Algorithms Combin., 25 (2003), Springer,
Berlin.
[43] Recski, A. (1989) “Matroid Theory and Its Applications in Electric Network
Theory and in Statistics”, Springer-Verlag; Akad´emiai Kiad´o (Publishing
House of the Hungarian Academy of Sciences).
[44] Reingold, O. (2005) “Undirected ST-connectivity in log-space”, STOC’05:
Proceedings of the 37th Annual ACM Symposium on Theory of Computing,
376–385, ACM.
[45] Sagan, B. E. (1998) “Unimodality and the reﬂection principle”, Ars Combin.
48, 65–72.
[46] Simion, R., Ullman, D. (1991) “On the structure of the lattice of noncrossing
partitions”, Discrete Math. 98, no. 3, 193–206.
[47] Sipser, M. (2012) “Introduction to the Theory of Computation”, Course
Technology; third edition.
[48] Stanley, R. (1983) “Combinatorics and Commutative Algebra”, Progress in
Mathematics 41, Birkh¨auser.
[49] Stanley, R. (1973) “Acyclic orientations of graphs”, Discrete Math. 5, 171–
178.
[50] Stanley, R. (2015) “Catalan numbers”, Cambridge University Press, Cam-
bridge, UK.
[51] Stanley, R. (1997) “Enumerative Combinatorics”, vol. 1, Cambridge Univer-
sity Press, second edition.
[52] Stanley, R. (1999) “Enumerative Combinatorics”, vol. 2, Cambridge Univer-
sity Press.
[53] Suk, A. (2016) “On the Erd˝os-Szekeres convex polygon problem, preprint,
available at arXiv:1604.08657.
[54] Trotter, W. T. (1992) “Combinatorics and Partially Ordered Sets. Dimen-
sion Theory”, Johns Hopkins Series in the Mathematical Sciences. Johns
Hopkins University Press.
[55] Vella, A. (2003) “Pattern avoidance in permutations: linear and cyclic or-
ders”, Permutation patterns (Otago, 2003) Electron. J. Combin. 9 no. 2,
Research paper 18, 43 pp, electronic.
[56] Wallis, W. D. (2007) “Introduction to Combinatorial Designs”, Chapman
Hall - CRC Press, Boca Raton, FL.
[57] West, D. (2001) “Introduction to Graph Theory”, Prentice Hall, second
edition.

586
A Walk Through Combinatorics
[58] West, J. (1996) “Generating trees and forbidden subsequences”, Proceedings
of the 6th Conference on Formal Power Series and Algebraic Combinatorics
(New Brunswick, NJ, 1994). Discrete Math. 157, no. 1-3, 363–374.
[59] Wilf, H. (2005) “generatingfunctionology”, AK Peters, third edition.
[60] Wilf, H. (2002) “Algorithms and Complexity”, AK Peters, second edition.

Index
Acyclic, 254
Acyclic orientation of a graph, 291
Adjacency matrix, 244
Algorithm, 523
Anti-automorphism of a poset, 439
Antichain, 420
Appel, Kenneth, 314
Ascent, 194, 359
Atom, 448
Automorphism
of a design, 477
of a graph, 220
of a poset, 423
orientation preserving, 513
Automorphism group of a graph, 491
Average value, 395
Backtracking, 545
Bayes’ theorem, 390
general version, 393
Bell number, 105, 185
Betweenness problem, 400
BIBD, 456
linked, 461
symmetric, 457
BIGSUBSETSUM, 575
Bijection, 48
Binomial coeﬃcient, 50
generalized version, 82
Binomial theorem, 73
for real exponents, 82
Birthday paradox, 384
Block, 456
Block design, 456
Boolean algebra, 418
Boolean expression, 567
satisﬁable, 567
Boolean variable, 567
Breadth ﬁrst search, 542
Brooks’ theorem, 287
Bruck-Ryser-Chowla theorem, 463
BubbleSort, 526
Burnside’s lemma, 494
Catalan
Eug`ene, 176
Catalan number, 174, 201, 345, 416
Cayley’s formula, 237
Center
of a graph, 257
Centroid, 337
Certiﬁcate, 559
Chain, 419
length of, 425
maximal, 441
saturated, 441
Chain cover, 421
smallest, 421
Chromatic number, 270
of the plane, 333
of the space, 333
Chromatic polynomial, 292
587

588
A Walk Through Combinatorics
Clause, 568
CLIQUE, 576
co-NP, 561
Coatom, 448
Code, 468
(n, m, d)-, 470
binary, 468
error-correcting, 470
Hamming, 474
linear, 473
perfect, 472
preﬁx-free, 468
uniquely decodable, 468
Codeword, 468
Coloring
proper, 270
Comparability graph, 423
Complement
of a binary vector, 471
of a lattice element, 439
of an event, 383
Complexity class, 558
Composition, 101
weak, 101
Compositional formula
for exponential generating
functions, 187
for ordinary generating functions,
179
Conjunctive Normal Form, 568
coNL, 573
Connected components, 207
coNPSPACE, 573
Cook’s theorem, 568
Coset, 489
Covering matrix, 438
Crossing number, 314
Cycle
Hamiltonian, 210
in a graph, 210
Decision problem, 556
Deferred acceptance algorithm, 284
Degree
of a graph vertex, 206
Degree sequence
ordered, 221
Depth ﬁrst search, 542, 545
Derangement, 150, 151, 193
Descendent vertex, 546
Descent, 155, 359, 410
Design, 456
balanced incomplete, 456
complementary, 458
complete, 456
derived, 463
dual, 459
incomplete, 456
k-uniform, 456
r-regular, 456
regular, 456
residual, 463
uniform, 456
Diagonalization method, 525
Diameter
of a graph, 258
Dijkstra algorithm, 537
Dijkstra, Edsger W., 537
Dilworth’s theorem, 421
Dimension of a poset, 438
Direct product of posets, 430
Distance
in a graph, 257
Dodecahedron, 310
Dominance order, 442
DOMINATING-SET, 575
Doubly stochastic matrix, 292
Drmota, Michael, 253
Dual of a graph, 309
Durfee square, 114
Edge
left, 362
non-similar, 504
right, 362
similar, 504
Edge cover, 295
Edge-equivalence, 304
Erd˝os, Paul, 219, 330
Erd˝os-Szekeres theorem
in combinatorial geometry, 329
Euler’s theorem

Index
589
on closed trails, 207
on pentagonal numbers, 113
on planar graphs, 302
on polyhedra, 305
on primes, 94, 513
Euler’s totient function, 159
Euler, Leonhard, 205
Event, 382
independent, 388, 393
mutually exclusive, 383
Excedance, 155, 404
Expectation, 395
conditional, 401
linearity of, 397
Expected value, 395
Exponential formula, 185
permutation version, 192
Faces
of a planar graph, 302
Fano plane, 465
Fermat’s theorem, 94
Ferrers shape, 107
Ferrers, Norman Macleod, 107
Fibonacci number, 197, 203
Finite aﬃne plane, 466
Fisher’s inequality, 461
Fixed point, 136, 151, 399
Forest, 236
rooted, 239
rooted unlabeled non-plane, 515
Formula
closed, 27
explicit, 27
Four-Color Conjecture, 312
Gale-Shapley algorithm, 284
Generating function
composition of, 177
exponential, 181
ordinary, 164
Graph, 206
bipartite, 271
color critical, 293
complete, 214
complete k-partite, 285
complete bipartite, 224, 274
complete tripartite, 256
connected, 207
directed, 213
balanced, 213
strongly connected, 213
factor critical, 292
minimally connected, 233
Petersen, 220
planar, 302
quadratic residue, 326
regular, 220, 225
bipartite, 299
saturated non-factorizable, 288
simple, 206
Greedy algorithm, 241
Greene–Fomin–Kleitman theorem,
438
Group, 488
symmetric, 490
transitive, 225
Haken, Wolfgang, 314
Halting problem, 524
HAMCYC, 565
Hamming distance, 469
Hamming, Richard, 474
HAMPATH, 570
Hasse diagram, 419
Hetyei, G´abor Sr., 288
HITSET, 577
Hypercube
n-dimensional, 224
Icosahedron, 310
Ideal, 423
principal, 423
Immerman-Szelepcs´enyi theorem, 573
In-order reading of a tree, 358
Incidence algebra, 423
Incidence matrix
of a design, 459
of a graph, 247
Inclusion-Exclusion Principle, 149
Incomparable elements, 418
Independent set of edges, 278

590
A Walk Through Combinatorics
INDEPENDENT-SET, 575
Index of a subgroup, 490
Induction
strong, 30
weak, 23
Injection, 48
Interval order, 442
Inversion, 137
Involution, 136
Isomorphism
of graphs, 217
of posets, 419
Join, 431
Joyal, Andr´e, 237
K¨onig’s theorem, 294
K¨onig, D´enes, 294
K¨onigsberg bridges, 205
Kruskal’s algorithm, 243, 534
Kruskal, Joseph, 243
Kuratowski’s theorem, 304
L, 572
Laplacian matrix, 252
Latin square, 477
mutually orthogonal, 477
orthogonal, 477
reduced, 484
Lattice, 431
distributive, 439
modular, 439
Lattice path, 86
Leaf, 235
Left-to-right maximum, 131
Left-to-right minimum, 346
Linear extension, 422
Log-concave sequence, 86
Loop
in a graph, 206
Lov´asz, L´aszl´o, 288
Magic cube, 292
Magic square, 57, 292
Matching, 278
in a bipartite graph, 279
maximal, 281
maximum, 281
perfect, 278
stable, 283
Matrix-Tree theorem, 249
eigenvalue version, 252
Maximal element, 419
Maximum element, 419
Mean, 395
Meet, 431
Meet-semilattice, 433
MergeSort, 529
Minimal element, 419
Minimum element, 419
M¨obius function, 426
M¨obius Inversion Formula, 429
Monty Hall problem, 393
Motzkin number, 190
Multichain, 424
length of, 425
Multinomial coeﬃcient, 79
Multinomial theorem, 80
Multiset, 45
NL, 572
Noy, Marc, 219
NP, 559
NP-complete problem, 566
NP-hard, 575
NPSPACE, 573
Octahedrite, 316
Octahedron, 310
One-line notation, 125
Orbit, 493
Order polynomial, 441
Order preserving map, 441
Order-preserving bijection, 422
Otter, Richard, 503
P, 557
Parking function, 254
Partially ordered set, 417
Partition
graphical, 221
non-crossing, 365, 368

Index
591
of a set, 103
of an integer, 106
generating function for, 173
self-conjugate, 108
Pascal triangle, 75
PATH, 577
Path, 207
alternating, 281
augmenting, 282
Hamiltonian, 210
shortest, 537
Pentagonal number, 113
Permutation, 44
132-avoiding, 344
circular translate of, 367
complement of, 142, 346
cycle type of, 127
cycles of, 125
even, 137
ﬁxed point of, 136
in canonical cycle form, 125
indecomposable, 192
inverse of, 136
layered, 365
multiset, 45
odd, 137
pop-stack sortable, 363
q-avoiding, 345
reverse of, 345
sorted, 368
square root of, 136
stack sortable, 353
t-stack sortable, 356
two-stack sortable, 355
Permutation group, 491
primitive, 513
transitive, 513
Permutation matrix, 136, 292
Permutation patterns, 344
Philip Hall’s theorem, 280
Pigeon-hole Principle, 1
general version, 4
Pitman, Jim, 255
Pittel, Boris, 219
Polyhedron, 304
regular, 304
trivalent, 316
Poset, 417
2+2 and 3+1 avoiding, 442
2+2-avoiding, 442
locally ﬁnite, 423
self-dual, 439
Postorder reading of a tree, 358
Pratt’s theorem, 562
Precedence ordering, 442
Prim’s algorithm, 550
PRIMES, 561
Probability, 382
conditional, 388
Product formula
for exponential generating
functions, 183
for ordinary generating functions,
170
Projective plane
ﬁnite, 464
Pr¨ufer sequence, 254
Pr¨ufer, Heinz, 254
Pseudo-code, 528
PSPACE, 571
q-pattern, 345
Quicksort, 550
Radoicic, Rados, 333
Ramsey number, 324, 385
Ramsey theorem
for graphs, 323
for hypergraphs, 329
Ramsey theorem for graphs
general version, 328
Ramsey theory, 322
Ramsey, Frank Plumpton, 322
Random variable, 395
independent, 396
indicator, 399
REACHABILIT Y , 573
Recurrence relation, 27
Reﬁnement order
of non-crossing partitions, 433
of set partitions, 419
Reﬁning sequence, 255

592
A Walk Through Combinatorics
Reingold, Omer, 572
Right-to-left maximum, 348
Run, 409
Sample space, 382
SAT, 568
Schr¨oder number, 191
large, 191
SHORTESTPATH, 576
Sieve Formula, 149
Simpson’s paradox, 390
Skeleton
1-, of a polyhedron, 305
SPANNING-TREE, 575
Sperner’s Lemma, 317
Stabilizer, 492
Stack sorting of permutations, 353
Standard deviation, 405
Stanley, Richard, 154, 189
Stanley-Wilf conjecture, 350
Stirling number
of the ﬁrst kind, 127
signless, 127
of the second kind, 104
explicit formula, 153
Stirling’s formula, 44
String, 47
Subdesign, 479
SUBGRAPH, 576
Subgraph
induced, 207, 219
Subgroup, 489
Subset sum problem, 559
SUBSETSUM, 570
Suk, Andrew, 330
Superpattern, 367
Surjection, 48
Symmetric diﬀerence, 234
Symmetric group, 126
Symmetry edge, 504
Szekeres, George, 330
t-design, 477
TAUT, 575
Tautology, 575
Taylor series, 165
Three houses, three wells problem,
302
3SAT, 569
T´oth, G´eza, 333
Tournament, 214
transitive, 215
Trail, 207
closed, 207
Eulerian, 207
closed, 207
Transition Lemma, 130
Traveling Salesman problem, 571
Tree, 233
complete k-ary, 254
decreasing binary, 358
non-plane, 512
decreasing non-plane, 512
doubly rooted, 237
non-plane
1-2, 498
2-, 511
rooted, 501
plane
1-2-, 512
spanning, 239
minimum cost, 240, 534
minimum weight, 240
unlabeled, 503
unlabeled binary, 366
unlabeled plane, 368
Triangle inequality, 469
Tur´an’s theorem, 286
Tur´an, P´al, 285
Turing machine, 553
deterministic, 555
non-deterministic, 563
Turing, Alan, 553
Tutte’s theorem, 288
2SAT, 575
Typewriter paradox, 523
Unimodal sequence, 78
Unit interval order, 442
UST, 572
Valley, 398

Index
593
Vandermonde’s identity, 77
Variance, 405
Varieties, 456
Vatter, Vincent, 434
Vertex
cut, 256
non-similar, 504
of a design, 456
of a graph, 206
similar, 504
Vertex cover, 294, 576
VERTEX-COVER, 576
Walk, 207
Weight
of a codeword, 473
of a spanning tree, 240
Weisner’s theorem, 434
West, Douglas, 219
West, Julian, 378
Wheel, 293
Width of a poset, 422
Wilf, Herbert, 135, 163
Wilson’s theorem, 511
Witness, 559
Zeta function, 424
