# Distiller ğŸ“š

> A powerful RAG pipeline fine-tuned for textbook PDF processing and information retrieval

## Overview ğŸ¯

Distiller is an advanced Retrieval Augmented Generation (RAG) pipeline specifically designed for processing and querying textbook PDFs. It combines state-of-the-art language models with efficient information retrieval techniques to make textbook knowledge easily accessible.

### Pipeline Architecture
![RAG Pipeline](visualizations/pipeline.png)
*The Distiller RAG pipeline showing the complete flow from PDF input to interactive querying*

## Key Features âœ¨

- ğŸ“„ **Smart PDF Processing**: Extract clean text from complex textbook PDFs using PyMuPDF
- âœ‚ï¸ **Intelligent Chunking**: Break down content into semantically meaningful chunks
- ğŸ¤– **GPT-4 Summaries**: Generate concise, accurate summaries of textbook sections
- ğŸ§® **Vector Embeddings**: Create high-quality embeddings using OpenAI's latest models
- ğŸ” **Fast Retrieval**: Efficient similarity search powered by FAISS indexing
- ğŸ’¡ **Natural Queries**: Ask questions in plain language and get relevant answers
- ğŸ“ **Domain-Specific Fine-tuning**: Optimized for textbook content understanding

## System Architecture ğŸ—ï¸
![Architecture Diagram](visualizations/architecture.png)
*Detailed system architecture showing the interaction between different components*

## Model Training & Fine-tuning ğŸ“

### Fine-tuning Process

1. **Data Collection**
   - Gather textbook PDFs from various subjects
   - Extract text and structure using PyMuPDF
   - Create question-answer pairs from textbook content
   - Generate summaries for different sections

2. **Data Preparation**
   ```python
   # Example data format
   {
       "instruction": "Explain the concept of...",
       "input": "Textbook section content...",
       "output": "Detailed explanation..."
   }
   ```

3. **Fine-tuning Options**

   a. **OpenAI Fine-tuning**
   ```bash
   # Prepare training data
   python src/prepare_training.py
   
   # Fine-tune GPT-4
   python src/fine_tune.py
   ```

   b. **Custom Model Training**
   ```bash
   # Train custom embedding model
   python src/train_embeddings.py
   
   # Train custom summarization model
   python src/train_summarizer.py
   ```

4. **Model Evaluation**
   - Accuracy on textbook-specific questions
   - Quality of generated summaries
   - Embedding quality metrics
   - Retrieval performance

### Training Data Requirements
- Minimum 1000 high-quality Q&A pairs
- Diverse subject coverage
- Various difficulty levels
- Balanced representation of concepts

### Fine-tuning Parameters
```yaml
# Fine-tuning Configuration
training:
  model: "gpt-4"
  epochs: 3
  batch_size: 4
  learning_rate: 1e-5
  warmup_steps: 100
  max_steps: 1000
  save_steps: 100
  eval_steps: 50

data:
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_length: 2048
```

## Performance Metrics âš¡
![Benchmark Graph](visualizations/benchmark.png)
*Processing time benchmarks across different pipeline stages*

## Getting Started ğŸš€

### Prerequisites
- Python 3.9 or higher
- OpenAI API key
- GraphViz (for visualization)
- CUDA-capable GPU (for custom model training)

### Installation

1. **Using Conda**
```bash
conda create -n distiller python=3.9
conda activate distiller
pip install -r requirements.txt
```

2. **Using pip**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Environment Setup**
```bash
cp .env.example .env
# Edit .env and add your OpenAI API key
```

## Usage Guide ğŸ“–

1. **Extract Text**
```bash
python src/extract.py
```

2. **Create Chunks**
```bash
python src/chunk.py
```

3. **Generate Summaries**
```bash
python src/summarize.py
```

4. **Create Embeddings**
```bash
python src/embeddings.py
```

5. **Query Information**
```bash
python src/retriever.py
```

## Project Structure ğŸ“
```
distiller/
â”œâ”€â”€ config/         # Configuration files
â”œâ”€â”€ data/          # Input PDF files
â”‚   â”œâ”€â”€ raw/       # Original PDFs
â”‚   â””â”€â”€ training/  # Training data
â”œâ”€â”€ outputs/       # Generated outputs
â”œâ”€â”€ src/           # Source code
â”‚   â”œâ”€â”€ extract.py         # PDF text extraction
â”‚   â”œâ”€â”€ chunk.py           # Text chunking
â”‚   â”œâ”€â”€ summarize.py       # GPT-4 summarization
â”‚   â”œâ”€â”€ embeddings.py      # Vector embeddings
â”‚   â”œâ”€â”€ retriever.py       # Query interface
â”‚   â”œâ”€â”€ visualize.py       # Visualization tools
â”‚   â”œâ”€â”€ prepare_training.py # Training data preparation
â”‚   â”œâ”€â”€ fine_tune.py       # OpenAI fine-tuning
â”‚   â”œâ”€â”€ train_embeddings.py # Custom embedding training
â”‚   â””â”€â”€ train_summarizer.py # Custom summarizer training
â”œâ”€â”€ tests/         # Test files
â””â”€â”€ visualizations/# Generated diagrams
```

## Configuration âš™ï¸

Key settings in `config/config.yaml`:

```yaml
# Text Processing
chunk_size: 500
overlap: 50

# Models
summarization:
  model: "gpt-4"
  max_tokens: 1000

# Retrieval
faiss:
  metric: "cosine"
  k: 3

# Fine-tuning
training:
  model: "gpt-4"
  epochs: 3
  batch_size: 4
```

## License ğŸ“

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Roadmap ğŸ—ºï¸

- [ ] Support for multiple PDF formats and layouts
- [ ] Advanced chunking algorithms with ML-based segmentation
- [ ] Additional embedding model options
- [ ] Interactive web interface
- [ ] Batch processing for multiple documents
- [ ] Enhanced visualization and analytics
- [ ] Multi-language support
- [ ] Automated fine-tuning pipeline
- [ ] Custom model training interface
- [ ] Distributed training support
